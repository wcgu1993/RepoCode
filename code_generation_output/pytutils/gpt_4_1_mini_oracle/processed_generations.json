{"task_id": 154, "project": "test-apps/pytutils", "module": "pytutils.urls", "predictions": ["def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict of key -> list of values\n    existing_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the existing query parameters with the new ones\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            # If doseq is True and value is a list/tuple, replace with that sequence\n            existing_params[key] = list(value)\n        else:\n            # Otherwise, replace with a single-element list\n            existing_params[key] = [value]\n\n    # Build the new query string\n    new_query = urlencode(existing_params, doseq=True)\n\n    # Construct a new URL with the updated query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n\n    # Parse the existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters with the new ones\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    # Encode the query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the URL with the updated query\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n\n    return new_url", "try:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n\n    # Parse the existing query parameters into a list of key-value pairs\n    query_params = urlparse.parse_qsl(parsed_url.query, keep_blank_values=True)\n\n    # Convert the list of pairs into a dictionary that supports multiple values per key\n    # We'll create a dict of key -> list of values\n    query_dict = {}\n    for key, value in query_params:\n        query_dict.setdefault(key, []).append(value)\n\n    # Update or insert the new params, replacing existing keys entirely\n    for key, value in params.items():\n        # If doseq is True and value is iterable (but not a string), store all individual items\n        if doseq and isinstance(value, (list, tuple)):\n            query_dict[key] = list(value)\n        else:\n            # Otherwise, store as a single string value in a list\n            query_dict[key] = [value]\n\n    # Flatten the dict back into a list of key-value pairs for urlencode\n    updated_query_params = []\n    for key, values in query_dict.items():\n        for v in values:\n            updated_query_params.append( (key, v) )\n\n    # Encode the updated query parameters back to a query string\n    updated_query = urlencode(updated_query_params, doseq=True)\n\n    # Rebuild the URL with the updated query string\n    new_url = urlparse.urlunparse(\n        (\n            parsed_url.scheme,\n            parsed_url.netloc,\n            parsed_url.path,\n            parsed_url.params,\n            updated_query,\n            parsed_url.fragment,\n        )\n    )\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict (values as lists)\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n    # Update with the given params: for each key, set the value as list (if doseq) or single element list\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n    # Encode the updated query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n    # Rebuild the URL with the new query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters\n    :type params: dict\n    :param doseq: If True, individual key elements in sequence values are encoded separately.\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse.urlparse(url)\n    # Parse existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed.query, keep_blank_values=True)\n    # Update query params with new params\n    for key, value in params.items():\n        query_params[key] = value if (not doseq or not isinstance(value, (list, tuple))) else list(value)\n    # Encode query params back to query string\n    new_query = urlencode(query_params, doseq=doseq)\n    # Rebuild URL with the updated query string\n    updated = parsed._replace(query=new_query)\n    return urlparse.urlunparse(updated)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict of key -> list of values\n    existing_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the existing query parameters with the new ones\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            # If doseq is True and value is a list/tuple, replace with that sequence\n            existing_params[key] = list(value)\n        else:\n            # Otherwise, replace with a single-element list\n            existing_params[key] = [value]\n\n    # Build the new query string\n    new_query = urlencode(existing_params, doseq=True)\n\n    # Construct a new URL with the updated query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n\n    # Parse the existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters with the new ones\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    # Encode the query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the URL with the updated query\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n\n    # Parse the existing query parameters into a list of key-value pairs\n    query_params = urlparse.parse_qsl(parsed_url.query, keep_blank_values=True)\n\n    # Convert the list of pairs into a dictionary that supports multiple values per key\n    # We'll create a dict of key -> list of values\n    query_dict = {}\n    for key, value in query_params:\n        query_dict.setdefault(key, []).append(value)\n\n    # Update or insert the new params, replacing existing keys entirely\n    for key, value in params.items():\n        # If doseq is True and value is iterable (but not a string), store all individual items\n        if doseq and isinstance(value, (list, tuple)):\n            query_dict[key] = list(value)\n        else:\n            # Otherwise, store as a single string value in a list\n            query_dict[key] = [value]\n\n    # Flatten the dict back into a list of key-value pairs for urlencode\n    updated_query_params = []\n    for key, values in query_dict.items():\n        for v in values:\n            updated_query_params.append( (key, v) )\n\n    # Encode the updated query parameters back to a query string\n    updated_query = urlencode(updated_query_params, doseq=True)\n\n    # Rebuild the URL with the updated query string\n    new_url = urlparse.urlunparse(\n        (\n            parsed_url.scheme,\n            parsed_url.netloc,\n            parsed_url.path,\n            parsed_url.params,\n            updated_query,\n            parsed_url.fragment,\n        )\n    )\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict (values as lists)\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n    # Update with the given params: for each key, set the value as list (if doseq) or single element list\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n    # Encode the updated query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n    # Rebuild the URL with the new query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters\n    :type params: dict\n    :param doseq: If True, individual key elements in sequence values are encoded separately.\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse.urlparse(url)\n    # Parse existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed.query, keep_blank_values=True)\n    # Update query params with new params\n    for key, value in params.items():\n        query_params[key] = value if (not doseq or not isinstance(value, (list, tuple))) else list(value)\n    # Encode query params back to query string\n    new_query = urlencode(query_params, doseq=doseq)\n    # Rebuild URL with the updated query string\n    updated = parsed._replace(query=new_query)\n    return urlparse.urlunparse(updated)\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n"]}
{"task_id": 155, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    return s.encode(encoding, errors)", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a bytes-like object; return as is\n        return s\n    elif isinstance(s, str):\n        # s is a str; encode it to bytes\n        return s.encode(encoding, errors)\n    else:\n        # Not str or allowed byteslike; raise TypeError\n        raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected {allowed_types} or str, got {type(s)}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # If s is already byteslike, just return as-is.\n        return s\n    if isinstance(s, str):\n        # Encode string to bytes using provided encoding and error handling.\n        return s.encode(encoding, errors)\n    # If s is neither string nor allowed byteslike, raise TypeError.\n    raise TypeError(f\"Expected str or byteslike object, got {type(s).__name__}\")"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    return s.encode(encoding, errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a bytes-like object; return as is\n        return s\n    elif isinstance(s, str):\n        # s is a str; encode it to bytes\n        return s.encode(encoding, errors)\n    else:\n        # Not str or allowed byteslike; raise TypeError\n        raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected {allowed_types} or str, got {type(s)}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # If s is already byteslike, just return as-is.\n        return s\n    if isinstance(s, str):\n        # Encode string to bytes using provided encoding and error handling.\n        return s.encode(encoding, errors)\n    # If s is neither string nor allowed byteslike, raise TypeError.\n    raise TypeError(f\"Expected str or byteslike object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n"]}
{"task_id": 156, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # s is bytes-like, decode it to a string using the given encoding and error handling.\n        # But note the docstring says \"Decoded string as bytes\" and \"Encoded string\" which is contradictory.\n        # However, from the name and docstring \"Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\"\n        # The input can be str or bytes-like, and output should be unicode string (six.text_type).\n        # But the return annotation says bytes | bytesarray | memoryview and return type is bytes, which is inconsistent.\n        # The input is str or bytes-like. Output should be str (unicode).\n        #\n        # Because of contradictions in the docstring return type, we assume the output should be unicode string (six.text_type),\n        # and \"decoded\" means converting bytes to str.\n        #\n        # So if s is bytes-like, decode it; else return as is.\n\n        # Actually, allowed_types defaults to (six.text_type,), so if s is not a unicode string,\n        # it must be bytes-like and so decode it.\n        return s.decode(encoding=encoding, errors=errors)", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return str: Decoded string\n\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        if isinstance(s, (bytes, bytearray, memoryview)):\n            return s.decode(encoding=encoding, errors=errors)\n        else:\n            return six.text_type(s)", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # s is bytes-like -> decode to text type (unicode string)\n        # but the docstring and return type is confusing:\n        # It says \"Ensure string is decoded (eg unicode)\", but return type says bytes.\n        # The docstring return is contradictory: \n        # \":return bytes|bytesarray|memoryview: Decoded string as bytes\"\n        # and \":return: Encoded string\", \":rtype: bytes\"\n        #\n        # Given the name ensure_decoded_text and param description, and\n        # in analogy with ensure_encoded_bytes, the most reasonable implementation:\n        # if s is not text_type, decode it to text_type and return.\n        #\n        # But return type specified is bytes, which contradicts, so assuming the docstring\n        # return typing and description is incorrect or copy-pasted error.\n        #\n        # Therefore, by logic, I will decode bytes to text (six.text_type) to ensure \"decoded\"\n        # and return that.\n\n        # However, since allowed_types default is (six.text_type,), we only return s if it is text.\n        # Otherwise decode bytes to six.text_type\n\n        # So final return type should be six.text_type (unicode string).\n\n        decoded = s.decode(encoding=encoding, errors=errors)\n        return decoded", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # If s is bytes or bytes-like, decode to text using encoding/errors.\n        return s.decode(encoding=encoding, errors=errors)", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.decode(encoding=encoding, errors=errors)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # s is bytes-like, decode it to a string using the given encoding and error handling.\n        # But note the docstring says \"Decoded string as bytes\" and \"Encoded string\" which is contradictory.\n        # However, from the name and docstring \"Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\"\n        # The input can be str or bytes-like, and output should be unicode string (six.text_type).\n        # But the return annotation says bytes | bytesarray | memoryview and return type is bytes, which is inconsistent.\n        # The input is str or bytes-like. Output should be str (unicode).\n        #\n        # Because of contradictions in the docstring return type, we assume the output should be unicode string (six.text_type),\n        # and \"decoded\" means converting bytes to str.\n        #\n        # So if s is bytes-like, decode it; else return as is.\n\n        # Actually, allowed_types defaults to (six.text_type,), so if s is not a unicode string,\n        # it must be bytes-like and so decode it.\n        return s.decode(encoding=encoding, errors=errors)\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return str: Decoded string\n\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        if isinstance(s, (bytes, bytearray, memoryview)):\n            return s.decode(encoding=encoding, errors=errors)\n        else:\n            return six.text_type(s)\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # s is bytes-like -> decode to text type (unicode string)\n        # but the docstring and return type is confusing:\n        # It says \"Ensure string is decoded (eg unicode)\", but return type says bytes.\n        # The docstring return is contradictory: \n        # \":return bytes|bytesarray|memoryview: Decoded string as bytes\"\n        # and \":return: Encoded string\", \":rtype: bytes\"\n        #\n        # Given the name ensure_decoded_text and param description, and\n        # in analogy with ensure_encoded_bytes, the most reasonable implementation:\n        # if s is not text_type, decode it to text_type and return.\n        #\n        # But return type specified is bytes, which contradicts, so assuming the docstring\n        # return typing and description is incorrect or copy-pasted error.\n        #\n        # Therefore, by logic, I will decode bytes to text (six.text_type) to ensure \"decoded\"\n        # and return that.\n\n        # However, since allowed_types default is (six.text_type,), we only return s if it is text.\n        # Otherwise decode bytes to six.text_type\n\n        # So final return type should be six.text_type (unicode string).\n\n        decoded = s.decode(encoding=encoding, errors=errors)\n        return decoded\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        # If s is bytes or bytes-like, decode to text using encoding/errors.\n        return s.decode(encoding=encoding, errors=errors)\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.decode(encoding=encoding, errors=errors)\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n"]}
{"task_id": 157, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["from six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create 'count' new queues using the factory\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fanout():\n        while True:\n            item = q.get()\n            # Propagate the item to all output queues\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n\n    # Run the fanout loop in a background thread to forward items as they arrive\n    t = Thread(target=fanout, daemon=True)\n    t.start()\n\n    return tuple(out_queues)", "from six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create a list of output queues using the factory function\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            if item is None:\n                # Propagate the sentinel to all output queues and stop\n                for out_q in out_queues:\n                    out_q.put(None)\n                break\n            for out_q in out_queues:\n                out_q.put(item)\n            q.task_done()\n\n    # Start the worker thread that distributes items\n    thread = Thread(target=worker, daemon=True)\n    thread.start()\n\n    return out_queues", "from six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    t = Thread(target=worker)\n    t.daemon = True\n    t.start()\n\n    return output_queues", "from six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues using the queue_factory\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            # Put the item into all output queues\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    # Start a single daemon thread that reads from q and distributes items\n    t = Thread(target=worker, daemon=True)\n    t.start()\n\n    return output_queues", "from six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def distributor():\n        while True:\n            item = q.get()\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n\n    # Start distributor thread as a daemon so it exits with the main program\n    t = Thread(target=distributor, daemon=True)\n    t.start()\n\n    return out_queues"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create 'count' new queues using the factory\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fanout():\n        while True:\n            item = q.get()\n            # Propagate the item to all output queues\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n\n    # Run the fanout loop in a background thread to forward items as they arrive\n    t = Thread(target=fanout, daemon=True)\n    t.start()\n\n    return tuple(out_queues)\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create a list of output queues using the factory function\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            if item is None:\n                # Propagate the sentinel to all output queues and stop\n                for out_q in out_queues:\n                    out_q.put(None)\n                break\n            for out_q in out_queues:\n                out_q.put(item)\n            q.task_done()\n\n    # Start the worker thread that distributes items\n    thread = Thread(target=worker, daemon=True)\n    thread.start()\n\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    t = Thread(target=worker)\n    t.daemon = True\n    t.start()\n\n    return output_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues using the queue_factory\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            # Put the item into all output queues\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    # Start a single daemon thread that reads from q and distributes items\n    t = Thread(target=worker, daemon=True)\n    t.start()\n\n    return output_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def distributor():\n        while True:\n            item = q.get()\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n\n    # Start distributor thread as a daemon so it exits with the main program\n    t = Thread(target=distributor, daemon=True)\n    t.start()\n\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()"]}
{"task_id": 158, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('out_q', Queue())\n\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push  # as given in context functions\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get(\"out_q\", Queue())\n\n    # For each input queue, start a daemon thread that pushes items into out_q\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.pop(\"queue_factory\", Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('out_q', Queue())\n\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push  # as given in context functions\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get(\"out_q\", Queue())\n\n    # For each input queue, start a daemon thread that pushes items into out_q\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.pop(\"queue_factory\", Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n"]}
{"task_id": 159, "project": "test-apps/pytutils", "module": "pytutils.env", "predictions": ["import typing\nimport collections\nimport os\nimport re\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))\n    [('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO', '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')]\n\n    \"\"\"\n    if lines is None:\n        return\n    # Pattern matches lines like KEY=VALUE or KEY='VALUE' or KEY=\"VALUE\"\n    # Ignores lines starting with # (comments) or empty lines\n    pattern = re.compile(\n        r\"\"\"\n        ^\\s*                            # leading whitespace\n        ([A-Za-z_][A-Za-z0-9_]*)       # key\n        \\s*=\\s*                        # equal sign around optional whitespace\n        (?:                            # non-capturing group for value\n          '([^']*)'                    # single quoted value (capture inside quotes)\n          |                            # OR\n          \"((?:[^\"\\\\]|\\\\.)*)\"          # double quoted value (capture inside quotes, allow escapes)\n          |                            # OR\n          ([^\\#\\n\\r]*)                 # unquoted value up to comment or line end\n        )\n        (?:\\s*\\#.*)?                   # optional comment after value\n        $\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n        m = pattern.match(line)\n        if not m:\n            continue  # ignore lines not matching pattern\n        key = m.group(1)\n\n        if m.group(2) is not None:  # single quoted\n            value = m.group(2)\n        elif m.group(3) is not None:  # double quoted with escapes\n            # Handle backslash escapes inside double quotes\n            value = bytes(m.group(3), \"utf-8\").decode(\"unicode_escape\")\n        else:\n            # unquoted value, stripped of trailing whitespace\n            value = m.group(4).strip() if m.group(4) else \"\"\n\n        # Expand environment variables and user (~)\n        value = expand(value)\n        yield key, value", "import typing\nimport collections\nimport os\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regex to match lines like KEY=VALUE, ignoring lines starting with '#' or empty lines\n    # KEY: any non-whitespace, non-'=' characters; VALUE: anything after '='\n    line_re = re.compile(r'^\\s*([\\w\\.]+)\\s*=\\s*(.*)?\\s*$')\n\n    for line in lines:\n        # Strip comment and whitespace\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = line_re.match(line)\n        if not m:\n            continue\n\n        key, val = m.groups()\n        if val is None:\n            val = ''\n        val = val.strip()\n\n        # Remove surrounding quotes if any (single or double), support escaping is minimal (only strip quotes)\n        if (val.startswith((\"'\", '\"')) and val.endswith((\"'\", '\"')) and len(val) > 1):\n            val = val[1:-1]\n\n        # Expand any environment variables and user home\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n\n        yield key, val", "import typing\nimport collections\nimport os\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))\n    [('TEST', os.path.expandvars(os.path.expanduser('${HOME}/yeee'))),\n     ('THISIS', os.path.expandvars(os.path.expanduser('~/a/test'))),\n     ('YOLO', os.path.expandvars(os.path.expanduser('~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')))]\n    \"\"\"\n    # Regular expression pattern to parse lines like KEY=VALUE, allowing optional quotes around VALUE\n    # Supports: KEY=VALUE, KEY=\"VALUE\", KEY='VALUE'\n    pattern = re.compile(\n        r\"\"\"\n        ^\\s*                             # Leading whitespace\n        (?P<key>[A-Za-z_][A-Za-z0-9_]*) # Key: letters, digits, underscores, no digits first char\n        \\s*=\\s*                         # '=' surrounded by optional whitespace\n        (?:                             # Start non-capturing group for value \n          (?P<quote>['\\\"])              # Optional quote capturing group\n          (?P<value_quoted>(?:\\\\.|[^\\\\\"'])*?) # Quoted value allowing escaped chars\n          (?P=quote)                   # Closing quote matching opening\n          |                             # OR\n          (?P<value_unquoted>[^#\\n]*)   # Unquoted value, stopping before '#' (comment) or newline\n        )\n        (?:\\s*#.*)?$                    # Optional trailing comment starting with #\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    if lines is None:\n        return  # Nothing to yield\n\n    for line in lines:\n        # Strip trailing newline and whitespace\n        line = line.strip()\n        # Skip empty lines and comments\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = pattern.match(line)\n        if not m:\n            # Line does not match expected env file syntax, skip\n            continue\n\n        key = m.group(\"key\")\n        if m.group(\"value_quoted\") is not None:\n            # Unescape any escaped chars inside quoted values, then expand\n            raw_value = m.group(\"value_quoted\")\n            # Unescape sequences: \\\\, \\n, \\t, \\r, \\\", \\'\n            # Use bytes decode trick to handle standard escapes\n            try:\n                unescaped_value = bytes(raw_value, \"utf-8\").decode(\"unicode_escape\")\n            except Exception:\n                unescaped_value = raw_value  # fallback if decode fails\n            val = unescaped_value\n        else:\n            val = m.group(\"value_unquoted\").rstrip()\n\n        # Expand environment variables and user (~)\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n\n        yield key, val", "import typing\nimport collections\nimport os\nimport re\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))  # doctest: +SKIP\n    [('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')]\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regular expression to parse lines like KEY=VALUE (supports quoted values)\n    line_re = re.compile(\n        r\"\"\"^\\s*\n        ([A-Za-z_][A-Za-z0-9_]*)  # key\n        \\s*=\\s*\n        (?:\n          (?:'((?:[^']|\\\\')*)')  # single quoted value\n          |\n          (?:\"((?:[^\"]|\\\\\")*)\")  # double quoted value\n          |\n          ([^\\n#]+)              # unquoted value\n        )?\n        \\s*(?:#.*)?$\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for lineno, line in enumerate(lines, 1):\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = line_re.match(line)\n        if not m:\n            # Doesn't match key=value pattern, skip line silently (honcho behavior)\n            continue\n\n        key = m.group(1)\n        val = (\n            m.group(2)\n            or m.group(3)\n            or m.group(4)\n            or \"\"\n        )\n\n        # Unescape quotes inside quoted value\n        if m.group(2):  # single quoted\n            val = val.replace(\"\\\\'\", \"'\")\n        elif m.group(3):  # double quoted\n            val = val.replace('\\\\\"', '\"').replace(\"\\\\n\", \"\\n\").replace(\"\\\\r\", \"\\r\").replace(\"\\\\t\", \"\\t\")\n\n        # Expand environment variables and user home directory\n        val = expand(val)\n\n        yield key, val", "import typing\nimport collections\nimport re\nimport os\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    # Pattern to parse lines with optional export keyword, variable name,\n    # equals sign, then variable value (possibly quoted)\n    env_line_re = re.compile(\n        r\"\"\"\n        ^\\s*(?:export\\s+)?       # optional export keyword\n        ([A-Za-z_][A-Za-z0-9_]*) # variable name\n        \\s*=\\s*                  # equals sign with optional spaces\n        (                       # start of value capture group\n            (?:'[^']*'           # single-quoted value\n            |\"[^\"]*\"             # double-quoted value\n            |[^\\s#]+             # unquoted value (non-space, non-# chars)\n            )?\n        )                       # end of value capture group\n        (?:\\s*#.*)?             # optional trailing comment\n        $                       # end of line\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    # Helper to unquote and expand\n    def unquote_and_expand(val: str) -> str:\n        val = val.strip()\n        if not val:\n            return val\n        # Remove quotes if present (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n        # Expand environment variables and ~ user home\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n        return val\n\n    if lines is None:\n        return\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            # Ignore empty lines and full-line comments\n            continue\n        m = env_line_re.match(line)\n        if not m:\n            # If line doesn't match expected pattern, skip\n            continue\n        key, val = m.group(1), m.group(2)\n        val = val or \"\"\n        val_expanded = unquote_and_expand(val)\n        yield key, val_expanded"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport collections\nimport os\nimport re\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))\n    [('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO', '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')]\n\n    \"\"\"\n    if lines is None:\n        return\n    # Pattern matches lines like KEY=VALUE or KEY='VALUE' or KEY=\"VALUE\"\n    # Ignores lines starting with # (comments) or empty lines\n    pattern = re.compile(\n        r\"\"\"\n        ^\\s*                            # leading whitespace\n        ([A-Za-z_][A-Za-z0-9_]*)       # key\n        \\s*=\\s*                        # equal sign around optional whitespace\n        (?:                            # non-capturing group for value\n          '([^']*)'                    # single quoted value (capture inside quotes)\n          |                            # OR\n          \"((?:[^\"\\\\]|\\\\.)*)\"          # double quoted value (capture inside quotes, allow escapes)\n          |                            # OR\n          ([^\\#\\n\\r]*)                 # unquoted value up to comment or line end\n        )\n        (?:\\s*\\#.*)?                   # optional comment after value\n        $\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n        m = pattern.match(line)\n        if not m:\n            continue  # ignore lines not matching pattern\n        key = m.group(1)\n\n        if m.group(2) is not None:  # single quoted\n            value = m.group(2)\n        elif m.group(3) is not None:  # double quoted with escapes\n            # Handle backslash escapes inside double quotes\n            value = bytes(m.group(3), \"utf-8\").decode(\"unicode_escape\")\n        else:\n            # unquoted value, stripped of trailing whitespace\n            value = m.group(4).strip() if m.group(4) else \"\"\n\n        # Expand environment variables and user (~)\n        value = expand(value)\n        yield key, value\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport collections\nimport os\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regex to match lines like KEY=VALUE, ignoring lines starting with '#' or empty lines\n    # KEY: any non-whitespace, non-'=' characters; VALUE: anything after '='\n    line_re = re.compile(r'^\\s*([\\w\\.]+)\\s*=\\s*(.*)?\\s*$')\n\n    for line in lines:\n        # Strip comment and whitespace\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = line_re.match(line)\n        if not m:\n            continue\n\n        key, val = m.groups()\n        if val is None:\n            val = ''\n        val = val.strip()\n\n        # Remove surrounding quotes if any (single or double), support escaping is minimal (only strip quotes)\n        if (val.startswith((\"'\", '\"')) and val.endswith((\"'\", '\"')) and len(val) > 1):\n            val = val[1:-1]\n\n        # Expand any environment variables and user home\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport collections\nimport os\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))\n    [('TEST', os.path.expandvars(os.path.expanduser('${HOME}/yeee'))),\n     ('THISIS', os.path.expandvars(os.path.expanduser('~/a/test'))),\n     ('YOLO', os.path.expandvars(os.path.expanduser('~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')))]\n    \"\"\"\n    # Regular expression pattern to parse lines like KEY=VALUE, allowing optional quotes around VALUE\n    # Supports: KEY=VALUE, KEY=\"VALUE\", KEY='VALUE'\n    pattern = re.compile(\n        r\"\"\"\n        ^\\s*                             # Leading whitespace\n        (?P<key>[A-Za-z_][A-Za-z0-9_]*) # Key: letters, digits, underscores, no digits first char\n        \\s*=\\s*                         # '=' surrounded by optional whitespace\n        (?:                             # Start non-capturing group for value \n          (?P<quote>['\\\"])              # Optional quote capturing group\n          (?P<value_quoted>(?:\\\\.|[^\\\\\"'])*?) # Quoted value allowing escaped chars\n          (?P=quote)                   # Closing quote matching opening\n          |                             # OR\n          (?P<value_unquoted>[^#\\n]*)   # Unquoted value, stopping before '#' (comment) or newline\n        )\n        (?:\\s*#.*)?$                    # Optional trailing comment starting with #\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    if lines is None:\n        return  # Nothing to yield\n\n    for line in lines:\n        # Strip trailing newline and whitespace\n        line = line.strip()\n        # Skip empty lines and comments\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = pattern.match(line)\n        if not m:\n            # Line does not match expected env file syntax, skip\n            continue\n\n        key = m.group(\"key\")\n        if m.group(\"value_quoted\") is not None:\n            # Unescape any escaped chars inside quoted values, then expand\n            raw_value = m.group(\"value_quoted\")\n            # Unescape sequences: \\\\, \\n, \\t, \\r, \\\", \\'\n            # Use bytes decode trick to handle standard escapes\n            try:\n                unescaped_value = bytes(raw_value, \"utf-8\").decode(\"unicode_escape\")\n            except Exception:\n                unescaped_value = raw_value  # fallback if decode fails\n            val = unescaped_value\n        else:\n            val = m.group(\"value_unquoted\").rstrip()\n\n        # Expand environment variables and user (~)\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport collections\nimport os\nimport re\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> list(parse_env_file_contents(lines))  # doctest: +SKIP\n    [('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')]\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regular expression to parse lines like KEY=VALUE (supports quoted values)\n    line_re = re.compile(\n        r\"\"\"^\\s*\n        ([A-Za-z_][A-Za-z0-9_]*)  # key\n        \\s*=\\s*\n        (?:\n          (?:'((?:[^']|\\\\')*)')  # single quoted value\n          |\n          (?:\"((?:[^\"]|\\\\\")*)\")  # double quoted value\n          |\n          ([^\\n#]+)              # unquoted value\n        )?\n        \\s*(?:#.*)?$\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for lineno, line in enumerate(lines, 1):\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = line_re.match(line)\n        if not m:\n            # Doesn't match key=value pattern, skip line silently (honcho behavior)\n            continue\n\n        key = m.group(1)\n        val = (\n            m.group(2)\n            or m.group(3)\n            or m.group(4)\n            or \"\"\n        )\n\n        # Unescape quotes inside quoted value\n        if m.group(2):  # single quoted\n            val = val.replace(\"\\\\'\", \"'\")\n        elif m.group(3):  # double quoted\n            val = val.replace('\\\\\"', '\"').replace(\"\\\\n\", \"\\n\").replace(\"\\\\r\", \"\\r\").replace(\"\\\\t\", \"\\t\")\n\n        # Expand environment variables and user home directory\n        val = expand(val)\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport collections\nimport re\nimport os\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    # Pattern to parse lines with optional export keyword, variable name,\n    # equals sign, then variable value (possibly quoted)\n    env_line_re = re.compile(\n        r\"\"\"\n        ^\\s*(?:export\\s+)?       # optional export keyword\n        ([A-Za-z_][A-Za-z0-9_]*) # variable name\n        \\s*=\\s*                  # equals sign with optional spaces\n        (                       # start of value capture group\n            (?:'[^']*'           # single-quoted value\n            |\"[^\"]*\"             # double-quoted value\n            |[^\\s#]+             # unquoted value (non-space, non-# chars)\n            )?\n        )                       # end of value capture group\n        (?:\\s*#.*)?             # optional trailing comment\n        $                       # end of line\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    # Helper to unquote and expand\n    def unquote_and_expand(val: str) -> str:\n        val = val.strip()\n        if not val:\n            return val\n        # Remove quotes if present (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n        # Expand environment variables and ~ user home\n        val = os.path.expandvars(val)\n        val = os.path.expanduser(val)\n        return val\n\n    if lines is None:\n        return\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            # Ignore empty lines and full-line comments\n            continue\n        m = env_line_re.match(line)\n        if not m:\n            # If line doesn't match expected pattern, skip\n            continue\n        key, val = m.group(1), m.group(2)\n        val = val or \"\"\n        val_expanded = unquote_and_expand(val)\n        yield key, val_expanded\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()"]}
{"task_id": 160, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["import six\nimport warnings\nimport pygments\nimport pygments.styles\nimport pygments.formatters\nimport pygments.lexers\n\ntry:\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\nexcept Exception:\n    __PP_STYLE = None\n    __PP_FORMATTER = None\n    __PP_LEXER_PYTHON = None\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    if not pygments:\n        # If pygments is not available, fall back to simple repr\n        return repr(arg)\n\n    try:\n        # Use pprint.pformat to get a nicely formatted string representation\n        import pprint\n        formatted = pprint.pformat(arg)\n        # Highlight the formatted string using pygments lexer and formatter\n        return pygments.highlight(formatted, lexer, formatter)\n    except Exception:\n        # In case of any error (e.g. lexer or formatter issues), fall back to repr\n        return repr(arg)", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pygments\n    import pygments.formatters\n    import pygments.lexers\n\n    # Use pprint.pformat to get a pretty-printed string from the argument\n    formatted_str = _pprint.pformat(arg)\n\n    # If pygments is not available, just return the plain formatted string\n    if not pygments:\n        return formatted_str\n\n    # Use pygments to highlight the string with given lexer and formatter\n    return pygments.highlight(formatted_str, lexer, formatter)", "import six\nimport warnings\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # First, get the pretty-printed string of the argument using pprint\n    pretty_str = _pprint.pformat(arg)\n\n    # If pygments is available, try to highlight the pretty-printed string\n    if pygments:\n        try:\n            # Highlight the string with the given lexer and formatter, result is bytes in Python 3\n            colored_bytes = pygments.highlight(pretty_str, lexer, formatter)\n            # In Python 3, decode bytes to str; in Python 2, highlight returns str already\n            if six.PY3:\n                return colored_bytes.decode('utf-8')\n            else:\n                return colored_bytes\n        except Exception:  # broad exception to fallback gracefully if something goes wrong\n            warnings.warn('Pygments highlight failed, falling back to plain pretty format.')\n            return pretty_str\n    else:\n        # If pygments is not imported/available, just return the pretty string\n        return pretty_str", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pprint\n\n    # Use pprint.pformat to get the pretty-formatted string of the argument\n    formatted_str = pprint.pformat(arg)\n\n    # If pygments is available, use it to highlight the formatted string\n    if pygments:\n        # Highlight using the given lexer and formatter\n        colored_str = pygments.highlight(formatted_str, lexer, formatter)\n        return colored_str\n    else:\n        # If pygments is not available, just return the plain pretty-formatted string\n        return formatted_str", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n    if pygments:\n        try:\n            return pygments.highlight(formatted, lexer, formatter)\n        except Exception:\n            # In case of any failure in pygments highlighting, fallback gracefully.\n            return formatted\n    else:\n        return formatted"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\nimport pygments\nimport pygments.styles\nimport pygments.formatters\nimport pygments.lexers\n\ntry:\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\nexcept Exception:\n    __PP_STYLE = None\n    __PP_FORMATTER = None\n    __PP_LEXER_PYTHON = None\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    if not pygments:\n        # If pygments is not available, fall back to simple repr\n        return repr(arg)\n\n    try:\n        # Use pprint.pformat to get a nicely formatted string representation\n        import pprint\n        formatted = pprint.pformat(arg)\n        # Highlight the formatted string using pygments lexer and formatter\n        return pygments.highlight(formatted, lexer, formatter)\n    except Exception:\n        # In case of any error (e.g. lexer or formatter issues), fall back to repr\n        return repr(arg)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pygments\n    import pygments.formatters\n    import pygments.lexers\n\n    # Use pprint.pformat to get a pretty-printed string from the argument\n    formatted_str = _pprint.pformat(arg)\n\n    # If pygments is not available, just return the plain formatted string\n    if not pygments:\n        return formatted_str\n\n    # Use pygments to highlight the string with given lexer and formatter\n    return pygments.highlight(formatted_str, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # First, get the pretty-printed string of the argument using pprint\n    pretty_str = _pprint.pformat(arg)\n\n    # If pygments is available, try to highlight the pretty-printed string\n    if pygments:\n        try:\n            # Highlight the string with the given lexer and formatter, result is bytes in Python 3\n            colored_bytes = pygments.highlight(pretty_str, lexer, formatter)\n            # In Python 3, decode bytes to str; in Python 2, highlight returns str already\n            if six.PY3:\n                return colored_bytes.decode('utf-8')\n            else:\n                return colored_bytes\n        except Exception:  # broad exception to fallback gracefully if something goes wrong\n            warnings.warn('Pygments highlight failed, falling back to plain pretty format.')\n            return pretty_str\n    else:\n        # If pygments is not imported/available, just return the pretty string\n        return pretty_str\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pprint\n\n    # Use pprint.pformat to get the pretty-formatted string of the argument\n    formatted_str = pprint.pformat(arg)\n\n    # If pygments is available, use it to highlight the formatted string\n    if pygments:\n        # Highlight using the given lexer and formatter\n        colored_str = pygments.highlight(formatted_str, lexer, formatter)\n        return colored_str\n    else:\n        # If pygments is not available, just return the plain pretty-formatted string\n        return formatted_str\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n    if pygments:\n        try:\n            return pygments.highlight(formatted, lexer, formatter)\n        except Exception:\n            # In case of any failure in pygments highlighting, fallback gracefully.\n            return formatted\n    else:\n        return formatted\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n"]}
{"task_id": 161, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["import sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n    __PP_STYLE = None\n    __PP_FORMATTER = None\n    __PP_LEXER_PYTHON = None\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = pf(arg, lexer=lexer, formatter=formatter)\n    outfile.write(s)", "import sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if pygments:\n        colored = pygments.highlight(formatted, lexer, formatter)\n        # pygments.highlight returns a str (unicode) that can be directly written to outfile\n        outfile.write(colored)\n    else:\n        outfile.write(formatted)\n    outfile.flush()", "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # pygments.highlight returns a str, which we can write to the output stream directly\n    outfile.write(colored)", "import sys\nimport pprint as _pprint\n\ntry:\n    import pygments\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # colored is a str when pygments is available\n    try:\n        outfile.write(colored)\n    except TypeError:\n        # In some environments outfile may expect bytes\n        outfile.buffer.write(colored.encode('utf-8'))", "import sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        # If pygments is not available, simply print the formatted string\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # Write the colored output directly to the outfile\n    outfile.write(colored)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n    __PP_STYLE = None\n    __PP_FORMATTER = None\n    __PP_LEXER_PYTHON = None\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = pf(arg, lexer=lexer, formatter=formatter)\n    outfile.write(s)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if pygments:\n        colored = pygments.highlight(formatted, lexer, formatter)\n        # pygments.highlight returns a str (unicode) that can be directly written to outfile\n        outfile.write(colored)\n    else:\n        outfile.write(formatted)\n    outfile.flush()\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # pygments.highlight returns a str, which we can write to the output stream directly\n    outfile.write(colored)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ntry:\n    import pygments\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # colored is a str when pygments is available\n    try:\n        outfile.write(colored)\n    except TypeError:\n        # In some environments outfile may expect bytes\n        outfile.buffer.write(colored.encode('utf-8'))\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        # If pygments is not available, simply print the formatted string\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    # Write the colored output directly to the outfile\n    outfile.write(colored)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n"]}
{"task_id": 162, "project": "test-apps/pytutils", "module": "pytutils.trees", "predictions": ["import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n"]}
{"task_id": 163, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["import operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\nfrom typing import Iterable, Callable, TypeVar, Generator\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    iterator = iter(iterable)\n    try:\n        total = next(iterator)\n    except StopIteration:\n        return  # empty iterable, yield nothing\n\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total", "import operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\nS = TypeVar('S')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[S, T], S] = operator.add) -> Generator[S, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    iterator = iter(iterable)\n    try:\n        total = next(iterator)\n    except StopIteration:\n        return\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total", "import operator\nfrom collections.abc import Iterable\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nfrom typing import Iterable, Callable, TypeVar, Generator\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    iterator = iter(iterable)\n    try:\n        total = next(iterator)\n    except StopIteration:\n        return  # empty iterable, yield nothing\n\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\nS = TypeVar('S')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[S, T], S] = operator.add) -> Generator[S, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    iterator = iter(iterable)\n    try:\n        total = next(iterator)\n    except StopIteration:\n        return\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nfrom collections.abc import Iterable\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nfrom typing import Iterable, Callable, Generator, TypeVar\n\nT = TypeVar('T')\n\ndef accumulate(iterable: Iterable[T], func: Callable[[T, T], T] = operator.add) -> Generator[T, None, None]:\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()"]}
{"task_id": 164, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["from pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()"]}
