{"task_id": 154, "project": "test-apps/pytutils", "module": "pytutils.urls", "predictions": ["from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters\n    :type params: dict\n    :param doseq: Whether to encode sequences as separate parameters\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the input URL into components\n    parsed_url = urlparse(url)\n    # Parse existing query parameters into a dict with list values\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters with new params\n    for key, value in params.items():\n        query_params[key] = value if (doseq or not isinstance(value, (list, tuple))) else [value]\n\n    # Encode the updated query parameters\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Rebuild the URL with the updated query string\n    updated_url = urlunparse(parsed_url._replace(query=new_query))\n\n    return updated_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parts = urlparse.urlparse(url)\n\n    # Parse existing query parameters into a dict\n    query_dict = dict(urlparse.parse_qsl(parts.query, keep_blank_values=True))\n\n    # Update the query dict with new params\n    for key, value in params.items():\n        query_dict[key] = value\n\n    # Encode the updated query parameters\n    new_query = urlencode(query_dict, doseq=doseq)\n\n    # Reconstruct the URL with the updated query string\n    new_parts = parts._replace(query=new_query)\n    return urlparse.urlunparse(new_parts)", "try:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict (list values)\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update query parameters with the given params\n    for key, value in params.items():\n        # If doseq is True, value can be a sequence, otherwise treat as str\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = [str(v) for v in value]\n        else:\n            query_params[key] = [str(value)]\n\n    # Encode the updated query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the full URL with updated query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters to update or add\n    :type params: dict\n    :param doseq: Whether to treat values in params as sequences\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the original URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n    # Update query parameters with the provided params\n    for key, value in params.items():\n        # If doseq is True and value is a list/tuple, replace with all values\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(map(str, value))\n        else:\n            # Otherwise, replace with single value as list\n            query_params[key] = [str(value)]\n    # Encode the updated query parameters into a query string\n    new_query = urlencode(query_params, doseq=True)\n    # Rebuild the URL with the new query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url", "try:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict preserving duplicates if any\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update with new params (overwrite existing keys)\n    for k, v in params.items():\n        query_params[k] = [v] if not (doseq and isinstance(v, (list, tuple))) else v\n\n    # Encode the new query string\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Reconstruct the URL with the updated query string\n    new_url = urlparse.urlunparse(\n        (parsed_url.scheme, parsed_url.netloc, parsed_url.path,\n         parsed_url.params, new_query, parsed_url.fragment)\n    )\n\n    return new_url"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\nfrom urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters\n    :type params: dict\n    :param doseq: Whether to encode sequences as separate parameters\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the input URL into components\n    parsed_url = urlparse(url)\n    # Parse existing query parameters into a dict with list values\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters with new params\n    for key, value in params.items():\n        query_params[key] = value if (doseq or not isinstance(value, (list, tuple))) else [value]\n\n    # Encode the updated query parameters\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Rebuild the URL with the updated query string\n    updated_url = urlunparse(parsed_url._replace(query=new_query))\n\n    return updated_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parts = urlparse.urlparse(url)\n\n    # Parse existing query parameters into a dict\n    query_dict = dict(urlparse.parse_qsl(parts.query, keep_blank_values=True))\n\n    # Update the query dict with new params\n    for key, value in params.items():\n        query_dict[key] = value\n\n    # Encode the updated query parameters\n    new_query = urlencode(query_dict, doseq=doseq)\n\n    # Reconstruct the URL with the updated query string\n    new_parts = parts._replace(query=new_query)\n    return urlparse.urlunparse(new_parts)\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict (list values)\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update query parameters with the given params\n    for key, value in params.items():\n        # If doseq is True, value can be a sequence, otherwise treat as str\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = [str(v) for v in value]\n        else:\n            query_params[key] = [str(value)]\n\n    # Encode the updated query parameters back to a query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the full URL with updated query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?foo=stuff&biz=baz'\n\n    :param url: URL\n    :type url: str\n    :param params: Query parameters to update or add\n    :type params: dict\n    :param doseq: Whether to treat values in params as sequences\n    :type doseq: bool\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the original URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse existing query parameters into a dict of lists\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n    # Update query parameters with the provided params\n    for key, value in params.items():\n        # If doseq is True and value is a list/tuple, replace with all values\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(map(str, value))\n        else:\n            # Otherwise, replace with single value as list\n            query_params[key] = [str(value)]\n    # Encode the updated query parameters into a query string\n    new_query = urlencode(query_params, doseq=True)\n    # Rebuild the URL with the new query string\n    new_url = urlparse.urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    # Parse the URL into components\n    parsed_url = urlparse.urlparse(url)\n    # Parse the existing query parameters into a dict preserving duplicates if any\n    query_params = urlparse.parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update with new params (overwrite existing keys)\n    for k, v in params.items():\n        query_params[k] = [v] if not (doseq and isinstance(v, (list, tuple))) else v\n\n    # Encode the new query string\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Reconstruct the URL with the updated query string\n    new_url = urlparse.urlunparse(\n        (parsed_url.scheme, parsed_url.netloc, parsed_url.path,\n         parsed_url.params, new_query, parsed_url.fragment)\n    )\n\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n"]}
{"task_id": 155, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["import six\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding=encoding, errors=errors)\n    # If s is neither a text type nor allowed byteslike type, try to convert it to string then encode.\n    return str(s).encode(encoding=encoding, errors=errors)", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    # If s is already one of the allowed bytes-like types, return as is\n    if isinstance(s, allowed_types):\n        return s\n\n    # If s is text (str), encode it using the specified encoding and errors handling\n    if isinstance(s, str):\n        return s.encode(encoding=encoding, errors=errors)\n\n    # For any other type, raise TypeError to signal unsupported input type\n    raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\nimport six\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding=encoding, errors=errors)\n    # If s is neither a text type nor allowed byteslike type, try to convert it to string then encode.\n    return str(s).encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    # If s is already one of the allowed bytes-like types, return as is\n    if isinstance(s, allowed_types):\n        return s\n\n    # If s is text (str), encode it using the specified encoding and errors handling\n    if isinstance(s, str):\n        return s.encode(encoding=encoding, errors=errors)\n\n    # For any other type, raise TypeError to signal unsupported input type\n    raise TypeError(f\"Expected string or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n"]}
{"task_id": 156, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a text (unicode) string, encode it to bytes and return\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is already bytes-like, return as is\n        return s", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s", "import six\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    # If input is already decoded text (unicode in Py2/str in Py3), encode it to bytes\n    if isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    # Else, if it is bytes-like (bytes, bytearray, memoryview), return as-is\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return s\n    else:\n        # For any other type, try to convert to str then encode\n        return str(s).encode(encoding=encoding, errors=errors)", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # Already decoded text (unicode), encode it to bytes\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is bytes-like, ensure it is bytes (if bytearray etc)\n        # For memoryview, convert to bytes\n        if isinstance(s, memoryview):\n            return s.tobytes()  # Convert memoryview to bytes\n        elif isinstance(s, (bytes, bytearray)):\n            return bytes(s)\n        else:\n            raise TypeError(f\"Expected types {allowed_types + (bytes, bytearray, memoryview)}, got {type(s)}\")", "import six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a decoded text (str/unicode) so encode it into bytes\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is bytes-like, ensure it's bytes or bytes-like\n        # if it's memoryview, convert to bytes; if bytes or bytearray, return as is\n        if isinstance(s, memoryview):\n            return s.tobytes()\n        return s"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a text (unicode) string, encode it to bytes and return\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is already bytes-like, return as is\n        return s\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    # If input is already decoded text (unicode in Py2/str in Py3), encode it to bytes\n    if isinstance(s, allowed_types):\n        return s.encode(encoding=encoding, errors=errors)\n    # Else, if it is bytes-like (bytes, bytearray, memoryview), return as-is\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return s\n    else:\n        # For any other type, try to convert to str then encode\n        return str(s).encode(encoding=encoding, errors=errors)\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # Already decoded text (unicode), encode it to bytes\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is bytes-like, ensure it is bytes (if bytearray etc)\n        # For memoryview, convert to bytes\n        if isinstance(s, memoryview):\n            return s.tobytes()  # Convert memoryview to bytes\n        elif isinstance(s, (bytes, bytearray)):\n            return bytes(s)\n        else:\n            raise TypeError(f\"Expected types {allowed_types + (bytes, bytearray, memoryview)}, got {type(s)}\")\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\nimport six\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if isinstance(s, allowed_types):\n        # s is already a decoded text (str/unicode) so encode it into bytes\n        return s.encode(encoding=encoding, errors=errors)\n    else:\n        # s is bytes-like, ensure it's bytes or bytes-like\n        # if it's memoryview, convert to bytes; if bytes or bytearray, return as is\n        if isinstance(s, memoryview):\n            return s.tobytes()\n        return s\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n"]}
{"task_id": 157, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["from six.moves.queue import Queue\nfrom threading import Thread\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=worker)\n    t.daemon = True\n    t.start()\n\n    return out_queues if count > 1 else out_queues[0]", "from six.moves.queue import Queue\nfrom threading import Thread\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fanout():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=fanout)\n    t.daemon = True\n    t.start()\n\n    return out_queues", "from six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    def push(in_q, out_q):\n        while True:\n            x = in_q.get()\n            out_q.put(x)\n\n    out_queues = [queue_factory() for _ in range(count)]\n    threads = []\n    for out_q in out_queues:\n        t = Thread(target=push, args=(q, out_q))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n    return tuple(out_queues)", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fan_out():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=fan_out)\n    t.daemon = True\n    t.start()\n\n    return out_queues", "from six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    def push(in_q, out_q):\n        while True:\n            x = in_q.get()\n            out_q.put(x)\n\n    out_queues = [queue_factory() for _ in range(count)]\n    for out_q in out_queues:\n        t = Thread(target=push, args=(q, out_q))\n        t.daemon = True\n        t.start()\n    return out_queues"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    # Create output queues\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=worker)\n    t.daemon = True\n    t.start()\n\n    return out_queues if count > 1 else out_queues[0]\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fanout():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=fanout)\n    t.daemon = True\n    t.start()\n\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    def push(in_q, out_q):\n        while True:\n            x = in_q.get()\n            out_q.put(x)\n\n    out_queues = [queue_factory() for _ in range(count)]\n    threads = []\n    for out_q in out_queues:\n        t = Thread(target=push, args=(q, out_q))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n    return tuple(out_queues)\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def fan_out():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n\n    t = Thread(target=fan_out)\n    t.daemon = True\n    t.start()\n\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    def push(in_q, out_q):\n        while True:\n            x = in_q.get()\n            out_q.put(x)\n\n    out_queues = [queue_factory() for _ in range(count)]\n    for out_q in out_queues:\n        t = Thread(target=push, args=(q, out_q))\n        t.daemon = True\n        t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()"]}
{"task_id": 158, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('queue_factory', Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push  # as described in context functions\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q", "from six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('queue_factory', Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('queue_factory', Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push  # as described in context functions\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\nfrom pytutils.queues import push\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = kwargs.get('queue_factory', Queue)()\n    for in_q in in_qs:\n        t = Thread(target=push, args=(in_q, out_q))\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n"]}
{"task_id": 159, "project": "test-apps/pytutils", "module": "pytutils.env", "predictions": ["import typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regex to parse lines like KEY=VALUE, skipping comments/empty lines\n    env_var_re = re.compile(\n        r'^\\s*'                 # Optional leading whitespace\n        r'([A-Za-z_][A-Za-z0-9_]*)'  # Key: variable name (similar to shell var rules)\n        r'\\s*=\\s*'              # Equals sign surrounded by optional whitespace\n        r'(.*)$'                # Value as the rest of the line (can be empty)\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            # Ignore empty lines and comments\n            continue\n\n        match = env_var_re.match(line)\n        if not match:\n            # Line doesn't comply, skip it\n            continue\n        \n        key, value = match.group(1), match.group(2)\n\n        # Remove optional surrounding quotes from value (single or double)\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            value = value[1:-1]\n\n        # Yield the (key, value) pair as is, no expansion here (expansion happens in load_env_file)\n        yield key, value", "import typing\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n\n    if lines is None:\n        return\n    # Pattern to parse lines like: KEY=VALUE, where VALUE can be quoted or unquoted\n    env_var_re = re.compile(\n        r\"\"\"\n        ^\\s*\n        ([\\w\\.]+)                    # key: word chars or dots\n        \\s*=\\s*\n        (?:                         # non-capturing group for value\n          '([^']*)'                 # single-quoted value (no escapes handled)\n          |                         # or\n          \"((?:[^\"\\\\]|\\\\.)*)\"       # double-quoted value, allowing escaped chars\n          |                         # or\n          ([^\\#\\n\\r]+?)             # unquoted value (stop at # or end)\n        )\n        \\s*(?:\\#.*)?$               # optional comment after value\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = env_var_re.match(line)\n        if not m:\n            # line doesn't match expected pattern, ignore it\n            continue\n\n        key = m.group(1)\n\n        if m.group(2) is not None:\n            # single quoted\n            val = m.group(2)\n        elif m.group(3) is not None:\n            # double quoted - need to handle escapes\n            val = m.group(3)\n            # unescape \\n, \\r, \\t, \\\\, \\\", \\', \\$\n            escaped_val = \"\"\n            i = 0\n            while i < len(val):\n                c = val[i]\n                if c == \"\\\\\" and i+1 < len(val):\n                    next_c = val[i+1]\n                    if next_c == \"n\":\n                        escaped_val += \"\\n\"\n                    elif next_c == \"r\":\n                        escaped_val += \"\\r\"\n                    elif next_c == \"t\":\n                        escaped_val += \"\\t\"\n                    elif next_c == \"\\\\\":\n                        escaped_val += \"\\\\\"\n                    elif next_c == \"\\\"\":\n                        escaped_val += \"\\\"\"\n                    elif next_c == \"$\":\n                        escaped_val += \"$\"\n                    else:\n                        # unknown escape, keep as-is (e.g. \\x)\n                        escaped_val += next_c\n                    i += 2\n                else:\n                    escaped_val += c\n                    i += 1\n            val = escaped_val\n        else:\n            # unquoted value - strip trailing spaces\n            val = m.group(4)\n            if val is not None:\n                val = val.strip()\n            else:\n                val = \"\"\n\n        yield key, val", "import typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n    env_var_pattern = re.compile(\n        r'^\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*='  # key (variable name) = \n        r'(.*)$'                              # value (anything after equals)\n    )\n    for line in lines:\n        line = line.strip()\n        if not line:\n            continue\n        if line.startswith('#'):\n            continue\n\n        m = env_var_pattern.match(line)\n        if not m:\n            continue\n        key = m.group(1)\n        val = m.group(2).strip()\n\n        # Remove surrounding quotes if present (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        yield key, val", "import typing\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    # Pattern to parse lines like: KEY=VALUE or export KEY=VALUE, allowing spaces around equal sign\n    # We capture KEY and VALUE; comments and empty lines are ignored.\n    env_pattern = re.compile(\n        r'''\n        ^\\s*                           # Leading whitespace\n        (?:export\\s+)?                 # Optional export keyword\n        (?P<key>[A-Za-z_][A-Za-z0-9_]*) # Key: starts with letter/_ followed by alphanum/_\n        \\s*=\\s*                       # Equal sign with optional spaces\n        (?P<value>.*)                 # Value: rest of the line (including empty)\n        $                             # End of line\n        ''',\n        re.VERBOSE\n    )\n\n    if lines is None:\n        return\n        yield  # make this a generator even if empty\n\n    for lineno, line in enumerate(lines, 1):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue  # Skip empty lines and comments\n\n        m = env_pattern.match(line)\n        if not m:\n            continue  # Skip lines that do not match KEY=VALUE pattern\n\n        key = m.group('key')\n        val = m.group('value')\n\n        # Remove surrounding quotes if any (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        yield key, val", "import typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n    pattern = re.compile(\n        r'''^\\s*              # Optional leading whitespace\n            (?:export\\s+)?    # Optional 'export ' prefix\n            ([\\w\\.]+)         # Key: word characters or dot\n            \\s*=\\s*           # Equal sign with optional spaces around\n            (.*?)             # Value: non-greedy, anything\n            \\s*$              # Optional trailing whitespace till end of line\n        ''',\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        # Remove any leading/trailing whitespace\n        line = line.strip()\n        # Ignore empty lines or comments\n        if not line or line.startswith('#'):\n            continue\n\n        match = pattern.match(line)\n        if not match:\n            continue\n        key, value = match.groups()\n\n        # Handle quotes around the value\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            # Remove the surrounding quotes\n            value = value[1:-1]\n\n            # For double quotes, interpret escape sequences (like \\n, \\t, \\\", \\$, etc)\n            if value and value != '' and line.strip().startswith('export'):\n                # To better handle escape sequences only for double quotes and not for single quotes\n                # But as per usual behavior, only double quotes allow escape sequences\n                # We'll only replace escaped \\$ and \\\" properly.\n\n                # In .env files, usually only \\$, \\\" and \\\\ are escaped inside double quotes\n                # We can use python's decode string escape by encoding to latin1 and decoding unicode_escape\n                try:\n                    value = bytes(value, \"utf-8\").decode(\"unicode_escape\")\n                except Exception:\n                    # Fallback if decoding fails, just keep raw string\n                    pass\n\n        yield key, value"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n\n    # Regex to parse lines like KEY=VALUE, skipping comments/empty lines\n    env_var_re = re.compile(\n        r'^\\s*'                 # Optional leading whitespace\n        r'([A-Za-z_][A-Za-z0-9_]*)'  # Key: variable name (similar to shell var rules)\n        r'\\s*=\\s*'              # Equals sign surrounded by optional whitespace\n        r'(.*)$'                # Value as the rest of the line (can be empty)\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            # Ignore empty lines and comments\n            continue\n\n        match = env_var_re.match(line)\n        if not match:\n            # Line doesn't comply, skip it\n            continue\n        \n        key, value = match.group(1), match.group(2)\n\n        # Remove optional surrounding quotes from value (single or double)\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            value = value[1:-1]\n\n        # Yield the (key, value) pair as is, no expansion here (expansion happens in load_env_file)\n        yield key, value\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n\n    if lines is None:\n        return\n    # Pattern to parse lines like: KEY=VALUE, where VALUE can be quoted or unquoted\n    env_var_re = re.compile(\n        r\"\"\"\n        ^\\s*\n        ([\\w\\.]+)                    # key: word chars or dots\n        \\s*=\\s*\n        (?:                         # non-capturing group for value\n          '([^']*)'                 # single-quoted value (no escapes handled)\n          |                         # or\n          \"((?:[^\"\\\\]|\\\\.)*)\"       # double-quoted value, allowing escaped chars\n          |                         # or\n          ([^\\#\\n\\r]+?)             # unquoted value (stop at # or end)\n        )\n        \\s*(?:\\#.*)?$               # optional comment after value\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n\n        m = env_var_re.match(line)\n        if not m:\n            # line doesn't match expected pattern, ignore it\n            continue\n\n        key = m.group(1)\n\n        if m.group(2) is not None:\n            # single quoted\n            val = m.group(2)\n        elif m.group(3) is not None:\n            # double quoted - need to handle escapes\n            val = m.group(3)\n            # unescape \\n, \\r, \\t, \\\\, \\\", \\', \\$\n            escaped_val = \"\"\n            i = 0\n            while i < len(val):\n                c = val[i]\n                if c == \"\\\\\" and i+1 < len(val):\n                    next_c = val[i+1]\n                    if next_c == \"n\":\n                        escaped_val += \"\\n\"\n                    elif next_c == \"r\":\n                        escaped_val += \"\\r\"\n                    elif next_c == \"t\":\n                        escaped_val += \"\\t\"\n                    elif next_c == \"\\\\\":\n                        escaped_val += \"\\\\\"\n                    elif next_c == \"\\\"\":\n                        escaped_val += \"\\\"\"\n                    elif next_c == \"$\":\n                        escaped_val += \"$\"\n                    else:\n                        # unknown escape, keep as-is (e.g. \\x)\n                        escaped_val += next_c\n                    i += 2\n                else:\n                    escaped_val += c\n                    i += 1\n            val = escaped_val\n        else:\n            # unquoted value - strip trailing spaces\n            val = m.group(4)\n            if val is not None:\n                val = val.strip()\n            else:\n                val = \"\"\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n    env_var_pattern = re.compile(\n        r'^\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*='  # key (variable name) = \n        r'(.*)$'                              # value (anything after equals)\n    )\n    for line in lines:\n        line = line.strip()\n        if not line:\n            continue\n        if line.startswith('#'):\n            continue\n\n        m = env_var_pattern.match(line)\n        if not m:\n            continue\n        key = m.group(1)\n        val = m.group(2).strip()\n\n        # Remove surrounding quotes if present (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport re\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    # Pattern to parse lines like: KEY=VALUE or export KEY=VALUE, allowing spaces around equal sign\n    # We capture KEY and VALUE; comments and empty lines are ignored.\n    env_pattern = re.compile(\n        r'''\n        ^\\s*                           # Leading whitespace\n        (?:export\\s+)?                 # Optional export keyword\n        (?P<key>[A-Za-z_][A-Za-z0-9_]*) # Key: starts with letter/_ followed by alphanum/_\n        \\s*=\\s*                       # Equal sign with optional spaces\n        (?P<value>.*)                 # Value: rest of the line (including empty)\n        $                             # End of line\n        ''',\n        re.VERBOSE\n    )\n\n    if lines is None:\n        return\n        yield  # make this a generator even if empty\n\n    for lineno, line in enumerate(lines, 1):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue  # Skip empty lines and comments\n\n        m = env_pattern.match(line)\n        if not m:\n            continue  # Skip lines that do not match KEY=VALUE pattern\n\n        key = m.group('key')\n        val = m.group('value')\n\n        # Remove surrounding quotes if any (single or double)\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\nimport typing\nimport re\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    if lines is None:\n        return\n    pattern = re.compile(\n        r'''^\\s*              # Optional leading whitespace\n            (?:export\\s+)?    # Optional 'export ' prefix\n            ([\\w\\.]+)         # Key: word characters or dot\n            \\s*=\\s*           # Equal sign with optional spaces around\n            (.*?)             # Value: non-greedy, anything\n            \\s*$              # Optional trailing whitespace till end of line\n        ''',\n        re.VERBOSE,\n    )\n\n    for line in lines:\n        # Remove any leading/trailing whitespace\n        line = line.strip()\n        # Ignore empty lines or comments\n        if not line or line.startswith('#'):\n            continue\n\n        match = pattern.match(line)\n        if not match:\n            continue\n        key, value = match.groups()\n\n        # Handle quotes around the value\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            # Remove the surrounding quotes\n            value = value[1:-1]\n\n            # For double quotes, interpret escape sequences (like \\n, \\t, \\\", \\$, etc)\n            if value and value != '' and line.strip().startswith('export'):\n                # To better handle escape sequences only for double quotes and not for single quotes\n                # But as per usual behavior, only double quotes allow escape sequences\n                # We'll only replace escaped \\$ and \\\" properly.\n\n                # In .env files, usually only \\$, \\\" and \\\\ are escaped inside double quotes\n                # We can use python's decode string escape by encoding to latin1 and decoding unicode_escape\n                try:\n                    value = bytes(value, \"utf-8\").decode(\"unicode_escape\")\n                except Exception:\n                    # Fallback if decoding fails, just keep raw string\n                    pass\n\n        yield key, value\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()"]}
{"task_id": 160, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["import six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pprint\n\n    # Convert arg to formatted string using pprint\n    formatted = pprint.pformat(arg)\n\n    # If pygments is available, highlight the formatted string\n    if pygments:\n        try:\n            # pygments.highlight returns bytes when using console16m formatter,\n            # so decode to str if necessary (Python3)\n            highlighted = pygments.highlight(formatted, lexer, formatter)\n            if isinstance(highlighted, bytes):\n                highlighted = highlighted.decode(sys.stdout.encoding or 'utf-8', 'replace')\n            return highlighted\n        except Exception:\n            # fallback: just return the formatted string without highlighting\n            return formatted\n    else:\n        return formatted", "from pygments import highlight\nfrom pygments.token import Token\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # Use pprint.pformat to get a nicely formatted string representation of arg\n    formatted_str = _pprint.pformat(arg)\n\n    # Use pygments to highlight the formatted string with the given lexer and formatter\n    colored_str = highlight(formatted_str, lexer, formatter)\n\n    return colored_str", "import six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    if not pygments:\n        # If pygments is not available, fallback to simple repr\n        return repr(arg)\n\n    # Import pprint here to avoid circular dependency if any, and for pretty formatting\n    import pprint\n\n    # First, pretty format the object to a string with pprint.pformat\n    formatted = pprint.pformat(arg)\n\n    # Now colorize the formatted string using pygments with the given lexer and formatter\n    colored = pygments.highlight(formatted, lexer, formatter)\n\n    return colored", "import six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # If pygments is not available, fallback to repr\n    if not pygments:\n        return repr(arg)\n\n    # Import pprint inside function to avoid circular import or dependency if needed\n    import pprint\n\n    # Get the pretty-printed string representation of arg, with indentation for nested structures\n    pretty_str = pprint.pformat(arg)\n\n    # Highlight the pretty printed string using pygments with given lexer and formatter\n    try:\n        colored_str = pygments.highlight(pretty_str, lexer, formatter)\n    except Exception:\n        # On any exception fallback to plain repr string\n        colored_str = pretty_str\n\n    return colored_str", "import six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # If pygments is not available, fallback to pprint without coloring\n    if not pygments:\n        import pprint\n        return pprint.pformat(arg)\n\n    # Import pprint for fallback formatting with indentation and line wraps\n    import pprint\n\n    # Use pprint.pformat to generate a nice string representation first\n    pretty_str = pprint.pformat(arg)\n\n    try:\n        # Use pygments to apply syntax highlighting on the pretty-printed string\n        colored = pygments.highlight(pretty_str, lexer, formatter)\n    except Exception:\n        # If something goes wrong, fallback to plain pretty string\n        return pretty_str\n\n    # colored is bytes when using formatters for terminal, decode if needed\n    if isinstance(colored, bytes):\n        try:\n            colored = colored.decode('utf-8')\n        except Exception:\n            # Fallback to fallback string in case decode fails\n            return pretty_str\n\n    return colored"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pprint\n\n    # Convert arg to formatted string using pprint\n    formatted = pprint.pformat(arg)\n\n    # If pygments is available, highlight the formatted string\n    if pygments:\n        try:\n            # pygments.highlight returns bytes when using console16m formatter,\n            # so decode to str if necessary (Python3)\n            highlighted = pygments.highlight(formatted, lexer, formatter)\n            if isinstance(highlighted, bytes):\n                highlighted = highlighted.decode(sys.stdout.encoding or 'utf-8', 'replace')\n            return highlighted\n        except Exception:\n            # fallback: just return the formatted string without highlighting\n            return formatted\n    else:\n        return formatted\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nfrom pygments import highlight\nfrom pygments.token import Token\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # Use pprint.pformat to get a nicely formatted string representation of arg\n    formatted_str = _pprint.pformat(arg)\n\n    # Use pygments to highlight the formatted string with the given lexer and formatter\n    colored_str = highlight(formatted_str, lexer, formatter)\n\n    return colored_str\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    if not pygments:\n        # If pygments is not available, fallback to simple repr\n        return repr(arg)\n\n    # Import pprint here to avoid circular dependency if any, and for pretty formatting\n    import pprint\n\n    # First, pretty format the object to a string with pprint.pformat\n    formatted = pprint.pformat(arg)\n\n    # Now colorize the formatted string using pygments with the given lexer and formatter\n    colored = pygments.highlight(formatted, lexer, formatter)\n\n    return colored\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # If pygments is not available, fallback to repr\n    if not pygments:\n        return repr(arg)\n\n    # Import pprint inside function to avoid circular import or dependency if needed\n    import pprint\n\n    # Get the pretty-printed string representation of arg, with indentation for nested structures\n    pretty_str = pprint.pformat(arg)\n\n    # Highlight the pretty printed string using pygments with given lexer and formatter\n    try:\n        colored_str = pygments.highlight(pretty_str, lexer, formatter)\n    except Exception:\n        # On any exception fallback to plain repr string\n        colored_str = pretty_str\n\n    return colored_str\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\nimport six\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # If pygments is not available, fallback to pprint without coloring\n    if not pygments:\n        import pprint\n        return pprint.pformat(arg)\n\n    # Import pprint for fallback formatting with indentation and line wraps\n    import pprint\n\n    # Use pprint.pformat to generate a nice string representation first\n    pretty_str = pprint.pformat(arg)\n\n    try:\n        # Use pygments to apply syntax highlighting on the pretty-printed string\n        colored = pygments.highlight(pretty_str, lexer, formatter)\n    except Exception:\n        # If something goes wrong, fallback to plain pretty string\n        return pretty_str\n\n    # colored is bytes when using formatters for terminal, decode if needed\n    if isinstance(colored, bytes):\n        try:\n            colored = colored.decode('utf-8')\n        except Exception:\n            # Fallback to fallback string in case decode fails\n            return pretty_str\n\n    return colored\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n"]}
{"task_id": 161, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["import sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    try:\n        outfile.write(colored)\n    except Exception:\n        # In case writing bytes vs string issues occur, fallback to printing plain formatted\n        print(formatted, file=outfile)", "import sys\nimport pprint as _pprint\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # Pretty format with color highlighting\n    formatted = pf(arg, lexer, formatter)\n\n    try:\n        # Write to the provided outfile\n        outfile.write(formatted)\n        # Make sure output is flushed immediately\n        outfile.flush()\n    except Exception:\n        # In case outfile doesn't have write or flush,\n        # fallback to printing normally without color\n        print(_pprint.pformat(arg))", "import sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = _pprint.pformat(arg)\n\n    if not pygments:\n        print(s, file=outfile)\n        return\n\n    colored_text = pygments.highlight(s, lexer, formatter)\n    outfile.write(colored_text)", "import sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = _pprint.pformat(arg)\n\n    if not pygments:\n        print(s, file=outfile)\n        return\n\n    colored = pygments.highlight(s, lexer, formatter)\n    outfile.write(colored)", "import sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n    else:\n        colored = pygments.highlight(formatted, lexer, formatter)\n        # pygments.highlight returns a str that may contain terminal escape sequences\n        # just write it directly to outfile\n        outfile.write(colored)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n        return\n\n    colored = pygments.highlight(formatted, lexer, formatter)\n    try:\n        outfile.write(colored)\n    except Exception:\n        # In case writing bytes vs string issues occur, fallback to printing plain formatted\n        print(formatted, file=outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\nimport warnings\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    # Pretty format with color highlighting\n    formatted = pf(arg, lexer, formatter)\n\n    try:\n        # Write to the provided outfile\n        outfile.write(formatted)\n        # Make sure output is flushed immediately\n        outfile.flush()\n    except Exception:\n        # In case outfile doesn't have write or flush,\n        # fallback to printing normally without color\n        print(_pprint.pformat(arg))\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python3' if sys.version_info[0] >= 3 else 'python')\n\nexcept ImportError:\n    pygments = False\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = _pprint.pformat(arg)\n\n    if not pygments:\n        print(s, file=outfile)\n        return\n\n    colored_text = pygments.highlight(s, lexer, formatter)\n    outfile.write(colored_text)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    s = _pprint.pformat(arg)\n\n    if not pygments:\n        print(s, file=outfile)\n        return\n\n    colored = pygments.highlight(s, lexer, formatter)\n    outfile.write(colored)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\nimport sys\nimport pprint as _pprint\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    formatted = _pprint.pformat(arg)\n\n    if not pygments:\n        print(formatted, file=outfile)\n    else:\n        colored = pygments.highlight(formatted, lexer, formatter)\n        # pygments.highlight returns a str that may contain terminal escape sequences\n        # just write it directly to outfile\n        outfile.write(colored)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n"]}
{"task_id": 162, "project": "test-apps/pytutils", "module": "pytutils.trees", "predictions": ["import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "import collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\nimport collections\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n"]}
{"task_id": 163, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["import operator\nimport collections\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n        yield  # this is to make function a generator if no elements in iterable\n\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\nimport collections\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "import operator\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        # Empty iterable\n        return\n        yield  # This makes it a generator even when no elements\n\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nimport collections\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n        yield  # this is to make function a generator if no elements in iterable\n\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\nimport collections\nimport itertools\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\nimport operator\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        # Empty iterable\n        return\n        yield  # This makes it a generator even when no elements\n\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()"]}
{"task_id": 164, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)", "from pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)", "from pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    # Deduplicate the resulting iterable using dedupe_iter\n    return dedupe_iter(result)", "from pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    # Call the wrapped function with provided args and kwargs to get its output iterable\n    result_iterable = f(*args, **kwargs)\n    # Use the dedupe_iter context function to deduplicate the iterable output\n    return dedupe_iter(result_iterable)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    return dedupe_iter(result)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    # Deduplicate the resulting iterable using dedupe_iter\n    return dedupe_iter(result)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\nfrom pytutils.iters import dedupe_iter\n\n\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    # Call the wrapped function with provided args and kwargs to get its output iterable\n    result_iterable = f(*args, **kwargs)\n    # Use the dedupe_iter context function to deduplicate the iterable output\n    return dedupe_iter(result_iterable)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()"]}
