{"task_id": 154, "project": "test-apps/pytutils", "module": "pytutils.urls", "predictions": ["def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    new_query = urlencode(query_params, doseq=True)\n\n    new_url = urlunparse(\n        (\n            parsed_url.scheme,\n            parsed_url.netloc,\n            parsed_url.path,\n            parsed_url.params,\n            new_query,\n            parsed_url.fragment,\n        )\n    )\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    # Parse the URL into components\n    parsed_url = urlparse(url)\n    # Parse the query string into a dict of params\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query params with the new params, replacing existing values\n    for key, value in params.items():\n        query_params[key] = value if doseq and isinstance(value, (list, tuple)) else [value]\n\n    # Build the new query string\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Reconstruct the URL with the new query string\n    new_url = urlunparse(\n        (parsed_url.scheme,\n         parsed_url.netloc,\n         parsed_url.path,\n         parsed_url.params,\n         new_query,\n         parsed_url.fragment)\n    )\n\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq:\n            if isinstance(value, list):\n                query_params[key] = value\n            else:\n                query_params[key] = [value]\n        else:\n            query_params[key] = [value] if not isinstance(value, str) else [value]\n\n    new_query = urlencode(query_params, doseq=True)\n\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    # Parse the URL into components\n    parsed_url = urlparse(url)\n    # Parse the query parameters into a dict with values as lists\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters dict with the new values\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    # Re-encode the query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the URL with the new query string\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url", "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = value\n        else:\n            query_params[key] = [value]\n\n    new_query = urlencode(query_params, doseq=True)\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    new_query = urlencode(query_params, doseq=True)\n\n    new_url = urlunparse(\n        (\n            parsed_url.scheme,\n            parsed_url.netloc,\n            parsed_url.path,\n            parsed_url.params,\n            new_query,\n            parsed_url.fragment,\n        )\n    )\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    # Parse the URL into components\n    parsed_url = urlparse(url)\n    # Parse the query string into a dict of params\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query params with the new params, replacing existing values\n    for key, value in params.items():\n        query_params[key] = value if doseq and isinstance(value, (list, tuple)) else [value]\n\n    # Build the new query string\n    new_query = urlencode(query_params, doseq=doseq)\n\n    # Reconstruct the URL with the new query string\n    new_url = urlunparse(\n        (parsed_url.scheme,\n         parsed_url.netloc,\n         parsed_url.path,\n         parsed_url.params,\n         new_query,\n         parsed_url.fragment)\n    )\n\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq:\n            if isinstance(value, list):\n                query_params[key] = value\n            else:\n                query_params[key] = [value]\n        else:\n            query_params[key] = [value] if not isinstance(value, str) else [value]\n\n    new_query = urlencode(query_params, doseq=True)\n\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    # Parse the URL into components\n    parsed_url = urlparse(url)\n    # Parse the query parameters into a dict with values as lists\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    # Update the query parameters dict with the new values\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = list(value)\n        else:\n            query_params[key] = [value]\n\n    # Re-encode the query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Reconstruct the URL with the new query string\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\ntry:\n    import urlparse\n    from urllib import urlencode\nexcept ImportError:  # py3k\n    import urllib.parse as urlparse\n    urlencode = urlparse.urlencode\n\n\ndef update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n\n    parsed_url = urlparse(url)\n    query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n\n    for key, value in params.items():\n        if doseq and isinstance(value, (list, tuple)):\n            query_params[key] = value\n        else:\n            query_params[key] = [value]\n\n    new_query = urlencode(query_params, doseq=True)\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    return new_url\n\n\nimport pickle\ndef test_0():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim'), doseq=True) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_0()\n\ndef test_1():\n    assert update_query_params(\"http://example.com?a=1\",dict(b=2))==\"http://example.com?a=1&b=2\"\ntest_1()\n\ndef test_2():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}) == 'http://example.com?foo=stuff&biz=baz')\ntest_2()\n\ndef test_5():\n    assert update_query_params(\"https://www.youtube.com/watch?v=2lAe1cFze2o\",\n                                                        dict(t='15')) == 'https://www.youtube.com/watch?v=2lAe1cFze2o&t=15'\ntest_5()\n\ndef test_6():\n    assert update_query_params('http://example.com?foo=bar', dict(foo='stuff', test='test')) == 'http://example.com?foo=stuff&test=test'\ntest_6()\n\ndef test_7():\n    assert update_query_params(\n        'http://example.com?foo=bar&biz=baz',\n        {'foo': 'stuff'}\n    ) == 'http://example.com?foo=stuff&biz=baz'\ntest_7()\n\ndef test_8():\n    assert update_query_params('http://example.com?foo=bar', {'foo': ['baz', 'qux']}) == 'http://example.com?foo=baz&foo=qux'\ntest_8()\n\ndef test_9():\n    assert update_query_params(\"http://test.com?p1=fo&p2=ba\", {\"p2\":\"bar\"}) == 'http://test.com?p1=fo&p2=bar'\ntest_9()\n\ndef test_10():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo': 'stuff'}) == 'http://example.com?foo=stuff&biz=baz'\ntest_10()\n\ndef test_12():\n    assert (update_query_params('http://example.com?foo=bar&biz=baz&foo=grunt', {'foo':'stuff', 'nuf':'grunt'}) == 'http://example.com?foo=stuff&biz=baz&nuf=grunt')\ntest_12()\n\ndef test_13():\n    assert update_query_params(\"http://example.com?a=1&b=2\", {\"b\": \"2\"}) == \"http://example.com?a=1&b=2\"\ntest_13()\n\ndef test_14():\n    assert update_query_params('http://example.com?a=b', {'a':'c'})=='http://example.com?a=c'\ntest_14()\n\ndef test_15():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(new='stuff')) == 'http://example.com?foo=bar&biz=baz&new=stuff'\ntest_15()\n\ndef test_16():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', boo='zim')) =='http://example.com?foo=stuff&biz=baz&boo=zim'\ntest_16()\n\ndef test_17():\n    assert update_query_params('https://www.examplesite.com?food=cake', {'food': ['soup', 'candy']}) == 'https://www.examplesite.com?food=soup&food=candy'\ntest_17()\n\ndef test_18():\n    assert update_query_params('http://example.com', {'foo': 'bar'}) == 'http://example.com?foo=bar'\ntest_18()\n\ndef test_19():\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', baz='test')) == 'http://example.com?foo=stuff&biz=baz&baz=test'\ntest_19()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', {'foo':'stuff'}, doseq=False) == output\ntest_3()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff', new='stuff', xyz=None)) == output\ntest_4()\n\ndef test_11():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_11\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('http://example.com?foo=bar&biz=baz', dict(foo=['stuff','things'])) == output\ntest_11()\n\ndef test_20():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+urls/update_query_params/test_20\", \"rb\") as f:\n        output = pickle.load(f)\n    assert update_query_params('https://example.com/abc?foo=bar&foo=baz&biz=baz', dict(foo='stuff', biz='thing')) == output\ntest_20()\n\n\n"]}
{"task_id": 155, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    elif isinstance(s, str):\n        return s.encode(encoding, errors)\n    else:\n        raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or one of {allowed_types}, got {type(s)}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected string or byteslike object, got {type(s).__name__}\")", "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    elif isinstance(s, str):\n        return s.encode(encoding, errors)\n    else:\n        raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or one of {allowed_types}, got {type(s)}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected string or byteslike object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, str):\n        return s.encode(encoding, errors)\n    raise TypeError(f\"Expected str or bytes-like object, got {type(s).__name__}\")\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s\n\n\n\nimport pickle\ndef test_235():\n    assert ensure_encoded_bytes(u\"café\") == b\"caf\\xc3\\xa9\"\ntest_235()\n\ndef test_236():\n    assert 0 == b'0'.find(ensure_encoded_bytes('0'))\ntest_236()\n\ndef test_238():\n    assert b'abc' == ensure_encoded_bytes(u'abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_238()\n\ndef test_239():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-8') == b'abc'\ntest_239()\n\ndef test_240():\n    assert b'abc' == ensure_encoded_bytes('abc', errors='strict', allowed_types=(bytes, bytearray, memoryview))\ntest_240()\n\ndef test_241():\n    assert ensure_encoded_bytes(memoryview(b'abc')) == b'abc'\ntest_241()\n\ndef test_242():\n    assert isinstance(ensure_encoded_bytes(\"Hallo\"), six.binary_type)\ntest_242()\n\ndef test_243():\n    assert ensure_encoded_bytes(u'xxx', encoding='utf-8', errors='strict') == b'xxx'\ntest_243()\n\ndef test_0():\n    assert b'abc' == ensure_encoded_bytes(memoryview(b'abc'))\ntest_0()\n\ndef test_2():\n    assert isinstance(ensure_encoded_bytes(\"x\"), six.binary_type)\ntest_2()\n\ndef test_3():\n    assert b'string' == ensure_encoded_bytes(b'string')\ntest_3()\n\ndef test_4():\n    assert isinstance(ensure_encoded_bytes(memoryview(b'test')), (bytes, bytearray, memoryview))\ntest_4()\n\ndef test_5():\n    assert isinstance(ensure_encoded_bytes(u\"foo\", encoding=\"utf-8\", errors=\"strict\"), (bytes, bytearray, memoryview))\ntest_5()\n\ndef test_6():\n    assert ensure_encoded_bytes(b'b', encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)) == b'b'\ntest_6()\n\ndef test_8():\n    assert ensure_encoded_bytes(bytearray(b'abc'), 'utf-32') == b'abc'\ntest_8()\n\ndef test_7():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_encoded_bytes/test_7\", \"rb\") as f:\n        output = pickle.load(f)\n    assert int(hash(ensure_encoded_bytes(b\"xyzzy\"))) == output\ntest_7()\n\n\n"]}
{"task_id": 156, "project": "test-apps/pytutils", "module": "pytutils.pythree", "predictions": ["def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n    \n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(\"Expected str, bytes, bytearray, or memoryview, got %r\" % type(s))", "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(\"Expected bytes, bytearray, memoryview or text_type but got %s.\" % type(s))", "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    if isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    raise TypeError('Expected bytes, bytearray, memoryview, or text string, got %r' % type(s))", "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(f'Expected string or bytes-like object, got {type(s).__name__}')", "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding, errors)\n    raise TypeError('Expected bytes, bytearray, memoryview or str, got %r' % type(s))"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n    \n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(\"Expected str, bytes, bytearray, or memoryview, got %r\" % type(s))\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(\"Expected bytes, bytearray, memoryview or text_type but got %s.\" % type(s))\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    if isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    raise TypeError('Expected bytes, bytearray, memoryview, or text string, got %r' % type(s))\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s.encode(encoding, errors)\n    elif isinstance(s, (bytes, bytearray, memoryview)):\n        return bytes(s)\n    else:\n        raise TypeError(f'Expected string or bytes-like object, got {type(s).__name__}')\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport six\n\n\ndef ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)\n\n\ndef ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    import six\n\n    if isinstance(s, allowed_types):\n        return s\n    if isinstance(s, six.text_type):\n        return s.encode(encoding, errors)\n    raise TypeError('Expected bytes, bytearray, memoryview or str, got %r' % type(s))\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(b\"hello world\"), str) == output\ntest_0()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pythree/ensure_decoded_text/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert isinstance(ensure_decoded_text(bytearray(b'ABC'), errors='ignore'), bytearray) == output\ntest_2()\n\n\n"]}
{"task_id": 157, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    import threading\n    out_queues = [queue_factory() for _ in range(count)]\n    def _fanout():\n        while True:\n            item = q.get()\n            if item is None:\n                for oq in out_queues:\n                    oq.put(None)\n                break\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n    t = threading.Thread(target=_fanout, daemon=True)\n    t.start()\n    return out_queues", "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def forward():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n            if item is None:\n                break\n\n    Thread(target=forward, daemon=True).start()\n    return out_queues", "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    import threading\n    from queue import Empty\n\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def distributor():\n        while True:\n            try:\n                item = q.get()\n                if item is None:\n                    # signal stop to all output queues\n                    for oq in out_queues:\n                        oq.put(None)\n                    break\n                for oq in out_queues:\n                    oq.put(item)\n            except Exception:\n                # In case of other exceptions, stop distribution\n                for oq in out_queues:\n                    oq.put(None)\n                break\n\n    threading.Thread(target=distributor, daemon=True).start()\n\n    return out_queues if count > 1 else out_queues[0]", "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            if item is None:\n                for out_q in output_queues:\n                    out_q.put(None)\n                break\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    t = Thread(target=worker, daemon=True)\n    t.start()\n    return output_queues", "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def forwarder():\n        while True:\n            item = q.get()\n            if item is None:\n                for oq in out_queues:\n                    oq.put(None)\n                break\n            for oq in out_queues:\n                oq.put(item)\n\n    Thread(target=forwarder, daemon=True).start()\n    return out_queues"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    import threading\n    out_queues = [queue_factory() for _ in range(count)]\n    def _fanout():\n        while True:\n            item = q.get()\n            if item is None:\n                for oq in out_queues:\n                    oq.put(None)\n                break\n            for oq in out_queues:\n                oq.put(item)\n            q.task_done()\n    t = threading.Thread(target=_fanout, daemon=True)\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def forward():\n        while True:\n            item = q.get()\n            for out_q in out_queues:\n                out_q.put(item)\n            if item is None:\n                break\n\n    Thread(target=forward, daemon=True).start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    import threading\n    from queue import Empty\n\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def distributor():\n        while True:\n            try:\n                item = q.get()\n                if item is None:\n                    # signal stop to all output queues\n                    for oq in out_queues:\n                        oq.put(None)\n                    break\n                for oq in out_queues:\n                    oq.put(item)\n            except Exception:\n                # In case of other exceptions, stop distribution\n                for oq in out_queues:\n                    oq.put(None)\n                break\n\n    threading.Thread(target=distributor, daemon=True).start()\n\n    return out_queues if count > 1 else out_queues[0]\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n    output_queues = [queue_factory() for _ in range(count)]\n\n    def worker():\n        while True:\n            item = q.get()\n            if item is None:\n                for out_q in output_queues:\n                    out_q.put(None)\n                break\n            for out_q in output_queues:\n                out_q.put(item)\n            q.task_done()\n\n    t = Thread(target=worker, daemon=True)\n    t.start()\n    return output_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    from threading import Thread\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def forwarder():\n        while True:\n            item = q.get()\n            if item is None:\n                for oq in out_queues:\n                    oq.put(None)\n                break\n            for oq in out_queues:\n                oq.put(item)\n\n    Thread(target=forwarder, daemon=True).start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q\n\n\nimport pickle\ndef test_22():\n    assert 5 == len(multiplex(Queue(), count=5))\ntest_22()\n\ndef test_24():\n    assert 2 == len(multiplex(Queue(), count=2))\ntest_24()\n\ndef test_27():\n    assert 2 == len(multiplex(Queue(maxsize=3), 2))\ntest_27()\n\ndef test_28():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/multiplex/test_28\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(multiplex(Queue())) == output\ntest_28()\n\n\ndef test_extra_2():\n    in_q = Queue(maxsize=1)\n    out_q1, out_q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\ntest_extra_2()\n\ndef test_extra_3():\n    in_q = Queue()\n    out_q1, out_q2, out_q3, out_q4, out_q5 = multiplex(in_q, count=5)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    in_q.put(4)\n    in_q.put(5)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q4.get() == 1\n    assert out_q5.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q4.get() == 2\n    assert out_q5.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\n    assert out_q4.get() == 3\n    assert out_q5.get() == 3\n    assert out_q1.get() == 4\n    assert out_q2.get() == 4\n    assert out_q3.get() == 4\n    assert out_q4.get() == 4\n    assert out_q5.get() == 4\n    assert out_q1.get() == 5\n    assert out_q2.get() == 5\n    assert out_q3.get() == 5\n    assert out_q4.get() == 5\n    assert out_q5.get() == 5\ntest_extra_3()\n\ndef test_extra_4():\n    in_q = Queue()\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    out_queues = multiplex(in_q, count=3)\n    assert len(out_queues) == 3\n    for out_q in out_queues:\n        assert out_q.get() == 1\n        assert out_q.get() == 2\n        assert out_q.get() == 3\ntest_extra_4()\n\ndef test_extra_5():\n    in_q = Queue()\n    q1, q2 = multiplex(in_q, count=2)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\ntest_extra_5()\n\ndef test_extra_6():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\ntest_extra_6()\n\ndef test_extra_7():\n    in_q = Queue()\n    q1, q2, q3, q4 = multiplex(in_q, count=4)\n    in_q.put(1)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q4.get() == 1\ntest_extra_7()\n\ndef test_extra_8():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert q1.get() == 1\n    assert q2.get() == 1\n    assert q3.get() == 1\n    assert q1.get() == 2\n    assert q2.get() == 2\n    assert q3.get() == 2\n    assert q1.get() == 3\n    assert q2.get() == 3\n    assert q3.get() == 3\ntest_extra_8()\n\ndef test_extra_9():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(None)\n    assert q1.get() is None\n    assert q2.get() is None\n    assert q3.get() is None\ntest_extra_9()\n\ndef test_extra_10():\n    in_q = Queue()\n    q1, q2, q3 = multiplex(in_q, count=3)\n    in_q.put(\"a\")\n    in_q.put(\"b\")\n    in_q.put(\"c\")\n    assert q1.get() == \"a\"\n    assert q2.get() == \"a\"\n    assert q3.get() == \"a\"\n    assert q1.get() == \"b\"\n    assert q2.get() == \"b\"\n    assert q3.get() == \"b\"\n    assert q1.get() == \"c\"\n    assert q2.get() == \"c\"\n    assert q3.get() == \"c\"\ntest_extra_10()\n\ndef test_extra_0():\n    q = Queue()\n    q.put(1)\n    q.put(2)\n    q.put(3)\n\n    q1 = multiplex(q, count=1)[0]\n    assert q1.get() == 1\n    assert q1.get() == 2\n    assert q1.get() == 3\ntest_extra_0()\n\ndef test_extra_1():\n    in_q = Queue()\n    out_q1, out_q2, out_q3 = multiplex(in_q, count=3)\n    in_q.put(1)\n    in_q.put(2)\n    in_q.put(3)\n    assert out_q1.get() == 1\n    assert out_q2.get() == 1\n    assert out_q3.get() == 1\n    assert out_q1.get() == 2\n    assert out_q2.get() == 2\n    assert out_q3.get() == 2\n    assert out_q1.get() == 3\n    assert out_q2.get() == 3\n    assert out_q3.get() == 3\ntest_extra_1()"]}
{"task_id": 158, "project": "test-apps/pytutils", "module": "pytutils.queues", "predictions": ["def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = kwargs.get('out_q', queue.Queue())\n\n    def forward(q):\n        while True:\n            item = q.get()\n            if item is None:\n                break\n            out_q.put(item)\n        out_q.put(None)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=forward, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def close_when_done():\n        finished_count = 0\n        while finished_count < len(in_qs):\n            sentinel = out_q.get()\n            if sentinel is None:\n                finished_count += 1\n            else:\n                out_q.put(sentinel)\n        out_q.put(None)\n\n    t = threading.Thread(target=close_when_done)\n    t.daemon = True\n    t.start()\n\n    return out_q", "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = kwargs.get('out_q', queue.Queue())\n    sentinel = object()\n    num_queues = len(in_qs)\n    finished_count = 0\n\n    def worker(q):\n        nonlocal finished_count\n        while True:\n            try:\n                item = q.get()\n                if item is sentinel:\n                    break\n                out_q.put(item)\n            finally:\n                q.task_done()\n        finished_count += 1\n        if finished_count == num_queues:\n            out_q.put(sentinel)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=worker, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    return out_q", "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    from queue import Queue, Empty\n    import threading\n    import time\n\n    out_q = Queue()\n\n    def worker(q):\n        while True:\n            try:\n                item = q.get(timeout=0.1)\n                if item is None:\n                    break\n                out_q.put(item)\n            except Empty:\n                continue\n        out_q.put(None)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=worker, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def closer():\n        end_markers = 0\n        while end_markers < len(in_qs):\n            item = out_q.get()\n            if item is None:\n                end_markers += 1\n            else:\n                out_q.put(item)\n            time.sleep(0)\n        out_q.put(None)\n\n    close_thread = threading.Thread(target=closer)\n    close_thread.daemon = True\n    close_thread.start()\n\n    return out_q", "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = queue.Queue()\n    def worker(in_q):\n        while True:\n            item = in_q.get()\n            if item is None:\n                # None is used as a sentinel to indicate the queue is done.\n                break\n            out_q.put(item)\n            in_q.task_done()\n        in_q.task_done()\n\n    threads = []\n    for q_in in in_qs:\n        t = threading.Thread(target=worker, args=(q_in,), daemon=True)\n        t.start()\n        threads.append(t)\n\n    def waiter():\n        for q_in in in_qs:\n            q_in.join()\n            q_in.put(None)  # signal the worker thread to exit\n        for t in threads:\n            t.join()\n        out_q.put(None)  # signal that no more data will be added\n\n    threading.Thread(target=waiter, daemon=True).start()\n\n    return out_q", "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    from queue import Queue\n    out_q = Queue()\n\n    def worker(in_q):\n        while True:\n            item = in_q.get()\n            if item is None:\n                break\n            out_q.put(item)\n            in_q.task_done()\n        in_q.task_done()\n\n    import threading\n    threads = []\n    for in_q in in_qs:\n        t = threading.Thread(target=worker, args=(in_q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def close():\n        for in_q in in_qs:\n            in_q.put(None)\n        for t in threads:\n            t.join()\n        out_q.put(None)\n\n    out_q.close = close\n    return out_q"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = kwargs.get('out_q', queue.Queue())\n\n    def forward(q):\n        while True:\n            item = q.get()\n            if item is None:\n                break\n            out_q.put(item)\n        out_q.put(None)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=forward, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def close_when_done():\n        finished_count = 0\n        while finished_count < len(in_qs):\n            sentinel = out_q.get()\n            if sentinel is None:\n                finished_count += 1\n            else:\n                out_q.put(sentinel)\n        out_q.put(None)\n\n    t = threading.Thread(target=close_when_done)\n    t.daemon = True\n    t.start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = kwargs.get('out_q', queue.Queue())\n    sentinel = object()\n    num_queues = len(in_qs)\n    finished_count = 0\n\n    def worker(q):\n        nonlocal finished_count\n        while True:\n            try:\n                item = q.get()\n                if item is sentinel:\n                    break\n                out_q.put(item)\n            finally:\n                q.task_done()\n        finished_count += 1\n        if finished_count == num_queues:\n            out_q.put(sentinel)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=worker, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    from queue import Queue, Empty\n    import threading\n    import time\n\n    out_q = Queue()\n\n    def worker(q):\n        while True:\n            try:\n                item = q.get(timeout=0.1)\n                if item is None:\n                    break\n                out_q.put(item)\n            except Empty:\n                continue\n        out_q.put(None)\n\n    threads = []\n    for q in in_qs:\n        t = threading.Thread(target=worker, args=(q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def closer():\n        end_markers = 0\n        while end_markers < len(in_qs):\n            item = out_q.get()\n            if item is None:\n                end_markers += 1\n            else:\n                out_q.put(item)\n            time.sleep(0)\n        out_q.put(None)\n\n    close_thread = threading.Thread(target=closer)\n    close_thread.daemon = True\n    close_thread.start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    import queue\n    import threading\n\n    out_q = queue.Queue()\n    def worker(in_q):\n        while True:\n            item = in_q.get()\n            if item is None:\n                # None is used as a sentinel to indicate the queue is done.\n                break\n            out_q.put(item)\n            in_q.task_done()\n        in_q.task_done()\n\n    threads = []\n    for q_in in in_qs:\n        t = threading.Thread(target=worker, args=(q_in,), daemon=True)\n        t.start()\n        threads.append(t)\n\n    def waiter():\n        for q_in in in_qs:\n            q_in.join()\n            q_in.put(None)  # signal the worker thread to exit\n        for t in threads:\n            t.join()\n        out_q.put(None)  # signal that no more data will be added\n\n    threading.Thread(target=waiter, daemon=True).start()\n\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nfrom six.moves.queue import Queue\nfrom threading import Thread\n\n\ndef multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues\n\n\ndef push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)\n\n\ndef merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    from queue import Queue\n    out_q = Queue()\n\n    def worker(in_q):\n        while True:\n            item = in_q.get()\n            if item is None:\n                break\n            out_q.put(item)\n            in_q.task_done()\n        in_q.task_done()\n\n    import threading\n    threads = []\n    for in_q in in_qs:\n        t = threading.Thread(target=worker, args=(in_q,))\n        t.daemon = True\n        t.start()\n        threads.append(t)\n\n    def close():\n        for in_q in in_qs:\n            in_q.put(None)\n        for t in threads:\n            t.join()\n        out_q.put(None)\n\n    out_q.close = close\n    return out_q\n\n\nimport pickle\ndef test_15():\n    assert 0 == merge(Queue(), Queue(), Queue()).qsize()\ntest_15()\n\ndef test_14():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_14\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=100), Queue(maxsize=100)).qsize() == output\ntest_14()\n\ndef test_18():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+queues/merge/test_18\", \"rb\") as f:\n        output = pickle.load(f)\n    assert merge(Queue(maxsize=1000), Queue(maxsize=1000), maxsize=1000).qsize() == output\ntest_18()\n\n\n"]}
{"task_id": 159, "project": "test-apps/pytutils", "module": "pytutils.env", "predictions": ["def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n\n    if lines is None:\n        lines = []\n\n    var_pattern = re.compile(r\"\\A([\\w\\.]+)\\s*=\\s*(.*)\\Z\")\n    var_expand_pattern = re.compile(r\"\\$(?:{([^}]+)}|(\\w+))\")\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = var_pattern.match(line)\n        if not m:\n            continue\n\n        key, val = m.group(1), m.group(2)\n\n        # Remove surrounding quotes\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        # Expand tilde (~) at start of val\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n\n        # Expand environment variables if present\n        def var_expand(match):\n            return os.environ.get(match.group(1) or match.group(2), match.group(0))\n\n        val = var_expand_pattern.sub(var_expand, val)\n\n        yield key, val", "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import typing\n    import os\n    import re\n\n    if lines is None:\n        return\n\n    def _expand_val(val):\n        # Expand ~ to user home directory only at start\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n        # Expand environment variables like $VAR or ${VAR}\n        pattern = re.compile(r'\\$(\\w+|\\{[^}]+\\})')\n\n        def repl(m):\n            var = m.group(1)\n            if var.startswith('{') and var.endswith('}'):\n                var = var[1:-1]\n            return os.environ.get(var, m.group(0))\n\n        val = pattern.sub(repl, val)\n        return val\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' not in line:\n            continue\n        key, val = line.split('=', 1)\n        key = key.strip()\n        val = val.strip()\n        # remove quotes if val is quoted\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n        val = _expand_val(val)\n        yield key, val", "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import typing\n    import re\n\n    if lines is None:\n        lines = []\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = re.match(r'^([\\w\\.]+)=(.*)$', line)\n        if not m:\n            continue\n\n        key, val = m.group(1), m.group(2)\n\n        val = val.strip()\n\n        # Remove surrounding quotes if any\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        # Expand ~ to user home\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n\n        # Expand environment variables in the value\n        val = os.path.expandvars(val)\n\n        yield key, val", "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n    import typing\n\n    if lines is None:\n        return\n\n    var_pattern = re.compile(\n        r'''\n        \\$(\\w+|\\{[^}]+\\})  # Matches $VAR or ${VAR}\n        ''',\n        re.VERBOSE,\n    )\n\n    def substitute_var(value: str) -> str:\n        # Replace leading ~ with home directory\n        if value.startswith('~'):\n            value = os.path.expanduser(value)\n\n        def repl(match: re.Match) -> str:\n            var = match.group(1)\n            if var.startswith('{') and var.endswith('}'):\n                var = var[1:-1]\n            return os.environ.get(var, match.group(0))\n\n        return var_pattern.sub(repl, value)\n\n    for line in lines:\n        line = line.strip()\n\n        # Skip empty lines and comments\n        if not line or line.startswith('#'):\n            continue\n\n        if '=' not in line:\n            continue\n\n        key, value = line.split('=', 1)\n        key = key.strip()\n        value = value.strip()\n\n        # Remove surrounding quotes if any\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            value = value[1:-1]\n\n        value = substitute_var(value)\n\n        yield key, value", "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n    import typing\n\n    if lines is None:\n        return\n\n    var_re = re.compile(r'\\$(\\w+)|\\$\\{([^}]+)\\}')\n\n    def expand_vars(value):\n        def replacer(match):\n            # match group 1: $VAR, group 2: ${VAR}\n            var_name = match.group(1) or match.group(2)\n            return os.getenv(var_name, match.group(0))\n        return var_re.sub(replacer, value)\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        key, sep, value = line.partition('=')\n        if sep != '=':\n            continue\n        key = key.strip()\n        value = value.strip()\n\n        if value.startswith('~'):\n            value = os.path.expanduser(value)\n\n        value = expand_vars(value)\n\n        yield key, value"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n\n    if lines is None:\n        lines = []\n\n    var_pattern = re.compile(r\"\\A([\\w\\.]+)\\s*=\\s*(.*)\\Z\")\n    var_expand_pattern = re.compile(r\"\\$(?:{([^}]+)}|(\\w+))\")\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = var_pattern.match(line)\n        if not m:\n            continue\n\n        key, val = m.group(1), m.group(2)\n\n        # Remove surrounding quotes\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        # Expand tilde (~) at start of val\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n\n        # Expand environment variables if present\n        def var_expand(match):\n            return os.environ.get(match.group(1) or match.group(2), match.group(0))\n\n        val = var_expand_pattern.sub(var_expand, val)\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import typing\n    import os\n    import re\n\n    if lines is None:\n        return\n\n    def _expand_val(val):\n        # Expand ~ to user home directory only at start\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n        # Expand environment variables like $VAR or ${VAR}\n        pattern = re.compile(r'\\$(\\w+|\\{[^}]+\\})')\n\n        def repl(m):\n            var = m.group(1)\n            if var.startswith('{') and var.endswith('}'):\n                var = var[1:-1]\n            return os.environ.get(var, m.group(0))\n\n        val = pattern.sub(repl, val)\n        return val\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' not in line:\n            continue\n        key, val = line.split('=', 1)\n        key = key.strip()\n        val = val.strip()\n        # remove quotes if val is quoted\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n        val = _expand_val(val)\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import typing\n    import re\n\n    if lines is None:\n        lines = []\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        m = re.match(r'^([\\w\\.]+)=(.*)$', line)\n        if not m:\n            continue\n\n        key, val = m.group(1), m.group(2)\n\n        val = val.strip()\n\n        # Remove surrounding quotes if any\n        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n            val = val[1:-1]\n\n        # Expand ~ to user home\n        if val.startswith('~'):\n            val = os.path.expanduser(val)\n\n        # Expand environment variables in the value\n        val = os.path.expandvars(val)\n\n        yield key, val\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n    import typing\n\n    if lines is None:\n        return\n\n    var_pattern = re.compile(\n        r'''\n        \\$(\\w+|\\{[^}]+\\})  # Matches $VAR or ${VAR}\n        ''',\n        re.VERBOSE,\n    )\n\n    def substitute_var(value: str) -> str:\n        # Replace leading ~ with home directory\n        if value.startswith('~'):\n            value = os.path.expanduser(value)\n\n        def repl(match: re.Match) -> str:\n            var = match.group(1)\n            if var.startswith('{') and var.endswith('}'):\n                var = var[1:-1]\n            return os.environ.get(var, match.group(0))\n\n        return var_pattern.sub(repl, value)\n\n    for line in lines:\n        line = line.strip()\n\n        # Skip empty lines and comments\n        if not line or line.startswith('#'):\n            continue\n\n        if '=' not in line:\n            continue\n\n        key, value = line.split('=', 1)\n        key = key.strip()\n        value = value.strip()\n\n        # Remove surrounding quotes if any\n        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n            value = value[1:-1]\n\n        value = substitute_var(value)\n\n        yield key, value\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\nimport os\nimport re\nimport typing\n\n\ndef expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val\n\n\ndef parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    import os\n    import re\n    import typing\n\n    if lines is None:\n        return\n\n    var_re = re.compile(r'\\$(\\w+)|\\$\\{([^}]+)\\}')\n\n    def expand_vars(value):\n        def replacer(match):\n            # match group 1: $VAR, group 2: ${VAR}\n            var_name = match.group(1) or match.group(2)\n            return os.getenv(var_name, match.group(0))\n        return var_re.sub(replacer, value)\n\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        key, sep, value = line.partition('=')\n        if sep != '=':\n            continue\n        key = key.strip()\n        value = value.strip()\n\n        if value.startswith('~'):\n            value = os.path.expanduser(value)\n\n        value = expand_vars(value)\n\n        yield key, value\n\n\ndef load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes\n\n\n\nimport pickle\ndef test_0():\n    assert dict(parse_env_file_contents([\"TEST=hi\", \"TEST=hi2\"])) == {\"TEST\":\"hi2\"}\ntest_0()\n\ndef test_1():\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=123', 'TEST=456'])) == {'TEST': '456', 'TEST1': '123'}\ntest_1()\n\ndef test_3():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) != {'TEST': '${HOME}/yeee', 'THISIS': '~/a/test', 'YOLO': '~/swaggins/'}\ntest_3()\n\ndef test_4():\n    assert collections.OrderedDict(parse_env_file_contents([\"TEST=${HOME}/yeee\", \"THISIS=~/a/test\", \"YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST\"])) == collections.OrderedDict([('TEST', '${HOME}/yeee'), ('THISIS', '~/a/test'), ('YOLO', '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\ntest_4()\n\ndef test_7():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456'])) == {'TEST': '123', 'TEST2': '456'}\ntest_7()\n\ndef test_8():\n    assert dict(parse_env_file_contents(['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST'])) == {'YOLO': '~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST', 'TEST': '${HOME}/yeee', 'THISIS': '~/a/test'}\ntest_8()\n\ndef test_5():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_5\", \"rb\") as f:\n        output = pickle.load(f)\n    assert dict(parse_env_file_contents(['TEST=$TEST1', 'TEST1=$TEST2', 'TEST2=123', 'TEST1=', 'TEST2='])) == output\ntest_5()\n\ndef test_9():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+env/parse_env_file_contents/test_9\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(list(parse_env_file_contents(['THISIS=~/a/test', 'TEST=a/b/c']))) == output\ntest_9()\n\n\ndef test_extra_0():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\"1=2=3\"'])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_0()\n\ndef test_extra_1():\n    assert dict(parse_env_file_contents(['TEST=123', 'TEST2=456', 'TEST3=789', 'TEST4=\\'1=2=3\\''])) == {'TEST': '123', 'TEST2': '456', 'TEST3': '789', 'TEST4': '1=2=3'}\ntest_extra_1()\n\ndef test_extra_2():\n    assert dict(parse_env_file_contents(['TEST=value with spaces', 'TEST2=\"value with spaces in quotes\"'])) == {'TEST': 'value with spaces', 'TEST2': 'value with spaces in quotes'}\ntest_extra_2()"]}
{"task_id": 160, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalTrueColorFormatter\n    from pygments.formatters.terminals import TerminalFormatter\n    from pprint import pformat\n\n    formatted = pformat(arg)\n    return highlight(formatted, lexer, formatter)", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n\n    # Use provided lexer and formatter, or defaults\n    lex = lexer if lexer is not None else PythonLexer()\n    fmt = formatter if formatter is not None else Terminal256Formatter()\n\n    s = repr(arg)\n    colored = highlight(s, lex, fmt)\n    print(colored, end='')", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n    import pprint\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = Terminal256Formatter()\n\n    pretty_str = pprint.pformat(arg, width=80)\n    return highlight(pretty_str, lexer, formatter)", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pygments\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    from pygments.token import Token\n    import pprint\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n\n    formatted_text = pprint.pformat(arg)\n    colored = pygments.highlight(formatted_text, lexer, formatter)\n    print(colored, end='')", "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = Terminal256Formatter()\n\n    try:\n        formatted = highlight(arg, lexer, formatter)\n        print(formatted, end='')\n    except Exception:\n        # fallback plain print if any error occurs in highlighting\n        print(arg)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalTrueColorFormatter\n    from pygments.formatters.terminals import TerminalFormatter\n    from pprint import pformat\n\n    formatted = pformat(arg)\n    return highlight(formatted, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n\n    # Use provided lexer and formatter, or defaults\n    lex = lexer if lexer is not None else PythonLexer()\n    fmt = formatter if formatter is not None else Terminal256Formatter()\n\n    s = repr(arg)\n    colored = highlight(s, lex, fmt)\n    print(colored, end='')\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n    import pprint\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = Terminal256Formatter()\n\n    pretty_str = pprint.pformat(arg, width=80)\n    return highlight(pretty_str, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    import pygments\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    from pygments.token import Token\n    import pprint\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n\n    formatted_text = pprint.pformat(arg)\n    colored = pygments.highlight(formatted_text, lexer, formatter)\n    print(colored, end='')\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import Terminal256Formatter\n\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = Terminal256Formatter()\n\n    try:\n        formatted = highlight(arg, lexer, formatter)\n        print(formatted, end='')\n    except Exception:\n        # fallback plain print if any error occurs in highlighting\n        print(arg)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()\n\npprint = pp\n\n\n\nimport pickle\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1.0j, 2.0j, 3.0j])) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2])) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf(1)) == output\ntest_2()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pf/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(pf([1, 2, 3, 4.0, 5.0, 6.0j])) == output\ntest_3()\n\n\n"]}
{"task_id": 161, "project": "test-apps/pytutils", "module": "pytutils.pretty", "predictions": ["def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    s = repr(arg)\n    return highlight(s, lexer, formatter, outfile=outfile)", "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    text = repr(arg)\n    highlight(text, lexer, formatter, outfile)", "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n    try:\n        s = repr(arg)\n    except Exception:\n        s = str(arg)\n    highlight(s, lexer, formatter, outfile)", "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    \n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n    s = repr(arg)\n    highlight(s, lexer, formatter, outfile)", "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    try:\n        s = repr(arg)\n    except Exception:\n        s = str(arg)\n    highlight(s, lexer, formatter, outfile)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    s = repr(arg)\n    return highlight(s, lexer, formatter, outfile=outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    text = repr(arg)\n    highlight(text, lexer, formatter, outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n    try:\n        s = repr(arg)\n    except Exception:\n        s = str(arg)\n    highlight(s, lexer, formatter, outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    from pygments.lexers import PythonLexer\n    from pygments.formatters import TerminalFormatter\n    \n    if lexer is None:\n        lexer = PythonLexer()\n    if formatter is None:\n        formatter = TerminalFormatter()\n    s = repr(arg)\n    highlight(s, lexer, formatter, outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport six\nimport sys\nimport warnings\nimport pprint as _pprint\n\ntry:\n    import pygments\n    import pygments.styles\n    import pygments.formatters\n    import pygments.lexers\n\n    __PP_STYLE = pygments.styles.get_style_by_name('monokai')\n    __PP_FORMATTER = pygments.formatters.get_formatter_by_name('console16m', style=__PP_STYLE)\n    __PP_LEXER_PYTHON = pygments.lexers.get_lexer_by_name('python{}'.format(six.PY3 and '3' or ''))\n\nexcept ImportError:\n    warnings.warn('Could not import `pygments`. Disabling syntax highlighting I guess.')\n    pygments = False\n\n__all__ = ('pf', 'pformat', 'pp', 'pprint')\n\n\ndef pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)\n\npformat = pf\n\n\ndef pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    from pygments import highlight\n    try:\n        s = repr(arg)\n    except Exception:\n        s = str(arg)\n    highlight(s, lexer, formatter, outfile)\n\npprint = pp\n\n\n\nimport pickle\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(42) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+pretty/pp/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert pp(2) == output\ntest_3()\n\n\n"]}
{"task_id": 162, "project": "test-apps/pytutils", "module": "pytutils.trees", "predictions": ["def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)", "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)", "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)", "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)", "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport collections\n\n_sentinel = object()\n\n\ndef get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node\n\n\ndef set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node\n\n\ndef tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    from collections import defaultdict\n    return defaultdict(tree)\n\n\nclass Tree(collections.defaultdict):\n    \"\"\"\n    Same extremely simple tree based on defaultdict as `tree`, but implemented as a class for extensibility.\n    Use ':' to delve down into dimensions without choosing doors [][][] .\n    Supports specifying a namespace that acts as a key prefix.\n    \"\"\"\n    namespace = None\n\n    def __init__(self, initial=None, namespace='', initial_is_ref=False):\n        if initial is not None and initial_is_ref:\n            self.data = initial_is_ref\n        self.namespace = namespace\n        super(Tree, self).__init__(self.__class__)\n        if initial is not None:\n            self.update(initial)\n\n    def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key\n\n    def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)\n\n    def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)\n\n    get = __getitem__\n\n\nclass RegistryTree(Tree):\n\n    # Alias\n    register = Tree.__setitem__\n\n\n\nimport pickle\ndef test_0():\n    assert isinstance(tree()['a'], dict)\ntest_0()\n\ndef test_3():\n    assert isinstance(tree()[1], dict)\ntest_3()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[\"a\"][\"b\"][\"c\"][\"d\"][\"e\"]) == output\ntest_1()\n\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()[1][2]) == output\ntest_2()\n\ndef test_4():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+trees/tree/test_4\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(tree()['b']['q']['j']) == output\ntest_4()\n\n\n"]}
{"task_id": 163, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)\n\n\nimport pickle\ndef test_2():\n    assert [1, 2, 6, 24, 120] == list(accumulate([1, 2, 3, 4, 5], operator.mul))\ntest_2()\n\ndef test_4():\n    assert all([x == y for x,y in zip(list(accumulate([1,2,3,4,5], operator.mul)), [1, 2, 6, 24, 120])])\ntest_4()\n\ndef test_5():\n    assert 1 == next(accumulate([1,2]))\ntest_5()\n\ndef test_0():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_0\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate(range(10000))) == output\ntest_0()\n\ndef test_1():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_1\", \"rb\") as f:\n        output = pickle.load(f)\n    assert sum(accumulate([1,2,3,4,5], operator.mul)) == output\ntest_1()\n\ndef test_3():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_3\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3])) == output\ntest_3()\n\ndef test_6():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/accumulate/test_6\", \"rb\") as f:\n        output = pickle.load(f)\n    assert next(accumulate([1,2,3,4,5], lambda a,b: a+b*b)) == output\ntest_6()\n\n\ndef test_extra_2():\n    assert [] == list(accumulate([]))\ntest_extra_2()\n\ndef test_extra_3():\n    assert [] == list(accumulate([]))\ntest_extra_3()\n\ndef test_extra_4():\n    assert [] == list(accumulate([]))\ntest_extra_4()\n\ndef test_extra_5():\n    assert [] == list(accumulate([]))\ntest_extra_5()\n\ndef test_extra_0():\n    assert list(accumulate([])) == []\ntest_extra_0()\n\ndef test_extra_1():\n    assert [] == list(accumulate([]))\ntest_extra_1()"]}
{"task_id": 164, "project": "test-apps/pytutils", "module": "pytutils.iters", "predictions": ["def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    seen = set()\n    for item in f(*args, **kwargs):\n        if item not in seen:\n            seen.add(item)\n            yield item", "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    def decorator(*args, **kwargs):\n        seen = set()\n        for item in f(*args, **kwargs):\n            if item not in seen:\n                seen.add(item)\n                yield item\n    return decorator()", "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    from collections.abc import Iterable\n    \n    iterable = f(*args, **kwargs)\n    seen = set()\n    \n    if not isinstance(iterable, Iterable):\n        # If not iterable, just return as is\n        return iterable\n    \n    for item in iterable:\n        if item not in seen:\n            yield item\n            seen.add(item)", "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    seen = set()\n    for item in result_iterable:\n        if item not in seen:\n            seen.add(item)\n            yield item", "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    seen = set()\n    for item in result:\n        if item not in seen:\n            seen.add(item)\n            yield item"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    seen = set()\n    for item in f(*args, **kwargs):\n        if item not in seen:\n            seen.add(item)\n            yield item\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    def decorator(*args, **kwargs):\n        seen = set()\n        for item in f(*args, **kwargs):\n            if item not in seen:\n                seen.add(item)\n                yield item\n    return decorator()\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    from collections.abc import Iterable\n    \n    iterable = f(*args, **kwargs)\n    seen = set()\n    \n    if not isinstance(iterable, Iterable):\n        # If not iterable, just return as is\n        return iterable\n    \n    for item in iterable:\n        if item not in seen:\n            yield item\n            seen.add(item)\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result_iterable = f(*args, **kwargs)\n    seen = set()\n    for item in result_iterable:\n        if item not in seen:\n            seen.add(item)\n            yield item\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/pytutils\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\nimport wrapt\nimport collections\nimport itertools\nimport operator\n\n\ndef accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n\n\ndef consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)\n\n\ndef dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item\n\n\n@wrapt.decorator\ndef dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    result = f(*args, **kwargs)\n    seen = set()\n    for item in result:\n        if item not in seen:\n            seen.add(item)\n            yield item\n\n\nimport pickle\ndef test_2():\n    with open(\"/output/test-apps+pytutils/test_output/pytutils+iters/dedupe/test_2\", \"rb\") as f:\n        output = pickle.load(f)\n    assert len(dedupe([1, 1, 2, 2, 3, 3, 4, 4])) == output\ntest_2()\n\n\ndef test_extra_0():\n    \"\"\"Test dedupe function with empty input\"\"\"\n    @dedupe\n    def empty_gen():\n        return []\n    assert list(empty_gen()) == []\ntest_extra_0()\n\ndef test_extra_1():\n    \"\"\"Test dedupe function with input that has no duplicates\"\"\"\n    @dedupe\n    def no_duplicates_gen():\n        return [1, 2, 3]\n    assert list(no_duplicates_gen()) == [1, 2, 3]\ntest_extra_1()\n\ndef test_extra_2():\n    \"\"\"Test dedupe function with input that has duplicates\"\"\"\n    @dedupe\n    def duplicates_gen():\n        return [1, 2, 2, 3, 3, 3]\n    assert list(duplicates_gen()) == [1, 2, 3]\ntest_extra_2()"]}
