{"task_id": 165, "project": "test-apps/docstring_parser", "module": "docstring_parser.google", "predictions": ["import typing as T\nfrom collections import OrderedDict\nimport inspect\nimport re\n\n# Re-declare or import needed classes/types from the provided file context\nclass Docstring:\n    \"\"\"Placeholder for the actual Docstring class to hold parsed elements.\"\"\"\n\n    def __init__(self):\n        self.short_description: T.Optional[str] = None\n        self.long_description: T.Optional[str] = None\n        self.blank_after_short_description: bool = False\n        self.blank_after_long_description: bool = False\n        self.meta: T.List = []\n\nclass ParseError(Exception):\n    pass\n\nclass SectionType(int):\n    SINGULAR = 0\n    MULTIPLE = 1\n    SINGULAR_OR_MULTIPLE = 2\n\nclass Section(T.NamedTuple):\n    title: str\n    key: str\n    type: SectionType\n\n# Re-define DEFAULT_SECTIONS as per file content to align GoogleParser's defaults\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n# Regular expressions copied from file content\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\n\nPARAM_KEYWORDS = {\"param\"}\nRAISES_KEYWORDS = {\"raises\"}\nRETURNS_KEYWORDS = {\"returns\"}\nYIELDS_KEYWORDS = {\"yields\"}\n\n# Minimal DocstringMeta and related classes as per file content's logic\nclass DocstringMeta:\n    def __init__(self, args, description):\n        self.args = args\n        self.description = description\n\nclass DocstringParam(DocstringMeta):\n    def __init__(self, args, description, arg_name, type_name, is_optional, default):\n        super().__init__(args, description)\n        self.arg_name = arg_name\n        self.type_name = type_name\n        self.is_optional = is_optional\n        self.default = default\n\nclass DocstringReturns(DocstringMeta):\n    def __init__(self, args, description, type_name=None, is_generator=False):\n        super().__init__(args, description)\n        self.type_name = type_name\n        self.is_generator = is_generator\n\nclass DocstringRaises(DocstringMeta):\n    def __init__(self, args, description, type_name=None):\n        super().__init__(args, description)\n        self.type_name = type_name\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected parameter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def parse(self, text: str) -> Docstring:\n        ret = Docstring()\n        if not text:\n            return ret\n\n        text = inspect.cleandoc(text)\n\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start():]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\"\\n\")\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        for title, chunk in chunks.items():\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError(f\"Can't infer indent from \\\"{chunk}\\\"\")\n            indent = indent_match.group()\n\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(f'No specification for \"{title}\": \"{chunk}\"')\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport typing as T\nfrom collections import OrderedDict\nimport inspect\nimport re\n\n# Re-declare or import needed classes/types from the provided file context\nclass Docstring:\n    \"\"\"Placeholder for the actual Docstring class to hold parsed elements.\"\"\"\n\n    def __init__(self):\n        self.short_description: T.Optional[str] = None\n        self.long_description: T.Optional[str] = None\n        self.blank_after_short_description: bool = False\n        self.blank_after_long_description: bool = False\n        self.meta: T.List = []\n\nclass ParseError(Exception):\n    pass\n\nclass SectionType(int):\n    SINGULAR = 0\n    MULTIPLE = 1\n    SINGULAR_OR_MULTIPLE = 2\n\nclass Section(T.NamedTuple):\n    title: str\n    key: str\n    type: SectionType\n\n# Re-define DEFAULT_SECTIONS as per file content to align GoogleParser's defaults\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n# Regular expressions copied from file content\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\n\nPARAM_KEYWORDS = {\"param\"}\nRAISES_KEYWORDS = {\"raises\"}\nRETURNS_KEYWORDS = {\"returns\"}\nYIELDS_KEYWORDS = {\"yields\"}\n\n# Minimal DocstringMeta and related classes as per file content's logic\nclass DocstringMeta:\n    def __init__(self, args, description):\n        self.args = args\n        self.description = description\n\nclass DocstringParam(DocstringMeta):\n    def __init__(self, args, description, arg_name, type_name, is_optional, default):\n        super().__init__(args, description)\n        self.arg_name = arg_name\n        self.type_name = type_name\n        self.is_optional = is_optional\n        self.default = default\n\nclass DocstringReturns(DocstringMeta):\n    def __init__(self, args, description, type_name=None, is_generator=False):\n        super().__init__(args, description)\n        self.type_name = type_name\n        self.is_generator = is_generator\n\nclass DocstringRaises(DocstringMeta):\n    def __init__(self, args, description, type_name=None):\n        super().__init__(args, description)\n        self.type_name = type_name\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected parameter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def parse(self, text: str) -> Docstring:\n        ret = Docstring()\n        if not text:\n            return ret\n\n        text = inspect.cleandoc(text)\n\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start():]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\"\\n\")\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        for title, chunk in chunks.items():\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError(f\"Can't infer indent from \\\"{chunk}\\\"\")\n            indent = indent_match.group()\n\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(f'No specification for \"{title}\": \"{chunk}\"')\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n"]}
{"task_id": 166, "project": "test-apps/docstring_parser", "module": "docstring_parser.rest", "predictions": ["import re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    if not text:\n        return Docstring(short_description=None, long_description=None, meta=[])\n\n    # Normalize line endings and split into lines\n    lines = text.expandtabs().splitlines()\n\n    # Separate short_description, long_description, and meta sections\n    # According to ReST conventions, short description is the first non-empty line or paragraph,\n    # then an optional blank line, then long description (paragraphs before any field list),\n    # followed by optional field lists (meta).\n\n    short_description = None\n    long_description_lines = []\n    meta_lines = []\n\n    # State machine: 0=collect short desc, 1=collect long desc, 2=collect meta\n    state = 0\n\n    # Helper to detect if a line starts a field list directive (e.g. \":param\")\n    field_list_re = re.compile(r\"^:(\\w+)(?:\\s+[^:]*)?:\")  # matches e.g. \":param foo:\", \":returns:\", \":raises Exception:\"\n\n    buffer = []  # buffer lines of current paragraph\n\n    def flush_buffer_to_long_description():\n        nonlocal long_description_lines, buffer\n        if buffer:\n            if long_description_lines:\n                long_description_lines.append(\"\")\n            long_description_lines.extend(buffer)\n            buffer = []\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n\n        if state == 0:\n            # Skip blank lines at the start\n            if not stripped:\n                continue\n            # first paragraph is short description until blank line\n            buffer.append(stripped)\n            # Look ahead to see if next line is blank or absent - if yes, short desc done\n            next_is_blank = (i + 1 >= len(lines)) or (lines[i + 1].strip() == \"\")\n            if next_is_blank:\n                short_description = \" \".join(buffer)\n                buffer = []\n                state = 1\n            # else keep accumulating short description lines (if spread across multiple lines)\n        elif state == 1:\n            # Collect long description lines until blank line before meta\n            if not stripped:\n                # blank line indicates paragraph separation or end of long desc\n                if buffer:\n                    flush_buffer_to_long_description()\n                # After blank line, if next non-blank line starts with colon, start meta\n                # peek ahead\n                peek_j = i + 1\n                while peek_j < len(lines) and lines[peek_j].strip() == \"\":\n                    peek_j += 1\n                if peek_j < len(lines) and field_list_re.match(lines[peek_j].lstrip()):\n                    state = 2\n                else:\n                    # keep long description accumulating blank lines as paragraph separation\n                    # Long description can have multiple paragraphs separated by blank lines\n                    long_description_lines.append(\"\")\n            else:\n                # Check if this line is start of meta section (field list)\n                if field_list_re.match(line.lstrip()):\n                    if buffer:\n                        flush_buffer_to_long_description()\n                    state = 2\n                    meta_lines.append(line)\n                else:\n                    buffer.append(line)\n        else:\n            # state == 2, meta lines\n            meta_lines.append(line)\n\n    # If finished parsing but buffer non-empty and in long description\n    if state == 1 and buffer:\n        flush_buffer_to_long_description()\n\n    # Clean long_description text\n    long_description = None\n    if long_description_lines:\n        # Remove trailing blank lines\n        while long_description_lines and long_description_lines[-1].strip() == \"\":\n            long_description_lines.pop()\n        long_description = \"\\n\".join(long_description_lines) if long_description_lines else None\n\n    meta: T.List[DocstringMeta] = []\n\n    # Parse meta_lines into DocstringMeta objects\n    # Meta lines may contain multiple field entries.\n    # The format generally is:\n    #   :keyword [type] name: description...\n    # We must parse each directive line and collect continuation lines indented.\n\n    # Group meta lines by entries starting with ':keyword'\n    entries = []\n    current_entry_lines = []\n\n    for line in meta_lines:\n        if re.match(r\"^:\\w+\", line.lstrip()):\n            # new entry starts\n            if current_entry_lines:\n                entries.append(current_entry_lines)\n            current_entry_lines = [line]\n        else:\n            # continuation line for current meta entry (usually indented)\n            if current_entry_lines:\n                current_entry_lines.append(line)\n            else:\n                # strange case: continuation with no current entry - ignore or treat as normal?\n                # We ignore dangling lines outside meta entry\n                pass\n    if current_entry_lines:\n        entries.append(current_entry_lines)\n\n    # Helper to parse one meta entry block into args and description\n    for entry_lines in entries:\n        # The first line contains the field keyword and its arguments, e.g.\n        # \":param int foo: description\"\n        first_line = entry_lines[0].lstrip()\n\n        # match keyword and args up to colon\n        m = re.match(r\"^:(\\w+)(?:\\s+(.*?))?:\\s*(.*)$\", first_line)\n        if not m:\n            # Doesn't match expected pattern, ignore or treat as generic meta\n            # We'll store whole lines as description, with args = [first word]\n            args = [first_line[1:].split()[0]]\n            desc = \"\\n\".join(line.strip() for line in entry_lines[1:])\n            meta.append(DocstringMeta(args=args, description=desc))\n            continue\n\n        key_word = m.group(1)\n        args_str = m.group(2) or \"\"\n        initial_desc = m.group(3)\n\n        # Compose args list: key_word + split args_str by whitespace (but keep sequence intact)\n        args: T.List[str] = [key_word]\n        if args_str:\n            args.extend(args_str.split())\n\n        # Description possibly continues in subsequent indented lines\n        # Join description lines, stripping leading whitespace (usual reST indent is 3 or more)\n        continuation_desc = []\n        for cont_line in entry_lines[1:]:\n            # Strip at most 4 spaces from continuation lines (typical indent)\n            continuation_desc.append(cont_line.lstrip(\" \\t\"))\n        full_desc = initial_desc\n        if continuation_desc:\n            if full_desc:\n                full_desc += \"\\n\" + \"\\n\".join(continuation_desc)\n            else:\n                full_desc = \"\\n\".join(continuation_desc)\n\n        try:\n            meta_obj = _build_meta(args, full_desc)\n        except ParseError:\n            meta_obj = DocstringMeta(args=args, description=full_desc)\n\n        meta.append(meta_obj)\n\n    return Docstring(\n        short_description=short_description if short_description else None,\n        long_description=long_description,\n        meta=meta,\n    )", "import re\nfrom typing import List\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    if not text:\n        # Empty docstring, return empty Docstring object with no content\n        return Docstring(\"\", [], [], [], [])\n\n    lines = text.splitlines()\n\n    short_description_lines: List[str] = []\n    long_description_lines: List[str] = []\n    meta_blocks: List[str] = []\n\n    # States to track parsing phases\n    in_short_desc = True\n    in_long_desc = False\n    in_meta = False\n\n    # Regex to detect meta lines (e.g. :param int foo: description)\n    meta_line_re = re.compile(r\"^:(\\w+)\")  # start with colon + word\n\n    # We will gather meta blocks that start with colon-prefixed lines\n    # A meta block can be multiple lines: first line with \":param ...\" then indented description lines\n\n    i = 0\n    n = len(lines)\n\n    # Step 1: Extract short description: first non-empty lines until an empty line or a meta line\n    while i < n:\n        line = lines[i]\n        stripped = line.strip()\n        if stripped == \"\":\n            # blank line ends short description\n            i += 1\n            if short_description_lines:\n                # Only end short desc if we have contents\n                break\n            # else continue skipping leading blank lines\n        elif meta_line_re.match(stripped):\n            # meta section start before short description ends means no short description\n            break\n        else:\n            short_description_lines.append(stripped)\n            i += 1\n\n    # Step 2: Extract long description: lines after short desc until meta or EOF\n    # Skip any blank lines right after short desc\n    while i < n and lines[i].strip() == \"\":\n        i += 1\n\n    # Collect lines until next meta or end\n    while i < n:\n        line = lines[i]\n        stripped = line.strip()\n        if meta_line_re.match(stripped):\n            break\n        long_description_lines.append(line)\n        i += 1\n\n    # Step 3: Extract meta blocks lines (starting at i)\n    # Each meta block begins with a line starting with \":\" and continues with indented lines\n    meta_blocks_lines = []\n    while i < n:\n        line = lines[i]\n        if not line.strip():\n            # blank lines inside meta blocks separate them, keep as some empty line\n            meta_blocks_lines.append(\"\")\n            i += 1\n            continue\n\n        if meta_line_re.match(line.strip()):\n            # start of a new meta block\n            block = [line.strip()]\n            i += 1\n            # collect following lines that are indented (start with space or tab)\n            while i < n:\n                next_line = lines[i]\n                if next_line.strip() == \"\":\n                    block.append(\"\")\n                    i += 1\n                elif next_line.startswith(\" \") or next_line.startswith(\"\\t\"):\n                    # continuation line (description continuation)\n                    block.append(next_line.strip())\n                    i += 1\n                else:\n                    break\n            meta_blocks_lines.append(\"\\n\".join(block))\n        else:\n            # unexpected line not starting with \":\"\n            # May be continuation but no indent, just break\n            i += 1\n\n    # Parse meta blocks lines into DocstringMeta (DocstringParam, DocstringReturns, etc)\n    meta: List[DocstringMeta] = []\n    for block in meta_blocks_lines:\n        if not block.strip():\n            # skip empty blocks\n            continue\n        # The first line contains the metadata keyword and optional arguments and description after colon\n        # example: \":param int foo: the foo parameter\"\n        # Extract args inside \":param int foo:\" and description text after colon:\n        # Match pattern of form \":keyword [args...]: description\"\n        m = re.match(r\"^:(\\w+)\\s*(.*?)\\s*:(.*)$\", block, flags=re.DOTALL)\n        if not m:\n            raise ParseError(f\"Unable to parse meta directive: {block!r}\")\n\n        key = m.group(1)\n        args_str = m.group(2).strip()\n        desc = m.group(3).strip()\n\n        # The block may have continuation lines in desc, appended after first line's desc\n        # The block lines after first line are after first line's desc\n        # For now desc should contain all continuation lines joined by space or newlines.\n        # But since we stripped and joined lines with '\\n', let's preserve \\n in desc\n\n        # Actually desc may contain newlines due to the block join with \\n, so better to\n        # re-collect desc lines after colon line\n\n        desc_lines = [desc]\n        block_lines = block.splitlines()\n        # first line is \":keyword args: desc\"\n        # continuation lines start at line index 1\n        for cont_line in block_lines[1:]:\n            if cont_line.strip():\n                desc_lines.append(cont_line.strip())\n            else:\n                desc_lines.append(\"\")\n\n        full_desc = \"\\n\".join(desc_lines).strip()\n\n        # Arguments can be split by spaces, e.g. \"int foo\" -> ['int', 'foo']\n        # But the _build_meta expects a list with first element = key\n        # number of args depends on the key and format:\n        # param -> :param [type] name:\n        # returns -> :returns [type]:\n        # raises -> :raises [type]:\n        # yields -> :yields [type]:\n\n        # split args_str on spaces to get arguments (might be empty)\n        args = [key]\n        if args_str:\n            args.extend(args_str.split())\n\n        try:\n            meta_obj = _build_meta(args, full_desc)\n        except ParseError as e:\n            raise ParseError(f\"{e} (in meta block: {block!r})\") from e\n\n        meta.append(meta_obj)\n\n    short_description = \"\\n\".join(short_description_lines).strip() or None\n    long_description = \"\\n\".join(long_description_lines).strip() or None\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        params=[m for m in meta if isinstance(m, DocstringParam)],\n        returns=next((m for m in meta if isinstance(m, DocstringReturns)), None),\n        raises=[m for m in meta if isinstance(m, DocstringRaises)],\n        meta=[m for m in meta if not isinstance(m, (DocstringParam, DocstringReturns, DocstringRaises))],\n    )", "import re\nfrom typing import List, Optional\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    lines = text.expandtabs().splitlines()\n    lines = [line.rstrip() for line in lines]\n\n    short_descr_lines: List[str] = []\n    long_descr_lines: List[str] = []\n    meta_lines: List[str] = []\n\n    state = \"short_descr\"  # states: short_descr, blank_after_short_descr, long_descr, meta\n    meta_indent: Optional[int] = None\n\n    for index, line in enumerate(lines):\n        stripped = line.lstrip()\n        indent = len(line) - len(stripped)\n\n        # Detect meta lines which start with ':'\n        if stripped.startswith(\":\"):\n            state = \"meta\"\n            # Capture the indent level for meta lines to detect continuation lines\n            meta_indent = indent\n            meta_lines.append(line)\n            continue\n\n        if state == \"short_descr\":\n            if not line.strip():\n                state = \"blank_after_short_descr\"\n            else:\n                short_descr_lines.append(line)\n        elif state == \"blank_after_short_descr\":\n            if not line.strip():\n                # consecutive blank lines after short descr, continue waiting\n                continue\n            elif stripped.startswith(\":\"):\n                # first meta line after short descr\n                state = \"meta\"\n                meta_indent = indent\n                meta_lines.append(line)\n            else:\n                # non-meta line means start of long description\n                state = \"long_descr\"\n                long_descr_lines.append(line)\n        elif state == \"long_descr\":\n            if not line.strip():\n                long_descr_lines.append(line)\n            elif stripped.startswith(\":\"):\n                state = \"meta\"\n                meta_indent = indent\n                meta_lines.append(line)\n            else:\n                long_descr_lines.append(line)\n        elif state == \"meta\":\n            # Handle continuation lines indented more than meta_indent\n            if line.strip() == \"\":\n                # Blank lines inside meta treated as separation? Include to keep descriptions multi-line\n                meta_lines.append(line)\n            elif indent > meta_indent:\n                meta_lines.append(line)\n            else:\n                # New meta line or end\n                if stripped.startswith(\":\"):\n                    meta_indent = indent\n                    meta_lines.append(line)\n                else:\n                    # Not a meta line and not indented more - probably invalid or descriptive paragraph\n                    # In practice, this is ignored or treated as invalid meta, but we treat as meta line continuation if rare.\n                    meta_lines.append(line)\n\n    # Compose short and long descriptions, join lines preserving blank lines (empty lines)\n    # Strip trailing empty lines\n    while short_descr_lines and not short_descr_lines[-1].strip():\n        short_descr_lines.pop()\n    short_description = \"\\n\".join(short_descr_lines).strip()\n\n    while long_descr_lines and not long_descr_lines[-1].strip():\n        long_descr_lines.pop()\n    long_description = \"\\n\".join(long_descr_lines).strip()\n\n    # Parse meta lines into DocstringMeta objects\n    meta: List[DocstringMeta] = []\n    if meta_lines:\n        # Join meta lines into logical blocks\n        blocks: List[List[str]] = []\n        current_block: List[str] = []\n\n        for line in meta_lines:\n            stripped = line.lstrip()\n            if stripped.startswith(\":\"):\n                # Start of new block\n                if current_block:\n                    blocks.append(current_block)\n                current_block = [line]\n            else:\n                # continuation line, add to current block\n                if current_block:\n                    current_block.append(line)\n                else:\n                    # stray continuation line before any meta, ignore or start new (unlikely)\n                    current_block = [line]\n        if current_block:\n            blocks.append(current_block)\n\n        # Process each block\n        for block_lines in blocks:\n            # Merge block lines into a single string\n            # The first line starts with \":\" which introduces a field\n            first_line = block_lines[0].lstrip()\n            # Extract the key and args from the first line: pattern :key[arg1 arg2]: description\n            # We can match pattern: ^:(\\w+)([^\\:]*)\\:(.*)$\n            m = re.match(r\"^:(\\w+)([^:]*)\\:(.*)$\", first_line)\n            if not m:\n                raise ParseError(f\"Malformed field line: {first_line}\")\n\n            key = m.group(1)\n            args_part = m.group(2).strip()\n            desc_part = m.group(3).lstrip()\n\n            # Extract arguments separated by spaces (but keep quoted? No quotes used in ReST by default)\n            args = [key] + args_part.split() if args_part else [key]\n\n            # Description includes desc_part plus continuation lines unindented relative to first line\n            if len(block_lines) > 1:\n                # strip the indentation from continuation lines\n                continuation = []\n                # Determine minimum indentation of continuation lines (ignore empty lines)\n                cont_lines = block_lines[1:]\n                min_indent = None\n                for cont_line in cont_lines:\n                    if cont_line.strip():\n                        ind = len(cont_line) - len(cont_line.lstrip())\n                        if min_indent is None or ind < min_indent:\n                            min_indent = ind\n                if min_indent is None:\n                    min_indent = 0\n                for cont_line in cont_lines:\n                    # de-indent by min_indent\n                    if len(cont_line) >= min_indent:\n                        continuation.append(cont_line[min_indent:])\n                    else:\n                        continuation.append(cont_line.lstrip())\n                continuation_text = \"\\n\".join(continuation).rstrip()\n                if continuation_text:\n                    if desc_part:\n                        desc = desc_part + \"\\n\" + continuation_text\n                    else:\n                        desc = continuation_text\n                else:\n                    desc = desc_part\n            else:\n                desc = desc_part\n\n            # Build the meta object using _build_meta\n            meta_obj = _build_meta(args, desc)\n            meta.append(meta_obj)\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )", "import re\nfrom typing import List\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    DocstringMeta,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize line endings and split lines\n    lines = text.expandtabs().splitlines()\n    # Strip trailing and leading empty lines\n    while lines and lines[0].strip() == \"\":\n        lines.pop(0)\n    while lines and lines[-1].strip() == \"\":\n        lines.pop()\n\n    summary_lines = []\n    extended_desc_lines = []\n    meta_lines = []\n\n    # States for parsing\n    # 0 = parsing summary (first paragraph)\n    # 1 = parsing extended description (after first blank line)\n    # 2 = parsing meta block (lines starting with :keyword: etc)\n    state = 0\n\n    # We will join meta lines into blocks separated by blank lines\n    # to parse individual meta entries independently\n    # Accumulate meta blocks as lists of lines\n    meta_blocks = []\n    current_meta_block = []\n\n    # A regex to detect meta keywords lines like: \":param str name: ...\"\n    meta_re = re.compile(r\"^:([^:\\s]+)(?:\\s+([^:]*?))?(?:\\s+([^:]+?))?:\\s*(.*)\")\n\n    # Process lines to separate summary, extended desc and meta blocks\n    line_iter = iter(lines)\n    for line in line_iter:\n        stripped = line.strip()\n\n        if state == 0:\n            # Accumulate summary lines until first blank line\n            if stripped == \"\":\n                # blank line ends summary\n                state = 1\n            else:\n                summary_lines.append(line)\n        elif state == 1:\n            # After summary, accumulate extended description lines until blank line preceding meta or meta line\n            if stripped == \"\":\n                # blank line, continue extended description lines\n                extended_desc_lines.append(line)\n            elif meta_re.match(stripped):\n                # meta block starts\n                state = 2\n                current_meta_block.append(line)\n            else:\n                # Any other non-blank non-meta line belongs to extended description\n                extended_desc_lines.append(line)\n        else:  # state == 2 (parsing meta)\n            if stripped == \"\":\n                # blank line denotes end of current meta block\n                if current_meta_block:\n                    meta_blocks.append(current_meta_block)\n                    current_meta_block = []\n            else:\n                # continuation or new meta line\n                # if line starts with colon + keyword, it's a new meta entry\n                if meta_re.match(stripped):\n                    if current_meta_block:\n                        meta_blocks.append(current_meta_block)\n                    current_meta_block = [line]\n                else:\n                    # continuation line, indent or not, join to last meta block line\n                    current_meta_block.append(line)\n\n    # Append any remaining meta block\n    if current_meta_block:\n        meta_blocks.append(current_meta_block)\n\n    # Join summary and extended description\n    summary = \"\\n\".join(summary_lines).strip()\n    extended_description = \"\\n\".join(extended_desc_lines).strip()\n\n    params: List[DocstringParam] = []\n    returns = None\n    yields = None\n    raises: List[DocstringRaises] = []\n    metas: List[DocstringMeta] = []\n\n    # Helper to parse each meta block into DocstringMeta subclass\n    for block_lines in meta_blocks:\n        # Join block lines with newlines to a single string, then split first line for keys\n        first_line = block_lines[0]\n        m = meta_re.match(first_line.strip())\n        if not m:\n            # If no match, ignore this block (should not happen)\n            continue\n        keyword, arg1, arg2, desc = m.groups()\n        # Compose args list\n        args = [keyword]\n        if arg1 is not None and arg1 != \"\":\n            args.append(arg1)\n        if arg2 is not None and arg2 != \"\":\n            args.append(arg2)\n\n        # Join continuation lines into description\n        if len(block_lines) > 1:\n            # continuation lines: join them preserving newline and indentation\n            desc_lines = [desc] + [line.strip() for line in block_lines[1:]]\n            desc = \"\\n\".join(desc_lines).strip()\n        else:\n            desc = desc.strip()\n\n        # Use _build_meta to parse this entry\n        try:\n            meta = _build_meta(args, desc)\n        except ParseError:\n            # If parsing fails, treat as generic meta\n            meta = DocstringMeta(args=args, description=desc)\n\n        # Collect meta according to type\n        if isinstance(meta, DocstringParam):\n            params.append(meta)\n        elif isinstance(meta, DocstringReturns):\n            returns = meta\n        elif isinstance(meta, DocstringReturns) and meta.is_generator:\n            yields = meta\n        elif isinstance(meta, DocstringRaises):\n            raises.append(meta)\n        else:\n            metas.append(meta)\n\n    return Docstring(\n        short_description=summary,\n        long_description=extended_description if extended_description else None,\n        params=params,\n        returns=returns,\n        yields=yields,\n        raises=raises,\n        metas=metas,\n    )", "import re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    lines = text.strip().splitlines()\n    short_description_lines = []\n    long_description_lines = []\n    metas: T.List[DocstringMeta] = []\n\n    # Stage tracking:\n    # 0 = before first blank line (short description)\n    # 1 = after first blank line (long description or metas)\n    # 2 = after metas started\n    stage = 0\n\n    # Buffer for lines belonging to a meta entry we are parsing\n    meta_lines: T.List[str] = []\n\n    def flush_meta():\n        \"\"\"Parse the buffered meta lines and add to metas if any.\"\"\"\n        if not meta_lines:\n            return\n        first_line = meta_lines[0]\n        # Meta lines start with ':' and have the form:\n        # :key [type] name: description\n        m = re.match(r\"^:([^:]+):\\s*(.*)$\", first_line)\n        if not m:\n            # Not a meta, ignore buffer\n            meta_lines.clear()\n            return\n        key_args_part = m.group(1).strip()  # e.g. \"param int foo\"\n        desc_part = m.group(2).strip()  # first line description part\n\n        # Split key_args_part by whitespace but respecting brackets and question marks in types\n        # Usually, these are like \"param int foo\" or \"param foo\"\n\n        # A simple split is ok if we assume no spaces inside type names\n        args = key_args_part.split()\n        # Append remaining description lines\n        if len(meta_lines) > 1:\n            desc_full = desc_part + \"\\n\" + \"\\n\".join(line.strip() for line in meta_lines[1:])\n        else:\n            desc_full = desc_part\n\n        try:\n            meta = _build_meta(args, desc_full)\n            metas.append(meta)\n        except ParseError:\n            # In case of parse error, ignore this meta\n            pass\n        meta_lines.clear()\n\n    for line in lines:\n        stripped = line.strip()\n        if stage == 0:\n            if stripped == \"\":\n                # End of short description\n                stage = 1\n            else:\n                short_description_lines.append(stripped)\n        elif stage == 1:\n            if stripped == \"\":\n                # Blank lines separate sections, continue gathering long description lines\n                long_description_lines.append(\"\")\n            elif stripped.startswith(\":\"):\n                # Meta entry starts\n                flush_meta()\n                meta_lines.append(line)\n                stage = 2\n            else:\n                long_description_lines.append(stripped)\n        else:  # stage == 2, parsing metas\n            if stripped.startswith(\":\"):\n                flush_meta()\n                meta_lines.append(line)\n            else:\n                # Continuation line for meta description (indented or blank line)\n                # Append original line preserving indentation for multi-line description\n                meta_lines.append(line)\n\n    # Flush any remaining meta lines after loop ends\n    flush_meta()\n\n    short_description = (\n        \" \".join(short_description_lines).strip() if short_description_lines else None\n    )\n    if long_description_lines:\n        # Normalize long description: join lines by newlines; preserve paragraphs as blank lines\n        long_description = \"\\n\".join(long_description_lines).strip()\n    else:\n        long_description = None\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=metas,\n    )"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    if not text:\n        return Docstring(short_description=None, long_description=None, meta=[])\n\n    # Normalize line endings and split into lines\n    lines = text.expandtabs().splitlines()\n\n    # Separate short_description, long_description, and meta sections\n    # According to ReST conventions, short description is the first non-empty line or paragraph,\n    # then an optional blank line, then long description (paragraphs before any field list),\n    # followed by optional field lists (meta).\n\n    short_description = None\n    long_description_lines = []\n    meta_lines = []\n\n    # State machine: 0=collect short desc, 1=collect long desc, 2=collect meta\n    state = 0\n\n    # Helper to detect if a line starts a field list directive (e.g. \":param\")\n    field_list_re = re.compile(r\"^:(\\w+)(?:\\s+[^:]*)?:\")  # matches e.g. \":param foo:\", \":returns:\", \":raises Exception:\"\n\n    buffer = []  # buffer lines of current paragraph\n\n    def flush_buffer_to_long_description():\n        nonlocal long_description_lines, buffer\n        if buffer:\n            if long_description_lines:\n                long_description_lines.append(\"\")\n            long_description_lines.extend(buffer)\n            buffer = []\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n\n        if state == 0:\n            # Skip blank lines at the start\n            if not stripped:\n                continue\n            # first paragraph is short description until blank line\n            buffer.append(stripped)\n            # Look ahead to see if next line is blank or absent - if yes, short desc done\n            next_is_blank = (i + 1 >= len(lines)) or (lines[i + 1].strip() == \"\")\n            if next_is_blank:\n                short_description = \" \".join(buffer)\n                buffer = []\n                state = 1\n            # else keep accumulating short description lines (if spread across multiple lines)\n        elif state == 1:\n            # Collect long description lines until blank line before meta\n            if not stripped:\n                # blank line indicates paragraph separation or end of long desc\n                if buffer:\n                    flush_buffer_to_long_description()\n                # After blank line, if next non-blank line starts with colon, start meta\n                # peek ahead\n                peek_j = i + 1\n                while peek_j < len(lines) and lines[peek_j].strip() == \"\":\n                    peek_j += 1\n                if peek_j < len(lines) and field_list_re.match(lines[peek_j].lstrip()):\n                    state = 2\n                else:\n                    # keep long description accumulating blank lines as paragraph separation\n                    # Long description can have multiple paragraphs separated by blank lines\n                    long_description_lines.append(\"\")\n            else:\n                # Check if this line is start of meta section (field list)\n                if field_list_re.match(line.lstrip()):\n                    if buffer:\n                        flush_buffer_to_long_description()\n                    state = 2\n                    meta_lines.append(line)\n                else:\n                    buffer.append(line)\n        else:\n            # state == 2, meta lines\n            meta_lines.append(line)\n\n    # If finished parsing but buffer non-empty and in long description\n    if state == 1 and buffer:\n        flush_buffer_to_long_description()\n\n    # Clean long_description text\n    long_description = None\n    if long_description_lines:\n        # Remove trailing blank lines\n        while long_description_lines and long_description_lines[-1].strip() == \"\":\n            long_description_lines.pop()\n        long_description = \"\\n\".join(long_description_lines) if long_description_lines else None\n\n    meta: T.List[DocstringMeta] = []\n\n    # Parse meta_lines into DocstringMeta objects\n    # Meta lines may contain multiple field entries.\n    # The format generally is:\n    #   :keyword [type] name: description...\n    # We must parse each directive line and collect continuation lines indented.\n\n    # Group meta lines by entries starting with ':keyword'\n    entries = []\n    current_entry_lines = []\n\n    for line in meta_lines:\n        if re.match(r\"^:\\w+\", line.lstrip()):\n            # new entry starts\n            if current_entry_lines:\n                entries.append(current_entry_lines)\n            current_entry_lines = [line]\n        else:\n            # continuation line for current meta entry (usually indented)\n            if current_entry_lines:\n                current_entry_lines.append(line)\n            else:\n                # strange case: continuation with no current entry - ignore or treat as normal?\n                # We ignore dangling lines outside meta entry\n                pass\n    if current_entry_lines:\n        entries.append(current_entry_lines)\n\n    # Helper to parse one meta entry block into args and description\n    for entry_lines in entries:\n        # The first line contains the field keyword and its arguments, e.g.\n        # \":param int foo: description\"\n        first_line = entry_lines[0].lstrip()\n\n        # match keyword and args up to colon\n        m = re.match(r\"^:(\\w+)(?:\\s+(.*?))?:\\s*(.*)$\", first_line)\n        if not m:\n            # Doesn't match expected pattern, ignore or treat as generic meta\n            # We'll store whole lines as description, with args = [first word]\n            args = [first_line[1:].split()[0]]\n            desc = \"\\n\".join(line.strip() for line in entry_lines[1:])\n            meta.append(DocstringMeta(args=args, description=desc))\n            continue\n\n        key_word = m.group(1)\n        args_str = m.group(2) or \"\"\n        initial_desc = m.group(3)\n\n        # Compose args list: key_word + split args_str by whitespace (but keep sequence intact)\n        args: T.List[str] = [key_word]\n        if args_str:\n            args.extend(args_str.split())\n\n        # Description possibly continues in subsequent indented lines\n        # Join description lines, stripping leading whitespace (usual reST indent is 3 or more)\n        continuation_desc = []\n        for cont_line in entry_lines[1:]:\n            # Strip at most 4 spaces from continuation lines (typical indent)\n            continuation_desc.append(cont_line.lstrip(\" \\t\"))\n        full_desc = initial_desc\n        if continuation_desc:\n            if full_desc:\n                full_desc += \"\\n\" + \"\\n\".join(continuation_desc)\n            else:\n                full_desc = \"\\n\".join(continuation_desc)\n\n        try:\n            meta_obj = _build_meta(args, full_desc)\n        except ParseError:\n            meta_obj = DocstringMeta(args=args, description=full_desc)\n\n        meta.append(meta_obj)\n\n    return Docstring(\n        short_description=short_description if short_description else None,\n        long_description=long_description,\n        meta=meta,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport re\nfrom typing import List\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    if not text:\n        # Empty docstring, return empty Docstring object with no content\n        return Docstring(\"\", [], [], [], [])\n\n    lines = text.splitlines()\n\n    short_description_lines: List[str] = []\n    long_description_lines: List[str] = []\n    meta_blocks: List[str] = []\n\n    # States to track parsing phases\n    in_short_desc = True\n    in_long_desc = False\n    in_meta = False\n\n    # Regex to detect meta lines (e.g. :param int foo: description)\n    meta_line_re = re.compile(r\"^:(\\w+)\")  # start with colon + word\n\n    # We will gather meta blocks that start with colon-prefixed lines\n    # A meta block can be multiple lines: first line with \":param ...\" then indented description lines\n\n    i = 0\n    n = len(lines)\n\n    # Step 1: Extract short description: first non-empty lines until an empty line or a meta line\n    while i < n:\n        line = lines[i]\n        stripped = line.strip()\n        if stripped == \"\":\n            # blank line ends short description\n            i += 1\n            if short_description_lines:\n                # Only end short desc if we have contents\n                break\n            # else continue skipping leading blank lines\n        elif meta_line_re.match(stripped):\n            # meta section start before short description ends means no short description\n            break\n        else:\n            short_description_lines.append(stripped)\n            i += 1\n\n    # Step 2: Extract long description: lines after short desc until meta or EOF\n    # Skip any blank lines right after short desc\n    while i < n and lines[i].strip() == \"\":\n        i += 1\n\n    # Collect lines until next meta or end\n    while i < n:\n        line = lines[i]\n        stripped = line.strip()\n        if meta_line_re.match(stripped):\n            break\n        long_description_lines.append(line)\n        i += 1\n\n    # Step 3: Extract meta blocks lines (starting at i)\n    # Each meta block begins with a line starting with \":\" and continues with indented lines\n    meta_blocks_lines = []\n    while i < n:\n        line = lines[i]\n        if not line.strip():\n            # blank lines inside meta blocks separate them, keep as some empty line\n            meta_blocks_lines.append(\"\")\n            i += 1\n            continue\n\n        if meta_line_re.match(line.strip()):\n            # start of a new meta block\n            block = [line.strip()]\n            i += 1\n            # collect following lines that are indented (start with space or tab)\n            while i < n:\n                next_line = lines[i]\n                if next_line.strip() == \"\":\n                    block.append(\"\")\n                    i += 1\n                elif next_line.startswith(\" \") or next_line.startswith(\"\\t\"):\n                    # continuation line (description continuation)\n                    block.append(next_line.strip())\n                    i += 1\n                else:\n                    break\n            meta_blocks_lines.append(\"\\n\".join(block))\n        else:\n            # unexpected line not starting with \":\"\n            # May be continuation but no indent, just break\n            i += 1\n\n    # Parse meta blocks lines into DocstringMeta (DocstringParam, DocstringReturns, etc)\n    meta: List[DocstringMeta] = []\n    for block in meta_blocks_lines:\n        if not block.strip():\n            # skip empty blocks\n            continue\n        # The first line contains the metadata keyword and optional arguments and description after colon\n        # example: \":param int foo: the foo parameter\"\n        # Extract args inside \":param int foo:\" and description text after colon:\n        # Match pattern of form \":keyword [args...]: description\"\n        m = re.match(r\"^:(\\w+)\\s*(.*?)\\s*:(.*)$\", block, flags=re.DOTALL)\n        if not m:\n            raise ParseError(f\"Unable to parse meta directive: {block!r}\")\n\n        key = m.group(1)\n        args_str = m.group(2).strip()\n        desc = m.group(3).strip()\n\n        # The block may have continuation lines in desc, appended after first line's desc\n        # The block lines after first line are after first line's desc\n        # For now desc should contain all continuation lines joined by space or newlines.\n        # But since we stripped and joined lines with '\\n', let's preserve \\n in desc\n\n        # Actually desc may contain newlines due to the block join with \\n, so better to\n        # re-collect desc lines after colon line\n\n        desc_lines = [desc]\n        block_lines = block.splitlines()\n        # first line is \":keyword args: desc\"\n        # continuation lines start at line index 1\n        for cont_line in block_lines[1:]:\n            if cont_line.strip():\n                desc_lines.append(cont_line.strip())\n            else:\n                desc_lines.append(\"\")\n\n        full_desc = \"\\n\".join(desc_lines).strip()\n\n        # Arguments can be split by spaces, e.g. \"int foo\" -> ['int', 'foo']\n        # But the _build_meta expects a list with first element = key\n        # number of args depends on the key and format:\n        # param -> :param [type] name:\n        # returns -> :returns [type]:\n        # raises -> :raises [type]:\n        # yields -> :yields [type]:\n\n        # split args_str on spaces to get arguments (might be empty)\n        args = [key]\n        if args_str:\n            args.extend(args_str.split())\n\n        try:\n            meta_obj = _build_meta(args, full_desc)\n        except ParseError as e:\n            raise ParseError(f\"{e} (in meta block: {block!r})\") from e\n\n        meta.append(meta_obj)\n\n    short_description = \"\\n\".join(short_description_lines).strip() or None\n    long_description = \"\\n\".join(long_description_lines).strip() or None\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        params=[m for m in meta if isinstance(m, DocstringParam)],\n        returns=next((m for m in meta if isinstance(m, DocstringReturns)), None),\n        raises=[m for m in meta if isinstance(m, DocstringRaises)],\n        meta=[m for m in meta if not isinstance(m, (DocstringParam, DocstringReturns, DocstringRaises))],\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport re\nfrom typing import List, Optional\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    lines = text.expandtabs().splitlines()\n    lines = [line.rstrip() for line in lines]\n\n    short_descr_lines: List[str] = []\n    long_descr_lines: List[str] = []\n    meta_lines: List[str] = []\n\n    state = \"short_descr\"  # states: short_descr, blank_after_short_descr, long_descr, meta\n    meta_indent: Optional[int] = None\n\n    for index, line in enumerate(lines):\n        stripped = line.lstrip()\n        indent = len(line) - len(stripped)\n\n        # Detect meta lines which start with ':'\n        if stripped.startswith(\":\"):\n            state = \"meta\"\n            # Capture the indent level for meta lines to detect continuation lines\n            meta_indent = indent\n            meta_lines.append(line)\n            continue\n\n        if state == \"short_descr\":\n            if not line.strip():\n                state = \"blank_after_short_descr\"\n            else:\n                short_descr_lines.append(line)\n        elif state == \"blank_after_short_descr\":\n            if not line.strip():\n                # consecutive blank lines after short descr, continue waiting\n                continue\n            elif stripped.startswith(\":\"):\n                # first meta line after short descr\n                state = \"meta\"\n                meta_indent = indent\n                meta_lines.append(line)\n            else:\n                # non-meta line means start of long description\n                state = \"long_descr\"\n                long_descr_lines.append(line)\n        elif state == \"long_descr\":\n            if not line.strip():\n                long_descr_lines.append(line)\n            elif stripped.startswith(\":\"):\n                state = \"meta\"\n                meta_indent = indent\n                meta_lines.append(line)\n            else:\n                long_descr_lines.append(line)\n        elif state == \"meta\":\n            # Handle continuation lines indented more than meta_indent\n            if line.strip() == \"\":\n                # Blank lines inside meta treated as separation? Include to keep descriptions multi-line\n                meta_lines.append(line)\n            elif indent > meta_indent:\n                meta_lines.append(line)\n            else:\n                # New meta line or end\n                if stripped.startswith(\":\"):\n                    meta_indent = indent\n                    meta_lines.append(line)\n                else:\n                    # Not a meta line and not indented more - probably invalid or descriptive paragraph\n                    # In practice, this is ignored or treated as invalid meta, but we treat as meta line continuation if rare.\n                    meta_lines.append(line)\n\n    # Compose short and long descriptions, join lines preserving blank lines (empty lines)\n    # Strip trailing empty lines\n    while short_descr_lines and not short_descr_lines[-1].strip():\n        short_descr_lines.pop()\n    short_description = \"\\n\".join(short_descr_lines).strip()\n\n    while long_descr_lines and not long_descr_lines[-1].strip():\n        long_descr_lines.pop()\n    long_description = \"\\n\".join(long_descr_lines).strip()\n\n    # Parse meta lines into DocstringMeta objects\n    meta: List[DocstringMeta] = []\n    if meta_lines:\n        # Join meta lines into logical blocks\n        blocks: List[List[str]] = []\n        current_block: List[str] = []\n\n        for line in meta_lines:\n            stripped = line.lstrip()\n            if stripped.startswith(\":\"):\n                # Start of new block\n                if current_block:\n                    blocks.append(current_block)\n                current_block = [line]\n            else:\n                # continuation line, add to current block\n                if current_block:\n                    current_block.append(line)\n                else:\n                    # stray continuation line before any meta, ignore or start new (unlikely)\n                    current_block = [line]\n        if current_block:\n            blocks.append(current_block)\n\n        # Process each block\n        for block_lines in blocks:\n            # Merge block lines into a single string\n            # The first line starts with \":\" which introduces a field\n            first_line = block_lines[0].lstrip()\n            # Extract the key and args from the first line: pattern :key[arg1 arg2]: description\n            # We can match pattern: ^:(\\w+)([^\\:]*)\\:(.*)$\n            m = re.match(r\"^:(\\w+)([^:]*)\\:(.*)$\", first_line)\n            if not m:\n                raise ParseError(f\"Malformed field line: {first_line}\")\n\n            key = m.group(1)\n            args_part = m.group(2).strip()\n            desc_part = m.group(3).lstrip()\n\n            # Extract arguments separated by spaces (but keep quoted? No quotes used in ReST by default)\n            args = [key] + args_part.split() if args_part else [key]\n\n            # Description includes desc_part plus continuation lines unindented relative to first line\n            if len(block_lines) > 1:\n                # strip the indentation from continuation lines\n                continuation = []\n                # Determine minimum indentation of continuation lines (ignore empty lines)\n                cont_lines = block_lines[1:]\n                min_indent = None\n                for cont_line in cont_lines:\n                    if cont_line.strip():\n                        ind = len(cont_line) - len(cont_line.lstrip())\n                        if min_indent is None or ind < min_indent:\n                            min_indent = ind\n                if min_indent is None:\n                    min_indent = 0\n                for cont_line in cont_lines:\n                    # de-indent by min_indent\n                    if len(cont_line) >= min_indent:\n                        continuation.append(cont_line[min_indent:])\n                    else:\n                        continuation.append(cont_line.lstrip())\n                continuation_text = \"\\n\".join(continuation).rstrip()\n                if continuation_text:\n                    if desc_part:\n                        desc = desc_part + \"\\n\" + continuation_text\n                    else:\n                        desc = continuation_text\n                else:\n                    desc = desc_part\n            else:\n                desc = desc_part\n\n            # Build the meta object using _build_meta\n            meta_obj = _build_meta(args, desc)\n            meta.append(meta_obj)\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport re\nfrom typing import List\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    DocstringMeta,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize line endings and split lines\n    lines = text.expandtabs().splitlines()\n    # Strip trailing and leading empty lines\n    while lines and lines[0].strip() == \"\":\n        lines.pop(0)\n    while lines and lines[-1].strip() == \"\":\n        lines.pop()\n\n    summary_lines = []\n    extended_desc_lines = []\n    meta_lines = []\n\n    # States for parsing\n    # 0 = parsing summary (first paragraph)\n    # 1 = parsing extended description (after first blank line)\n    # 2 = parsing meta block (lines starting with :keyword: etc)\n    state = 0\n\n    # We will join meta lines into blocks separated by blank lines\n    # to parse individual meta entries independently\n    # Accumulate meta blocks as lists of lines\n    meta_blocks = []\n    current_meta_block = []\n\n    # A regex to detect meta keywords lines like: \":param str name: ...\"\n    meta_re = re.compile(r\"^:([^:\\s]+)(?:\\s+([^:]*?))?(?:\\s+([^:]+?))?:\\s*(.*)\")\n\n    # Process lines to separate summary, extended desc and meta blocks\n    line_iter = iter(lines)\n    for line in line_iter:\n        stripped = line.strip()\n\n        if state == 0:\n            # Accumulate summary lines until first blank line\n            if stripped == \"\":\n                # blank line ends summary\n                state = 1\n            else:\n                summary_lines.append(line)\n        elif state == 1:\n            # After summary, accumulate extended description lines until blank line preceding meta or meta line\n            if stripped == \"\":\n                # blank line, continue extended description lines\n                extended_desc_lines.append(line)\n            elif meta_re.match(stripped):\n                # meta block starts\n                state = 2\n                current_meta_block.append(line)\n            else:\n                # Any other non-blank non-meta line belongs to extended description\n                extended_desc_lines.append(line)\n        else:  # state == 2 (parsing meta)\n            if stripped == \"\":\n                # blank line denotes end of current meta block\n                if current_meta_block:\n                    meta_blocks.append(current_meta_block)\n                    current_meta_block = []\n            else:\n                # continuation or new meta line\n                # if line starts with colon + keyword, it's a new meta entry\n                if meta_re.match(stripped):\n                    if current_meta_block:\n                        meta_blocks.append(current_meta_block)\n                    current_meta_block = [line]\n                else:\n                    # continuation line, indent or not, join to last meta block line\n                    current_meta_block.append(line)\n\n    # Append any remaining meta block\n    if current_meta_block:\n        meta_blocks.append(current_meta_block)\n\n    # Join summary and extended description\n    summary = \"\\n\".join(summary_lines).strip()\n    extended_description = \"\\n\".join(extended_desc_lines).strip()\n\n    params: List[DocstringParam] = []\n    returns = None\n    yields = None\n    raises: List[DocstringRaises] = []\n    metas: List[DocstringMeta] = []\n\n    # Helper to parse each meta block into DocstringMeta subclass\n    for block_lines in meta_blocks:\n        # Join block lines with newlines to a single string, then split first line for keys\n        first_line = block_lines[0]\n        m = meta_re.match(first_line.strip())\n        if not m:\n            # If no match, ignore this block (should not happen)\n            continue\n        keyword, arg1, arg2, desc = m.groups()\n        # Compose args list\n        args = [keyword]\n        if arg1 is not None and arg1 != \"\":\n            args.append(arg1)\n        if arg2 is not None and arg2 != \"\":\n            args.append(arg2)\n\n        # Join continuation lines into description\n        if len(block_lines) > 1:\n            # continuation lines: join them preserving newline and indentation\n            desc_lines = [desc] + [line.strip() for line in block_lines[1:]]\n            desc = \"\\n\".join(desc_lines).strip()\n        else:\n            desc = desc.strip()\n\n        # Use _build_meta to parse this entry\n        try:\n            meta = _build_meta(args, desc)\n        except ParseError:\n            # If parsing fails, treat as generic meta\n            meta = DocstringMeta(args=args, description=desc)\n\n        # Collect meta according to type\n        if isinstance(meta, DocstringParam):\n            params.append(meta)\n        elif isinstance(meta, DocstringReturns):\n            returns = meta\n        elif isinstance(meta, DocstringReturns) and meta.is_generator:\n            yields = meta\n        elif isinstance(meta, DocstringRaises):\n            raises.append(meta)\n        else:\n            metas.append(meta)\n\n    return Docstring(\n        short_description=summary,\n        long_description=extended_description if extended_description else None,\n        params=params,\n        returns=returns,\n        yields=yields,\n        raises=raises,\n        metas=metas,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    lines = text.strip().splitlines()\n    short_description_lines = []\n    long_description_lines = []\n    metas: T.List[DocstringMeta] = []\n\n    # Stage tracking:\n    # 0 = before first blank line (short description)\n    # 1 = after first blank line (long description or metas)\n    # 2 = after metas started\n    stage = 0\n\n    # Buffer for lines belonging to a meta entry we are parsing\n    meta_lines: T.List[str] = []\n\n    def flush_meta():\n        \"\"\"Parse the buffered meta lines and add to metas if any.\"\"\"\n        if not meta_lines:\n            return\n        first_line = meta_lines[0]\n        # Meta lines start with ':' and have the form:\n        # :key [type] name: description\n        m = re.match(r\"^:([^:]+):\\s*(.*)$\", first_line)\n        if not m:\n            # Not a meta, ignore buffer\n            meta_lines.clear()\n            return\n        key_args_part = m.group(1).strip()  # e.g. \"param int foo\"\n        desc_part = m.group(2).strip()  # first line description part\n\n        # Split key_args_part by whitespace but respecting brackets and question marks in types\n        # Usually, these are like \"param int foo\" or \"param foo\"\n\n        # A simple split is ok if we assume no spaces inside type names\n        args = key_args_part.split()\n        # Append remaining description lines\n        if len(meta_lines) > 1:\n            desc_full = desc_part + \"\\n\" + \"\\n\".join(line.strip() for line in meta_lines[1:])\n        else:\n            desc_full = desc_part\n\n        try:\n            meta = _build_meta(args, desc_full)\n            metas.append(meta)\n        except ParseError:\n            # In case of parse error, ignore this meta\n            pass\n        meta_lines.clear()\n\n    for line in lines:\n        stripped = line.strip()\n        if stage == 0:\n            if stripped == \"\":\n                # End of short description\n                stage = 1\n            else:\n                short_description_lines.append(stripped)\n        elif stage == 1:\n            if stripped == \"\":\n                # Blank lines separate sections, continue gathering long description lines\n                long_description_lines.append(\"\")\n            elif stripped.startswith(\":\"):\n                # Meta entry starts\n                flush_meta()\n                meta_lines.append(line)\n                stage = 2\n            else:\n                long_description_lines.append(stripped)\n        else:  # stage == 2, parsing metas\n            if stripped.startswith(\":\"):\n                flush_meta()\n                meta_lines.append(line)\n            else:\n                # Continuation line for meta description (indented or blank line)\n                # Append original line preserving indentation for multi-line description\n                meta_lines.append(line)\n\n    # Flush any remaining meta lines after loop ends\n    flush_meta()\n\n    short_description = (\n        \" \".join(short_description_lines).strip() if short_description_lines else None\n    )\n    if long_description_lines:\n        # Normalize long description: join lines by newlines; preserve paragraphs as blank lines\n        long_description = \"\\n\".join(long_description_lines).strip()\n    else:\n        long_description = None\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=metas,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()"]}
{"task_id": 167, "project": "test-apps/docstring_parser", "module": "docstring_parser.numpydoc", "predictions": ["from typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "from typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "from docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "import inspect\nfrom typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "from .numpydoc import NumpydocParser\nfrom .common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nfrom typing import Optional\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom .numpydoc import NumpydocParser\nfrom .common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n"]}
