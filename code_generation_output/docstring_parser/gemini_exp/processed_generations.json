{"task_id": 165, "project": "test-apps/docstring_parser", "module": "docstring_parser.google", "predictions": ["import inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n# The following classes and regexes are class-level definitions from the file content\n# that the GoogleParser class implicitly depends on.\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret", "import inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret", "import inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\n# Assuming these are available in the environment due to relative import and problem context.\n# They are part of the 'common' module within the 'docstring_parser' package.\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Prepares a regular expression pattern to efficiently match and locate specific section titles within a document, considering optional colons.\"\"\"\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Parses a Google-style docstring element, structuring its text into `DocstringMeta`. It handles both single and multi-item descriptions for accurate interpretation.\"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        \"\"\"Constructs a specific `DocstringMeta` object for a docstring section based on its keyword, differentiating between returns, yields, and raises. This helper method standardizes metadata creation for a Google-style docstring parser.\"\"\"\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        \"\"\"A `GoogleParser` helper method that parses sections of a Google-style docstring. It extracts and structures metadata for parameters, return values, and raised exceptions into specialized `DocstringMeta` objects.\"\"\"\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret", "import inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret", "import inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n# The following classes and regexes are class-level definitions from the file content\n# that the GoogleParser class implicitly depends on.\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\n# Assuming these are available in the environment due to relative import and problem context.\n# They are part of the 'common' module within the 'docstring_parser' package.\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Prepares a regular expression pattern to efficiently match and locate specific section titles within a document, considering optional colons.\"\"\"\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Parses a Google-style docstring element, structuring its text into `DocstringMeta`. It handles both single and multi-item descriptions for accurate interpretation.\"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        \"\"\"Constructs a specific `DocstringMeta` object for a docstring section based on its keyword, differentiating between returns, yields, and raises. This helper method standardizes metadata creation for a Google-style docstring parser.\"\"\"\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        \"\"\"A `GoogleParser` helper method that parses sections of a Google-style docstring. It extracts and structures metadata for parameters, return values, and raised exceptions into specialized `DocstringMeta` objects.\"\"\"\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n"]}
{"task_id": 166, "project": "test-apps/docstring_parser", "module": "docstring_parser.rest", "predictions": ["import inspect\nimport re\nimport typing as T\n\n# Imports from file_content\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n# Imports from context functions\n# Context 2: _clean_str - Cleans a string by removing leading/trailing whitespace.\nfrom docstring_parser.numpydoc import _clean_str\n\n# _build_meta is provided in the file content and is accessible in the current scope.\n# Its purpose is to convert extracted keyword arguments and description into a DocstringMeta object.\n\n# Regex to match ReST field list syntax: :keyword arguments: description\n# - Group 1: The keyword (e.g., 'param', 'returns', 'raises').\n# - Group 2: The arguments string (e.g., 'int foo', 'ValueError').\n# - Group 3: The initial description text on the same line as the keyword.\n_REST_KEYWORD_REGEX = re.compile(r\"^:([a-zA-Z0-9_-]+)\\s*(.*?):\\s*(.*)\", re.MULTILINE)\n\ndef _parse_intro_text(intro_text: str) -> T.Tuple[T.Optional[str], T.Optional[str]]:\n    \"\"\"Helper function to parse the short and long description from a block of text.\n\n    This function expects a block of text that precedes any ReST field lists.\n    It extracts the first non-empty line as the short description and the rest\n    as the long description.\n\n    :param intro_text: The string containing the introductory description.\n    :returns: A tuple containing the short description and long description (both can be None).\n    \"\"\"\n    lines = intro_text.splitlines()\n    short_description = None\n    long_description = None\n\n    # Find the first non-empty line to set as the short description\n    first_content_line_idx = -1\n    for i, line in enumerate(lines):\n        cleaned_line = _clean_str(line)\n        if cleaned_line:\n            short_description = cleaned_line\n            first_content_line_idx = i\n            break\n    \n    if short_description is not None:\n        # Collect all subsequent lines to form the long description\n        remaining_lines = lines[first_content_line_idx + 1:]\n        if remaining_lines:\n            # Join and clean the remaining lines for the long description\n            long_description = _clean_str(\"\\n\".join(remaining_lines))\n    \n    return short_description, long_description\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    This function processes a ReST-style docstring to extract its short\n    description, long description, and structured metadata (parameters,\n    returns, raises, etc.).\n\n    The parsing logic identifies keyword-prefixed lines (e.g., :param:, :returns:)\n    to delineate metadata sections. Any text before the first keyword is\n    considered part of the main description. Multi-line descriptions for\n    metadata fields are supported by including subsequent lines until a new\n    keyword is found or the docstring ends.\n\n    :param text: The raw ReST-style docstring string.\n    :returns: A :class:`Docstring` object containing the parsed components.\n    \"\"\"\n    # 1. Clean the entire docstring by dedenting it using inspect.cleandoc.\n    # This removes common leading whitespace from all lines, making relative\n    # indentation (for multi-line descriptions) consistent.\n    cleaned_text = inspect.cleandoc(text)\n    \n    # Handle empty docstrings immediately\n    if not cleaned_text:\n        return Docstring(\n            short_description=None,\n            long_description=None,\n            meta=[],\n        )\n\n    # Find all occurrences of ReST keyword fields using the defined regex.\n    # We collect all matches upfront to easily determine the start and end\n    # of different sections within the docstring.\n    all_matches = list(_REST_KEYWORD_REGEX.finditer(cleaned_text))\n\n    short_description = None\n    long_description = None\n    meta_objects = []\n\n    # If no meta sections are found, the entire cleaned text is treated as description.\n    if not all_matches:\n        short_description, long_description = _parse_intro_text(cleaned_text)\n        return Docstring(short_description, long_description, [])\n\n    # If meta sections exist, first process the introductory part of the docstring.\n    # This is the text from the beginning up to the start of the first meta section.\n    first_meta_start_index = all_matches[0].start()\n    intro_text = cleaned_text[:first_meta_start_index]\n    \n    short_description, long_description = _parse_intro_text(intro_text)\n\n    # Process each identified meta section.\n    for i, match in enumerate(all_matches):\n        keyword = match.group(1)  # e.g., 'param', 'returns'\n        args_str = match.group(2) # e.g., 'int foo', 'ValueError'\n        \n        # Determine the start index of the next meta section, or the end of the docstring.\n        # This helps define the boundary for the current meta's description block.\n        next_meta_start_index = None\n        if i + 1 < len(all_matches):\n            next_meta_start_index = all_matches[i+1].start()\n        \n        # The initial part of the description is on the same line as the keyword.\n        initial_desc_part = match.group(3)\n        \n        # The remaining block of text for this meta's description includes all lines\n        # that follow the keyword line, up to the next meta section or end of string.\n        # `match.end()` points to the character index immediately after the matched\n        # keyword line (including the newline character if present).\n        remaining_block_text = cleaned_text[match.end():next_meta_start_index]\n        \n        # Combine the initial description part and the remaining block for the full raw description.\n        # A newline is added to ensure separation if there are subsequent lines.\n        full_raw_description = initial_desc_part\n        if remaining_block_text:\n            full_raw_description += \"\\n\" + remaining_block_text\n        \n        # Clean the final description string by stripping leading/trailing whitespace.\n        description = _clean_str(full_raw_description)\n\n        # Prepare the arguments list for _build_meta. The first argument is the keyword itself,\n        # followed by any arguments parsed from `args_str`.\n        args = [keyword]\n        if args_str:\n            # Split the arguments string by space. _build_meta is designed to handle\n            # different lengths of the 'args' list based on the keyword (e.g., param vs. returns).\n            args.extend(args_str.split())\n        \n        # Use the internal _build_meta function to create the appropriate DocstringMeta object.\n        # Ensure 'description' is an empty string if it's None, as _build_meta expects a string.\n        meta_objects.append(_build_meta(args, description or \"\"))\n\n    # Construct and return the final Docstring object.\n    return Docstring(short_description, long_description, meta_objects)", "import inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or\n    contains only whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\n# Regex to match ReST-style keyword lines: \":keyword args: description\"\n# Examples:\n# \":param str name: The name of something.\"\n# \":returns int: The result.\"\n# \":raises ValueError:\"\n#\n# Group 1: keyword (e.g., \"param\", \"returns\", \"raises\")\n# Group 2: arguments (e.g., \"str name\", \"int\") - this part can be empty\n# Group 3: initial description (e.g., \"The name of something.\") - this part can be empty\n_LINE_REGEX = re.compile(r\"^:\\s*(\\S+?)\\s*(.*?):\\s*(.*)\", re.DOTALL)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Clean the entire docstring text, removing common leading whitespace\n    text = inspect.cleandoc(text)\n    lines = text.splitlines()\n\n    main_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    current_meta_args: T.Optional[T.List[str]] = None\n    current_meta_description_lines: T.List[str] = []\n\n    # Flag to indicate if we've entered the section with keyword arguments\n    in_meta_section = False\n\n    for line in lines:\n        # Match against the stripped line to handle varying indentation for keywords\n        stripped_line = line.strip()\n        match = _LINE_REGEX.match(stripped_line)\n\n        if match:\n            # We hit a new meta section. Process the previous one if it exists.\n            if current_meta_args is not None:\n                # Join and clean the collected description for the previous meta item\n                desc = _clean_str(\"\\n\".join(current_meta_description_lines))\n                # _build_meta expects a string, empty string if no description\n                meta.append(_build_meta(current_meta_args, desc or \"\"))\n                current_meta_description_lines = []\n\n            # Extract details for the new meta item\n            keyword = match.group(1)\n            args_str = match.group(2).strip()\n            initial_desc = match.group(3).strip()\n\n            # Build the arguments list for _build_meta.\n            # _build_meta expects a list like ['param', 'type_name', 'arg_name']\n            # or ['returns', 'type_name'].\n            args_list = [keyword]\n            if args_str:\n                args_list.extend(arg for arg in args_str.split(' ') if arg)\n            current_meta_args = args_list\n\n            # Start collecting description for the new meta item\n            if initial_desc:\n                current_meta_description_lines.append(initial_desc)\n\n            in_meta_section = True  # We are now in the meta section\n        else:\n            # This line is not a meta keyword line.\n            if in_meta_section:\n                # If we are already in a meta section, this line must be a continuation\n                # of the current meta item's description.\n                # Append the stripped line to maintain relative indentation within description.\n                current_meta_description_lines.append(stripped_line)\n            else:\n                # This line belongs to the main description (short/long).\n                # Append the original line (after initial cleandoc) to preserve internal structure\n                # for later split into short/long.\n                main_description_lines.append(line)\n\n    # After the loop, process the last meta item if it exists\n    if current_meta_args is not None:\n        desc = _clean_str(\"\\n\".join(current_meta_description_lines))\n        meta.append(_build_meta(current_meta_args, desc or \"\"))\n\n    # Now, parse the collected main_description_lines into short and long descriptions.\n    # ReST typically separates short and long descriptions by an empty line.\n    # The `main_description_lines` already have `inspect.cleandoc` applied to their block.\n    main_desc_raw_text = \"\\n\".join(main_description_lines)\n    # Split by the first occurrence of one or more empty lines\n    main_desc_blocks = re.split(r\"\\n\\s*\\n\", main_desc_raw_text, maxsplit=1)\n\n    short_description: T.Optional[str] = None\n    long_description: T.Optional[str] = None\n\n    if main_desc_blocks:\n        # The first block is typically the short description\n        cleaned_first_block = _clean_str(main_desc_blocks[0])\n        if cleaned_first_block:\n            short_description = cleaned_first_block\n        \n        # If there's a second block after an empty line, it's the long description\n        if len(main_desc_blocks) > 1:\n            cleaned_second_block = _clean_str(main_desc_blocks[1])\n            if cleaned_second_block:\n                long_description = cleaned_second_block\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )", "import inspect\nimport re\nimport typing as T\n\n# The following imports are available from the file content:\n# from .common import (\n#     PARAM_KEYWORDS,\n#     RAISES_KEYWORDS,\n#     RETURNS_KEYWORDS,\n#     YIELDS_KEYWORDS,\n#     Docstring,\n#     DocstringMeta,\n#     DocstringParam,\n#     DocstringRaises,\n#     DocstringReturns,\n#     ParseError,\n# )\n\n# _build_meta is also defined in the file content.\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or contains only\n    whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Clean the entire docstring using inspect.cleandoc to handle common indentation\n    text = inspect.cleandoc(text)\n    if not text:\n        return Docstring()\n\n    lines = text.splitlines()\n\n    short_description: T.Optional[str] = None\n    long_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    # State variables for parsing different sections of the docstring\n    # \"initial\": before short_description is found\n    # \"short_desc_parsed\": short_description found, looking for long_description or meta\n    # \"long_desc_or_meta\": actively collecting long_description lines, or looking for meta\n    # \"in_meta_field\": currently collecting description for a meta field\n    parsing_state = \"initial\"\n\n    current_meta_key_line: T.Optional[str] = None # Stores the raw first line of a meta field (e.g., \":param str name: description\")\n    current_meta_description_lines: T.List[str] = [] # Stores subsequent indented lines for the current meta field's description\n\n    # Regex to detect ReST field lines: `:field_key args_and_desc`\n    # Captures the keyword (e.g., 'param', 'returns') and everything that follows it.\n    meta_line_pattern = re.compile(r\"^\\s*:(?P<field_key>\\w+)(?P<args_and_desc>.*)\")\n\n    def _process_current_meta_block():\n        \"\"\"\n        Processes the accumulated meta block (key line and description lines)\n        and appends the resulting DocstringMeta object to the `meta` list.\n        \"\"\"\n        nonlocal current_meta_key_line, current_meta_description_lines, meta\n\n        if current_meta_key_line is None:\n            return\n\n        match = meta_line_pattern.match(current_meta_key_line)\n        if not match:\n            # This case should ideally not be hit if current_meta_key_line was set correctly\n            current_meta_key_line = None\n            current_meta_description_lines = []\n            return\n\n        field_key = match.group(\"field_key\")\n        raw_args_and_desc = match.group(\"args_and_desc\").strip()\n\n        args_list: T.List[str] = [field_key]\n        initial_desc_part: str = \"\"\n\n        # Find the first colon within raw_args_and_desc. This colon separates\n        # the arguments part from the initial part of the description.\n        first_colon_idx = raw_args_and_desc.find(':')\n\n        if first_colon_idx != -1:\n            # Colon found: part before is arguments, part after is initial description.\n            arg_string = raw_args_and_desc[:first_colon_idx].strip()\n            initial_desc_part = raw_args_and_desc[first_colon_idx + 1:].strip()\n            if arg_string:\n                args_list.extend(arg_string.split())\n        else:\n            # No colon found: the entire raw_args_and_desc is treated as arguments.\n            arg_string = raw_args_and_desc.strip()\n            if arg_string:\n                args_list.extend(arg_string.split())\n            # initial_desc_part remains an empty string.\n\n        # Combine the initial description part with the subsequent indented lines.\n        # Then, clean the combined description again using inspect.cleandoc\n        # to handle relative indentation within the description block itself.\n        full_description_raw = [initial_desc_part] + current_meta_description_lines\n        full_description_text = _clean_str(inspect.cleandoc(\"\\n\".join(full_description_raw)))\n\n        try:\n            # Use the _build_meta function (defined in the same file)\n            meta_obj = _build_meta(args_list, full_description_text)\n            meta.append(meta_obj)\n        except ParseError:\n            # If _build_meta raises a ParseError (e.g., malformed arguments),\n            # fall back to a generic DocstringMeta object.\n            meta.append(DocstringMeta(args=args_list, description=full_description_text))\n\n        # Reset meta block accumulators\n        current_meta_key_line = None\n        current_meta_description_lines = []\n\n    # Iterate through each line of the docstring\n    for line in lines:\n        stripped_line = line.strip()\n\n        if not stripped_line:  # Handle empty lines\n            if parsing_state == \"in_meta_field\":\n                # An empty line explicitly terminates a meta field's description block.\n                _process_current_meta_block()\n                parsing_state = \"long_desc_or_meta\"  # Transition to looking for more long desc or new meta\n            elif parsing_state == \"short_desc_parsed\":\n                # An empty line after short description implies transition to long description area.\n                parsing_state = \"long_desc_or_meta\"\n            # If in \"initial\" or \"long_desc_or_meta\" and empty, just continue.\n            continue\n\n        meta_match = meta_line_pattern.match(line)\n\n        if meta_match:\n            # This line starts a new meta field (e.g., :param, :returns).\n            # First, process any previously accumulated meta field block.\n            if parsing_state == \"in_meta_field\":\n                _process_current_meta_block()\n            # If we were in short_desc_parsed or long_desc_or_meta, simply transition.\n\n            # Start accumulating for the new meta field.\n            current_meta_key_line = line\n            current_meta_description_lines = []\n            parsing_state = \"in_meta_field\"\n\n        else:\n            # This line is not the start of a meta field.\n            if parsing_state == \"initial\":\n                # The very first non-empty line is the short description.\n                short_description = stripped_line\n                parsing_state = \"short_desc_parsed\"\n            elif parsing_state == \"short_desc_parsed\" or parsing_state == \"long_desc_or_meta\":\n                # Lines after short description, and before any meta fields, form the long description.\n                long_description_lines.append(line)\n                parsing_state = \"long_desc_or_meta\"\n            elif parsing_state == \"in_meta_field\":\n                # This line is a continuation of the current meta field's description.\n                current_meta_description_lines.append(line)\n\n    # After iterating through all lines, process any pending meta field block.\n    _process_current_meta_block()\n\n    # Clean and join the accumulated long description lines.\n    # inspect.cleandoc handles common indentation for the whole docstring,\n    # but re-applying it here on the joined lines correctly handles relative\n    # indentation within the long description block itself.\n    long_description = _clean_str(inspect.cleandoc(\"\\n\".join(long_description_lines)))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )", "import inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\n# _build_meta is already defined in the file content and is used by this parser.\n# Its implementation is provided in the file content, so it is directly callable.\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty\n    or contains only whitespace after cleaning.\n    (From Context Function 2)\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    cleaned_text = inspect.cleandoc(text)\n    if not cleaned_text:\n        return Docstring()\n\n    lines = cleaned_text.splitlines()\n\n    short_description: T.Optional[str] = None\n    long_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    current_meta_args: T.Optional[T.List[str]] = None\n    current_meta_desc_lines: T.List[str] = []\n\n    # Regex to identify a ReST-style meta field start, e.g., :param name: description\n    # Group 1: The keyword (e.g., 'param', 'returns')\n    # Group 2: The part between the first colon and the optional second colon\n    #          (e.g., 'int x', 'arg1', 'ExceptionType'). This holds the arguments for _build_meta.\n    # Group 3: The initial part of the description, after the second optional colon.\n    REST_META_START_REGEX = re.compile(r\":(\\S+)\\s*([^:]*)(?::\\s*(.*))?\")\n\n    line_idx = 0\n\n    # 1. Extract short description\n    # Skip initial empty lines\n    while line_idx < len(lines) and not lines[line_idx].strip():\n        line_idx += 1\n\n    if line_idx < len(lines):\n        # The first meaningful line might be the short description or a meta field.\n        # If it's a meta field, there is no short description for the overall docstring.\n        first_meaningful_line = lines[line_idx].strip()\n        if not REST_META_START_REGEX.match(first_meaningful_line):\n            short_description = _clean_str(first_meaningful_line)\n            line_idx += 1\n        # If the docstring starts directly with a meta field, short_description remains None.\n\n    # 2. Extract long description and meta sections\n    while line_idx < len(lines):\n        line = lines[line_idx]\n        stripped_line = line.strip()\n        leading_whitespace_len = len(line) - len(line.lstrip())\n        is_meta_start_match = REST_META_START_REGEX.match(stripped_line)\n\n        if is_meta_start_match:\n            # End of previous meta block (if any)\n            if current_meta_args is not None:\n                # Join description lines, clean, and pass to _build_meta.\n                # _build_meta expects a string, so convert None from _clean_str to empty string.\n                desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n                meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n            \n            # Start new meta block\n            keyword = is_meta_start_match.group(1)\n            meta_args_str = is_meta_start_match.group(2).strip()\n            initial_desc_part = is_meta_start_match.group(3)\n\n            # Build the args list for _build_meta.\n            # Example: for \":param int x: Desc\", args_list would be [\"param\", \"int\", \"x\"].\n            args_list = [keyword]\n            if meta_args_str:\n                args_list.extend(meta_args_str.split())\n\n            current_meta_args = args_list\n            current_meta_desc_lines = []\n            if initial_desc_part is not None:\n                # Add the initial description part found on the meta line itself.\n                current_meta_desc_lines.append(initial_desc_part.strip())\n\n        elif current_meta_args is not None:\n            # We are currently inside a meta block. This line is either a continuation of its description\n            # or it signifies the end of the current meta block.\n            # A line continues the meta description if it's indented or is an empty line.\n            if stripped_line == \"\" or leading_whitespace_len > 0:\n                current_meta_desc_lines.append(stripped_line)\n            else:\n                # This line is not indented, not empty, and not a new meta field.\n                # This signifies the end of the current meta block.\n                # Process the completed meta block.\n                desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n                meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n                \n                # Reset current meta state as it has ended.\n                current_meta_args = None\n                current_meta_desc_lines = []\n                \n                # This line now belongs to the long description, as it's not part of a meta block.\n                long_description_lines.append(stripped_line)\n        else:\n            # This line is not a meta line and we are not currently processing a meta block.\n            # Therefore, it belongs to the general long description.\n            long_description_lines.append(stripped_line)\n        \n        line_idx += 1\n\n    # 3. After the loop, process the last meta block if any remained open.\n    if current_meta_args is not None:\n        desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n        meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n\n    # 4. Finalize the long description.\n    # _clean_str handles stripping leading/trailing whitespace for the entire block.\n    long_description = _clean_str(\"\\n\".join(long_description_lines))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta\n    )", "import inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or\n    contains only whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    \"\"\"\n    Parses a segment of a docstring, converting keyword-prefixed lines\n    into structured metadata objects. It extracts details for parameters,\n    return values, or raised exceptions, facilitating docstring analysis.\n    \"\"\"\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    cleaned_text = inspect.cleandoc(text)\n    lines = cleaned_text.splitlines()\n\n    short_description = None\n    long_description_raw_lines = []\n    meta = []\n\n    current_meta_args = None\n    current_meta_desc_lines = []\n\n    # Flag to indicate if we are currently parsing a meta section's description\n    in_meta_section = False\n\n    # Regex to match ReST field lists like \":key argument_type argument_name: description\"\n    # It captures the keyword, any arguments before the second colon, and the initial description.\n    FIELD_REGEX = re.compile(r\"^:(?P<key>\\w+)\\s*(?P<args_part>.*?):\\s*(?P<first_desc_line>.*)\")\n\n    for line_num, line in enumerate(lines):\n        stripped_line = line.strip()\n\n        match = FIELD_REGEX.match(stripped_line)\n\n        if match:\n            # A new meta field line is encountered\n            if in_meta_section and current_meta_args:\n                # Finalize the description of the previous meta field\n                # before starting a new one. The description should be joined\n                # and then cleaned.\n                meta.append(_build_meta(current_meta_args, \"\\n\".join(current_meta_desc_lines)))\n            \n            # Transition to a new meta section\n            in_meta_section = True\n            current_meta_key = match.group(\"key\")\n            args_part = match.group(\"args_part\").strip()\n            first_desc_line = match.group(\"first_desc_line\").strip()\n\n            # Construct the list of arguments for _build_meta.\n            # This includes the keyword itself as the first argument.\n            if args_part:\n                current_meta_args = [current_meta_key] + args_part.split()\n            else:\n                current_meta_args = [current_meta_key]\n            \n            # Start collecting description lines for the current meta field\n            current_meta_desc_lines = [first_desc_line]\n\n        elif in_meta_section:\n            # This line is a continuation of the current meta description.\n            # `inspect.cleandoc` handles common indentation, so `stripped_line` is fine.\n            current_meta_desc_lines.append(stripped_line)\n\n        else:\n            # This line belongs to the main description (summary or long description)\n            if not stripped_line:\n                # An empty line. If a short description already exists, this blank\n                # line is part of the long description.\n                if short_description is not None:\n                    long_description_raw_lines.append(\"\")\n            else:\n                # A non-empty line\n                if short_description is None:\n                    # This is the first non-empty line, so it's the short description.\n                    short_description = stripped_line\n                else:\n                    # Subsequent non-empty lines are part of the long description.\n                    long_description_raw_lines.append(stripped_line)\n\n    # After the loop, finalize any pending meta field that was being parsed\n    if in_meta_section and current_meta_args:\n        meta.append(_build_meta(current_meta_args, \"\\n\".join(current_meta_desc_lines)))\n\n    # Post-process and clean descriptions\n    if short_description is not None:\n        short_description = _clean_str(short_description)\n\n    # Remove any leading or trailing empty strings from the long description list.\n    # This accounts for blank lines separating summary/long_description or\n    # blank lines before the metadata section.\n    while long_description_raw_lines and long_description_raw_lines[0] == \"\":\n        long_description_raw_lines.pop(0)\n    while long_description_raw_lines and long_description_raw_lines[-1] == \"\":\n        long_description_raw_lines.pop()\n\n    # Join the remaining lines and clean the final long description string.\n    long_description = _clean_str(\"\\n\".join(long_description_raw_lines))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport inspect\nimport re\nimport typing as T\n\n# Imports from file_content\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n# Imports from context functions\n# Context 2: _clean_str - Cleans a string by removing leading/trailing whitespace.\nfrom docstring_parser.numpydoc import _clean_str\n\n# _build_meta is provided in the file content and is accessible in the current scope.\n# Its purpose is to convert extracted keyword arguments and description into a DocstringMeta object.\n\n# Regex to match ReST field list syntax: :keyword arguments: description\n# - Group 1: The keyword (e.g., 'param', 'returns', 'raises').\n# - Group 2: The arguments string (e.g., 'int foo', 'ValueError').\n# - Group 3: The initial description text on the same line as the keyword.\n_REST_KEYWORD_REGEX = re.compile(r\"^:([a-zA-Z0-9_-]+)\\s*(.*?):\\s*(.*)\", re.MULTILINE)\n\ndef _parse_intro_text(intro_text: str) -> T.Tuple[T.Optional[str], T.Optional[str]]:\n    \"\"\"Helper function to parse the short and long description from a block of text.\n\n    This function expects a block of text that precedes any ReST field lists.\n    It extracts the first non-empty line as the short description and the rest\n    as the long description.\n\n    :param intro_text: The string containing the introductory description.\n    :returns: A tuple containing the short description and long description (both can be None).\n    \"\"\"\n    lines = intro_text.splitlines()\n    short_description = None\n    long_description = None\n\n    # Find the first non-empty line to set as the short description\n    first_content_line_idx = -1\n    for i, line in enumerate(lines):\n        cleaned_line = _clean_str(line)\n        if cleaned_line:\n            short_description = cleaned_line\n            first_content_line_idx = i\n            break\n    \n    if short_description is not None:\n        # Collect all subsequent lines to form the long description\n        remaining_lines = lines[first_content_line_idx + 1:]\n        if remaining_lines:\n            # Join and clean the remaining lines for the long description\n            long_description = _clean_str(\"\\n\".join(remaining_lines))\n    \n    return short_description, long_description\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    This function processes a ReST-style docstring to extract its short\n    description, long description, and structured metadata (parameters,\n    returns, raises, etc.).\n\n    The parsing logic identifies keyword-prefixed lines (e.g., :param:, :returns:)\n    to delineate metadata sections. Any text before the first keyword is\n    considered part of the main description. Multi-line descriptions for\n    metadata fields are supported by including subsequent lines until a new\n    keyword is found or the docstring ends.\n\n    :param text: The raw ReST-style docstring string.\n    :returns: A :class:`Docstring` object containing the parsed components.\n    \"\"\"\n    # 1. Clean the entire docstring by dedenting it using inspect.cleandoc.\n    # This removes common leading whitespace from all lines, making relative\n    # indentation (for multi-line descriptions) consistent.\n    cleaned_text = inspect.cleandoc(text)\n    \n    # Handle empty docstrings immediately\n    if not cleaned_text:\n        return Docstring(\n            short_description=None,\n            long_description=None,\n            meta=[],\n        )\n\n    # Find all occurrences of ReST keyword fields using the defined regex.\n    # We collect all matches upfront to easily determine the start and end\n    # of different sections within the docstring.\n    all_matches = list(_REST_KEYWORD_REGEX.finditer(cleaned_text))\n\n    short_description = None\n    long_description = None\n    meta_objects = []\n\n    # If no meta sections are found, the entire cleaned text is treated as description.\n    if not all_matches:\n        short_description, long_description = _parse_intro_text(cleaned_text)\n        return Docstring(short_description, long_description, [])\n\n    # If meta sections exist, first process the introductory part of the docstring.\n    # This is the text from the beginning up to the start of the first meta section.\n    first_meta_start_index = all_matches[0].start()\n    intro_text = cleaned_text[:first_meta_start_index]\n    \n    short_description, long_description = _parse_intro_text(intro_text)\n\n    # Process each identified meta section.\n    for i, match in enumerate(all_matches):\n        keyword = match.group(1)  # e.g., 'param', 'returns'\n        args_str = match.group(2) # e.g., 'int foo', 'ValueError'\n        \n        # Determine the start index of the next meta section, or the end of the docstring.\n        # This helps define the boundary for the current meta's description block.\n        next_meta_start_index = None\n        if i + 1 < len(all_matches):\n            next_meta_start_index = all_matches[i+1].start()\n        \n        # The initial part of the description is on the same line as the keyword.\n        initial_desc_part = match.group(3)\n        \n        # The remaining block of text for this meta's description includes all lines\n        # that follow the keyword line, up to the next meta section or end of string.\n        # `match.end()` points to the character index immediately after the matched\n        # keyword line (including the newline character if present).\n        remaining_block_text = cleaned_text[match.end():next_meta_start_index]\n        \n        # Combine the initial description part and the remaining block for the full raw description.\n        # A newline is added to ensure separation if there are subsequent lines.\n        full_raw_description = initial_desc_part\n        if remaining_block_text:\n            full_raw_description += \"\\n\" + remaining_block_text\n        \n        # Clean the final description string by stripping leading/trailing whitespace.\n        description = _clean_str(full_raw_description)\n\n        # Prepare the arguments list for _build_meta. The first argument is the keyword itself,\n        # followed by any arguments parsed from `args_str`.\n        args = [keyword]\n        if args_str:\n            # Split the arguments string by space. _build_meta is designed to handle\n            # different lengths of the 'args' list based on the keyword (e.g., param vs. returns).\n            args.extend(args_str.split())\n        \n        # Use the internal _build_meta function to create the appropriate DocstringMeta object.\n        # Ensure 'description' is an empty string if it's None, as _build_meta expects a string.\n        meta_objects.append(_build_meta(args, description or \"\"))\n\n    # Construct and return the final Docstring object.\n    return Docstring(short_description, long_description, meta_objects)\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or\n    contains only whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\n# Regex to match ReST-style keyword lines: \":keyword args: description\"\n# Examples:\n# \":param str name: The name of something.\"\n# \":returns int: The result.\"\n# \":raises ValueError:\"\n#\n# Group 1: keyword (e.g., \"param\", \"returns\", \"raises\")\n# Group 2: arguments (e.g., \"str name\", \"int\") - this part can be empty\n# Group 3: initial description (e.g., \"The name of something.\") - this part can be empty\n_LINE_REGEX = re.compile(r\"^:\\s*(\\S+?)\\s*(.*?):\\s*(.*)\", re.DOTALL)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Clean the entire docstring text, removing common leading whitespace\n    text = inspect.cleandoc(text)\n    lines = text.splitlines()\n\n    main_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    current_meta_args: T.Optional[T.List[str]] = None\n    current_meta_description_lines: T.List[str] = []\n\n    # Flag to indicate if we've entered the section with keyword arguments\n    in_meta_section = False\n\n    for line in lines:\n        # Match against the stripped line to handle varying indentation for keywords\n        stripped_line = line.strip()\n        match = _LINE_REGEX.match(stripped_line)\n\n        if match:\n            # We hit a new meta section. Process the previous one if it exists.\n            if current_meta_args is not None:\n                # Join and clean the collected description for the previous meta item\n                desc = _clean_str(\"\\n\".join(current_meta_description_lines))\n                # _build_meta expects a string, empty string if no description\n                meta.append(_build_meta(current_meta_args, desc or \"\"))\n                current_meta_description_lines = []\n\n            # Extract details for the new meta item\n            keyword = match.group(1)\n            args_str = match.group(2).strip()\n            initial_desc = match.group(3).strip()\n\n            # Build the arguments list for _build_meta.\n            # _build_meta expects a list like ['param', 'type_name', 'arg_name']\n            # or ['returns', 'type_name'].\n            args_list = [keyword]\n            if args_str:\n                args_list.extend(arg for arg in args_str.split(' ') if arg)\n            current_meta_args = args_list\n\n            # Start collecting description for the new meta item\n            if initial_desc:\n                current_meta_description_lines.append(initial_desc)\n\n            in_meta_section = True  # We are now in the meta section\n        else:\n            # This line is not a meta keyword line.\n            if in_meta_section:\n                # If we are already in a meta section, this line must be a continuation\n                # of the current meta item's description.\n                # Append the stripped line to maintain relative indentation within description.\n                current_meta_description_lines.append(stripped_line)\n            else:\n                # This line belongs to the main description (short/long).\n                # Append the original line (after initial cleandoc) to preserve internal structure\n                # for later split into short/long.\n                main_description_lines.append(line)\n\n    # After the loop, process the last meta item if it exists\n    if current_meta_args is not None:\n        desc = _clean_str(\"\\n\".join(current_meta_description_lines))\n        meta.append(_build_meta(current_meta_args, desc or \"\"))\n\n    # Now, parse the collected main_description_lines into short and long descriptions.\n    # ReST typically separates short and long descriptions by an empty line.\n    # The `main_description_lines` already have `inspect.cleandoc` applied to their block.\n    main_desc_raw_text = \"\\n\".join(main_description_lines)\n    # Split by the first occurrence of one or more empty lines\n    main_desc_blocks = re.split(r\"\\n\\s*\\n\", main_desc_raw_text, maxsplit=1)\n\n    short_description: T.Optional[str] = None\n    long_description: T.Optional[str] = None\n\n    if main_desc_blocks:\n        # The first block is typically the short description\n        cleaned_first_block = _clean_str(main_desc_blocks[0])\n        if cleaned_first_block:\n            short_description = cleaned_first_block\n        \n        # If there's a second block after an empty line, it's the long description\n        if len(main_desc_blocks) > 1:\n            cleaned_second_block = _clean_str(main_desc_blocks[1])\n            if cleaned_second_block:\n                long_description = cleaned_second_block\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport inspect\nimport re\nimport typing as T\n\n# The following imports are available from the file content:\n# from .common import (\n#     PARAM_KEYWORDS,\n#     RAISES_KEYWORDS,\n#     RETURNS_KEYWORDS,\n#     YIELDS_KEYWORDS,\n#     Docstring,\n#     DocstringMeta,\n#     DocstringParam,\n#     DocstringRaises,\n#     DocstringReturns,\n#     ParseError,\n# )\n\n# _build_meta is also defined in the file content.\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or contains only\n    whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Clean the entire docstring using inspect.cleandoc to handle common indentation\n    text = inspect.cleandoc(text)\n    if not text:\n        return Docstring()\n\n    lines = text.splitlines()\n\n    short_description: T.Optional[str] = None\n    long_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    # State variables for parsing different sections of the docstring\n    # \"initial\": before short_description is found\n    # \"short_desc_parsed\": short_description found, looking for long_description or meta\n    # \"long_desc_or_meta\": actively collecting long_description lines, or looking for meta\n    # \"in_meta_field\": currently collecting description for a meta field\n    parsing_state = \"initial\"\n\n    current_meta_key_line: T.Optional[str] = None # Stores the raw first line of a meta field (e.g., \":param str name: description\")\n    current_meta_description_lines: T.List[str] = [] # Stores subsequent indented lines for the current meta field's description\n\n    # Regex to detect ReST field lines: `:field_key args_and_desc`\n    # Captures the keyword (e.g., 'param', 'returns') and everything that follows it.\n    meta_line_pattern = re.compile(r\"^\\s*:(?P<field_key>\\w+)(?P<args_and_desc>.*)\")\n\n    def _process_current_meta_block():\n        \"\"\"\n        Processes the accumulated meta block (key line and description lines)\n        and appends the resulting DocstringMeta object to the `meta` list.\n        \"\"\"\n        nonlocal current_meta_key_line, current_meta_description_lines, meta\n\n        if current_meta_key_line is None:\n            return\n\n        match = meta_line_pattern.match(current_meta_key_line)\n        if not match:\n            # This case should ideally not be hit if current_meta_key_line was set correctly\n            current_meta_key_line = None\n            current_meta_description_lines = []\n            return\n\n        field_key = match.group(\"field_key\")\n        raw_args_and_desc = match.group(\"args_and_desc\").strip()\n\n        args_list: T.List[str] = [field_key]\n        initial_desc_part: str = \"\"\n\n        # Find the first colon within raw_args_and_desc. This colon separates\n        # the arguments part from the initial part of the description.\n        first_colon_idx = raw_args_and_desc.find(':')\n\n        if first_colon_idx != -1:\n            # Colon found: part before is arguments, part after is initial description.\n            arg_string = raw_args_and_desc[:first_colon_idx].strip()\n            initial_desc_part = raw_args_and_desc[first_colon_idx + 1:].strip()\n            if arg_string:\n                args_list.extend(arg_string.split())\n        else:\n            # No colon found: the entire raw_args_and_desc is treated as arguments.\n            arg_string = raw_args_and_desc.strip()\n            if arg_string:\n                args_list.extend(arg_string.split())\n            # initial_desc_part remains an empty string.\n\n        # Combine the initial description part with the subsequent indented lines.\n        # Then, clean the combined description again using inspect.cleandoc\n        # to handle relative indentation within the description block itself.\n        full_description_raw = [initial_desc_part] + current_meta_description_lines\n        full_description_text = _clean_str(inspect.cleandoc(\"\\n\".join(full_description_raw)))\n\n        try:\n            # Use the _build_meta function (defined in the same file)\n            meta_obj = _build_meta(args_list, full_description_text)\n            meta.append(meta_obj)\n        except ParseError:\n            # If _build_meta raises a ParseError (e.g., malformed arguments),\n            # fall back to a generic DocstringMeta object.\n            meta.append(DocstringMeta(args=args_list, description=full_description_text))\n\n        # Reset meta block accumulators\n        current_meta_key_line = None\n        current_meta_description_lines = []\n\n    # Iterate through each line of the docstring\n    for line in lines:\n        stripped_line = line.strip()\n\n        if not stripped_line:  # Handle empty lines\n            if parsing_state == \"in_meta_field\":\n                # An empty line explicitly terminates a meta field's description block.\n                _process_current_meta_block()\n                parsing_state = \"long_desc_or_meta\"  # Transition to looking for more long desc or new meta\n            elif parsing_state == \"short_desc_parsed\":\n                # An empty line after short description implies transition to long description area.\n                parsing_state = \"long_desc_or_meta\"\n            # If in \"initial\" or \"long_desc_or_meta\" and empty, just continue.\n            continue\n\n        meta_match = meta_line_pattern.match(line)\n\n        if meta_match:\n            # This line starts a new meta field (e.g., :param, :returns).\n            # First, process any previously accumulated meta field block.\n            if parsing_state == \"in_meta_field\":\n                _process_current_meta_block()\n            # If we were in short_desc_parsed or long_desc_or_meta, simply transition.\n\n            # Start accumulating for the new meta field.\n            current_meta_key_line = line\n            current_meta_description_lines = []\n            parsing_state = \"in_meta_field\"\n\n        else:\n            # This line is not the start of a meta field.\n            if parsing_state == \"initial\":\n                # The very first non-empty line is the short description.\n                short_description = stripped_line\n                parsing_state = \"short_desc_parsed\"\n            elif parsing_state == \"short_desc_parsed\" or parsing_state == \"long_desc_or_meta\":\n                # Lines after short description, and before any meta fields, form the long description.\n                long_description_lines.append(line)\n                parsing_state = \"long_desc_or_meta\"\n            elif parsing_state == \"in_meta_field\":\n                # This line is a continuation of the current meta field's description.\n                current_meta_description_lines.append(line)\n\n    # After iterating through all lines, process any pending meta field block.\n    _process_current_meta_block()\n\n    # Clean and join the accumulated long description lines.\n    # inspect.cleandoc handles common indentation for the whole docstring,\n    # but re-applying it here on the joined lines correctly handles relative\n    # indentation within the long description block itself.\n    long_description = _clean_str(inspect.cleandoc(\"\\n\".join(long_description_lines)))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\n# _build_meta is already defined in the file content and is used by this parser.\n# Its implementation is provided in the file content, so it is directly callable.\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty\n    or contains only whitespace after cleaning.\n    (From Context Function 2)\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    cleaned_text = inspect.cleandoc(text)\n    if not cleaned_text:\n        return Docstring()\n\n    lines = cleaned_text.splitlines()\n\n    short_description: T.Optional[str] = None\n    long_description_lines: T.List[str] = []\n    meta: T.List[DocstringMeta] = []\n\n    current_meta_args: T.Optional[T.List[str]] = None\n    current_meta_desc_lines: T.List[str] = []\n\n    # Regex to identify a ReST-style meta field start, e.g., :param name: description\n    # Group 1: The keyword (e.g., 'param', 'returns')\n    # Group 2: The part between the first colon and the optional second colon\n    #          (e.g., 'int x', 'arg1', 'ExceptionType'). This holds the arguments for _build_meta.\n    # Group 3: The initial part of the description, after the second optional colon.\n    REST_META_START_REGEX = re.compile(r\":(\\S+)\\s*([^:]*)(?::\\s*(.*))?\")\n\n    line_idx = 0\n\n    # 1. Extract short description\n    # Skip initial empty lines\n    while line_idx < len(lines) and not lines[line_idx].strip():\n        line_idx += 1\n\n    if line_idx < len(lines):\n        # The first meaningful line might be the short description or a meta field.\n        # If it's a meta field, there is no short description for the overall docstring.\n        first_meaningful_line = lines[line_idx].strip()\n        if not REST_META_START_REGEX.match(first_meaningful_line):\n            short_description = _clean_str(first_meaningful_line)\n            line_idx += 1\n        # If the docstring starts directly with a meta field, short_description remains None.\n\n    # 2. Extract long description and meta sections\n    while line_idx < len(lines):\n        line = lines[line_idx]\n        stripped_line = line.strip()\n        leading_whitespace_len = len(line) - len(line.lstrip())\n        is_meta_start_match = REST_META_START_REGEX.match(stripped_line)\n\n        if is_meta_start_match:\n            # End of previous meta block (if any)\n            if current_meta_args is not None:\n                # Join description lines, clean, and pass to _build_meta.\n                # _build_meta expects a string, so convert None from _clean_str to empty string.\n                desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n                meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n            \n            # Start new meta block\n            keyword = is_meta_start_match.group(1)\n            meta_args_str = is_meta_start_match.group(2).strip()\n            initial_desc_part = is_meta_start_match.group(3)\n\n            # Build the args list for _build_meta.\n            # Example: for \":param int x: Desc\", args_list would be [\"param\", \"int\", \"x\"].\n            args_list = [keyword]\n            if meta_args_str:\n                args_list.extend(meta_args_str.split())\n\n            current_meta_args = args_list\n            current_meta_desc_lines = []\n            if initial_desc_part is not None:\n                # Add the initial description part found on the meta line itself.\n                current_meta_desc_lines.append(initial_desc_part.strip())\n\n        elif current_meta_args is not None:\n            # We are currently inside a meta block. This line is either a continuation of its description\n            # or it signifies the end of the current meta block.\n            # A line continues the meta description if it's indented or is an empty line.\n            if stripped_line == \"\" or leading_whitespace_len > 0:\n                current_meta_desc_lines.append(stripped_line)\n            else:\n                # This line is not indented, not empty, and not a new meta field.\n                # This signifies the end of the current meta block.\n                # Process the completed meta block.\n                desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n                meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n                \n                # Reset current meta state as it has ended.\n                current_meta_args = None\n                current_meta_desc_lines = []\n                \n                # This line now belongs to the long description, as it's not part of a meta block.\n                long_description_lines.append(stripped_line)\n        else:\n            # This line is not a meta line and we are not currently processing a meta block.\n            # Therefore, it belongs to the general long description.\n            long_description_lines.append(stripped_line)\n        \n        line_idx += 1\n\n    # 3. After the loop, process the last meta block if any remained open.\n    if current_meta_args is not None:\n        desc = _clean_str(\"\\n\".join(current_meta_desc_lines))\n        meta.append(_build_meta(current_meta_args, desc if desc is not None else \"\"))\n\n    # 4. Finalize the long description.\n    # _clean_str handles stripping leading/trailing whitespace for the entire block.\n    long_description = _clean_str(\"\\n\".join(long_description_lines))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    \"\"\"\n    Cleans a string by removing leading/trailing whitespace.\n    Returns the cleaned string, or None if the string is empty or\n    contains only whitespace after cleaning.\n    \"\"\"\n    string = string.strip()\n    if len(string) > 0:\n        return string\n    return None\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    \"\"\"\n    Parses a segment of a docstring, converting keyword-prefixed lines\n    into structured metadata objects. It extracts details for parameters,\n    return values, or raised exceptions, facilitating docstring analysis.\n    \"\"\"\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    cleaned_text = inspect.cleandoc(text)\n    lines = cleaned_text.splitlines()\n\n    short_description = None\n    long_description_raw_lines = []\n    meta = []\n\n    current_meta_args = None\n    current_meta_desc_lines = []\n\n    # Flag to indicate if we are currently parsing a meta section's description\n    in_meta_section = False\n\n    # Regex to match ReST field lists like \":key argument_type argument_name: description\"\n    # It captures the keyword, any arguments before the second colon, and the initial description.\n    FIELD_REGEX = re.compile(r\"^:(?P<key>\\w+)\\s*(?P<args_part>.*?):\\s*(?P<first_desc_line>.*)\")\n\n    for line_num, line in enumerate(lines):\n        stripped_line = line.strip()\n\n        match = FIELD_REGEX.match(stripped_line)\n\n        if match:\n            # A new meta field line is encountered\n            if in_meta_section and current_meta_args:\n                # Finalize the description of the previous meta field\n                # before starting a new one. The description should be joined\n                # and then cleaned.\n                meta.append(_build_meta(current_meta_args, \"\\n\".join(current_meta_desc_lines)))\n            \n            # Transition to a new meta section\n            in_meta_section = True\n            current_meta_key = match.group(\"key\")\n            args_part = match.group(\"args_part\").strip()\n            first_desc_line = match.group(\"first_desc_line\").strip()\n\n            # Construct the list of arguments for _build_meta.\n            # This includes the keyword itself as the first argument.\n            if args_part:\n                current_meta_args = [current_meta_key] + args_part.split()\n            else:\n                current_meta_args = [current_meta_key]\n            \n            # Start collecting description lines for the current meta field\n            current_meta_desc_lines = [first_desc_line]\n\n        elif in_meta_section:\n            # This line is a continuation of the current meta description.\n            # `inspect.cleandoc` handles common indentation, so `stripped_line` is fine.\n            current_meta_desc_lines.append(stripped_line)\n\n        else:\n            # This line belongs to the main description (summary or long description)\n            if not stripped_line:\n                # An empty line. If a short description already exists, this blank\n                # line is part of the long description.\n                if short_description is not None:\n                    long_description_raw_lines.append(\"\")\n            else:\n                # A non-empty line\n                if short_description is None:\n                    # This is the first non-empty line, so it's the short description.\n                    short_description = stripped_line\n                else:\n                    # Subsequent non-empty lines are part of the long description.\n                    long_description_raw_lines.append(stripped_line)\n\n    # After the loop, finalize any pending meta field that was being parsed\n    if in_meta_section and current_meta_args:\n        meta.append(_build_meta(current_meta_args, \"\\n\".join(current_meta_desc_lines)))\n\n    # Post-process and clean descriptions\n    if short_description is not None:\n        short_description = _clean_str(short_description)\n\n    # Remove any leading or trailing empty strings from the long description list.\n    # This accounts for blank lines separating summary/long_description or\n    # blank lines before the metadata section.\n    while long_description_raw_lines and long_description_raw_lines[0] == \"\":\n        long_description_raw_lines.pop(0)\n    while long_description_raw_lines and long_description_raw_lines[-1] == \"\":\n        long_description_raw_lines.pop()\n\n    # Join the remaining lines and clean the final long description string.\n    long_description = _clean_str(\"\\n\".join(long_description_raw_lines))\n\n    return Docstring(\n        short_description=short_description,\n        long_description=long_description,\n        meta=meta,\n    )\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()"]}
{"task_id": 167, "project": "test-apps/docstring_parser", "module": "docstring_parser.numpydoc", "predictions": ["import inspect\nimport typing as T\nimport re\nimport itertools\n\nfrom .common import (\n    Docstring,\n    DocstringMeta,\n    DocstringDeprecated,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n# The following helper functions and regexes are assumed to be defined\n# in the same module scope as NumpydocParser, as indicated by the File Content.\n# For the parse method to work, it relies on these definitions:\n\n# def _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n#     a, b = itertools.tee(iterable)\n#     next(b, None)\n#     return itertools.zip_longest(a, b, fillvalue=end)\n\n# def _clean_str(string: str) -> T.Optional[str]:\n#     string = string.strip()\n#     if len(string) > 0:\n#         return string\n\n# KV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n# PARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n# PARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n# PARAM_DEFAULT_REGEX = re.compile(\n#     r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n# )\n# RETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\n# The parse method is part of the NumpydocParser class and relies on its\n# initialized state (self.titles_re, self.sections).\n# The implementation below is derived directly from the provided File Content,\n# as it perfectly matches the query function's signature and intent within the class.\ndef parse(self, text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    ret = Docstring()\n    if not text:\n        return ret\n\n    # Clean according to PEP-0257\n    text = inspect.cleandoc(text)\n\n    # Find first title and split on its position\n    match = self.titles_re.search(text)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    # Break description into short and long parts\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\n            \"\\n\"\n        )\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n        # Identify the matched section title.\n        # `next(g for g in match.groups() if g is not None)` extracts the content\n        # of the anonymous group `({})` in the section's title pattern.\n        title = next(g for g in match.groups() if g is not None)\n        factory = self.sections[title]\n\n        # section chunk starts after the header,\n        # ends at the start of the next header\n        start = match.end()\n        end = nextmatch.start() if nextmatch is not None else None\n        ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n    return ret", "import inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\n# numpydoc format has no formal grammar for this,\n# but we can make some educated guesses...\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret", "import inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\n# numpydoc format has no formal grammar for this,\n# but we can make some educated guesses...\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret", "import inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n# These helper functions and regexes are defined in the same file scope\n# as NumpydocParser, so they are directly accessible.\n# For clarity, their definitions are not repeated here, but assumed\n# to be present from the \"File Content\".\n\n# def _pairwise(...)\n# def _clean_str(...)\n# KV_REGEX = re.compile(...)\n# PARAM_KEY_REGEX = re.compile(...)\n# PARAM_OPTIONAL_REGEX = re.compile(...)\n# PARAM_DEFAULT_REGEX = re.compile(...)\n# RETURN_KEY_REGEX = re.compile(...)\n\n# class Section(...)\n# class _KVSection(...)\n# class _SphinxSection(...)\n# class ParamSection(...)\n# class RaisesSection(...)\n# class ReturnsSection(...)\n# class YieldsSection(...)\n# class DeprecationSection(...)\n# DEFAULT_SECTIONS = [...]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret", "import inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\n# Regex patterns from file context are also available\n# KV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n# PARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n# PARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n# PARAM_DEFAULT_REGEX = re.compile(\n#     r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n# )\n# RETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n# Section classes are defined in the file context, for clarity I will omit\n# their full re-definition here as the NumpydocParser depends on them being\n# already defined and initialized via DEFAULT_SECTIONS.\n# Example:\n# class Section: ...\n# class _KVSection(Section): ...\n# class ParamSection(_KVSection): ...\n# class RaisesSection(_KVSection): ...\n# class ReturnsSection(_KVSection): ...\n# class YieldsSection(ReturnsSection): ...\n# class DeprecationSection(_SphinxSection): ...\n\n# DEFAULT_SECTIONS is also defined in the file context, used by NumpydocParser's __init__\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, 'Section']] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        # Assuming DEFAULT_SECTIONS and all Section classes are defined earlier in the file\n        # as per file content.\n        from .numpydoc import DEFAULT_SECTIONS, Section # Required for type hinting Section\n\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        # Assuming Section.title_pattern and _SphinxSection.title_pattern are defined\n        # as per file content.\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: 'Section'):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport typing as T\nimport re\nimport itertools\n\nfrom .common import (\n    Docstring,\n    DocstringMeta,\n    DocstringDeprecated,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n# The following helper functions and regexes are assumed to be defined\n# in the same module scope as NumpydocParser, as indicated by the File Content.\n# For the parse method to work, it relies on these definitions:\n\n# def _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n#     a, b = itertools.tee(iterable)\n#     next(b, None)\n#     return itertools.zip_longest(a, b, fillvalue=end)\n\n# def _clean_str(string: str) -> T.Optional[str]:\n#     string = string.strip()\n#     if len(string) > 0:\n#         return string\n\n# KV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n# PARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n# PARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n# PARAM_DEFAULT_REGEX = re.compile(\n#     r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n# )\n# RETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\n# The parse method is part of the NumpydocParser class and relies on its\n# initialized state (self.titles_re, self.sections).\n# The implementation below is derived directly from the provided File Content,\n# as it perfectly matches the query function's signature and intent within the class.\ndef parse(self, text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    ret = Docstring()\n    if not text:\n        return ret\n\n    # Clean according to PEP-0257\n    text = inspect.cleandoc(text)\n\n    # Find first title and split on its position\n    match = self.titles_re.search(text)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    # Break description into short and long parts\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\n            \"\\n\"\n        )\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n        # Identify the matched section title.\n        # `next(g for g in match.groups() if g is not None)` extracts the content\n        # of the anonymous group `({})` in the section's title pattern.\n        title = next(g for g in match.groups() if g is not None)\n        factory = self.sections[title]\n\n        # section chunk starts after the header,\n        # ends at the start of the next header\n        start = match.end()\n        end = nextmatch.start() if nextmatch is not None else None\n        ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n    return ret\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\n# numpydoc format has no formal grammar for this,\n# but we can make some educated guesses...\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\n# numpydoc format has no formal grammar for this,\n# but we can make some educated guesses...\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n# These helper functions and regexes are defined in the same file scope\n# as NumpydocParser, so they are directly accessible.\n# For clarity, their definitions are not repeated here, but assumed\n# to be present from the \"File Content\".\n\n# def _pairwise(...)\n# def _clean_str(...)\n# KV_REGEX = re.compile(...)\n# PARAM_KEY_REGEX = re.compile(...)\n# PARAM_OPTIONAL_REGEX = re.compile(...)\n# PARAM_DEFAULT_REGEX = re.compile(...)\n# RETURN_KEY_REGEX = re.compile(...)\n\n# class Section(...)\n# class _KVSection(...)\n# class _SphinxSection(...)\n# class ParamSection(...)\n# class RaisesSection(...)\n# class ReturnsSection(...)\n# class YieldsSection(...)\n# class DeprecationSection(...)\n# DEFAULT_SECTIONS = [...]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\n# Regex patterns from file context are also available\n# KV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n# PARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n# PARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n# PARAM_DEFAULT_REGEX = re.compile(\n#     r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n# )\n# RETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n# Section classes are defined in the file context, for clarity I will omit\n# their full re-definition here as the NumpydocParser depends on them being\n# already defined and initialized via DEFAULT_SECTIONS.\n# Example:\n# class Section: ...\n# class _KVSection(Section): ...\n# class ParamSection(_KVSection): ...\n# class RaisesSection(_KVSection): ...\n# class ReturnsSection(_KVSection): ...\n# class YieldsSection(ReturnsSection): ...\n# class DeprecationSection(_SphinxSection): ...\n\n# DEFAULT_SECTIONS is also defined in the file context, used by NumpydocParser's __init__\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, 'Section']] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        # Assuming DEFAULT_SECTIONS and all Section classes are defined earlier in the file\n        # as per file content.\n        from .numpydoc import DEFAULT_SECTIONS, Section # Required for type hinting Section\n\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        # Assuming Section.title_pattern and _SphinxSection.title_pattern are defined\n        # as per file content.\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: 'Section'):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n"]}
