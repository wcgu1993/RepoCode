{"task_id": 165, "project": "test-apps/docstring_parser", "module": "docstring_parser.google", "predictions": ["from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from .google import GoogleParser\nfrom .common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from .google import GoogleParser\nfrom .common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)", "from docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom .google import GoogleParser\nfrom .common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom .google import GoogleParser\nfrom .common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\nfrom collections import namedtuple, OrderedDict\nfrom enum import IntEnum\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\nclass SectionType(IntEnum):\n    \"\"\"Types of sections.\"\"\"\n\n    SINGULAR = 0\n    \"\"\"For sections like examples.\"\"\"\n\n    MULTIPLE = 1\n    \"\"\"For sections like params.\"\"\"\n\n    SINGULAR_OR_MULTIPLE = 2\n    \"\"\"For sections like returns or yields.\"\"\"\n\n\nclass Section(namedtuple(\"SectionBase\", \"title key type\")):\n    \"\"\"A docstring section.\"\"\"\n\n\nGOOGLE_TYPED_ARG_REGEX = re.compile(r\"\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)\")\nGOOGLE_ARG_DESC_REGEX = re.compile(r\".*\\. Defaults to (.+)\\.\")\nMULTIPLE_PATTERN = re.compile(r\"(\\s*[^:\\s]+:)|([^:]*\\]:.*)\")\n\nDEFAULT_SECTIONS = [\n    Section(\"Arguments\", \"param\", SectionType.MULTIPLE),\n    Section(\"Args\", \"param\", SectionType.MULTIPLE),\n    Section(\"Parameters\", \"param\", SectionType.MULTIPLE),\n    Section(\"Params\", \"param\", SectionType.MULTIPLE),\n    Section(\"Raises\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Exceptions\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Except\", \"raises\", SectionType.MULTIPLE),\n    Section(\"Attributes\", \"attribute\", SectionType.MULTIPLE),\n    Section(\"Example\", \"examples\", SectionType.SINGULAR),\n    Section(\"Examples\", \"examples\", SectionType.SINGULAR),\n    Section(\"Returns\", \"returns\", SectionType.SINGULAR_OR_MULTIPLE),\n    Section(\"Yields\", \"yields\", SectionType.SINGULAR_OR_MULTIPLE),\n]\n\n\nclass GoogleParser:\n    def __init__(\n        self, sections: T.Optional[T.List[Section]] = None, title_colon=True\n    ):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        :param title_colon: require colon after section title.\n        \"\"\"\n        if not sections:\n            sections = DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self.title_colon = title_colon\n        self._setup()\n\n    def _setup(self):\n        if self.title_colon:\n            colon = \":\"\n        else:\n            colon = \"\"\n        self.titles_re = re.compile(\n            \"^(\"\n            + \"|\".join(\"(%s)\" % t for t in self.sections)\n            + \")\"\n            + colon\n            + \"[ \\t\\r\\f\\v]*$\",\n            flags=re.M,\n        )\n\n    def _build_meta(self, text: str, title: str) -> DocstringMeta:\n        \"\"\"Build docstring element.\n\n        :param text: docstring element text\n        :param title: title of section containing element\n        :return:\n        \"\"\"\n\n        section = self.sections[title]\n\n        if (\n            section.type == SectionType.SINGULAR_OR_MULTIPLE\n            and not MULTIPLE_PATTERN.match(text)\n        ) or section.type == SectionType.SINGULAR:\n            return self._build_single_meta(section, text)\n\n        # Split spec and description\n        before, desc = text.split(\":\", 1)\n        if desc:\n            desc = desc[1:] if desc[0] == \" \" else desc\n            if \"\\n\" in desc:\n                first_line, rest = desc.split(\"\\n\", 1)\n                desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n            desc = desc.strip(\"\\n\")\n\n        return self._build_multi_meta(section, before, desc)\n\n    def _build_single_meta(self, section: Section, desc: str) -> DocstringMeta:\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key],\n                description=desc,\n                type_name=None,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key], description=desc, type_name=None\n            )\n        if section.key in PARAM_KEYWORDS:\n            raise ParseError(\"Expected paramenter name.\")\n        return DocstringMeta(args=[section.key], description=desc)\n\n    def _build_multi_meta(\n        self, section: Section, before: str, desc: str\n    ) -> DocstringMeta:\n        if section.key in PARAM_KEYWORDS:\n            m = GOOGLE_TYPED_ARG_REGEX.match(before)\n            if m:\n                arg_name, type_name = m.group(1, 2)\n                if type_name.endswith(\", optional\"):\n                    is_optional = True\n                    type_name = type_name[:-10]\n                elif type_name.endswith(\"?\"):\n                    is_optional = True\n                    type_name = type_name[:-1]\n                else:\n                    is_optional = False\n            else:\n                arg_name, type_name = before, None\n                is_optional = None\n\n            m = GOOGLE_ARG_DESC_REGEX.match(desc)\n            default = m.group(1) if m else None\n\n            return DocstringParam(\n                args=[section.key, before],\n                description=desc,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=is_optional,\n                default=default,\n            )\n        if section.key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n            return DocstringReturns(\n                args=[section.key, before],\n                description=desc,\n                type_name=before,\n                is_generator=section.key in YIELDS_KEYWORDS,\n            )\n        if section.key in RAISES_KEYWORDS:\n            return DocstringRaises(\n                args=[section.key, before], description=desc, type_name=before\n            )\n        return DocstringMeta(args=[section.key, before], description=desc)\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the Google-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        # Split by sections determined by titles\n        matches = list(self.titles_re.finditer(meta_chunk))\n        if not matches:\n            return ret\n        splits = []\n        for j in range(len(matches) - 1):\n            splits.append((matches[j].end(), matches[j + 1].start()))\n        splits.append((matches[-1].end(), len(meta_chunk)))\n\n        chunks = OrderedDict()\n        for j, (start, end) in enumerate(splits):\n            title = matches[j].group(1)\n            if title not in self.sections:\n                continue\n            chunks[title] = meta_chunk[start:end].strip(\"\\n\")\n        if not chunks:\n            return ret\n\n        # Add elements from each chunk\n        for title, chunk in chunks.items():\n            # Determine indent\n            indent_match = re.search(r\"^\\s+\", chunk)\n            if not indent_match:\n                raise ParseError('Can\\'t infer indent from \"{}\"'.format(chunk))\n            indent = indent_match.group()\n\n            # Check for singular elements\n            if self.sections[title].type in [\n                SectionType.SINGULAR,\n                SectionType.SINGULAR_OR_MULTIPLE,\n            ]:\n                part = inspect.cleandoc(chunk)\n                ret.meta.append(self._build_meta(part, title))\n                continue\n\n            # Split based on lines which have exactly that indent\n            _re = \"^\" + indent + r\"(?=\\S)\"\n            c_matches = list(re.finditer(_re, chunk, flags=re.M))\n            if not c_matches:\n                raise ParseError(\n                    'No specification for \"{}\": \"{}\"'.format(title, chunk)\n                )\n            c_splits = []\n            for j in range(len(c_matches) - 1):\n                c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n            c_splits.append((c_matches[-1].end(), len(chunk)))\n            for j, (start, end) in enumerate(c_splits):\n                part = chunk[start:end].strip(\"\\n\")\n                ret.meta.append(self._build_meta(part, title))\n\n        return ret\n\n\nfrom docstring_parser.google import GoogleParser\nfrom docstring_parser.common import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = GoogleParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_2():\n    assert isinstance(parse.__qualname__, str)\ntest_2()\n\ndef test_3():\n    assert isinstance(parse(\"\"), Docstring)\ntest_3()\n\ndef test_4():\n    assert isinstance(parse, T.Callable)\ntest_4()\n\ndef test_5():\n    assert isinstance(parse.__doc__, str)\ntest_5()\n\ndef test_13():\n    assert isinstance(parse.__name__, str)\ntest_13()\n\n\n"]}
{"task_id": 166, "project": "test-apps/docstring_parser", "module": "docstring_parser.rest", "predictions": ["import typing as T\nfrom docstring_parser.common import Docstring, ParseError\nfrom docstring_parser.rest import _build_meta\nimport re\nimport inspect\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize and split input text into lines\n    lines = text.expandtabs().splitlines()\n    lines = [line.rstrip() for line in lines]\n\n    docstring = Docstring()\n    docstring.meta = []\n\n    if not lines:\n        return docstring\n\n    # State variables\n    short_desc_lines = []\n    long_desc_lines = []\n    cur_meta_lines = []\n    cur_meta_args: T.Optional[T.List[str]] = None\n\n    # A line indicates metadata start if it starts with `:`\n    # For example: \":param arg: description\"\n    # Pattern to parse the metadata directive line (e.g. \":param int foo:\")\n    meta_line_re = re.compile(r\"^:(?P<key>[a-zA-Z0-9-]+)(?P<args>[^:]*)\\s*:(?P<desc>.*)$\")\n\n    # First pass: separate short description, long description, and meta blocks\n    # Convention:\n    # - Short description is the initial non-empty line(s) before first blank line\n    # - Long description starts from first blank line after short description till before meta section or end\n    # - Meta sections start at lines beginning with ':', may have indented continuation lines\n\n    # Find the line index where meta directives start (if any)\n    meta_start_idx = None\n    for idx, line in enumerate(lines):\n        if line.lstrip().startswith(\":\"):\n            meta_start_idx = idx\n            break\n\n    # If meta lines found, process different parts accordingly\n    if meta_start_idx is not None:\n        # Short and long description lines are everything before meta_start_idx\n        desc_block_lines = lines[:meta_start_idx]\n        meta_lines = lines[meta_start_idx:]\n    else:\n        # No meta lines, all is description\n        desc_block_lines = lines\n        meta_lines = []\n\n    # Extract short and long description from desc_block_lines\n    # Short description: lines from start up to first blank line\n    # Long description: lines after the first blank line (ignoring leading blank lines)\n    first_blank_idx = None\n    for i, line in enumerate(desc_block_lines):\n        if line.strip() == \"\":\n            first_blank_idx = i\n            break\n\n    if first_blank_idx is None:\n        # No blank line found, all lines form the short description\n        short_desc_lines = desc_block_lines\n        long_desc_lines = []\n    else:\n        short_desc_lines = desc_block_lines[:first_blank_idx]\n        long_desc_lines = desc_block_lines[first_blank_idx + 1 :]\n\n    # Assign short_description and long_description, stripping leading/trailing blanks and cleaning indent\n    if short_desc_lines:\n        docstring.short_description = \"\\n\".join(short_desc_lines).strip()\n    else:\n        docstring.short_description = None\n\n    # For long description, join lines, remove uniform indentation\n    if long_desc_lines:\n        # Use inspect.cleandoc to remove common indentation & trailing spaces\n        long_desc_text = \"\\n\".join(long_desc_lines)\n        long_desc_text = inspect.cleandoc(long_desc_text)\n        if long_desc_text.strip() != \"\":\n            docstring.long_description = long_desc_text\n        else:\n            docstring.long_description = None\n    else:\n        docstring.long_description = None\n\n    # Parse the meta lines (e.g. \":param x: description\")\n    # Meta lines may be multiline; lines indented relative to the first ':' line belong to previous meta entry\n\n    # We will group meta lines into blocks: each block starts with a line matching meta_line_re,\n    # and continues with subsequent indented lines (at least 1 space or tab)\n    meta_blocks: T.List[T.List[str]] = []\n\n    current_block: T.List[str] = []\n    for line in meta_lines:\n        if line.strip() == \"\":\n            # blank lines inside meta blocks are part of the previous block (append as is)\n            if current_block:\n                current_block.append(line)\n            continue\n\n        if meta_line_re.match(line):\n            # New meta block starts\n            if current_block:\n                meta_blocks.append(current_block)\n            current_block = [line]\n        else:\n            # Continuation line: must be indented relative to previous meta_line\n            # According to reST, continuation lines are indented (at least one space/tab)\n            if not current_block:\n                # malformed, a continuation line before any metadata line.\n                # Skip or treat as normal? We skip it\n                continue\n            # Check indentation (leading whitespace)\n            leading_ws = len(line) - len(line.lstrip())\n            if leading_ws > 0:\n                current_block.append(line)\n            else:\n                # Not indented, means probably a new meta start line without colon? \n                # Add current_block, start new?\n                # Best to append current block and restart\n                meta_blocks.append(current_block)\n                current_block = []\n                # This line doesn't start with colon and is not indented, ignore\n                # Or treat as an error? We'll skip it\n    if current_block:\n        meta_blocks.append(current_block)\n\n    # For each meta block, combine lines and parse key, args, description\n    for block_lines in meta_blocks:\n        # Join block lines; first line is :key arguments: description possibly multiline\n        # continuation lines are appended preserving new lines\n        # We'll reconstruct the entire block string by joining with newline, and strip trailing spaces\n        block_text = \"\\n\".join(block_lines)\n        # Split first line from continuation lines for parsing key and args\n        first_line = block_lines[0]\n        match = meta_line_re.match(first_line)\n        if not match:\n            # malformed, treat whole block as a generic meta with key=None and description all lines joined\n            docstring.meta.append(DocstringMeta(args=[], description=block_text))\n            continue\n        key = match.group(\"key\")\n        args_part = match.group(\"args\").strip()\n        first_desc_line = match.group(\"desc\").rstrip()\n\n        # Determine args list\n        # Args part might be empty or contain arguments, split on spaces\n        # Often like \"int foo\" or \"foo\"\n        args_list: T.List[str] = []\n        if args_part:\n            args_list = args_part.split()\n        # First argument is the key (e.g. param, returns, raises)\n        # The full args for _build_meta is [key] + args_list (or key + args + arg_name)\n        parsed_args = [key] + args_list\n\n        # The description lines after the first line (i.e. continuation lines) should be appended to the first_desc_line\n        if len(block_lines) > 1:\n            # continuation lines, join them with newlines preserving indentation as is\n            cont_lines = block_lines[1:]\n            cont_text = \"\\n\".join(cont_lines)\n            # Compose full description as first_desc_line + '\\n' + continuation\n            if first_desc_line:\n                full_desc = first_desc_line + \"\\n\" + inspect.cleandoc(cont_text)\n            else:\n                full_desc = inspect.cleandoc(cont_text)\n        else:\n            full_desc = first_desc_line\n\n        # Build the metadata object using _build_meta from rest module\n        try:\n            meta = _build_meta(parsed_args, full_desc)\n        except ParseError as e:\n            # If parsing fails, fallback to generic meta\n            meta = DocstringMeta(args=parsed_args, description=full_desc)\n        docstring.meta.append(meta)\n\n    return docstring", "import typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize text and split into lines\n    lines = text.expandtabs().splitlines()\n\n    doc = Docstring()\n\n    # Strip leading and trailing blank lines\n    while lines and not lines[0].strip():\n        lines.pop(0)\n    while lines and not lines[-1].strip():\n        lines.pop()\n\n    if not lines:\n        return doc  # Empty docstring\n\n    # Extract short description\n    short_desc_lines = []\n    i = 0\n    while i < len(lines):\n        line = lines[i].strip()\n        if not line:\n            # blank line signals end of short description\n            break\n        if line.startswith(\":\"):\n            # tag line signals end of short description\n            break\n        short_desc_lines.append(line)\n        i += 1\n\n    doc.short_description = \" \".join(short_desc_lines) if short_desc_lines else None\n\n    # Determine if there's a blank line after short description\n    # Look ahead to next line if exists and is blank\n    if i < len(lines) and not lines[i].strip():\n        doc.blank_after_short_description = True\n        i += 1  # Skip blank line after short description\n    else:\n        doc.blank_after_short_description = False\n\n    # Extract long description lines until metadata starts (lines starting with ':')\n\n    long_desc_lines = []\n    while i < len(lines):\n        line = lines[i]\n        if line.strip().startswith(\":\"):\n            break\n        long_desc_lines.append(line)\n        i += 1\n\n    # Clean the long description using inspect.cleandoc to remove common indentation\n    long_desc_text = \"\\n\".join(long_desc_lines).rstrip()\n    if long_desc_text:\n        doc.long_description = inspect.cleandoc(long_desc_text)\n    else:\n        doc.long_description = None\n\n    # Determine if blank line after long description if any lines existed there\n    if long_desc_lines:\n        # Check if next line is blank\n        if i < len(lines) and not lines[i].strip():\n            doc.blank_after_long_description = True\n            i += 1\n        else:\n            doc.blank_after_long_description = False\n    else:\n        doc.blank_after_long_description = False\n\n    # Now parse metadata lines starting at i, which should be lines starting with ':' for meta entries\n    meta_lines = lines[i:]\n\n    # Parse the meta entries. Group lines by metadata entry starting with ':'\n    meta_entries = []  # List of tuples (start_line_index, line_content list)\n    current_entry_lines = []\n\n    for line in meta_lines:\n        if line.lstrip().startswith(\":\"):\n            # Start of a new meta entry\n            if current_entry_lines:\n                meta_entries.append(current_entry_lines)\n            current_entry_lines = [line]\n        else:\n            # continuation line, append if any\n            if current_entry_lines:\n                current_entry_lines.append(line)\n            # else ignore stray lines not belonging to meta entries\n\n    if current_entry_lines:\n        meta_entries.append(current_entry_lines)\n\n    # Parse each meta entry into DocstringMeta using _build_meta function from this file\n    # We must parse the key and args from the initial line, and collect description from rest lines\n\n    for entry_lines in meta_entries:\n        # First line should be like \":param int foo:\" or \":raises ValueError:\"\n        first_line = entry_lines[0].lstrip()\n        # Match pattern: :keyword (type)? argname? :\n        # The pattern: start with ':', then a key (sequence of letters), then possible args separated by spaces, then ':'\n        # e.g. \":param int foo:\", \":returns:\", \":raises ValueError:\"\n        m = re.match(r\":([^\\s:]+)\\s*([^:]*)\\s*:\", first_line)\n        if not m:\n            # fallback: treat entire line as key, no args, description empty for now\n            key = first_line[1:].rstrip(\":\").strip()\n            args = [key]\n            desc_lines = [line for line in entry_lines[1:]]\n            desc = \"\\n\".join(desc_lines).strip()\n            meta_obj = DocstringMeta(args=args, description=desc)\n            doc.meta.append(meta_obj)\n            continue\n\n        keyword = m.group(1)\n        args_text = m.group(2).strip()\n\n        # Split args by whitespace but keep complex types (like int foo)\n        # For param entries, args_text can be like \"int foo\" or \"foo\"\n        args = [keyword]\n        if args_text:\n            # further split args_text by spaces, but complication if args_text is \"int foo\"\n            # For ReST param, it's either:\n            # \":param foo:\"      -> args = ['param', 'foo']\n            # \":param int foo:\"  -> args = ['param', 'int', 'foo']\n            arg_parts = args_text.split()\n            args.extend(arg_parts)\n\n        # Rest lines after the first line form the description\n        desc_lines = entry_lines[1:]\n\n        # Also collect an initial description suffix on the first line after \":keyword args:\"\n        # For instance: \":param foo: description here\"\n        # The match above stops at the colon, but there may be description after, so check that:\n        after_colon_pos = first_line.find(\":\", m.end()-1)\n        desc_suffix = first_line[m.end():].strip()\n        if desc_suffix:\n            desc_lines = [desc_suffix] + desc_lines\n\n        # Combine description lines, dedent using inspect.cleandoc, preserving intentional indentations\n        desc_text = \"\\n\".join(desc_lines)\n        desc_cleaned = inspect.cleandoc(desc_text) if desc_text else \"\"\n\n        # Use _build_meta helper to build the right DocstringMeta subclass object\n        try:\n            meta_obj = _build_meta(args, desc_cleaned)\n        except ParseError:\n            # fallback: use generic DocstringMeta in case of parse errors\n            meta_obj = DocstringMeta(args=args, description=desc_cleaned)\n\n        doc.meta.append(meta_obj)\n\n    return doc", "import typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize text: remove leading/trailing blank lines and unify line endings\n    if text is None:\n        text = \"\"\n    text = text.expandtabs().rstrip()\n\n    # Split text into lines for processing\n    lines = text.splitlines()\n\n    # Initialize the Docstring object\n    docstring = Docstring()\n\n    # States and containers\n    meta = []\n    short_desc_lines = []\n    long_desc_lines = []\n    current_section_lines = []\n    current_meta_key = None\n    current_meta_args = None\n    parsing_meta = False\n\n    # Patterns to identify metadata lines in ReST-style\n    # e.g. \":param foo:\", \":param int foo:\", \":raises ValueError:\", \":returns int:\"\n    meta_line_re = re.compile(\n        r\"^:(?P<key>\\w+)(?:\\s+(?P<type_or_name>[^:]+?))?(?:\\s+(?P<arg>[^:]+?))?:\\s*(?P<desc>.*)\"\n    )\n\n    # Actually, the above regex is too naive for multi-args keys like :param int foo:\n    # The rest docstring style is roughly :param <type> <arg_name>: desc\n    # Or :param <arg_name>: desc\n    # So we try two regex alternatives:\n    meta_line_re1 = re.compile(r\"^:(?P<key>\\w+)\\s+(?P<type_name>\\S+)\\s+(?P<arg_name>\\S+):\\s*(?P<desc>.*)\")\n    meta_line_re2 = re.compile(r\"^:(?P<key>\\w+)\\s+(?P<arg_name>\\S+):\\s*(?P<desc>.*)\")\n    meta_line_re3 = re.compile(r\"^:(?P<key>\\w+):\\s*(?P<desc>.*)\")\n\n    # Helper function to finish the current meta block and add it to meta list\n    def finish_meta_block():\n        nonlocal current_meta_key, current_meta_args, current_section_lines\n        if current_meta_key is not None and current_section_lines is not None:\n            desc_text = \"\\n\".join(current_section_lines).rstrip()\n            desc_text = inspect.cleandoc(desc_text)\n            try:\n                m = _build_meta(current_meta_args, desc_text)\n                meta.append(m)\n            except ParseError:\n                # fallback: add unparsed meta\n                meta.append(DocstringMeta(args=current_meta_args, description=desc_text))\n        current_meta_key = None\n        current_meta_args = None\n        current_section_lines = []\n\n    # First, we parse short description and long description:\n    # The short description is the first non-blank line(s) until a blank line appears\n    # Then the long description is the continuation until the first metadata line appears\n\n    # Step 1: extract short description lines\n    # We consider lines from start until first blank line or metadata line\n    i = 0\n    n = len(lines)\n    # Collect short description lines until a blank line or a metadata line is found\n    while i < n and lines[i].strip() == \"\":\n        i += 1\n    # Lines now at first non-empty line or end\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            # blank line ends short description\n            i += 1\n            break\n        # Check if line is a meta line start\n        if (meta_line_re1.match(line)\n                or meta_line_re2.match(line)\n                or meta_line_re3.match(line)):\n            break\n        short_desc_lines.append(line)\n        i += 1\n\n    # Step 2: extract long description lines until a meta line or end\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            long_desc_lines.append(line)\n            i += 1\n            continue\n        if (meta_line_re1.match(line)\n                or meta_line_re2.match(line)\n                or meta_line_re3.match(line)):\n            # start of meta section\n            break\n        long_desc_lines.append(line)\n        i += 1\n\n    # Set short_description and long_description\n    if short_desc_lines:\n        docstring.short_description = inspect.cleandoc(\"\\n\".join(short_desc_lines))\n    else:\n        docstring.short_description = None\n\n    if long_desc_lines:\n        longdesc = \"\\n\".join(long_desc_lines)\n        # long description may contain indented blocks, so use cleandoc\n        docstring.long_description = inspect.cleandoc(longdesc)\n    else:\n        docstring.long_description = None\n\n    # Count blank lines after short_description and long_description\n    # to set blank_after_short_description and blank_after_long_description flags\n    # by checking text after short_desc and long_desc sections\n    # Find the index in original lines where short_desc ends\n    sd_end_idx = 0\n    for j, line in enumerate(lines):\n        if line.strip() == \"\":\n            if j >= len(short_desc_lines):\n                sd_end_idx = j\n                break\n    else:\n        sd_end_idx = len(short_desc_lines)\n\n    # Blank after short description is if line at sd_end_idx is blank (should be True if it was a blank line)\n    docstring.blank_after_short_description = (\n        sd_end_idx < n and lines[sd_end_idx].strip() == \"\"\n    )\n\n    # Find if blank after long description exists\n    ld_end_idx = i  # line index where long description ended (start of meta)\n    # Check if the line at ld_end_idx (if any) is blank\n    docstring.blank_after_long_description = (\n        ld_end_idx < n and lines[ld_end_idx].strip() == \"\"\n    )\n\n    # Step 3: parse meta blocks from lines[i:] until end\n    # Meta blocks start with lines like :param ..., :raises ..., etc.\n    # Multi-line descriptions start indented lines after a meta line\n\n    # Iterate from current line until end\n    idx = i\n    current_meta_key = None\n    current_meta_args = None\n    current_section_lines = []\n\n    while idx < n:\n        line = lines[idx]\n        if line.strip() == \"\":\n            # blank line - separator or part of description of meta item\n            if current_meta_key is not None:\n                current_section_lines.append(line)\n            idx += 1\n            continue\n\n        # Check if line starts new meta block\n        m1 = meta_line_re1.match(line)\n        m2 = meta_line_re2.match(line)\n        m3 = meta_line_re3.match(line)\n\n        if m1:\n            # Finish previous block\n            finish_meta_block()\n            key = m1.group(\"key\")\n            type_name = m1.group(\"type_name\")\n            arg_name = m1.group(\"arg_name\")\n            desc = m1.group(\"desc\")\n            current_meta_key = key\n            # Following _build_meta expects args list with key and either arg_name or type_name and arg_name\n            # For param: key, type_name, arg_name\n            # For others, key + something else\n            # Use args accordingly:\n            if key in PARAM_KEYWORDS:\n                current_meta_args = [key, type_name, arg_name]\n            else:\n                # For raises, returns, yields, etc\n                # Just pass key and type_name as args\n                current_meta_args = [key, type_name]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        elif m2:\n            finish_meta_block()\n            key = m2.group(\"key\")\n            arg_name = m2.group(\"arg_name\")\n            desc = m2.group(\"desc\")\n            current_meta_key = key\n            # args: key, arg_name\n            current_meta_args = [key, arg_name]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        elif m3:\n            finish_meta_block()\n            key = m3.group(\"key\")\n            desc = m3.group(\"desc\")\n            current_meta_key = key\n            current_meta_args = [key]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        # If line is indented (starts with space or tab), it continues the current meta description\n        if current_meta_key is not None and (line.startswith(\" \") or line.startswith(\"\\t\")):\n            current_section_lines.append(line)\n            idx += 1\n            continue\n\n        # If line is not recognized as meta and not indented for meta continuation, treat as stray line or end meta parsing\n        # We'll just append lines to long description as fallback if no meta_key active (unlikely here)\n        # Or break\n        break\n\n    # Finalize last meta block\n    finish_meta_block()\n\n    docstring.meta = meta\n\n    return docstring", "import typing as T\nimport re\nimport inspect\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom docstring_parser.rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Initialize the Docstring object to fill\n    doc = Docstring()\n\n    # Normalize text by stripping leading/trailing blank lines\n    lines = text.expandtabs().splitlines()\n    while lines and lines[0].strip() == \"\":\n        lines.pop(0)\n    while lines and lines[-1].strip() == \"\":\n        lines.pop()\n    text = \"\\n\".join(lines)\n\n    # If the docstring is empty after stripping, return empty Docstring\n    if not text.strip():\n        return doc\n\n    # We want to parse ReST-style docstring structured with sections like:\n    # :param type name: description\n    # :raises ExceptionType: description\n    # :returns type: description\n    # etc.\n\n    # We'll parse line by line, grouping consecutive continuation lines of meta\n    # fields, and separate the short description, long description, and meta.\n\n    lines = text.splitlines()\n    n = len(lines)\n\n    short_description_lines = []\n    long_description_lines = []\n    meta_lines = []\n\n    # States:\n    #   0 - reading short description (first non-empty text cluster)\n    #   1 - reading long description (optional, after blank line following short desc)\n    #   2 - reading meta fields (lines starting with :keyword:)\n    state = 0\n\n    def is_meta_line(line: str) -> bool:\n        # Match lines starting with colon and keyword\n        return bool(re.match(r\"^\\s*:[^:]+?:\", line))\n\n    # For continuation lines (indented), detect by leading spaces > 0\n    def is_indented(line: str) -> bool:\n        return len(line) > 0 and (line[0] == \" \" or line[0] == \"\\t\")\n\n    i = 0\n    # Parse short description (continuous lines until first blank line)\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            # blank line means end of short description\n            i += 1\n            break\n        short_description_lines.append(line)\n        i += 1\n\n    # Parse long description (continuous until blank line before meta)\n    while i < n:\n        line = lines[i]\n        if is_meta_line(line):\n            # Start of meta section\n            state = 2\n            break\n        elif line.strip() == \"\":\n            # blank line: maybe separating long description paragraphs\n            long_description_lines.append(line)\n            i += 1\n            # Check if following lines are meta or not in next iteration\n            # If next line is meta, end long description parsing\n            if i < n and is_meta_line(lines[i]):\n                state = 2\n                break\n            continue\n        else:\n            long_description_lines.append(line)\n            i += 1\n\n    # For meta lines, group continuation lines with the initial meta line\n    # We'll collect blocks of lines, each block representing one meta element.\n\n    meta_blocks = []\n    current_block_lines = []\n\n    while i < n:\n        line = lines[i]\n        if is_meta_line(line):\n            # start new meta block\n            if current_block_lines:\n                meta_blocks.append(current_block_lines)\n            current_block_lines = [line]\n        else:\n            # continuation line or empty line within meta block\n            if current_block_lines and (line.strip() == \"\" or is_indented(line)):\n                current_block_lines.append(line)\n            else:\n                # If line isn't indented or empty and not meta line,\n                # treat as blank or ignore? According to ReST style,\n                # meta continuation lines must be indented or empty.\n                if current_block_lines:\n                    meta_blocks.append(current_block_lines)\n                    current_block_lines = []\n                # Else skip line or consider as error? We'll skip.\n        i += 1\n\n    # Append last collected meta block if any\n    if current_block_lines:\n        meta_blocks.append(current_block_lines)\n\n    # Fill short_description and long_description\n    short_description = \"\\n\".join(short_description_lines).strip() or None\n    long_description = inspect.cleandoc(\"\\n\".join(long_description_lines)).strip() or None\n\n    if long_description == \"\":\n        long_description = None\n\n    doc.short_description = short_description\n    doc.long_description = long_description\n\n    # Analyze blank lines after short and long description for flags\n    # According to the initial code, these are stored as boolean attributes:\n    # \"blank_after_short_description\" and \"blank_after_long_description\"\n    # We can detect them by checking if there's a blank line after short desc and long desc in the original text.\n\n    # Determine blank_after_short_description:\n    # The short description is lines[:len(short_description_lines)]\n    # After that, if next line(s) is blank, set flag True\n\n    if short_description_lines:\n        idx = len(short_description_lines)\n        if idx < len(lines) and lines[idx].strip() == \"\":\n            doc.blank_after_short_description = True\n\n    # Determine blank_after_long_description similarly\n    # Long description was extracted starting after short desc blank line, ends before meta or end.\n    # So blank line after long_description if exists.\n\n    if long_description_lines:\n        # Locate long desc start index: after short desc + 1 blank line\n        long_start = len(short_description_lines) + 1\n        # Long desc lines are from long_start to long_start + len(long_description_lines)\n        long_end = long_start + len(long_description_lines)\n        if long_end < len(lines) and lines[long_end].strip() == \"\":\n            doc.blank_after_long_description = True\n\n    # Now parse each meta block text into DocstringMeta objects using _build_meta helper\n    # Each block starts with a line like \":param int foo:\" or \":raises ValueError:\"\n    # The first line contains the key and arguments, and rest lines are continuation description.\n\n    # Parse meta blocks\n    for block in meta_blocks:\n        first_line = block[0]\n        # Pattern: :keyword optional_type? optional_arg_name?:\n        m = re.match(r\"^\\s*:(\\S+)\\s*(.*?)\\s*:\\s*(.*)$\", first_line)\n        if not m:\n            # If the line doesn't match meta pattern, skip or treat as normal meta?\n            # We'll skip to next block\n            continue\n\n        key_raw = m.group(1)  # e.g., param, raises, returns\n        after_key = m.group(2)  # e.g., int foo\n        first_desc_line = m.group(3)  # first line of description after colon\n\n        # Compose full description with continuation lines\n        desc_lines = [first_desc_line] + block[1:]\n        # Clean indentation of continuation description lines\n        # We want to cleandoc the description lines after joining with \"\\n\"\n        desc = \"\\n\".join(desc_lines)\n        desc = inspect.cleandoc(desc)\n\n        # Parse args from key and rest\n        # For rest, split by spaces but keep them combined for param type and argname (like \"int foo\")\n        args = [key_raw]\n        # Split after_key, but take care if it contains multiple parts (for example: \"int foo\" or just \"foo\")\n        # Because _build_meta expects args like [\"param\", \"int\", \"foo\"] or [\"param\", \"foo\"]\n        if after_key:\n            # Try to split type and name if possible\n            # Use regex to split type and name intelligently\n            # We will split after_key by whitespace maxsplit=1\n\n            parts = after_key.strip().split(None, 1)\n            if len(parts) == 2:\n                type_name, arg_name = parts\n                args.extend([type_name, arg_name])\n            else:\n                # Only one part (either type or arg_name)\n                # We need to decide which it is: for param, it's likely the arg_name alone\n                # For raises or returns, it could be type only\n                # We'll append as single argument after key\n                args.append(parts[0])\n        # else no extra args\n\n        # Build the DocstringMeta using _build_meta\n        try:\n            meta_obj = _build_meta(args, desc)\n        except ParseError:\n            # If parsing fails, create a generic DocstringMeta fallback\n            meta_obj = DocstringMeta(args=args, description=desc)\n\n        doc.meta.append(meta_obj)\n\n    return doc", "import typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    Docstring,\n    ParseError,\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    DocstringMeta,\n)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n\n    # Strip leading/trailing whitespace and split into lines\n    lines = text.strip().splitlines()\n\n    doc = Docstring()\n    doc.meta = []\n\n    # Parse short description:\n    # The short description is the initial block of non-empty lines before\n    # - an empty line, or\n    # - a line starting a docstring field (e.g., \":param ...:\", \":returns:\", \":raises:\")\n\n    short_desc_lines = []\n    index = 0\n    n = len(lines)\n\n    # A regex to detect the start of a field directive line: e.g. \":param\", \":returns\", \":raises\"\n    field_start_re = re.compile(r\"^\\s*:(param|returns|raises|yields|meta|rtype|return|raise)\\b\")\n\n    while index < n:\n        line = lines[index]\n        if line.strip() == \"\":\n            # Stop at first blank line\n            break\n        if field_start_re.match(line):\n            # Stop if line starts with a recognized field\n            break\n        short_desc_lines.append(line)\n        index += 1\n\n    short_desc = \"\\n\".join(short_desc_lines).strip()\n    doc.short_description = short_desc if short_desc else None\n\n    # After short description, parse long description lines:\n    # The long description is the block of lines after short description and an empty line,\n    # up to the first field section.\n    # We'll skip empty lines immediately after short desc, then collect lines until a field starts.\n\n    # Move index forward skipping blank lines\n    while index < n and lines[index].strip() == \"\":\n        index += 1\n\n    long_desc_lines = []\n    while index < n:\n        line = lines[index]\n        if field_start_re.match(line):\n            break\n        long_desc_lines.append(line)\n        index += 1\n\n    long_desc = \"\\n\".join(long_desc_lines).strip()\n    doc.long_description = long_desc if long_desc else None\n\n    # Track if blank line after short/long desc to mark flags in Docstring\n    # (This is a minor feature, set flags accordingly)\n    # blank after short description if line after short desc is blank\n    # We only know the position after parsing short desc and before long desc\n    if short_desc_lines:\n        after_short_desc_line = len(short_desc_lines)\n        if after_short_desc_line < n:\n            doc.blank_after_short_description = (lines[after_short_desc_line].strip() == \"\")\n        else:\n            doc.blank_after_short_description = False\n    else:\n        doc.blank_after_short_description = False\n\n    if long_desc_lines:\n        after_long_desc_line = index\n        if after_long_desc_line < n:\n            doc.blank_after_long_description = (lines[after_long_desc_line].strip() == \"\")\n        else:\n            doc.blank_after_long_description = False\n    else:\n        doc.blank_after_long_description = False\n\n    # Now parse the meta fields (parameters, returns, raises, yields, meta, etc.)\n    #\n    # ReST fields start with colon `:field_name [args]: description`\n    # E.g.: \":param int foo: description\"\n    #       \":raises ValueError: description\"\n    #       \":return: description\"\n    #       \":returns int: description\"\n    #       \":yields int: description\"\n    #\n    # Multiline descriptions for a field are indented relative to the field line.\n    # We'll parse fields by scanning from current index to end.\n\n    meta_lines = lines[index:]\n    total = len(meta_lines)\n    i = 0\n\n    # Pattern to match a field line:\n    # starts with optional whitespace, colon, one keyword (param|raises|returns|yields|meta|...),\n    # then optional type and argument, then colon, then optional description\n    field_line_re = re.compile(\n        r\"\"\"\n        ^\\s*                             # optional leading whitespace\n        :(?P<key>\\w+)                   # field key (e.g. param, returns)\n        (?:\\s+                          # required space after key\n           (?P<type_and_arg>[^:]+?)     # non-greedy match of anything except colon, type_and_arg = type and/or arg name\n        )?\n        \\s*:                           # colon after key (and possible type_and_arg)\n        \\s*(?P<desc>.*)$               # optional description after colon\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    current_field = None  # holds current field's info: (args_list, description_lines)\n    # args_list: list of args (e.g. [\"param\", \"int\", \"foo\"])\n    # For param, args are usually: [\"param\", \"type\", \"arg_name\"] or [\"param\", \"arg_name\"]\n    # For returns/raises/yields/meta keys, args usually have one element or two\n\n    def finish_field():\n        # Build DocstringMeta from current_field, append to doc.meta\n        if current_field is None:\n            return\n        args, desc_lines = current_field\n        desc = \"\\n\".join(desc_lines).strip()\n        # Use the _build_meta helper defined in rest.py (file content) to build proper meta\n        meta_item = _build_meta(args, desc)\n        doc.meta.append(meta_item)\n\n    while i < total:\n        line = meta_lines[i]\n        m = field_line_re.match(line)\n        if m:\n            # new field detected, finish previous field first\n            finish_field()\n\n            key = m.group(\"key\")\n            type_and_arg = m.group(\"type_and_arg\")\n            desc = m.group(\"desc\")\n\n            # Parse args for the key\n            # Rules from _build_meta:\n            # PARAM_KEYWORDS: args can be (param, type_name, arg_name) OR (param, arg_name)\n            # RETURNS_KEYWORDS/YIELDS_KEYWORDS/RAISES_KEYWORDS: args can be (key,) or (key, type_name)\n            # Others: just [key]\n\n            args_list: T.List[str] = []\n            key_lower = key.lower()\n\n            if key_lower in PARAM_KEYWORDS:\n                # type_and_arg might be:\n                # - \"int foo\"\n                # - \"foo\"\n                # we need to split on whitespace, if two parts => type and arg_name\n                # if one part => arg_name only\n                if type_and_arg:\n                    parts = type_and_arg.strip().split(None, 1)\n                    if len(parts) == 2:\n                        args_list = [key_lower, parts[0], parts[1]]\n                    else:\n                        args_list = [key_lower, parts[0]]\n                else:\n                    # no argument after param key is likely parse error, but allow param with no arg_name?\n                    args_list = [key_lower]\n            elif key_lower in RETURNS_KEYWORDS | YIELDS_KEYWORDS | RAISES_KEYWORDS:\n                # type_and_arg could be type name, e.g. \"int\"\n                if type_and_arg:\n                    args_list = [key_lower, type_and_arg.strip()]\n                else:\n                    args_list = [key_lower]\n            else:\n                # generic meta key\n                if type_and_arg:\n                    args_list = [key_lower, type_and_arg.strip()]\n                else:\n                    args_list = [key_lower]\n\n            current_field = (args_list, [desc] if desc else [])\n\n            # Now parse following indented lines as continuation of description\n            i += 1\n            while i < total:\n                next_line = meta_lines[i]\n                # continuation lines are indented (at least one space or tab)\n                if next_line.strip() == \"\":\n                    # Blank line can be part of description\n                    current_field[1].append(\"\")\n                    i += 1\n                    continue\n                if re.match(r\"^\\s\", next_line):\n                    current_field[1].append(next_line)\n                    i += 1\n                else:\n                    # next field or no indentation stops continuation\n                    break\n        else:\n            # Line not starting with :keyword: and not blank or indented - ignored (could be faulty docstring)\n            # Skip line, do not consume, or break?\n            # We cannot safely parse free text here, so skip it.\n            i += 1\n\n    # after loop ends, finish last field if any\n    finish_field()\n\n    return doc"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport typing as T\nfrom docstring_parser.common import Docstring, ParseError\nfrom docstring_parser.rest import _build_meta\nimport re\nimport inspect\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize and split input text into lines\n    lines = text.expandtabs().splitlines()\n    lines = [line.rstrip() for line in lines]\n\n    docstring = Docstring()\n    docstring.meta = []\n\n    if not lines:\n        return docstring\n\n    # State variables\n    short_desc_lines = []\n    long_desc_lines = []\n    cur_meta_lines = []\n    cur_meta_args: T.Optional[T.List[str]] = None\n\n    # A line indicates metadata start if it starts with `:`\n    # For example: \":param arg: description\"\n    # Pattern to parse the metadata directive line (e.g. \":param int foo:\")\n    meta_line_re = re.compile(r\"^:(?P<key>[a-zA-Z0-9-]+)(?P<args>[^:]*)\\s*:(?P<desc>.*)$\")\n\n    # First pass: separate short description, long description, and meta blocks\n    # Convention:\n    # - Short description is the initial non-empty line(s) before first blank line\n    # - Long description starts from first blank line after short description till before meta section or end\n    # - Meta sections start at lines beginning with ':', may have indented continuation lines\n\n    # Find the line index where meta directives start (if any)\n    meta_start_idx = None\n    for idx, line in enumerate(lines):\n        if line.lstrip().startswith(\":\"):\n            meta_start_idx = idx\n            break\n\n    # If meta lines found, process different parts accordingly\n    if meta_start_idx is not None:\n        # Short and long description lines are everything before meta_start_idx\n        desc_block_lines = lines[:meta_start_idx]\n        meta_lines = lines[meta_start_idx:]\n    else:\n        # No meta lines, all is description\n        desc_block_lines = lines\n        meta_lines = []\n\n    # Extract short and long description from desc_block_lines\n    # Short description: lines from start up to first blank line\n    # Long description: lines after the first blank line (ignoring leading blank lines)\n    first_blank_idx = None\n    for i, line in enumerate(desc_block_lines):\n        if line.strip() == \"\":\n            first_blank_idx = i\n            break\n\n    if first_blank_idx is None:\n        # No blank line found, all lines form the short description\n        short_desc_lines = desc_block_lines\n        long_desc_lines = []\n    else:\n        short_desc_lines = desc_block_lines[:first_blank_idx]\n        long_desc_lines = desc_block_lines[first_blank_idx + 1 :]\n\n    # Assign short_description and long_description, stripping leading/trailing blanks and cleaning indent\n    if short_desc_lines:\n        docstring.short_description = \"\\n\".join(short_desc_lines).strip()\n    else:\n        docstring.short_description = None\n\n    # For long description, join lines, remove uniform indentation\n    if long_desc_lines:\n        # Use inspect.cleandoc to remove common indentation & trailing spaces\n        long_desc_text = \"\\n\".join(long_desc_lines)\n        long_desc_text = inspect.cleandoc(long_desc_text)\n        if long_desc_text.strip() != \"\":\n            docstring.long_description = long_desc_text\n        else:\n            docstring.long_description = None\n    else:\n        docstring.long_description = None\n\n    # Parse the meta lines (e.g. \":param x: description\")\n    # Meta lines may be multiline; lines indented relative to the first ':' line belong to previous meta entry\n\n    # We will group meta lines into blocks: each block starts with a line matching meta_line_re,\n    # and continues with subsequent indented lines (at least 1 space or tab)\n    meta_blocks: T.List[T.List[str]] = []\n\n    current_block: T.List[str] = []\n    for line in meta_lines:\n        if line.strip() == \"\":\n            # blank lines inside meta blocks are part of the previous block (append as is)\n            if current_block:\n                current_block.append(line)\n            continue\n\n        if meta_line_re.match(line):\n            # New meta block starts\n            if current_block:\n                meta_blocks.append(current_block)\n            current_block = [line]\n        else:\n            # Continuation line: must be indented relative to previous meta_line\n            # According to reST, continuation lines are indented (at least one space/tab)\n            if not current_block:\n                # malformed, a continuation line before any metadata line.\n                # Skip or treat as normal? We skip it\n                continue\n            # Check indentation (leading whitespace)\n            leading_ws = len(line) - len(line.lstrip())\n            if leading_ws > 0:\n                current_block.append(line)\n            else:\n                # Not indented, means probably a new meta start line without colon? \n                # Add current_block, start new?\n                # Best to append current block and restart\n                meta_blocks.append(current_block)\n                current_block = []\n                # This line doesn't start with colon and is not indented, ignore\n                # Or treat as an error? We'll skip it\n    if current_block:\n        meta_blocks.append(current_block)\n\n    # For each meta block, combine lines and parse key, args, description\n    for block_lines in meta_blocks:\n        # Join block lines; first line is :key arguments: description possibly multiline\n        # continuation lines are appended preserving new lines\n        # We'll reconstruct the entire block string by joining with newline, and strip trailing spaces\n        block_text = \"\\n\".join(block_lines)\n        # Split first line from continuation lines for parsing key and args\n        first_line = block_lines[0]\n        match = meta_line_re.match(first_line)\n        if not match:\n            # malformed, treat whole block as a generic meta with key=None and description all lines joined\n            docstring.meta.append(DocstringMeta(args=[], description=block_text))\n            continue\n        key = match.group(\"key\")\n        args_part = match.group(\"args\").strip()\n        first_desc_line = match.group(\"desc\").rstrip()\n\n        # Determine args list\n        # Args part might be empty or contain arguments, split on spaces\n        # Often like \"int foo\" or \"foo\"\n        args_list: T.List[str] = []\n        if args_part:\n            args_list = args_part.split()\n        # First argument is the key (e.g. param, returns, raises)\n        # The full args for _build_meta is [key] + args_list (or key + args + arg_name)\n        parsed_args = [key] + args_list\n\n        # The description lines after the first line (i.e. continuation lines) should be appended to the first_desc_line\n        if len(block_lines) > 1:\n            # continuation lines, join them with newlines preserving indentation as is\n            cont_lines = block_lines[1:]\n            cont_text = \"\\n\".join(cont_lines)\n            # Compose full description as first_desc_line + '\\n' + continuation\n            if first_desc_line:\n                full_desc = first_desc_line + \"\\n\" + inspect.cleandoc(cont_text)\n            else:\n                full_desc = inspect.cleandoc(cont_text)\n        else:\n            full_desc = first_desc_line\n\n        # Build the metadata object using _build_meta from rest module\n        try:\n            meta = _build_meta(parsed_args, full_desc)\n        except ParseError as e:\n            # If parsing fails, fallback to generic meta\n            meta = DocstringMeta(args=parsed_args, description=full_desc)\n        docstring.meta.append(meta)\n\n    return docstring\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize text and split into lines\n    lines = text.expandtabs().splitlines()\n\n    doc = Docstring()\n\n    # Strip leading and trailing blank lines\n    while lines and not lines[0].strip():\n        lines.pop(0)\n    while lines and not lines[-1].strip():\n        lines.pop()\n\n    if not lines:\n        return doc  # Empty docstring\n\n    # Extract short description\n    short_desc_lines = []\n    i = 0\n    while i < len(lines):\n        line = lines[i].strip()\n        if not line:\n            # blank line signals end of short description\n            break\n        if line.startswith(\":\"):\n            # tag line signals end of short description\n            break\n        short_desc_lines.append(line)\n        i += 1\n\n    doc.short_description = \" \".join(short_desc_lines) if short_desc_lines else None\n\n    # Determine if there's a blank line after short description\n    # Look ahead to next line if exists and is blank\n    if i < len(lines) and not lines[i].strip():\n        doc.blank_after_short_description = True\n        i += 1  # Skip blank line after short description\n    else:\n        doc.blank_after_short_description = False\n\n    # Extract long description lines until metadata starts (lines starting with ':')\n\n    long_desc_lines = []\n    while i < len(lines):\n        line = lines[i]\n        if line.strip().startswith(\":\"):\n            break\n        long_desc_lines.append(line)\n        i += 1\n\n    # Clean the long description using inspect.cleandoc to remove common indentation\n    long_desc_text = \"\\n\".join(long_desc_lines).rstrip()\n    if long_desc_text:\n        doc.long_description = inspect.cleandoc(long_desc_text)\n    else:\n        doc.long_description = None\n\n    # Determine if blank line after long description if any lines existed there\n    if long_desc_lines:\n        # Check if next line is blank\n        if i < len(lines) and not lines[i].strip():\n            doc.blank_after_long_description = True\n            i += 1\n        else:\n            doc.blank_after_long_description = False\n    else:\n        doc.blank_after_long_description = False\n\n    # Now parse metadata lines starting at i, which should be lines starting with ':' for meta entries\n    meta_lines = lines[i:]\n\n    # Parse the meta entries. Group lines by metadata entry starting with ':'\n    meta_entries = []  # List of tuples (start_line_index, line_content list)\n    current_entry_lines = []\n\n    for line in meta_lines:\n        if line.lstrip().startswith(\":\"):\n            # Start of a new meta entry\n            if current_entry_lines:\n                meta_entries.append(current_entry_lines)\n            current_entry_lines = [line]\n        else:\n            # continuation line, append if any\n            if current_entry_lines:\n                current_entry_lines.append(line)\n            # else ignore stray lines not belonging to meta entries\n\n    if current_entry_lines:\n        meta_entries.append(current_entry_lines)\n\n    # Parse each meta entry into DocstringMeta using _build_meta function from this file\n    # We must parse the key and args from the initial line, and collect description from rest lines\n\n    for entry_lines in meta_entries:\n        # First line should be like \":param int foo:\" or \":raises ValueError:\"\n        first_line = entry_lines[0].lstrip()\n        # Match pattern: :keyword (type)? argname? :\n        # The pattern: start with ':', then a key (sequence of letters), then possible args separated by spaces, then ':'\n        # e.g. \":param int foo:\", \":returns:\", \":raises ValueError:\"\n        m = re.match(r\":([^\\s:]+)\\s*([^:]*)\\s*:\", first_line)\n        if not m:\n            # fallback: treat entire line as key, no args, description empty for now\n            key = first_line[1:].rstrip(\":\").strip()\n            args = [key]\n            desc_lines = [line for line in entry_lines[1:]]\n            desc = \"\\n\".join(desc_lines).strip()\n            meta_obj = DocstringMeta(args=args, description=desc)\n            doc.meta.append(meta_obj)\n            continue\n\n        keyword = m.group(1)\n        args_text = m.group(2).strip()\n\n        # Split args by whitespace but keep complex types (like int foo)\n        # For param entries, args_text can be like \"int foo\" or \"foo\"\n        args = [keyword]\n        if args_text:\n            # further split args_text by spaces, but complication if args_text is \"int foo\"\n            # For ReST param, it's either:\n            # \":param foo:\"      -> args = ['param', 'foo']\n            # \":param int foo:\"  -> args = ['param', 'int', 'foo']\n            arg_parts = args_text.split()\n            args.extend(arg_parts)\n\n        # Rest lines after the first line form the description\n        desc_lines = entry_lines[1:]\n\n        # Also collect an initial description suffix on the first line after \":keyword args:\"\n        # For instance: \":param foo: description here\"\n        # The match above stops at the colon, but there may be description after, so check that:\n        after_colon_pos = first_line.find(\":\", m.end()-1)\n        desc_suffix = first_line[m.end():].strip()\n        if desc_suffix:\n            desc_lines = [desc_suffix] + desc_lines\n\n        # Combine description lines, dedent using inspect.cleandoc, preserving intentional indentations\n        desc_text = \"\\n\".join(desc_lines)\n        desc_cleaned = inspect.cleandoc(desc_text) if desc_text else \"\"\n\n        # Use _build_meta helper to build the right DocstringMeta subclass object\n        try:\n            meta_obj = _build_meta(args, desc_cleaned)\n        except ParseError:\n            # fallback: use generic DocstringMeta in case of parse errors\n            meta_obj = DocstringMeta(args=args, description=desc_cleaned)\n\n        doc.meta.append(meta_obj)\n\n    return doc\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    ParseError,\n)\nfrom .rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Normalize text: remove leading/trailing blank lines and unify line endings\n    if text is None:\n        text = \"\"\n    text = text.expandtabs().rstrip()\n\n    # Split text into lines for processing\n    lines = text.splitlines()\n\n    # Initialize the Docstring object\n    docstring = Docstring()\n\n    # States and containers\n    meta = []\n    short_desc_lines = []\n    long_desc_lines = []\n    current_section_lines = []\n    current_meta_key = None\n    current_meta_args = None\n    parsing_meta = False\n\n    # Patterns to identify metadata lines in ReST-style\n    # e.g. \":param foo:\", \":param int foo:\", \":raises ValueError:\", \":returns int:\"\n    meta_line_re = re.compile(\n        r\"^:(?P<key>\\w+)(?:\\s+(?P<type_or_name>[^:]+?))?(?:\\s+(?P<arg>[^:]+?))?:\\s*(?P<desc>.*)\"\n    )\n\n    # Actually, the above regex is too naive for multi-args keys like :param int foo:\n    # The rest docstring style is roughly :param <type> <arg_name>: desc\n    # Or :param <arg_name>: desc\n    # So we try two regex alternatives:\n    meta_line_re1 = re.compile(r\"^:(?P<key>\\w+)\\s+(?P<type_name>\\S+)\\s+(?P<arg_name>\\S+):\\s*(?P<desc>.*)\")\n    meta_line_re2 = re.compile(r\"^:(?P<key>\\w+)\\s+(?P<arg_name>\\S+):\\s*(?P<desc>.*)\")\n    meta_line_re3 = re.compile(r\"^:(?P<key>\\w+):\\s*(?P<desc>.*)\")\n\n    # Helper function to finish the current meta block and add it to meta list\n    def finish_meta_block():\n        nonlocal current_meta_key, current_meta_args, current_section_lines\n        if current_meta_key is not None and current_section_lines is not None:\n            desc_text = \"\\n\".join(current_section_lines).rstrip()\n            desc_text = inspect.cleandoc(desc_text)\n            try:\n                m = _build_meta(current_meta_args, desc_text)\n                meta.append(m)\n            except ParseError:\n                # fallback: add unparsed meta\n                meta.append(DocstringMeta(args=current_meta_args, description=desc_text))\n        current_meta_key = None\n        current_meta_args = None\n        current_section_lines = []\n\n    # First, we parse short description and long description:\n    # The short description is the first non-blank line(s) until a blank line appears\n    # Then the long description is the continuation until the first metadata line appears\n\n    # Step 1: extract short description lines\n    # We consider lines from start until first blank line or metadata line\n    i = 0\n    n = len(lines)\n    # Collect short description lines until a blank line or a metadata line is found\n    while i < n and lines[i].strip() == \"\":\n        i += 1\n    # Lines now at first non-empty line or end\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            # blank line ends short description\n            i += 1\n            break\n        # Check if line is a meta line start\n        if (meta_line_re1.match(line)\n                or meta_line_re2.match(line)\n                or meta_line_re3.match(line)):\n            break\n        short_desc_lines.append(line)\n        i += 1\n\n    # Step 2: extract long description lines until a meta line or end\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            long_desc_lines.append(line)\n            i += 1\n            continue\n        if (meta_line_re1.match(line)\n                or meta_line_re2.match(line)\n                or meta_line_re3.match(line)):\n            # start of meta section\n            break\n        long_desc_lines.append(line)\n        i += 1\n\n    # Set short_description and long_description\n    if short_desc_lines:\n        docstring.short_description = inspect.cleandoc(\"\\n\".join(short_desc_lines))\n    else:\n        docstring.short_description = None\n\n    if long_desc_lines:\n        longdesc = \"\\n\".join(long_desc_lines)\n        # long description may contain indented blocks, so use cleandoc\n        docstring.long_description = inspect.cleandoc(longdesc)\n    else:\n        docstring.long_description = None\n\n    # Count blank lines after short_description and long_description\n    # to set blank_after_short_description and blank_after_long_description flags\n    # by checking text after short_desc and long_desc sections\n    # Find the index in original lines where short_desc ends\n    sd_end_idx = 0\n    for j, line in enumerate(lines):\n        if line.strip() == \"\":\n            if j >= len(short_desc_lines):\n                sd_end_idx = j\n                break\n    else:\n        sd_end_idx = len(short_desc_lines)\n\n    # Blank after short description is if line at sd_end_idx is blank (should be True if it was a blank line)\n    docstring.blank_after_short_description = (\n        sd_end_idx < n and lines[sd_end_idx].strip() == \"\"\n    )\n\n    # Find if blank after long description exists\n    ld_end_idx = i  # line index where long description ended (start of meta)\n    # Check if the line at ld_end_idx (if any) is blank\n    docstring.blank_after_long_description = (\n        ld_end_idx < n and lines[ld_end_idx].strip() == \"\"\n    )\n\n    # Step 3: parse meta blocks from lines[i:] until end\n    # Meta blocks start with lines like :param ..., :raises ..., etc.\n    # Multi-line descriptions start indented lines after a meta line\n\n    # Iterate from current line until end\n    idx = i\n    current_meta_key = None\n    current_meta_args = None\n    current_section_lines = []\n\n    while idx < n:\n        line = lines[idx]\n        if line.strip() == \"\":\n            # blank line - separator or part of description of meta item\n            if current_meta_key is not None:\n                current_section_lines.append(line)\n            idx += 1\n            continue\n\n        # Check if line starts new meta block\n        m1 = meta_line_re1.match(line)\n        m2 = meta_line_re2.match(line)\n        m3 = meta_line_re3.match(line)\n\n        if m1:\n            # Finish previous block\n            finish_meta_block()\n            key = m1.group(\"key\")\n            type_name = m1.group(\"type_name\")\n            arg_name = m1.group(\"arg_name\")\n            desc = m1.group(\"desc\")\n            current_meta_key = key\n            # Following _build_meta expects args list with key and either arg_name or type_name and arg_name\n            # For param: key, type_name, arg_name\n            # For others, key + something else\n            # Use args accordingly:\n            if key in PARAM_KEYWORDS:\n                current_meta_args = [key, type_name, arg_name]\n            else:\n                # For raises, returns, yields, etc\n                # Just pass key and type_name as args\n                current_meta_args = [key, type_name]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        elif m2:\n            finish_meta_block()\n            key = m2.group(\"key\")\n            arg_name = m2.group(\"arg_name\")\n            desc = m2.group(\"desc\")\n            current_meta_key = key\n            # args: key, arg_name\n            current_meta_args = [key, arg_name]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        elif m3:\n            finish_meta_block()\n            key = m3.group(\"key\")\n            desc = m3.group(\"desc\")\n            current_meta_key = key\n            current_meta_args = [key]\n            current_section_lines = [desc] if desc else []\n            idx += 1\n            continue\n\n        # If line is indented (starts with space or tab), it continues the current meta description\n        if current_meta_key is not None and (line.startswith(\" \") or line.startswith(\"\\t\")):\n            current_section_lines.append(line)\n            idx += 1\n            continue\n\n        # If line is not recognized as meta and not indented for meta continuation, treat as stray line or end meta parsing\n        # We'll just append lines to long description as fallback if no meta_key active (unlikely here)\n        # Or break\n        break\n\n    # Finalize last meta block\n    finish_meta_block()\n\n    docstring.meta = meta\n\n    return docstring\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport typing as T\nimport re\nimport inspect\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\nfrom docstring_parser.rest import _build_meta\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    # Initialize the Docstring object to fill\n    doc = Docstring()\n\n    # Normalize text by stripping leading/trailing blank lines\n    lines = text.expandtabs().splitlines()\n    while lines and lines[0].strip() == \"\":\n        lines.pop(0)\n    while lines and lines[-1].strip() == \"\":\n        lines.pop()\n    text = \"\\n\".join(lines)\n\n    # If the docstring is empty after stripping, return empty Docstring\n    if not text.strip():\n        return doc\n\n    # We want to parse ReST-style docstring structured with sections like:\n    # :param type name: description\n    # :raises ExceptionType: description\n    # :returns type: description\n    # etc.\n\n    # We'll parse line by line, grouping consecutive continuation lines of meta\n    # fields, and separate the short description, long description, and meta.\n\n    lines = text.splitlines()\n    n = len(lines)\n\n    short_description_lines = []\n    long_description_lines = []\n    meta_lines = []\n\n    # States:\n    #   0 - reading short description (first non-empty text cluster)\n    #   1 - reading long description (optional, after blank line following short desc)\n    #   2 - reading meta fields (lines starting with :keyword:)\n    state = 0\n\n    def is_meta_line(line: str) -> bool:\n        # Match lines starting with colon and keyword\n        return bool(re.match(r\"^\\s*:[^:]+?:\", line))\n\n    # For continuation lines (indented), detect by leading spaces > 0\n    def is_indented(line: str) -> bool:\n        return len(line) > 0 and (line[0] == \" \" or line[0] == \"\\t\")\n\n    i = 0\n    # Parse short description (continuous lines until first blank line)\n    while i < n:\n        line = lines[i]\n        if line.strip() == \"\":\n            # blank line means end of short description\n            i += 1\n            break\n        short_description_lines.append(line)\n        i += 1\n\n    # Parse long description (continuous until blank line before meta)\n    while i < n:\n        line = lines[i]\n        if is_meta_line(line):\n            # Start of meta section\n            state = 2\n            break\n        elif line.strip() == \"\":\n            # blank line: maybe separating long description paragraphs\n            long_description_lines.append(line)\n            i += 1\n            # Check if following lines are meta or not in next iteration\n            # If next line is meta, end long description parsing\n            if i < n and is_meta_line(lines[i]):\n                state = 2\n                break\n            continue\n        else:\n            long_description_lines.append(line)\n            i += 1\n\n    # For meta lines, group continuation lines with the initial meta line\n    # We'll collect blocks of lines, each block representing one meta element.\n\n    meta_blocks = []\n    current_block_lines = []\n\n    while i < n:\n        line = lines[i]\n        if is_meta_line(line):\n            # start new meta block\n            if current_block_lines:\n                meta_blocks.append(current_block_lines)\n            current_block_lines = [line]\n        else:\n            # continuation line or empty line within meta block\n            if current_block_lines and (line.strip() == \"\" or is_indented(line)):\n                current_block_lines.append(line)\n            else:\n                # If line isn't indented or empty and not meta line,\n                # treat as blank or ignore? According to ReST style,\n                # meta continuation lines must be indented or empty.\n                if current_block_lines:\n                    meta_blocks.append(current_block_lines)\n                    current_block_lines = []\n                # Else skip line or consider as error? We'll skip.\n        i += 1\n\n    # Append last collected meta block if any\n    if current_block_lines:\n        meta_blocks.append(current_block_lines)\n\n    # Fill short_description and long_description\n    short_description = \"\\n\".join(short_description_lines).strip() or None\n    long_description = inspect.cleandoc(\"\\n\".join(long_description_lines)).strip() or None\n\n    if long_description == \"\":\n        long_description = None\n\n    doc.short_description = short_description\n    doc.long_description = long_description\n\n    # Analyze blank lines after short and long description for flags\n    # According to the initial code, these are stored as boolean attributes:\n    # \"blank_after_short_description\" and \"blank_after_long_description\"\n    # We can detect them by checking if there's a blank line after short desc and long desc in the original text.\n\n    # Determine blank_after_short_description:\n    # The short description is lines[:len(short_description_lines)]\n    # After that, if next line(s) is blank, set flag True\n\n    if short_description_lines:\n        idx = len(short_description_lines)\n        if idx < len(lines) and lines[idx].strip() == \"\":\n            doc.blank_after_short_description = True\n\n    # Determine blank_after_long_description similarly\n    # Long description was extracted starting after short desc blank line, ends before meta or end.\n    # So blank line after long_description if exists.\n\n    if long_description_lines:\n        # Locate long desc start index: after short desc + 1 blank line\n        long_start = len(short_description_lines) + 1\n        # Long desc lines are from long_start to long_start + len(long_description_lines)\n        long_end = long_start + len(long_description_lines)\n        if long_end < len(lines) and lines[long_end].strip() == \"\":\n            doc.blank_after_long_description = True\n\n    # Now parse each meta block text into DocstringMeta objects using _build_meta helper\n    # Each block starts with a line like \":param int foo:\" or \":raises ValueError:\"\n    # The first line contains the key and arguments, and rest lines are continuation description.\n\n    # Parse meta blocks\n    for block in meta_blocks:\n        first_line = block[0]\n        # Pattern: :keyword optional_type? optional_arg_name?:\n        m = re.match(r\"^\\s*:(\\S+)\\s*(.*?)\\s*:\\s*(.*)$\", first_line)\n        if not m:\n            # If the line doesn't match meta pattern, skip or treat as normal meta?\n            # We'll skip to next block\n            continue\n\n        key_raw = m.group(1)  # e.g., param, raises, returns\n        after_key = m.group(2)  # e.g., int foo\n        first_desc_line = m.group(3)  # first line of description after colon\n\n        # Compose full description with continuation lines\n        desc_lines = [first_desc_line] + block[1:]\n        # Clean indentation of continuation description lines\n        # We want to cleandoc the description lines after joining with \"\\n\"\n        desc = \"\\n\".join(desc_lines)\n        desc = inspect.cleandoc(desc)\n\n        # Parse args from key and rest\n        # For rest, split by spaces but keep them combined for param type and argname (like \"int foo\")\n        args = [key_raw]\n        # Split after_key, but take care if it contains multiple parts (for example: \"int foo\" or just \"foo\")\n        # Because _build_meta expects args like [\"param\", \"int\", \"foo\"] or [\"param\", \"foo\"]\n        if after_key:\n            # Try to split type and name if possible\n            # Use regex to split type and name intelligently\n            # We will split after_key by whitespace maxsplit=1\n\n            parts = after_key.strip().split(None, 1)\n            if len(parts) == 2:\n                type_name, arg_name = parts\n                args.extend([type_name, arg_name])\n            else:\n                # Only one part (either type or arg_name)\n                # We need to decide which it is: for param, it's likely the arg_name alone\n                # For raises or returns, it could be type only\n                # We'll append as single argument after key\n                args.append(parts[0])\n        # else no extra args\n\n        # Build the DocstringMeta using _build_meta\n        try:\n            meta_obj = _build_meta(args, desc)\n        except ParseError:\n            # If parsing fails, create a generic DocstringMeta fallback\n            meta_obj = DocstringMeta(args=args, description=desc)\n\n        doc.meta.append(meta_obj)\n\n    return doc\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\nimport inspect\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    Docstring,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    ParseError,\n)\n\n\ndef _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n    key = args[0]\n\n    if key in PARAM_KEYWORDS:\n        if len(args) == 3:\n            key, type_name, arg_name = args\n            if type_name.endswith(\"?\"):\n                is_optional = True\n                type_name = type_name[:-1]\n            else:\n                is_optional = False\n        elif len(args) == 2:\n            key, arg_name = args\n            type_name = None\n            is_optional = None\n        else:\n            raise ParseError(\n                \"Expected one or two arguments for a {} keyword.\".format(key)\n            )\n\n        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n        default = m.group(1).rstrip(\".\") if m else None\n\n        return DocstringParam(\n            args=args,\n            description=desc,\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n    if key in RETURNS_KEYWORDS | YIELDS_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n\n        return DocstringReturns(\n            args=args,\n            description=desc,\n            type_name=type_name,\n            is_generator=key in YIELDS_KEYWORDS,\n        )\n\n    if key in RAISES_KEYWORDS:\n        if len(args) == 2:\n            type_name = args[1]\n        elif len(args) == 1:\n            type_name = None\n        else:\n            raise ParseError(\n                \"Expected one or no arguments for a {} keyword.\".format(key)\n            )\n        return DocstringRaises(\n            args=args, description=desc, type_name=type_name\n        )\n\n    return DocstringMeta(args=args, description=desc)\n\n\nimport typing as T\nimport re\nimport inspect\n\nfrom .common import (\n    Docstring,\n    ParseError,\n    PARAM_KEYWORDS,\n    RAISES_KEYWORDS,\n    RETURNS_KEYWORDS,\n    YIELDS_KEYWORDS,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n    DocstringMeta,\n)\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n\n    # Strip leading/trailing whitespace and split into lines\n    lines = text.strip().splitlines()\n\n    doc = Docstring()\n    doc.meta = []\n\n    # Parse short description:\n    # The short description is the initial block of non-empty lines before\n    # - an empty line, or\n    # - a line starting a docstring field (e.g., \":param ...:\", \":returns:\", \":raises:\")\n\n    short_desc_lines = []\n    index = 0\n    n = len(lines)\n\n    # A regex to detect the start of a field directive line: e.g. \":param\", \":returns\", \":raises\"\n    field_start_re = re.compile(r\"^\\s*:(param|returns|raises|yields|meta|rtype|return|raise)\\b\")\n\n    while index < n:\n        line = lines[index]\n        if line.strip() == \"\":\n            # Stop at first blank line\n            break\n        if field_start_re.match(line):\n            # Stop if line starts with a recognized field\n            break\n        short_desc_lines.append(line)\n        index += 1\n\n    short_desc = \"\\n\".join(short_desc_lines).strip()\n    doc.short_description = short_desc if short_desc else None\n\n    # After short description, parse long description lines:\n    # The long description is the block of lines after short description and an empty line,\n    # up to the first field section.\n    # We'll skip empty lines immediately after short desc, then collect lines until a field starts.\n\n    # Move index forward skipping blank lines\n    while index < n and lines[index].strip() == \"\":\n        index += 1\n\n    long_desc_lines = []\n    while index < n:\n        line = lines[index]\n        if field_start_re.match(line):\n            break\n        long_desc_lines.append(line)\n        index += 1\n\n    long_desc = \"\\n\".join(long_desc_lines).strip()\n    doc.long_description = long_desc if long_desc else None\n\n    # Track if blank line after short/long desc to mark flags in Docstring\n    # (This is a minor feature, set flags accordingly)\n    # blank after short description if line after short desc is blank\n    # We only know the position after parsing short desc and before long desc\n    if short_desc_lines:\n        after_short_desc_line = len(short_desc_lines)\n        if after_short_desc_line < n:\n            doc.blank_after_short_description = (lines[after_short_desc_line].strip() == \"\")\n        else:\n            doc.blank_after_short_description = False\n    else:\n        doc.blank_after_short_description = False\n\n    if long_desc_lines:\n        after_long_desc_line = index\n        if after_long_desc_line < n:\n            doc.blank_after_long_description = (lines[after_long_desc_line].strip() == \"\")\n        else:\n            doc.blank_after_long_description = False\n    else:\n        doc.blank_after_long_description = False\n\n    # Now parse the meta fields (parameters, returns, raises, yields, meta, etc.)\n    #\n    # ReST fields start with colon `:field_name [args]: description`\n    # E.g.: \":param int foo: description\"\n    #       \":raises ValueError: description\"\n    #       \":return: description\"\n    #       \":returns int: description\"\n    #       \":yields int: description\"\n    #\n    # Multiline descriptions for a field are indented relative to the field line.\n    # We'll parse fields by scanning from current index to end.\n\n    meta_lines = lines[index:]\n    total = len(meta_lines)\n    i = 0\n\n    # Pattern to match a field line:\n    # starts with optional whitespace, colon, one keyword (param|raises|returns|yields|meta|...),\n    # then optional type and argument, then colon, then optional description\n    field_line_re = re.compile(\n        r\"\"\"\n        ^\\s*                             # optional leading whitespace\n        :(?P<key>\\w+)                   # field key (e.g. param, returns)\n        (?:\\s+                          # required space after key\n           (?P<type_and_arg>[^:]+?)     # non-greedy match of anything except colon, type_and_arg = type and/or arg name\n        )?\n        \\s*:                           # colon after key (and possible type_and_arg)\n        \\s*(?P<desc>.*)$               # optional description after colon\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    current_field = None  # holds current field's info: (args_list, description_lines)\n    # args_list: list of args (e.g. [\"param\", \"int\", \"foo\"])\n    # For param, args are usually: [\"param\", \"type\", \"arg_name\"] or [\"param\", \"arg_name\"]\n    # For returns/raises/yields/meta keys, args usually have one element or two\n\n    def finish_field():\n        # Build DocstringMeta from current_field, append to doc.meta\n        if current_field is None:\n            return\n        args, desc_lines = current_field\n        desc = \"\\n\".join(desc_lines).strip()\n        # Use the _build_meta helper defined in rest.py (file content) to build proper meta\n        meta_item = _build_meta(args, desc)\n        doc.meta.append(meta_item)\n\n    while i < total:\n        line = meta_lines[i]\n        m = field_line_re.match(line)\n        if m:\n            # new field detected, finish previous field first\n            finish_field()\n\n            key = m.group(\"key\")\n            type_and_arg = m.group(\"type_and_arg\")\n            desc = m.group(\"desc\")\n\n            # Parse args for the key\n            # Rules from _build_meta:\n            # PARAM_KEYWORDS: args can be (param, type_name, arg_name) OR (param, arg_name)\n            # RETURNS_KEYWORDS/YIELDS_KEYWORDS/RAISES_KEYWORDS: args can be (key,) or (key, type_name)\n            # Others: just [key]\n\n            args_list: T.List[str] = []\n            key_lower = key.lower()\n\n            if key_lower in PARAM_KEYWORDS:\n                # type_and_arg might be:\n                # - \"int foo\"\n                # - \"foo\"\n                # we need to split on whitespace, if two parts => type and arg_name\n                # if one part => arg_name only\n                if type_and_arg:\n                    parts = type_and_arg.strip().split(None, 1)\n                    if len(parts) == 2:\n                        args_list = [key_lower, parts[0], parts[1]]\n                    else:\n                        args_list = [key_lower, parts[0]]\n                else:\n                    # no argument after param key is likely parse error, but allow param with no arg_name?\n                    args_list = [key_lower]\n            elif key_lower in RETURNS_KEYWORDS | YIELDS_KEYWORDS | RAISES_KEYWORDS:\n                # type_and_arg could be type name, e.g. \"int\"\n                if type_and_arg:\n                    args_list = [key_lower, type_and_arg.strip()]\n                else:\n                    args_list = [key_lower]\n            else:\n                # generic meta key\n                if type_and_arg:\n                    args_list = [key_lower, type_and_arg.strip()]\n                else:\n                    args_list = [key_lower]\n\n            current_field = (args_list, [desc] if desc else [])\n\n            # Now parse following indented lines as continuation of description\n            i += 1\n            while i < total:\n                next_line = meta_lines[i]\n                # continuation lines are indented (at least one space or tab)\n                if next_line.strip() == \"\":\n                    # Blank line can be part of description\n                    current_field[1].append(\"\")\n                    i += 1\n                    continue\n                if re.match(r\"^\\s\", next_line):\n                    current_field[1].append(next_line)\n                    i += 1\n                else:\n                    # next field or no indentation stops continuation\n                    break\n        else:\n            # Line not starting with :keyword: and not blank or indented - ignored (could be faulty docstring)\n            # Skip line, do not consume, or break?\n            # We cannot safely parse free text here, so skip it.\n            i += 1\n\n    # after loop ends, finish last field if any\n    finish_field()\n\n    return doc\n\n\nimport pickle\ndef test_21():\n    assert None is parse(\":deprecated:\").returns\ntest_21()\n\n\ndef test_extra_7():\n    assert parse(\"\").short_description is None\ntest_extra_7()\n\ndef test_extra_8():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_8()\n\ndef test_extra_9():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").long_description == \"This is a long description.\"\ntest_extra_9()\n\ndef test_extra_10():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_short_description == True\ntest_extra_10()\n\ndef test_extra_11():\n    assert parse(\"Short description.\\n\\nThis is a long description.\").blank_after_long_description == False\ntest_extra_11()\n\ndef test_extra_12():\n    assert parse(\":param arg: This is a parameter.\\nAdditional information about the parameter.\").meta[0].description == \"This is a parameter.\\nAdditional information about the parameter.\"\ntest_extra_12()\n\ndef test_extra_20():\n    assert isinstance(parse(\"\"), Docstring)\ntest_extra_20()\n\ndef test_extra_21():\n    assert parse(\"\").short_description == None\n    assert parse(\"\").long_description == None\n    assert parse(\"\").meta == []\ntest_extra_21()\n\ndef test_extra_22():\n    assert parse(\"This is a short description.\").short_description == \"This is a short description.\"\ntest_extra_22()\n\ndef test_extra_23():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).long_description == \"This is a long description.\"\ntest_extra_23()\n\ndef test_extra_24():\n    text = \"This is a short description.\\n\\nThis is a long description.\"\n    assert parse(text).blank_after_short_description == True\ntest_extra_24()\n\ndef test_extra_33():\n    try:\n        parse(\"Short description\\n\\n:invalid\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":invalid\".'\ntest_extra_33()\n\ndef test_extra_39():\n    try:\n        parse(\":param arg1 description\")\n    except ParseError as e:\n        assert str(e) == 'Error parsing meta information near \":param arg1 description\".'\ntest_extra_39()"]}
{"task_id": 167, "project": "test-apps/docstring_parser", "module": "docstring_parser.numpydoc", "predictions": ["from docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "from docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "import inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "from docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.docstring import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)", "import inspect\nfrom typing import Optional, Dict\n\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)"], "test": ["\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.common import Docstring\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nfrom docstring_parser.numpydoc import NumpydocParser\nfrom docstring_parser.docstring import Docstring\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n", "\nimport sys\nsys.path.insert(1, \"/input/test-apps/docstring_parser\")\nimport unittest, pytest\nimport math\nimport random\nimport re\nimport copy\nimport datetime\nimport itertools\nimport collections\nimport heapq\nimport statistics\nimport functools\nimport hashlib\nimport numpy\nimport numpy as np\nimport string\nfrom typing import *\nfrom collections import *\nimport pickle\nimport timeout_decorator\n\n\n\nimport inspect\nimport itertools\nimport re\nimport typing as T\n\nfrom docstring_parser.common import (\n    Docstring,\n    DocstringDeprecated,\n    DocstringMeta,\n    DocstringParam,\n    DocstringRaises,\n    DocstringReturns,\n)\n\n\ndef _pairwise(iterable: T.Iterable, end=None) -> T.Iterable:\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return itertools.zip_longest(a, b, fillvalue=end)\n\n\ndef _clean_str(string: str) -> T.Optional[str]:\n    string = string.strip()\n    if len(string) > 0:\n        return string\n\n\nKV_REGEX = re.compile(r\"^[^\\s].*$\", flags=re.M)\n\nPARAM_KEY_REGEX = re.compile(r\"^(?P<name>.*?)(?:\\s*:\\s*(?P<type>.*?))?$\")\n\nPARAM_OPTIONAL_REGEX = re.compile(r\"(?P<type>.*?)(?:, optional|\\(optional\\))$\")\n\nPARAM_DEFAULT_REGEX = re.compile(\n    r\"[Dd]efault(?: is | = |: |s to |)\\s*(?P<value>[\\w\\-\\.]+)\"\n)\n\nRETURN_KEY_REGEX = re.compile(r\"^(?:(?P<name>.*?)\\s*:\\s*)?(?P<type>.*?)$\")\n\n\nclass Section:\n    \"\"\"Numpydoc section parser.\n\n    :param title: section title. For most sections, this is a heading like\n                  \"Parameters\" which appears on its own line, underlined by\n                  en-dashes ('-') on the following line.\n    :param key: meta key string. In the parsed ``DocstringMeta`` instance this\n                will be the first element of the ``args`` attribute list.\n    \"\"\"\n\n    def __init__(self, title: str, key: str) -> None:\n        self.title = title\n        self.key = key\n\n    @property\n    def title_pattern(self) -> str:\n        \"\"\"Regular expression pattern matching this section's header.\n\n        This pattern will match this instance's ``title`` attribute in\n        an anonymous group.\n        \"\"\"\n        return r\"^({})\\s*?\\n{}\\s*$\".format(self.title, \"-\" * len(self.title))\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n        :param text: section body text. Should be cleaned with\n                     ``inspect.cleandoc`` before parsing.\n        \"\"\"\n        yield DocstringMeta([self.key], description=_clean_str(text))\n\n\nclass _KVSection(Section):\n    \"\"\"Base parser for numpydoc sections with key-value syntax.\n\n    E.g. sections that look like this:\n        key\n            value\n        key2 : type\n            values can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringMeta:\n        pass\n\n    def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n        for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n            start = match.end()\n            end = next_match.start() if next_match is not None else None\n            value = text[start:end]\n            yield self._parse_item(\n                key=match.group(), value=inspect.cleandoc(value)\n            )\n\n\nclass _SphinxSection(Section):\n    \"\"\"Base parser for numpydoc sections with sphinx-style syntax.\n\n    E.g. sections that look like this:\n        .. title:: something\n            possibly over multiple lines\n    \"\"\"\n\n    @property\n    def title_pattern(self) -> str:\n        return r\"^\\.\\.\\s*({})\\s*::\".format(self.title)\n\n\nclass ParamSection(_KVSection):\n    \"\"\"Parser for numpydoc parameter sections.\n\n    E.g. any section that looks like this:\n        arg_name\n            arg_description\n        arg_2 : type, optional\n            descriptions can also span...\n            ... multiple lines\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringParam:\n        m = PARAM_KEY_REGEX.match(key)\n        arg_name = type_name = is_optional = None\n        if m is not None:\n            arg_name, type_name = m.group(\"name\"), m.group(\"type\")\n            if type_name is not None:\n                optional_match = PARAM_OPTIONAL_REGEX.match(type_name)\n                if optional_match is not None:\n                    type_name = optional_match.group(\"type\")\n                    is_optional = True\n                else:\n                    is_optional = False\n\n        default = None\n        if len(value) > 0:\n            default_match = PARAM_DEFAULT_REGEX.search(value)\n            if default_match is not None:\n                default = default_match.group(\"value\")\n\n        return DocstringParam(\n            args=[self.key, arg_name],\n            description=_clean_str(value),\n            arg_name=arg_name,\n            type_name=type_name,\n            is_optional=is_optional,\n            default=default,\n        )\n\n\nclass RaisesSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        ValueError\n            A description of what might raise ValueError\n    \"\"\"\n\n    def _parse_item(self, key: str, value: str) -> DocstringRaises:\n        return DocstringRaises(\n            args=[self.key, key],\n            description=_clean_str(value),\n            type_name=key if len(key) > 0 else None,\n        )\n\n\nclass ReturnsSection(_KVSection):\n    \"\"\"Parser for numpydoc raises sections.\n\n    E.g. any section that looks like this:\n        return_name : type\n            A description of this returned value\n        another_type\n            Return names are optional, types are required\n    \"\"\"\n\n    is_generator = False\n\n    def _parse_item(self, key: str, value: str) -> DocstringReturns:\n        m = RETURN_KEY_REGEX.match(key)\n        if m is not None:\n            return_name, type_name = m.group(\"name\"), m.group(\"type\")\n        else:\n            return_name = type_name = None\n\n        return DocstringReturns(\n            args=[self.key],\n            description=_clean_str(value),\n            type_name=type_name,\n            is_generator=self.is_generator,\n            return_name=return_name,\n        )\n\n\nclass YieldsSection(ReturnsSection):\n    \"\"\"Parser for numpydoc generator \"yields\" sections.\"\"\"\n\n    is_generator = True\n\n\nclass DeprecationSection(_SphinxSection):\n    \"\"\"Parser for numpydoc \"deprecation warning\" sections.\"\"\"\n\n    def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n        version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n        if desc is not None:\n            desc = _clean_str(inspect.cleandoc(desc))\n\n        yield DocstringDeprecated(\n            args=[self.key], description=desc, version=_clean_str(version)\n        )\n\n\nDEFAULT_SECTIONS = [\n    ParamSection(\"Parameters\", \"param\"),\n    ParamSection(\"Params\", \"param\"),\n    ParamSection(\"Arguments\", \"param\"),\n    ParamSection(\"Args\", \"param\"),\n    ParamSection(\"Other Parameters\", \"other_param\"),\n    ParamSection(\"Other Params\", \"other_param\"),\n    ParamSection(\"Other Arguments\", \"other_param\"),\n    ParamSection(\"Other Args\", \"other_param\"),\n    ParamSection(\"Receives\", \"receives\"),\n    ParamSection(\"Receive\", \"receives\"),\n    RaisesSection(\"Raises\", \"raises\"),\n    RaisesSection(\"Raise\", \"raises\"),\n    RaisesSection(\"Warns\", \"warns\"),\n    RaisesSection(\"Warn\", \"warns\"),\n    ParamSection(\"Attributes\", \"attribute\"),\n    ParamSection(\"Attribute\", \"attribute\"),\n    ReturnsSection(\"Returns\", \"returns\"),\n    ReturnsSection(\"Return\", \"returns\"),\n    YieldsSection(\"Yields\", \"yields\"),\n    YieldsSection(\"Yield\", \"yields\"),\n    Section(\"Examples\", \"examples\"),\n    Section(\"Example\", \"examples\"),\n    Section(\"Warnings\", \"warnings\"),\n    Section(\"Warning\", \"warnings\"),\n    Section(\"See Also\", \"see_also\"),\n    Section(\"Related\", \"see_also\"),\n    Section(\"Notes\", \"notes\"),\n    Section(\"Note\", \"notes\"),\n    Section(\"References\", \"references\"),\n    Section(\"Reference\", \"references\"),\n    DeprecationSection(\"deprecated\", \"deprecation\"),\n]\n\n\nclass NumpydocParser:\n    def __init__(self, sections: T.Optional[T.Dict[str, Section]] = None):\n        \"\"\"Setup sections.\n\n        :param sections: Recognized sections or None to defaults.\n        \"\"\"\n        sections = sections or DEFAULT_SECTIONS\n        self.sections = {s.title: s for s in sections}\n        self._setup()\n\n    def _setup(self):\n        self.titles_re = re.compile(\n            r\"|\".join(s.title_pattern for s in self.sections.values()),\n            flags=re.M,\n        )\n\n    def add_section(self, section: Section):\n        \"\"\"Add or replace a section.\n\n        :param section: The new section.\n        \"\"\"\n\n        self.sections[section.title] = section\n        self._setup()\n\n    def parse(self, text: str) -> Docstring:\n        \"\"\"Parse the numpy-style docstring into its components.\n\n        :returns: parsed docstring\n        \"\"\"\n        ret = Docstring()\n        if not text:\n            return ret\n\n        # Clean according to PEP-0257\n        text = inspect.cleandoc(text)\n\n        # Find first title and split on its position\n        match = self.titles_re.search(text)\n        if match:\n            desc_chunk = text[: match.start()]\n            meta_chunk = text[match.start() :]\n        else:\n            desc_chunk = text\n            meta_chunk = \"\"\n\n        # Break description into short and long parts\n        parts = desc_chunk.split(\"\\n\", 1)\n        ret.short_description = parts[0] or None\n        if len(parts) > 1:\n            long_desc_chunk = parts[1] or \"\"\n            ret.blank_after_short_description = long_desc_chunk.startswith(\n                \"\\n\"\n            )\n            ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n            ret.long_description = long_desc_chunk.strip() or None\n\n        for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n            title = next(g for g in match.groups() if g is not None)\n            factory = self.sections[title]\n\n            # section chunk starts after the header,\n            # ends at the start of the next header\n            start = match.end()\n            end = nextmatch.start() if nextmatch is not None else None\n            ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n        return ret\n\n\nimport inspect\nfrom typing import Optional, Dict\n\nfrom .common import Docstring\nfrom .numpydoc import NumpydocParser\n\n\ndef parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    parser = NumpydocParser()\n    return parser.parse(text)\n\n\nimport pickle\ndef test_22():\n    assert isinstance(parse(\"\"), Docstring)\ntest_22()\n\n\n"]}
