{"function": "_decode_dict_keys", "target_function_prompt": "def _decode_dict_keys(key_type, xs, infer_missing):\n    \"\"\"\n    Because JSON object keys must be strs, we need the extra step of decoding\n    them back into the user's chosen python type\n    \"\"\"\n", "f1_score": 0.1111111111111111, "recall": 1.0, "precision": 0.058823529411764705, "context_size": 17, "target_api_invocations": ["_decode_items"], "context": [{"fname": "_is_new_type", "evidence": "The function needs to handle complex or new-style types during decoding; checking for new types helps correctly decode keys that use typing.NewType or similar constructs."}, {"fname": "_is_mapping", "evidence": "Determining if the key_type is a mapping or has mapping characteristics could influence decoding logic for nested or complex key types, making this utility relevant."}, {"fname": "_handle_undefined_parameters_safe", "evidence": "Handling undefined parameters safely is important during decoding, as keys may be undefined or missing; this utility supports controlled handling of such cases."}, {"fname": "_isinstance_safe", "evidence": "Safe instance checking is essential when decoding keys to ensure type correctness without raising exceptions, making this utility highly likely to be invoked."}, {"fname": "_issubclass_safe", "evidence": "The target function likely needs to safely check if the key_type is a subclass of Enum or other special classes; this utility safely handles such subclass checks including typing NewType scenarios."}, {"fname": "_is_new_type_subclass_safe", "evidence": "This function supports safe subclass checking along the __supertype__ chain for NewType types, which supports node 1; thus it might be indirectly invoked when decoding keys for type checking."}, {"fname": "_support_extended_types", "evidence": "Decoding dict keys often requires converting string keys to complex types like UUID, datetime, or Decimal; this function supports such conversions and thus is relevant to the target function."}, {"fname": "_get_type_cons", "evidence": "The _get_type_cons utility extracts the underlying constructor from typing objects, which is likely necessary for decoding keys of possibly generic typing types in _decode_dict_keys."}, {"fname": "_get_type_origin", "evidence": "Determining the original type behind the typing construct is essential to decode keys to the correct Python type; this function provides that capability."}, {"fname": "_is_optional", "evidence": "Checking whether the key_type is optional is critical for handling None or missing keys during decoding."}, {"fname": "_hasargs", "evidence": "Inspecting presence of specific type arguments (such as None in optionals) is important for accurate decoding logic."}, {"fname": "_is_supported_generic", "evidence": "Determining if the key_type is a supported generic type guides the decoding process to handle collections, optionals, unions, or enums properly."}, {"fname": "_is_collection", "evidence": "Recognizing collection types among key_type is necessary to correctly decode keys especially if nested or composite key types are used."}, {"fname": "_decode_generic", "evidence": "_decode_dict_keys must convert string keys into arbitrary Python types; thus it likely calls _decode_generic to decode individual keys properly, handling enums and other complex types."}, {"fname": "_decode_items", "evidence": "_decode_dict_keys processes an iterable of keys and may call _decode_items to decode each key using the appropriate type-specific logic."}, {"fname": "_decode_dataclass", "evidence": "To support complex key types, including user-defined dataclasses, _decode_dict_keys might invoke _decode_dataclass to decode keys accurately."}, {"fname": "_user_overrides_or_exts", "evidence": "The '_user_overrides_or_exts' function generates field-specific encoder/decoder overrides by inspecting dataclass fields and metadata, which may provide decoding logic related to keys and fields. Since _decode_dict_keys must decode keys from strings to user types, it could rely on decoder override logic to perform or assist that decoding."}]}
{"function": "_decode_items", "target_function_prompt": "def _decode_items(type_arg, xs, infer_missing):\n    \"\"\"\n    This is a tricky situation where we need to check both the annotated\n    type info (which is usually a type from `typing`) and check the\n    value's type directly using `type()`.\n\n    If the type_arg is a generic we can use the annotated type, but if the\n    type_arg is a typevar we need to extract the reified type information\n    hence the check of `is_dataclass(vs)`\n    \"\"\"\n", "f1_score": 0.2857142857142857, "recall": 1.0, "precision": 0.16666666666666666, "context_size": 17, "target_api_invocations": ["_is_supported_generic", "_decode_generic", "_decode_dataclass"], "context": [{"fname": "_is_new_type", "evidence": "The target function deals with checking if a type is a new-style type with a '__supertype__'. This utility provides exactly that check, making it highly likely to be invoked."}, {"fname": "_is_mapping", "evidence": "The function decodes items and differentiates handling for mappings. This utility helps check if a type is a mapping subclass, so it is likely invoked."}, {"fname": "_isinstance_safe", "evidence": "Safe type checking is essential in decoding to avoid exceptions. The target function likely uses this to perform safe isinstance checks on values."}, {"fname": "_issubclass_safe", "evidence": "The target function needs safe subclass checks to analyze type annotations and uses _issubclass_safe to prevent exceptions during subclass checks."}, {"fname": "_support_extended_types", "evidence": "The target function needs to convert values into extended types like datetime, Decimal, or UUID, making this utility essential for such conversions."}, {"fname": "_get_type_cons", "evidence": "_decode_items needs to identify the constructor of the type argument to decode generics, exactly what _get_type_cons provides."}, {"fname": "_get_type_origin", "evidence": "_decode_items must determine the origin of generic types to correctly decode elements, so it is likely to invoke _get_type_origin."}, {"fname": "_is_optional", "evidence": "_decode_items must handle optional types and None values, so it likely calls _is_optional to detect optional type hints."}, {"fname": "_hasargs", "evidence": "_decode_items requires introspection of generic type arguments, making it plausible to invoke _hasargs for checking type parameters."}, {"fname": "_is_supported_generic", "evidence": "_decode_items needs to identify supported generic types to apply proper decoding logic; this utility provides exactly that check."}, {"fname": "_is_collection", "evidence": "Determining if a type is a collection is fundamental to decoding iterables; this function safely checks this and would be invoked."}, {"fname": "_decode_generic", "evidence": "_decode_items works closely with _decode_generic and likely invokes it to handle nested generic type decoding."}, {"fname": "_decode_dict_keys", "evidence": "_decode_items likely invokes _decode_dict_keys to decode dictionary keys when decoding mapping types."}, {"fname": "_decode_dataclass", "evidence": "The target function likely calls `_decode_dataclass` to decode values into dataclass instances when `type_arg` is a dataclass type, as indicated by its role in structured decoding and the target function's emphasis on handling dataclass-based type info."}, {"fname": "_user_overrides_or_exts", "evidence": "'_user_overrides_or_exts' generates encoder/decoder overrides for fields, which is highly relevant for '_decode_items' when it needs to apply custom decoders during decoding. Given '_decode_items' decodes each item with potential override logic, it is quite plausible this function is invoked."}, {"fname": "build_type", "evidence": "Decoding items according to complex type annotations may require generation or interpretation of marshmallow field types, so _decode_items might invoke build_type or similar logic to handle nested and complex types."}, {"fname": "_deserialize", "evidence": "The _deserialize method aligns closely with the task of _decode_items, which is to convert values to the appropriate types based on annotated type_args and inferred runtime types. _deserialize handles discriminated dataclasses, union-based type choices, and fallback warnings, which are exactly the kinds of logic _decode_items needs when decoding items of potentially varied or union types. Therefore, during implementation of _decode_items, it is reasonable to invoke _deserialize to delegate deserialization for matching types."}]}
{"function": "_asdict", "target_function_prompt": "def _asdict(obj, encode_json=False):\n    \"\"\"\n    A re-implementation of `asdict` (based on the original in the `dataclasses`\n    source) to support arbitrary Collection and Mapping types.\n    \"\"\"\n", "f1_score": 0.21428571428571425, "recall": 1.0, "precision": 0.12, "context_size": 24, "target_api_invocations": ["_handle_undefined_parameters_safe", "_encode_overrides", "_user_overrides_or_exts"], "context": [{"fname": "_is_new_type", "evidence": "Handling arbitrary types during conversion likely requires detecting new-style types with __supertype__, making _is_new_type relevant for _asdict."}, {"fname": "_is_mapping", "evidence": "Since _asdict supports arbitrary Mapping types, it likely needs to detect if objects or types are Mappings, so _is_mapping will be invoked."}, {"fname": "_handle_undefined_parameters_safe", "evidence": "_asdict may need to handle undefined parameters safely during serialization, and this utility manages such actions based on usage ('to'), making it likely invoked."}, {"fname": "_isinstance_safe", "evidence": "Safe type checking is essential during recursive conversions to avoid exceptions, so _isinstance_safe is very likely used by _asdict."}, {"fname": "_issubclass_safe", "evidence": "_issubclass_safe safely checks subclass relationships, which _asdict likely needs to handle arbitrary or new types safely."}, {"fname": "_is_new_type_subclass_safe", "evidence": "_is_new_type_subclass_safe is used internally by _issubclass_safe to handle new types safely, so it is indirectly invoked during subclass checks in _asdict."}, {"fname": "_support_extended_types", "evidence": "_support_extended_types converts values of extended types (datetime, Decimal, UUID), fitting the need of _asdict to handle such conversions while building dict representations."}, {"fname": "_encode_json_type", "evidence": "_encode_json_type converts values to JSON-compatible types, likely used by _asdict when encode_json=True to prepare data for JSON serialization."}, {"fname": "default", "evidence": "The _ExtendedEncoder.default method converts special types (datetime, UUID, Enum, Decimal, collections) into JSON-serializable forms, which aligns with _asdict's need to convert nested data into JSON-ready dictionaries."}, {"fname": "handle_to_dict", "evidence": "Although trivial, handle_to_dict returns a dict unchanged and might be used in the serialization pipeline where _asdict returns or manipulates dictionaries, making it possibly invoked."}, {"fname": "_get_type_cons", "evidence": "_get_type_cons helps extract the constructor or origin type from a typing object, which is useful for _asdict when recursively processing nested collections or generic types."}, {"fname": "_get_type_origin", "evidence": "Determining the type origin is necessary for identifying Collection and Mapping types in a way compatible with different Python typing versions, which _asdict needs to handle."}, {"fname": "_is_optional", "evidence": "Handling optional types is important for _asdict to correctly process fields that may be None or missing, supporting arbitrary nested types."}, {"fname": "_hasargs", "evidence": "Checking for specific type arguments is essential for detecting optional or Union types; since _asdict must handle such type hints, it likely invokes this helper directly or indirectly."}, {"fname": "_is_supported_generic", "evidence": "Identifying supported generic types such as collections, optionals, and enums helps _asdict decide how to convert fields recursively, matching the stated functionality."}, {"fname": "_is_collection", "evidence": "Recognizing whether a type is a Collection is fundamental for _asdict to correctly recurse into and convert nested container types."}, {"fname": "_is_nonstr_collection", "evidence": "The target function needs to detect if a type is a non-string collection to recurse correctly during dict conversion."}, {"fname": "_encode_overrides", "evidence": "The target function optionally encodes resulting dict fields and is likely to use this utility for applying encoders and overrides."}, {"fname": "_undefined_parameter_action_safe", "evidence": "The target function may check dataclass config for undefined parameter actions to handle missing or undefined fields safely during conversion."}, {"fname": "handle_to_dict", "evidence": "handle_to_dict merges the catch-all field's undefined parameters into the dict representation, a step logically needed by _asdict to produce a complete dictionary output."}, {"fname": "handle_dump", "evidence": "handle_dump provides access to the catch-all field data on the object, which _asdict may call to retrieve undefined parameters during serialization."}, {"fname": "_get_catch_all_field", "evidence": "_get_catch_all_field identifies the unique catch-all field of a dataclass, which _asdict likely needs to call to correctly handle and include catch-all data in its output."}, {"fname": "config", "evidence": "Node 5 provides configuration and metadata for JSON encoding, which _asdict likely uses to apply encoders or exclusions when serializing, so invocation is plausible."}, {"fname": "_user_overrides_or_exts", "evidence": "_asdict likely needs to apply field-level encoding overrides to handle JSON serialization properly; this function provides exactly those overrides."}]}
{"function": "dataclass_json", "target_function_prompt": "def dataclass_json(_cls=None, *, letter_case=None,\n                   undefined: Optional[Union[str, Undefined]] = None):\n    \"\"\"\n    Based on the code in the `dataclasses` module to handle optional-parens\n    decorators. See example below:\n\n    @dataclass_json\n    @dataclass_json(letter_case=LetterCase.CAMEL)\n    class Example:\n    ...\n    \"\"\"\n", "f1_score": 0.09523809523809523, "recall": 1.0, "precision": 0.05, "context_size": 20, "target_api_invocations": ["_process_class"], "context": [{"fname": "_separate_defined_undefined_kvs", "evidence": "The _separate_defined_undefined_kvs function partitions parameters into known and unknown sets, which is directly relevant to handling undefined parameters, a feature the dataclass_json decorator docstring suggests (i.e., handling configuration and undefined parameters). This helper could be invoked to manage parameter validation and handling within dataclass_json."}, {"fname": "_handle_undefined_parameters_safe", "evidence": "_handle_undefined_parameters_safe is a utility to manage how undefined parameters are handled based on context (to/from/dump/init). Given dataclass_json's decorator role and its handling of undefined configuration parameters (as indicated by the 'undefined' parameter), this function is likely invoked internally to process or handle such configurations or parameters safely."}, {"fname": "_issubclass_safe", "evidence": "The _issubclass_safe function is a utility for safely checking subclass relationships, which is often necessary in decorators and class-based processing like dataclass_json. Given dataclass_json may need to handle various types and inheritance checks while setting up the decorator, invoking this utility is plausible."}, {"fname": "_is_new_type_subclass_safe", "evidence": "_is_new_type_subclass_safe complements _issubclass_safe by handling special new-type subclass checks safely. Since dataclass_json works with types and may handle different type constructs or enforce type constraints, this utility could be used during implementation for robust subclass checks."}, {"fname": "handle_to_dict", "evidence": "dataclass_json likely uses this utility to handle dictionary parameter output when converting objects for serialization."}, {"fname": "handle_dump", "evidence": "This function returns schema parameters for dumping and may be invoked during schema generation handled by the decorator."}, {"fname": "dump", "evidence": "This dump method handles schema serialization and undefined parameters, matching the decorator's concerns about handling undefined values and dumping."}, {"fname": "override", "evidence": "The decorator accepts letter_case and would invoke this to transform field names accordingly during serialization."}, {"fname": "_encode_overrides", "evidence": "The target function dataclass_json is a decorator factory related to JSON serialization of dataclasses and involves optional parameters including letter_case. The _encode_overrides function applies letter casing transformations and encoding to dict entries, which matches closely with dataclass_json's concern about letter_case transformations and JSON encoding. It is plausible that dataclass_json internally uses or orchestrates such utility functions to apply letter casing and encoding behavior on dataclass dictionaries."}, {"fname": "_decode_letter_case_overrides", "evidence": "_decode_letter_case_overrides maps letter case transformations for field names, which fits well with dataclass_json's support of the letter_case parameter. Since dataclass_json handles decoration for dataclasses with optional letter casing, it could well invoke this utility for setting up decoding or encoding name mappings with overridden letter cases."}, {"fname": "_undefined_parameter_action_safe", "evidence": "The target function accepts an 'undefined' argument to control behavior for undefined keys in JSON dataclasses. The _undefined_parameter_action_safe function reads such configuration safely from a dataclass_json_config attribute, which is relevant in the context of the decorator's setup. It is thus likely dataclass_json would invoke this utility to robustly determine the behavior regarding undefined parameters in the decorated dataclass."}, {"fname": "_decode_items", "evidence": "The target function dataclass_json is a decorator factory that adds JSON serialization/deserialization support to dataclasses. To implement this, it would likely need to decode raw JSON or dict data into dataclass instances. Node 1's _decode_items function is a lower-level utility that decodes sequence contents into typed objects or dataclasses, which is highly relevant since dataclass_json deals with decoding input data structures, including handling generics. Hence, this utility fits well as an invoked helper function during decoding steps within the decorator's implementation."}, {"fname": "_decode_dataclass", "evidence": "Node 2's _decode_dataclass function is a core utility that transforms raw dict data into dataclass instances, handling missing fields, nested dataclasses, type conversions, and user overrides. The target function dataclass_json aims to provide JSON (de)serialization mixin behavior for dataclasses, and decoding raw input into dataclasses is fundamental to this. Therefore, it is highly likely that _decode_dataclass would be invoked either directly or indirectly in the decorator implementation."}, {"fname": "_asdict", "evidence": "Node 3's _asdict function converts dataclass instances recursively into dictionaries suitable for JSON serialization (optionally encoding JSON). The dataclass_json decorator adds capabilities for serializing dataclasses to JSON or dict representations, so this utility aligns directly with that. The decorator or associated mixin methods likely call _asdict to convert instances into serializable dicts before dumping to JSON."}, {"fname": "to_dict", "evidence": "The decorator sets up JSON serialization functionality and likely calls or injects to_dict to convert instances to dictionaries as part of its mechanism."}, {"fname": "to_json", "evidence": "The decorator provides JSON serialization, so it likely installs or references to_json to convert dataclass instances to JSON strings with customization."}, {"fname": "config", "evidence": "The decorator accepts letter_case and undefined parameters matching those configured by the config function, making it very likely to invoke this function during decoration."}, {"fname": "schema", "evidence": "The schema function provides serialization schemas, potentially invoked by the decorator to handle configuration of unknown fields and serialization rules."}, {"fname": "_user_overrides_or_exts", "evidence": "The decorator needs to manage field-specific serialization overrides, which aligns closely with the functionality of _user_overrides_or_exts, making it likely to be invoked."}, {"fname": "_process_class", "evidence": "The implementation of the target decorator function involves enhancing a class to support JSON serialization and deserialization, explicitly assigning methods from DataClassJsonMixin and configuring the class. The node's _process_class function assigns methods from DataClassJsonMixin (to_json, from_json, to_dict, from_dict, schema), calls config for configuration, and calls _handle_undefined_parameters_safe to wrap __init__. Since these methods are directly assigned and used by the decorator, this function is very likely invoked during implementation of the target decorator."}]}
