{"function": "_unquote_or_none", "target_function_prompt": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["url_unescape"], "context": []}
{"function": "multi", "target_function_prompt": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n    results = []\n    for future in list_of_futures:\n    results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n    If multiple yieldables fail, any exceptions after the first\n    (which is raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n    Replaced the class ``Multi`` and the function ``multi_future``\n    with a unified function ``multi``. Added support for yieldables\n    other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n", "f1_score": 0.10526315789473684, "recall": 1.0, "precision": 0.05555555555555555, "context_size": 16, "target_api_invocations": ["multi_future"], "context": [{"fname": "current", "evidence": "'current' returns or creates the currently running IOLoop instance, which is fundamental for running asynchronous operations and futures. Since 'multi' deals with multiple yieldable asynchronous operations in parallel, it likely needs access to the current event loop to coordinate and schedule these operations."}, {"fname": "future_add_done_callback", "evidence": "multi() must attach callbacks to futures to track completion of each child operation; this utility ensures callbacks are scheduled or run immediately as needed."}, {"fname": "handle_yield", "evidence": "multi() handles multiple yieldables converting them into managed futures and schedules their execution; this function provides that core functionality."}, {"fname": "spawn_callback", "evidence": "multi needs to schedule asynchronous callbacks to orchestrate multiple futures; spawn_callback provides this capability and is likely invoked."}, {"fname": "add_future", "evidence": "The 'multi' function aggregates multiple yieldables (futures) and returns a unified Future that resolves when all children are done. The 'add_future' method schedules callbacks on Futures to run on the IOLoop once those Futures complete. 'multi' needs to track completion of each child Future, so it is very plausible it invokes 'add_future' to attach callbacks handling completion and collecting results."}, {"fname": "add_callback", "evidence": "The 'add_callback' function schedules callbacks to run on the event loop, even across threads and with handling for loop closure. Since 'multi' orchestrates many Futures and needs to schedule and manage callbacks safely on the event loop, it very likely uses 'add_callback' to enqueue such callbacks in a thread-safe manner."}, {"fname": "_run_callback", "evidence": "'_run_callback' runs a given callback with error handling, logs exceptions, and tracks returned Futures for their completion. Given 'multi' must safely run callbacks that aggregate results or handle exceptions from children Futures, it is reasonable to expect it might use '_run_callback' or a similar pattern internally to manage and supervise callbacks with proper error handling."}, {"fname": "chain_future", "evidence": "'chain_future' links Futures and is likely used by 'multi' to aggregate results of child asynchronous operations into a single Future."}, {"fname": "future_set_result_unless_cancelled", "evidence": "'future_set_result_unless_cancelled' safely completes Futures, which is necessary for 'multi' when setting the aggregated Future’s result."}, {"fname": "multi_future", "evidence": "The node implements the function multi_future, which is nearly identical to the target function multi. Given the target function's documented behavior and goals, it is highly likely that multi either calls or shares logic/reuses multi_future internally or conceptually. The purpose of concurrently waiting on multiple futures and aggregating their results with controlled exception handling directly matches the target function's description."}, {"fname": "maybe_future", "evidence": "The function maybe_future converts any input into a Future and is useful in contexts where inputs to multi might be heterogeneous (some already futures, some not). To robustly handle all yieldable children, multi could invoke maybe_future to normalize elements before awaiting them. This aligns with multi's need to manage arbitrary yieldables."}, {"fname": "is_future", "evidence": "This node's function is_future checks if an object is a Future. multi involves identifying which children are Futures to handle them appropriately. Because multi_future (which multi likely relies upon) uses is_future to filter inputs and assert futures, multi will also need is_future to determine if inputs are futures or need wrapping. This function is thus logically invoked during multi's execution."}, {"fname": "wrapper", "evidence": "The wrapper function implementation wraps a callable, runs it under the appropriate context, and returns a Future representing eventual completion, handling generator and coroutine results. Because multi returns a yieldable object and Infra like this wrapper is designed to operate on callables producing Futures or generators, it is reasonable that multi could invoke or cooperate with this wrapping pattern or its utilities for managing the asynchronous execution context and Future creation."}, {"fname": "convert_yielded", "evidence": "The convert_yielded function converts various yielded objects, including lists and dicts, into a unified Future, invoking multi recursively when necessary. Since multi processes lists or dicts of yieldable objects to return a Future aggregating results, multi is directly involved in the control flow of convert_yielded. It is logical that multi could be invoked by or invoke convert_yielded, and thus multi might invoke utility functions like convert_yielded or vice versa during its implementation for handling heterogeneous yieldable inputs."}, {"fname": "coroutine", "evidence": "The coroutine decorator converts functions into Futures and is essential for asynchronous execution, matching multi's core asynchronous behavior."}, {"fname": "_value_from_stopiteration", "evidence": "multi needs to extract return values from StopIteration or Return exceptions when awaiting coroutines, which aligns directly with this helper's purpose."}]}
{"function": "multi_future", "target_function_prompt": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n    If multiple ``Futures`` fail, any exceptions after the first (which is\n    raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n    Use `multi` instead.\n    \"\"\"\n", "f1_score": 0.3333333333333333, "recall": 0.5, "precision": 0.25, "context_size": 10, "target_api_invocations": ["future_set_result_unless_cancelled", "is_future", "convert_yielded", "future_add_done_callback", "future_set_exc_info", "_create_future"], "context": [{"fname": "current", "evidence": "multi_future involves waiting on multiple futures and coordinating async operations; obtaining the current IOLoop instance is a necessary step for scheduling or managing futures, so it likely invokes or interacts with the current function."}, {"fname": "add_callback", "evidence": "The add_callback method is used to schedule asynchronous operations and is likely invoked during multi_future's management of Futures."}, {"fname": "future_add_done_callback", "evidence": "multi_future deals with waiting on multiple Futures and handling their completion. The provided future_add_done_callback function is designed to arrange a callback when a Future completes, invoking it immediately if the Future is already done. This is directly relevant to managing callbacks on Futures, which is central to multi_future's implementation."}, {"fname": "handle_yield", "evidence": "`handle_yield` converts yieldables into Futures and manages scheduling; this is directly relevant to `multi_future` which aggregates multiple yieldables/futures for parallel execution."}, {"fname": "handle_exception", "evidence": "Exception handling with Futures fits well with `multi_future`’s need to propagate and log exceptions from multiple awaited Futures."}, {"fname": "chain_future", "evidence": "chain_future links two Future objects, ensuring the completion and result propagation from one to the other. multi_future creates and returns futures that represent combined results; chaining futures is a fundamental operation likely used internally to coordinate individual futures with the aggregated future that multi_future returns."}, {"fname": "future_set_result_unless_cancelled", "evidence": "future_set_result_unless_cancelled safely sets a future's result only if not cancelled. multi_future needs to set results on futures it manages or creates; this utility prevents errors from setting results on cancelled futures and strongly aligns with internal mechanics of multi_future."}, {"fname": "multi", "evidence": "The target function 'multi_future' is explicitly deprecated in favor of 'multi', and its implementation simply calls 'multi_future'. Therefore, the 'multi' function is certainly invoked when implementing 'multi_future'."}, {"fname": "maybe_future", "evidence": "The 'multi_future' function deals with yieldables and Futures; in complex asynchronous operations, it is likely to wrap or convert inputs to Futures using 'maybe_future' to ensure uniform handling. Thus, it is plausible that 'maybe_future' is called to convert inputs that are not already Futures."}, {"fname": "is_future", "evidence": "The helper function 'is_future' is used within 'maybe_future' to check if a given input is already a Future. Since 'maybe_future' is likely invoked by 'multi_future', 'is_future' could be indirectly called during implementation of 'multi_future' as part of the input checking and wrapping process."}]}
{"function": "maybe_future", "target_function_prompt": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types\n    you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["_create_future", "is_future"], "context": []}
{"function": "with_timeout", "target_function_prompt": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n    Added the ``quiet_exceptions`` argument and the logging of unhandled\n    exceptions.\n\n    .. versionchanged:: 4.4\n    Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n    ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n", "f1_score": 0.06896551724137931, "recall": 0.2, "precision": 0.041666666666666664, "context_size": 20, "target_api_invocations": ["IOLoop.current", "convert_yielded", "future_add_done_callback", "_create_future", "chain_future"], "context": [{"fname": "test_timeout", "evidence": "The node includes a test method which directly invokes gen.with_timeout to verify timeout exceptions; since it calls with_timeout, it indicates interaction but not invocation by with_timeout. However, since this is a test method, it does not imply with_timeout invokes it; rather, the target is used by this node, so no invocation from with_timeout to this node."}, {"fname": "__lt__", "evidence": "The __lt__ method of the _Timeout class defines ordering between timeout instances by their deadline. Since with_timeout deals with timeouts and scheduling via IOLoop, it may need to compare timeout instances, directly or indirectly, to schedule or manage expiration order."}, {"fname": "__le__", "evidence": "The __le__ method of the _Timeout class provides an ordering operator for timeout instances, enabling checks for whether one timeout occurs before or at the same time as another. This is relevant for comparisons in managing timeouts, likely used in scheduling or cancellation logic within with_timeout."}, {"fname": "remove_timeout", "evidence": "remove_timeout cancels a scheduled timeout callback, a core operation needed by with_timeout to safely manage timeout scheduling."}, {"fname": "add_callback", "evidence": "add_callback schedules callbacks to the IOLoop, a fundamental action with_timeout must perform to implement timeout functionality."}, {"fname": "call_at", "evidence": "The call_at method schedules a callback at a specified absolute time on the event loop, matching with_timeout's need to schedule a timeout callback precisely."}, {"fname": "handle_yield", "evidence": "with_timeout must convert yieldable inputs into Futures and schedule their execution in the IOLoop, matching the functionality of this function."}, {"fname": "add_timeout", "evidence": "with_timeout explicitly schedules timeout callbacks using IOLoop.add_timeout, which this function implements."}, {"fname": "call_at", "evidence": "The with_timeout function description states it manages timeouts relative to IOLoop time and references add_timeout, which is about scheduling callbacks at absolute times. call_at schedules callbacks at specific absolute times on the IOLoop and returns a cancel handle, so it could be used internally or as a related utility in with_timeout to handle timing aspects."}, {"fname": "spawn_callback", "evidence": "with_timeout involves asynchronous handling and needs to schedule callbacks without blocking. spawn_callback schedules a callback in the next IOLoop iteration to enable asynchronous execution without blocking. This fits well with with_timeout's need to react asynchronously when a timeout occurs or a future completes."}, {"fname": "add_future", "evidence": "with_timeout operates by wrapping a future and needs to monitor its completion status. add_future schedules a callback to run when a Future completes on the IOLoop, which directly enables with_timeout to respond when the wrapped future completes to either return its result or trigger the timeout logic."}, {"fname": "add_callback", "evidence": "add_callback is a low-level IOLoop function to schedule callbacks (from any thread) to run soon on the event loop. with_timeout likely needs to schedule callbacks (for timeout triggers or future completion) in a thread-safe manner, so add_callback is a foundational utility it would invoke or rely upon."}, {"fname": "_run_callback", "evidence": "with_timeout manages asynchronous callbacks and futures, and _run_callback is responsible for running callbacks with error handling and logging exceptions related to those callbacks. Since with_timeout wraps futures and schedules callbacks, it likely uses or benefits from _run_callback internally to ensure robust error handling when scheduled callbacks run."}, {"fname": "run_sync", "evidence": "run_sync manages running an asynchronous function synchronously with a timeout and raises tornado.util.TimeoutError on timeout, matching with_timeout's timeout error behavior. with_timeout might invoke or be conceptually linked to similar timeout handling logic. Additionally, run_sync uses add_timeout and manages cancellation and exception propagation, which are relevant mechanisms for timeout enforcement."}, {"fname": "chain_future", "evidence": "chain_future links two Future objects so that completion of one completes the other. with_timeout wraps a Future and would likely use chain_future to propagate the result or exception from the wrapped Future to the timeout Future or vice versa. This chaining is essential for coordinating the timeout wrapper Future with the original Future."}, {"fname": "future_set_result_unless_cancelled", "evidence": "The target function with_timeout must set a result on a Future if the wrapped future completes successfully before timing out. The utility future_set_result_unless_cancelled provides exactly this functionality by setting the result only if the future has not been cancelled, avoiding errors. Hence, it is very likely invoked to safely set results."}, {"fname": "maybe_future", "evidence": "The with_timeout function needs to handle yieldable inputs that might not be Future instances, wrapping them as Futures to standardize processing. The maybe_future utility converts any input into a Future, precisely meeting this need, so it is likely called."}, {"fname": "is_future", "evidence": "The with_timeout function needs to detect whether the given input is a Future or another yieldable object. The is_future function provides this essential check to distinguish Future instances from others, thus it is very likely invoked."}, {"fname": "wait", "evidence": "The wait method returns an awaitable that may call gen.with_timeout to apply a timeout to waiting for an event, which directly shows invocation of with_timeout within its implementation, proving potential invocation."}, {"fname": "on_timeout", "evidence": "The 'on_timeout' function handles timeout events by resolving futures with a result indicating timeout status and performs resource cleanup. The target function with_timeout wraps futures with a timeout mechanism and must handle timing out correctly, including setting results on futures and doing cleanup. The presence of 'future_set_result_unless_cancelled' in 'on_timeout' matches the patterns described in the target function's docstring and comment about raising TimeoutError and handling quiet exceptions. This suggests that 'on_timeout' or a similar timeout handler function could be invoked in with_timeout's implementation to handle the timeout event."}]}
{"function": "convert_yielded", "target_function_prompt": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n    @convert_yielded.register(asyncio.Future)\n    def _(asyncio_future):\n    return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n", "f1_score": 0.14285714285714285, "recall": 0.5, "precision": 0.08333333333333333, "context_size": 9, "target_api_invocations": ["multi", "is_future"], "context": [{"fname": "current", "evidence": "The current function returns or creates the current thread's IOLoop instance, which is key for managing asynchronous event loops. Since convert_yielded converts yieldables (like coroutines or asyncio Futures) into Tornado Futures, it may need to access the current IOLoop to schedule or run callbacks appropriately. Therefore, invoking current is plausible during convert_yielded execution."}, {"fname": "future_add_done_callback", "evidence": "future_add_done_callback is relevant for attach callbacks to Futures whether completed or pending, matching convert_yielded's need to add completion callbacks."}, {"fname": "add_future", "evidence": "convert_yielded wraps or converts yielded objects into Futures. Scheduling a callback to run when a Future is finished (add_future) could be part of the internal implementation to monitor completion or chaining. The ability to add a callback when a Future completes aligns well with the conversion and wrapping process that convert_yielded performs. Therefore, it is plausible convert_yielded calls add_future to attach callbacks to futures it creates or converts."}, {"fname": "add_callback", "evidence": "add_callback schedules execution of callbacks soon on the event loop, which is a fundamental mechanism for asynchronous operations and is often used internally in managing Futures, scheduling their completions, or running coroutine resumption callbacks. Since convert_yielded manages Futures and coroutine interaction, it is highly likely to invoke add_callback for task scheduling and event-loop integration."}, {"fname": "_run_callback", "evidence": "_run_callback handles executing callbacks with error handling and manages returned Futures by converting yieldables. Given that convert_yielded is responsible for converting yieldables to Futures, it makes sense that it might invoke _run_callback to safely run callbacks or handle intermediate results as part of its processing."}, {"fname": "run_sync", "evidence": "The run_sync function directly calls convert_yielded to ensure that the result of the given function is transformed into a Future. Since convert_yielded is the target function here, run_sync clearly invokes it in its implementation."}, {"fname": "multi", "evidence": "The multi function returns a yieldable object aggregating multiple asynchronous operations. Its implementation returns multi_future, which internally uses convert_yielded to transform each child. Therefore, multi indirectly invokes convert_yielded as part of its processing."}, {"fname": "multi_future", "evidence": "multi_future explicitly calls convert_yielded on each element in the input collection to convert them into Futures before aggregation. This direct call in its implementation confirms multi_future invokes convert_yielded."}, {"fname": "maybe_future", "evidence": "maybe_future wraps a value into a Future if it is not already one, but it checks if the input is a Future via is_future, which is related but separate. There is no direct evidence it calls convert_yielded, but since maybe_future is a utility related to converting to Futures, it is plausible the target function might call or be called together with it. However, no direct invocation of convert_yielded inside it is shown, so more cautious decision is required here. Despite that, since convert_yielded aims to convert various yielded types to Futures, maybe_future might be called or relevant for convert_yielded implementation or its usages. Given no direct evidence of invocation of convert_yielded inside maybe_future, it should be false if strictly only functions called by convert_yielded are considered. But since prompt requests functions that might be called during implementation of convert_yielded, and maybe_future is a utility for wrapping into Futures, it might be invoked."}]}
{"function": "gen_test", "target_function_prompt": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test\n    def test_something(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test(timeout=10)\n    def test_something_slow(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n    The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n    variable.\n\n    .. versionchanged:: 4.0\n    The wrapper now passes along ``*args, **kwargs`` so it can be used\n    on functions with arguments.\n\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 44, "target_api_invocations": ["get_async_test_timeout"], "context": [{"fname": "test_asyncio_sleep_zero", "evidence": "Node 1 is a test method that would be decorated and then invoked by gen_test when running asynchronous test code."}, {"fname": "test_async_gen_return", "evidence": "Node 2 is similar to Node 1; gen_test decorates and eventually invokes tests like this to run coroutine-based asynchronous test methods."}, {"fname": "test_with_args", "evidence": "Node 3 is a test method yielding a generator moment and with argument validation; gen_test wraps and invokes such test methods."}, {"fname": "test_multi_dict", "evidence": "The node shows test code that runs asynchronous coroutines synchronously, similar to what gen_test decorates and manages, indicating possible invocation."}, {"fname": "test_no_yield", "evidence": "Empty coroutine tests align with gen_test’s need to handle arbitrary coroutine test methods, including those with no yields."}, {"fname": "test_async_return", "evidence": "The node tests coroutine returning a value, a core behavior gen_test must support and thus likely invokes or is compatible with."}, {"fname": "test_sync_raise_return", "evidence": "The node tests legacy coroutine return via gen.Return(), which gen_test likely supports for backward compatibility and may invoke."}, {"fname": "test_async_result", "evidence": "The target function 'gen_test' decorates test methods running asynchronous coroutines synchronously on the IOLoop, which involves invoking 'run_sync' as tested here."}, {"fname": "test_async_exception", "evidence": "Proper exception propagation from asynchronous coroutines is essential for 'gen_test' to function correctly, so it would use or rely on the mechanisms tested for error handling."}, {"fname": "test_timeout", "evidence": "'gen_test' supports timeout functionality for async tests, so it likely invokes or depends on 'run_sync' with timeout capabilities as tested here."}, {"fname": "test_native_coroutine", "evidence": "'gen_test' supports running both Tornado and native coroutines synchronously via the IOLoop, so it would invoke or rely on APIs demonstrated in this test."}, {"fname": "test_exception_logging_native_coro", "evidence": "Exception detection and logging in asynchronous callbacks is relevant to the execution environment of 'gen_test', so it may invoke or benefit from these logging mechanisms during test runs."}, {"fname": "test_sync_result", "evidence": "The target gen_test decorator likely invokes the IOLoop's run_sync or equivalent to run test coroutines, and Node 1 tests this mechanism with synchronous functions, so it is relevant and likely invoked."}, {"fname": "test_other_return", "evidence": "Node 2 tests that AsyncTestCase raises errors when test methods return invalid non-yieldable values, a behavior that gen_test wrapping and running test methods would trigger or detect during execution."}, {"fname": "test_sync_raise", "evidence": "Node 4 tests proper propagation of exceptions thrown synchronously inside coroutines, which gen_test would execute and handle as part of running asynchronous test methods."}, {"fname": "__call__", "evidence": "The _TestMethodWrapper.__call__ function is directly related to enforcing that test methods using generators or coroutines must be decorated with @gen_test. Since gen_test is a decorator ensuring proper coroutine usage in tests, it would be invoked or at least linked logically to this behavior."}, {"fname": "test_asyncio_future_debug_info", "evidence": "This test function uses the @gen_test decorator to mark an asynchronous testcase method, exercising the coroutine-debug functionality. It directly showcases the usage of gen_test, so it is clearly invoked in testing scenarios involving gen_test."}, {"fname": "test_native_coroutine_timeout", "evidence": "This test method explicitly applies the @gen_test decorator with a timeout parameter to an async test method. Since it tests timeout behavior for such tests, it necessarily involves invoking gen_test during its decoration and execution."}, {"fname": "test_timeout", "evidence": "Similar to Node 3, this test applies the @gen_test decorator (with timeout) to a generator-based coroutine test method and asserts timeout behavior, so it necessarily involves invoking gen_test."}, {"fname": "test_timeout_environment_variable", "evidence": "This test checks that @gen_test honors the ASYNC_TEST_TIMEOUT environment variable, applying the decorator to mark a test and then verifying timeout behavior. The @gen_test decorator is central to this test, so it must be invoked."}, {"fname": "test_no_timeout_environment_variable", "evidence": "The node's implementation explicitly uses the @gen_test decorator to wrap a test function; therefore, it directly invokes the gen_test function."}, {"fname": "test_no_timeout", "evidence": "This test_no_timeout method explicitly uses the gen_test decorator to define a coroutine-based test with a timeout parameter, directly demonstrating invocation of gen_test in a real-world scenario."}, {"fname": "tearDown", "evidence": "The tearDown method shown asserts that a test is finished before super().tearDown(), indicating lifecycle management that could be invoked in test classes that use the gen_test decorator. While the target function itself is a decorator, tests decorated by gen_test will ultimately run in classes whose tearDown methods like this one can be invoked as part of the testing lifecycle."}, {"fname": "initialize", "evidence": "'initialize' manages the IOLoop's current context, which is relevant since '@gen_test' wraps test methods that run on the IOLoop; it might be invoked to ensure proper event loop setup or switching during test execution."}, {"fname": "get_new_ioloop", "evidence": "The 'get_new_ioloop' method returns the current IOLoop instance instead of creating a new one, which aligns with '@gen_test's need to run code on an event loop; '@gen_test' might invoke it to get the loop for scheduling coroutines."}, {"fname": "get_new_ioloop", "evidence": "gen_test manages asynchronous test methods and likely invokes utilities that create or retrieve a fresh IOLoop to run coroutines."}, {"fname": "clear_current", "evidence": "gen_test needs to ensure a clean event loop state before running test coroutines, so it likely calls clear_current to reset the IOLoop and asyncio event loop."}, {"fname": "get_and_close_event_loop", "evidence": "gen_test may invoke utilities that close existing asyncio event loops to avoid resource leaks and warnings in asynchronous test execution."}, {"fname": "get_event_loop_on_thread", "evidence": "gen_test might use advanced utilities managing event loops on separate threads to ensure clean and safe asynchronous test execution environments."}, {"fname": "run", "evidence": "The target function gen_test is a decorator that handles generator or coroutine functions for testing. Node 1's run method is a core executor of generators handling yielding and resuming, an essential workflow likely used under the hood to drive the generators wrapped by gen_test."}, {"fname": "wrapper", "evidence": "Node 3's wrapper function closely matches the pattern of wrapping a callable and handling generator or coroutine results asynchronously, returning a Future. This aligns directly with the decorator functionality of gen_test, making it highly probable that gen_test uses or returns such a wrapper."}, {"fname": "convert_yielded", "evidence": "Node 4's convert_yielded function converts yielded objects into uniformly handled Future objects, supporting asynchronous coroutine execution. Since gen_test manages generator/coroutine test methods, it plausibly uses this utility to handle yielded values in the asynchronous test flow."}, {"fname": "coroutine", "evidence": "Node 5's coroutine function decorates generator-based coroutines into Futures to enable async execution. Given gen_test is a testing equivalent to @gen.coroutine, it is highly likely to invoke or rely on such a coroutine decorator to convert test functions appropriately."}, {"fname": "coroutine", "evidence": "The 'coroutine' decorator function converts generator-based functions to asynchronous coroutines returning Futures. Since '@gen_test' is described as a decorator enabling coroutine or generator-based test functions to run asynchronously, it is very likely to invoke or use this coroutine function to wrap the test method. The functionality aligns directly with the purpose of 'gen_test'."}, {"fname": "_value_from_stopiteration", "evidence": "This helper function extracts return values from StopIteration or custom Return exceptions, which is crucial in coroutine management. Since 'gen_test' must handle generator coroutines and their completion, it likely needs to interpret these return values, making it plausible that this function will be invoked internally during coroutine execution."}, {"fname": "test_hello_world", "evidence": "The target function gen_test is a decorator applied to asynchronous test methods such as this one, so it will invoke test_hello_world as part of running the test."}, {"fname": "test_singleton", "evidence": "This test method would be decorated by gen_test and invoked during test execution; thus gen_test may call test_singleton."}, {"fname": "test_post", "evidence": "As a test method, test_post is a likely candidate to be invoked by gen_test when executing decorated tests."}, {"fname": "test_mixed", "evidence": "test_mixed is a test method that gen_test would wrap and invoke during asynchronous test execution."}, {"fname": "initialize", "evidence": "The initialize function sets up AsyncIOLoop and integrates asyncio with IOLoop abstractions, which is relevant for gen_test's purpose of running test coroutines under an event loop environment."}, {"fname": "initialize", "evidence": "gen_test decorates asynchronous test methods which typically involve asynchronous HTTP requests via AsyncHTTPClient. The initialize method of AsyncHTTPClient sets up its event loop and defaults, which need to be properly configured before making HTTP requests in tests. Since gen_test enables coroutine-style async test methods likely involving AsyncHTTPClient, it could invoke this function or rely on it in the setup of the async client the tests use."}, {"fname": "async_exception", "evidence": "The function provides asynchronous exception raising for test coroutines, which aligns with gen_test's need to manage exceptions in async test flows."}, {"fname": "subTest", "evidence": "As a test method decorator, gen_test may invoke or coordinate with subTest compatibility wrappers to ensure consistent test sub-context management."}, {"fname": "test_render_method_return_future", "evidence": "This test checks asynchronous behavior of rendering by returning a Future after fetching a URL. gen_test decorates test methods that yield or await asynchronous operations, so functions like this or utilities related to Futures might be invoked or linked during the implementation or usage of gen_test."}]}
{"function": "_oauth_signature", "target_function_prompt": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 4, "target_api_invocations": ["_oauth_escape"], "context": [{"fname": "get", "evidence": "This OAuth1 login flow handler issues OAuth1 requests during authentication and authorization, which require signing those requests with _oauth_signature."}, {"fname": "get", "evidence": "This OAuth login handler retrieves user info and authorizes using OAuth1 request flows, which depend on signing via _oauth_signature."}, {"fname": "get", "evidence": "This handler manages OAuth1 login flows including authorization and token retrieval, which require signing requests using _oauth_signature."}, {"fname": "_oauth_request_parameters", "evidence": "The target function _oauth_signature calculates an HMAC-SHA1 OAuth signature, and Node_1's _oauth_request_parameters function builds OAuth 1.0 authentication parameters including a signature. Node_1 calls either _oauth10a_signature or _oauth_signature (the target function) to compute the signature. Since _oauth_request_parameters explicitly invokes _oauth_signature as part of its implementation, Node_1 could be invoked during or after the target function's implementation."}]}
{"function": "_oauth10a_signature", "target_function_prompt": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 3, "target_api_invocations": ["_oauth_escape"], "context": [{"fname": "get", "evidence": "This method handles OAuth1 login flow, which requires OAuth 1.0a signing for secure token-based authentication. Since '_oauth10a_signature' computes the OAuth 1.0a HMAC-SHA1 signature, it is likely invoked during the request token or access token signing in this flow."}, {"fname": "get", "evidence": "This method manages OAuth1 login including token-based authentication and authorization redirect. The OAuth1.0a signature calculation is crucial here to sign requests securely, making it probable that '_oauth10a_signature' is invoked."}, {"fname": "_oauth_request_parameters", "evidence": "The _oauth_request_parameters method calls _oauth10a_signature to compute the OAuth 1.0a signature, matching the target function's purpose."}]}
{"function": "bind_sockets", "target_function_prompt": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 5, "target_api_invocations": ["errno_from_exception"], "context": [{"fname": "bind_unix_socket", "evidence": "The target function bind_sockets creates listening sockets bound to network addresses and ports. bind_unix_socket also creates a listening socket but for Unix domain sockets. Both functions deal with socket creation, binding, setting options, listening, and returning socket objects. Although bind_unix_socket deals with Unix sockets and bind_sockets probably deals with TCP/IP sockets, the target function might invoke bind_unix_socket when binding Unix sockets as part of or as helper for bind_sockets or in an extended use case. At the very least, bind_unix_socket provides closely related functionality for socket binding, so it could be invoked or used internally or as a helper method."}, {"fname": "clear_instance", "evidence": "clear_instance clears the current global event loop, which can be relevant to socket operations in asynchronous frameworks. Given bind_sockets deals with network socket setup and potentially asynchronous I/O, it may rely on event loop management utilities such as this to ensure proper socket lifecycle and integration."}, {"fname": "close", "evidence": "This function shuts down an executor resource, which could be relevant for cleaning up thread or task executors involved in asynchronous socket operations or network utilities, possibly used in the bind_sockets environment."}, {"fname": "update_handler", "evidence": "Manages registration of file descriptors for asynchronous IO events; binding sockets may require registering descriptors with the event loop."}, {"fname": "add_accept_handler", "evidence": "add_accept_handler installs an IOLoop event handler to accept new socket connections and run callbacks. Since bind_sockets creates listening sockets, a follow-up step often involves adding accept handlers. While bind_sockets itself only binds sockets, it is reasonable to invoke this utility or related functionality to manage accepting connections on those sockets."}]}
{"function": "add_accept_handler", "target_function_prompt": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n    The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n    A callable is returned (``None`` was returned before).\n    \"\"\"\n", "f1_score": 0.1111111111111111, "recall": 0.5, "precision": 0.0625, "context_size": 16, "target_api_invocations": ["IOLoop.current", "callback"], "context": [{"fname": "_add_io_state", "evidence": "The function manages adding event states and handlers to the IOLoop, directly aligning with the target function's need to add event handlers on the socket."}, {"fname": "accept", "evidence": "The accept method directly handles new connections by wrapping them into IOStream objects and matches the nature of the callback used in add_accept_handler."}, {"fname": "_make_server_iostream", "evidence": "The helper method to create server IOStream wrappers over a connection aligns with the need to convert accepted sockets into IOStreams in add_accept_handler."}, {"fname": "instance", "evidence": "The instance function returns the current thread's IOLoop instance (IOLoop.current()), which is likely needed by add_accept_handler to register the socket accept handler with the IOLoop. This aligns with managing event handlers on the IOLoop as described in add_accept_handler's docstring."}, {"fname": "current", "evidence": "The target function likely obtains the current IOLoop instance to add an event handler; this node provides the mechanism to get or create the current IOLoop."}, {"fname": "add_callback", "evidence": "The target function registers event handlers or schedules callbacks on the IOLoop, so it likely invokes add_callback to schedule accept handlers or related callbacks."}, {"fname": "add_callback_from_signal", "evidence": "This thread-safe callback scheduling function is likely used to safely add the socket accept callback to the event loop, especially when adding from other threads or signal handlers."}, {"fname": "spawn_callback", "evidence": "spawn_callback schedules a callback to run asynchronously on the next IOLoop iteration, which is useful and likely used in add_accept_handler to invoke the accept callback asynchronously."}, {"fname": "add_callback", "evidence": "The target function add_accept_handler adds a callback handler to an IOLoop to accept new connections. The add_callback method is precisely about scheduling callbacks on the event loop safely and promptly, including from other threads. This aligns directly with the target's need to add event handlers, and thus add_callback may be invoked during its implementation."}, {"fname": "_run_callback", "evidence": "_run_callback provides a robust way to execute callbacks with error handling and logging. Since add_accept_handler attaches callbacks to the IOLoop which are subsequently run through a standard mechanism, it is highly likely that the callbacks added by add_accept_handler are run via _run_callback to ensure proper error management and asynchronous future handling."}, {"fname": "_sock_state_cb", "evidence": "The _sock_state_cb function manages adding, updating, or removing I/O handlers for socket file descriptors within the event loop. Since add_accept_handler must add an IOLoop event handler to accept connections on a given socket, it is very plausible that it would rely on or invoke functionality similar to _sock_state_cb (directly or through related mechanisms) to manage the socket's event registration and state."}, {"fname": "add_reader", "evidence": "add_reader adds a read-ready event handler for a file descriptor, which aligns with the need of add_accept_handler to monitor the socket for new connections."}, {"fname": "add_handler", "evidence": "add_handler registers a callback for specified I/O events on a file descriptor and is likely used by add_accept_handler to add a read event handler on the socket in a unified manner."}, {"fname": "split_fd", "evidence": "split_fd is a utility method called internally by add_handler to process file descriptor inputs, so it is indirectly invoked during the implementation of add_accept_handler."}, {"fname": "close_fd", "evidence": "The target function likely invokes a utility like close_fd to safely close or cleanup sockets or file descriptors when removing the accept handler or cleaning resources."}, {"fname": "remove_handler", "evidence": "The add_accept_handler function returns a callable that removes the IOLoop event handler for the given socket; this node's remove_handler method logically supports that removal functionality and may be invoked when the returned callable is called."}]}
{"function": "ssl_wrap_socket", "target_function_prompt": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n", "f1_score": 0.5, "recall": 1.0, "precision": 0.3333333333333333, "context_size": 3, "target_api_invocations": ["ssl_options_to_context"], "context": [{"fname": "ssl_options_to_context", "evidence": "ssl_options_to_context performs the essential task of converting ssl_options (dict or SSLContext) into an ssl.SSLContext object, exactly what ssl_wrap_socket's docstring explains it must do to handle both input forms before wrapping the socket; this function is very likely invoked."}, {"fname": "_get_ssl_options", "evidence": "_get_ssl_options deals directly with selecting or creating appropriate SSL configuration objects (ssl.SSLContext or dictionary) for wrapping sockets, which aligns conceptually with ssl_wrap_socket's task to use or convert ssl_options before wrapping the socket; it is plausible that ssl_wrap_socket or its callers could invoke _get_ssl_options to obtain ssl_options."}, {"fname": "get_ssl_options", "evidence": "This function calls ssl_options_to_context to convert SSL options into an ssl.SSLContext object and asserts the return type. ssl_wrap_socket directly needs to convert ssl_options dict to SSLContext (as described in the docstring), so it is highly probable it will invoke this utility or similar logic to obtain an SSLContext for wrapping the socket."}]}
{"function": "xhtml_unescape", "target_function_prompt": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["_convert_entity"], "context": []}
{"function": "url_escape", "target_function_prompt": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["utf8"], "context": []}
{"function": "recursive_unicode", "target_function_prompt": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["to_unicode"], "context": []}
{"function": "linkify", "target_function_prompt": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n", "f1_score": 0.5, "recall": 1.0, "precision": 0.3333333333333333, "context_size": 3, "target_api_invocations": ["xhtml_escape"], "context": [{"fname": "squeeze", "evidence": "squeeze provides string normalization by collapsing whitespace and trimming, which is likely useful for the text processing in linkify."}, {"fname": "xhtml_unescape", "evidence": "Unescaping XML-escaped characters is likely needed before detecting and converting URLs, ensuring correct identification of links in escaped text."}, {"fname": "xhtml_escape", "evidence": "Escaping special characters to XHTML-safe sequences is necessary when producing HTML output with links, to ensure valid and safe HTML markup."}]}
{"function": "_parse_request_range", "target_function_prompt": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["_int_or_none"], "context": []}
{"function": "_parse_header", "target_function_prompt": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["_parseparam"], "context": []}
{"function": "encode_username_password", "target_function_prompt": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 1, "target_api_invocations": ["utf8"], "context": [{"fname": "format_field", "evidence": "format_field encodes a string or bytes value by prefixing it with its length and a colon, producing bytes; this kind of length-prefixed encoding can be relevant when encoding username/password pairs for HTTP auth formats, so it is plausible that encode_username_password might use or invoke such a utility."}]}
{"function": "parse_cookie", "target_function_prompt": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 1, "target_api_invocations": ["_unquote_cookie"], "context": [{"fname": "_normalize_header", "evidence": "_normalize_header is a utility that standardizes header names to HTTP header case. While parse_cookie deals with cookie header contents, it might normalize header names as part of processing or validating headers related to cookies, or could reuse this utility when dealing with cookie header keys. This is plausible given cookie processing often involves header name handling."}]}
{"function": "re_unescape", "target_function_prompt": "def re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n", "f1_score": 0.0, "recall": 0.0, "precision": 0.0, "context_size": 0, "target_api_invocations": ["_re_unescape_replacement"], "context": []}
{"function": "get", "target_function_prompt": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n", "f1_score": 0.5, "recall": 1.0, "precision": 0.3333333333333333, "context_size": 3, "target_api_invocations": ["Locale.get_closest"], "context": [{"fname": "get_supported_locales", "evidence": "get needs to know the set of supported locales to find the closest matching locale code. This function returns all supported locale codes, making it likely invoked or functionality similarly used within get."}, {"fname": "get", "evidence": "This node provides the function to retrieve a Locale instance for a single locale code, which is necessary to return the closest matching locale in the target function."}, {"fname": "get_closest", "evidence": "This node performs the core logic of finding the closest matching locale code by normalization and fallback, directly matching the target function's description and likely invoked by it."}]}
