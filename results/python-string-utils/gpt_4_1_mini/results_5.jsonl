{"task_id": 5, "prediction_id": 0, "generation": "import unicodedata\nfrom .errors import InvalidInputError\nfrom .validation import is_string\n\ndef asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    # Normalize string to NFKD form to decompose characters (e.g., accented chars to base + accent)\n    normalized = unicodedata.normalize('NFKD', input_string)\n    # Filter out combining characters (unicode category starting with 'M') to leave only ASCII characters\n    ascii_chars = [c for c in normalized if not unicodedata.combining(c)]\n    ascii_string = ''.join(ascii_chars)\n    # Encode to ASCII, ignoring errors (some chars might be lost), then decode back to string\n    ascii_string = ascii_string.encode('ascii', 'ignore').decode('ascii')\n\n    return ascii_string", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 453, in <module>\nKeyError: \"'__name__' not in globals\"\n", "passed": false}
{"task_id": 5, "prediction_id": 1, "generation": "import unicodedata\nfrom .errors import InvalidInputError\nfrom .validation import is_string\n\n\ndef asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    # Normalize string to NFD form to decompose characters into base + accents\n    normalized = unicodedata.normalize('NFD', input_string)\n\n    # Filter to keep only base ASCII characters (category 'Mn' marks nonspacing marks)\n    ascii_chars = [\n        c for c in normalized\n        if unicodedata.category(c) != 'Mn' and ord(c) < 128\n    ]\n\n    return ''.join(ascii_chars)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 453, in <module>\nKeyError: \"'__name__' not in globals\"\n", "passed": false}
{"task_id": 5, "prediction_id": 2, "generation": "import unicodedata\nfrom .errors import InvalidInputError\nfrom .validation import is_string\n\ndef asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    # Normalize string to decomposed form (NFD),\n    # which separates base char from accents/diacritics\n    normalized = unicodedata.normalize('NFD', input_string)\n\n    # Filter out combining characters (accents), keep only ASCII chars\n    ascii_chars = []\n    for ch in normalized:\n        # Skip non-spacing marks (diacritics)\n        if unicodedata.category(ch) == 'Mn':\n            continue\n        # Keep ASCII chars only\n        if ord(ch) < 128:\n            ascii_chars.append(ch)\n        # If char is beyond ASCII and not combining, skip (lose data)\n\n    return ''.join(ascii_chars)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 453, in <module>\nKeyError: \"'__name__' not in globals\"\n", "passed": false}
{"task_id": 5, "prediction_id": 3, "generation": "import unicodedata\nfrom typing import Optional\n\n\ndef asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n    if not isinstance(input_string, str):\n        raise TypeError('Input must be a string.')\n\n    # Normalize string to NFD (decompose characters into base + diacritics)\n    normalized = unicodedata.normalize('NFD', input_string)\n\n    # Filter out the combining characters (diacritics), keep only base ascii chars\n    ascii_chars = []\n    for c in normalized:\n        if unicodedata.category(c) != 'Mn':  # nonspacing mark (diacritics)\n            ascii_chars.append(c)\n\n    # Join and encode to ASCII ignoring errors to drop any remaining non-ascii chars,\n    # then decode back to string\n    ascii_string = ''.join(ascii_chars).encode('ascii', 'ignore').decode('ascii')\n\n    return ascii_string", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 775, in <module>\n  File \"<string>\", line 774, in test_2\nAssertionError\n", "passed": false}
{"task_id": 5, "prediction_id": 4, "generation": "import unicodedata\nfrom typing import Optional\n\n\ndef asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n    if not isinstance(input_string, str):\n        raise TypeError(\"input_string must be a string\")\n\n    # Normalize the string to NFKD form (compatible decomposition)\n    normalized = unicodedata.normalize('NFKD', input_string)\n\n    # Encode to ASCII bytes ignoring errors (drops diacritics and non-ASCII chars),\n    # then decode back to string\n    ascii_string = normalized.encode('ascii', 'ignore').decode('ascii')\n\n    return ascii_string", "message": "passed", "passed": true}
