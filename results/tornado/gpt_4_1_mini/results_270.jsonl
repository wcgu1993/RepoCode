{"task_id": 270, "prediction_id": 0, "generation": "import re\nfrom typing import Union, Callable, List\nfrom tornado.escape import xhtml_escape, squeeze\n\n_URL_RE = re.compile(\n    r\"\"\"\n    \\b(\n        (?:([\\w-]+):(/{1,3})|www[.])                  # protocol or www.\n        (?:                                          \n            (?:[^\\s&()<>\"]+|                           # Either a run of non-space non-special chars\n            \\([^\\s()<>\"]+\\))                           # or balanced parentheses\n        )+\n        (?:\\([\\w\\d]+\\)|[^[:punct:]\\s]|/)?              # optional trailing balanced parens or non-punct/non-space\n    )\n    \"\"\",\n    re.VERBOSE | re.UNICODE | re.IGNORECASE,\n)\n\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n    # Convert bytes input to string\n    if isinstance(text, bytes):\n        text = text.decode(\"utf-8\", errors=\"replace\")\n\n    text = squeeze(text)\n\n    def _replace(match: re.Match) -> str:\n        url = match.group(0)\n\n        # Extract protocol if exists\n        protocol = None\n        protocol_match = re.match(r\"^([\\w\\-]+)://\", url)\n        if protocol_match:\n            protocol = protocol_match.group(1).lower()\n\n        # If require_protocol and no protocol => no linkification\n        if require_protocol and not protocol:\n            return url\n\n        # If protocol is present, check if permitted\n        if protocol:\n            if protocol not in permitted_protocols:\n                return url\n        else:\n            # No protocol -> if require_protocol False, permit linkify www. URLs\n            if require_protocol:\n                return url\n\n        href = url\n\n        # If the URL doesn't have a protocol but starts with www., add http://\n        if not protocol and url.startswith(\"www.\"):\n            href = \"http://\" + url\n\n        display = href\n        if shorten and len(href) > 50:\n            # Shorten the display text sensibly\n            # We'll show first 30 chars, ... , last 10 chars\n            display = href[:30] + \"...\" + href[-10:]\n\n        # Escape URL and display for safety\n        esc_href = xhtml_escape(href)\n        esc_display = xhtml_escape(display)\n\n        # Get extra params string\n        if callable(extra_params):\n            extra = extra_params(href)\n        else:\n            extra = extra_params\n        if extra:\n            extra = \" \" + extra.strip()\n        else:\n            extra = \"\"\n\n        return f'<a href=\"{esc_href}\"{extra}>{esc_display}</a>'\n\n    # Run substitution with the _URL_RE regex on the entire text\n    return _URL_RE.sub(_replace, text)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 419, in <module>\n  File \"<string>\", line 418, in test_3\nAssertionError\n", "passed": false}
{"task_id": 270, "prediction_id": 1, "generation": "import re\nfrom typing import Union, Callable, List\nfrom tornado.escape import squeeze, xhtml_escape\n\n# Precompiled regex for matching URLs according to file content's _URL_RE pattern\n_URL_RE = re.compile(\n    r\"\"\"\\b((?:([\\w-]+):(/{1,3})|www[.])(?:(?:(?:[^\\s&()]|&amp;|&quot;)*(?:[^!\"#$%&'()*+,.:;<=>?@\\[\\]^`{|}~\\s]))|(?:\\((?:[^\\s&()]|&amp;|&quot;)*\\)))+)\"\"\"  # noqa: E501\n)\n\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n    if not text:\n        return \"\"\n\n    # Normalize text to str\n    if isinstance(text, bytes):\n        text = text.decode(\"utf-8\", \"replace\")\n\n    # Normalize whitespace to single spaces\n    # This helps avoid matching URLs broken across strange spacing\n    text = squeeze(text)\n\n    # Prepare permitted protocols for quick membership checking (case-insensitive)\n    permitted_protocols_set = set(p.lower() for p in permitted_protocols)\n\n    def _shorten_url(url: str) -> str:\n        # Shorten display if requested and url is longer than 50 chars\n        # We preserve the start and end parts separated by ellipsis\n        if len(url) <= 50:\n            return url\n        return url[:30] + \"...\" + url[-15:]\n\n    def _get_extra_params(url: str) -> str:\n        if callable(extra_params):\n            # If callable, call with url as argument\n            result = extra_params(url)\n            # Ensure result is string\n            if not isinstance(result, str):\n                raise TypeError(\n                    \"extra_params callable must return a string, got %r\" % type(result)\n                )\n            return \" \" + result.strip() if result else \"\"\n        elif isinstance(extra_params, str):\n            return \" \" + extra_params.strip() if extra_params.strip() else \"\"\n        else:\n            # Defensive: fallback to empty\n            return \"\"\n\n    def _replace_match(match: re.Match) -> str:\n        url = match.group(0)\n        original_url = url  # preserve original for href\n\n        # If require_protocol is True, only linkify URLs with protocol\n        # Protocol check: scheme should be followed by ://\n        matcher = re.match(r\"(?P<schema>[\\w-]+):(/{1,3})\", url)\n        if require_protocol:\n            if not matcher:\n                # No protocol detected, skip linkify\n                return url\n        else:\n            # If no protocol but starts with www., prefix with http:// for href\n            if not matcher and url.startswith(\"www.\"):\n                original_url = \"http://\" + url\n\n        # Check protocol if protocol present\n        if matcher:\n            protocol = matcher.group('schema').lower()\n            if protocol not in permitted_protocols_set:\n                return url\n        else:\n            # No protocol, but might be www., allow only if require_protocol=False\n            if require_protocol:\n                return url\n\n        # Escape URL for href attribute\n        href = xhtml_escape(original_url)\n\n        # Display text (may shorten)\n        display_text = _shorten_url(url) if shorten else url\n        display_text = xhtml_escape(display_text)\n\n        # Add extra params\n        extra = _get_extra_params(original_url)\n\n        # Build anchor tag\n        return f'<a href=\"{href}\"{extra}>{display_text}</a>'\n\n    # Use _URL_RE to find urls and replace with anchor tags\n    result = _URL_RE.sub(_replace_match, text)\n    return result", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 503, in <module>\n  File \"<string>\", line 502, in test_36\nAssertionError\n", "passed": false}
{"task_id": 270, "prediction_id": 2, "generation": "import re\nfrom typing import Union, Callable, List\nfrom tornado.escape import squeeze, xhtml_escape\n\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n\n    # Normalize text to string (unicode)\n    if isinstance(text, bytes):\n        text = text.decode('utf-8', errors='ignore')\n\n    # Squeeze whitespace\n    text = squeeze(text)\n\n    # Regex groups:\n    # 1: protocol:// or www.\n    # 2: protocol (optional)\n    # 3: slashes (for protocol)\n    # 4: domain + path + query\n    # Use a regex similar to _URL_RE but adapted to capture needed parts\n    # This regex matches URLs starting with protocol:// or www.\n    url_re = re.compile(\n        r\"\"\"\n        (\n          (?:([\\w][\\w.+-]*):/{1,3})?         # protocol like http:// or ftp:// (optional)\n          (www\\.)?                           # www. (optional)\n          [^\\s()<>{}\\[\\]]+                   # domain or domain+path\n          (?:\\([\\w\\d]+\\)|([^[:punct:]\\s]|/)) # balanced parens or ending char not punctuation or whitespace\n        )\n        \"\"\",\n        re.VERBOSE | re.UNICODE | re.IGNORECASE,\n    )\n\n    # A safer, simpler URL matching regex that covers the most important cases,\n    # taking into account that _URL_RE is complicated and we want clarity for linkify.\n\n    # We will build from the provided _URL_RE pattern given in file content, which matches URLs broadly,\n    # but it matches the entire URL, so use it directly to find URLs.\n\n    # We replicate _URL_RE here to avoid importing it:\n    _URL_RE = re.compile(\n        r\"\"\"\\b((?:([\\w-]+):(/{1,3})|www[.])(?:(?:(?:[^\\s&()]|&amp;|&quot;)*(?:[^!\"#$%&'()*+,.:;<=>?@\\[\\]^`{|}~\\s]))|(?:\\((?:[^\\s&()]|&amp;|&quot;)*\\)))+)\"\"\"\n    )\n\n    def shorten_url(url: str) -> str:\n        if len(url) <= 50:\n            return url\n        # Heuristic shortening:\n        # Keep first 25 chars + \"...\" + last 20 chars\n        return url[:25] + \"...\" + url[-20:]\n\n    def protocol_allowed(proto: str) -> bool:\n        # Check protocol against permitted_protocols, case-insensitive\n        return proto.lower() in (p.lower() for p in permitted_protocols)\n\n    def get_extra_params(url: str) -> str:\n        if callable(extra_params):\n            return extra_params(url)\n        return extra_params\n\n    def replace(match: re.Match) -> str:\n        url = match.group(0)\n        # Determine protocol if any\n        # If url starts with protocol:// extract protocol part using regex group\n        m_proto = re.match(r\"^([\\w+-]+):\", url)\n        proto = m_proto.group(1) if m_proto else None\n\n        # When require_protocol is True, only linkify URLs with allowed protocol\n        if require_protocol:\n            if not proto:\n                return url  # no protocol, do not linkify\n            if not protocol_allowed(proto):\n                return url  # protocol not permitted\n        else:\n            # If no protocol, but it starts with \"www.\" then treat it as 'http' (default)\n            if not proto and url.lower().startswith(\"www.\"):\n                proto = \"http\"\n                if not protocol_allowed(proto):\n                    return url\n\n        # Escape URL for HTML attrs\n        href = xhtml_escape(url)\n\n        # Prepare displayed text\n        display = shorten_url(url) if shorten else url\n        display = xhtml_escape(display)\n\n        # Compute extra params safely\n        extra = get_extra_params(url)\n        if extra:\n            if not extra.startswith(\" \"):\n                extra = \" \" + extra\n        else:\n            extra = \"\"\n\n        return f'<a href=\"{href}\"{extra}>{display}</a>'\n\n    # Replace URLs using _URL_RE\n    # Use re.sub with function replacement to safely replace URLs in the text\n    result = _URL_RE.sub(replace, text)\n    return result", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 442, in <module>\n  File \"<string>\", line 441, in test_3\nAssertionError\n", "passed": false}
{"task_id": 270, "prediction_id": 3, "generation": "import re\nfrom typing import Union, Callable, List\nfrom tornado.escape import squeeze, xhtml_escape\nfrom tornado.escape import to_unicode\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n    # Normalize input to unicode string\n    text = to_unicode(text)\n    text = squeeze(text)\n\n    # Regex to match URLs (with protocol) or www.* style urls\n    # We'll capture the full url in group 'url', protocol in 'protocol' (if any)\n    # The regex is adapted to cover the specs:\n    # - protocol is optional if require_protocol is False\n    # - url characters are all non-whitespace, exclude some trailing punctuation\n\n    # Protocol matching group: e.g. http://, https:// etc.\n    # This is used if require_protocol=True or to check permitted protocols\n    protocol_re = r\"(?P<protocol>[a-zA-Z][a-zA-Z0-9+.-]*):\\/\\/\"\n\n    # Partial URL regex for domain and path etc.\n    # We use a conservative approach: avoid trailing punctuation such as .,?!;:\n    # Also allow query strings and fragments.\n    # For the domain part: letters, digits, hyphens, dots etc.\n    # For the path part: most url-safe chars\n\n    # The main url (without protocol) or with protocol will be captured as 'url'\n    # The regex matches:\n    # - with protocol: e.g. http://example.com/path?query\n    # - without protocol: e.g. www.example.com/path\n\n    # To distinguish under require_protocol (only linkify if protocol present)\n    # or allow www-style links\n\n    url_body = (\n        r\"(?:\"\n        r\"[a-zA-Z0-9\\-\\._~%]+\"  # domain and subdomains and TLD\n        r\"(?:\\.[a-zA-Z0-9\\-\\._~%]+)+\"  # at least one dot to separate domains\n        r\")\"\n        r\"(?::\\d+)?\"  # optional port\n        r\"(?:[/?#][^\\s<\\\"\\'`{}|\\\\^~\\[\\]`]*)?\"  # path/query/fragment (exclude spaces and some delimiters)\n    )\n\n    # Combine with protocol or www\n    if require_protocol:\n        # only match URLs with required protocols specified\n        # protocol group will be captured\n        pattern = re.compile(\n            r\"(?P<full>(?P<protocol>[a-zA-Z][a-zA-Z0-9+.-]*):\\/\\/\" + url_body + r\")\"\n        )\n    else:\n        # match protocol URLs or www.* URLs\n        pattern = re.compile(\n            r\"(?P<full>(?:(?P<protocol>[a-zA-Z][a-zA-Z0-9+.-]*):\\/\\/\" + url_body + r\")\"\n            r\"|\"\n            r\"(www\\.\" + url_body + r\"))\"\n        )\n\n    def _shorten_url(url: str) -> str:\n        # If shorten is True and url is longer than max length, shorten by clipping the middle part\n        max_len = 50  # max display length including \"...\" \n        if not shorten or len(url) <= max_len:\n            return url\n        # Show first 25 and last 22 chars with \"...\" in middle (50 total)\n        return url[:25] + \"...\" + url[-22:]\n\n    def _escape_html(s: str) -> str:\n        # use xhtml_escape to convert &, <, >, ' and \" for attribute safety\n        return xhtml_escape(s)\n\n    def replacer(match: re.Match) -> str:\n        full = match.group(\"full\")\n        protocol = match.group(\"protocol\")\n        # If protocol is None, and require_protocol is False, then it could be www.* style url\n        if protocol:\n            proto = protocol.lower()\n            if proto not in permitted_protocols:\n                # Not permitted protocol, don't linkify\n                return full\n            href = full\n        else:\n            # no protocol match (should only happen if require_protocol=False), assume www.* url\n            href = full\n            # We automatically add http:// prefix to href for www links\n            href = \"http://\" + href\n\n            # We don't have a protocol group so can't check permitted_protocols here reliably.\n            # But if require_protocol is False, www.* links are accepted.\n\n        display = full\n        if shorten:\n            display = _shorten_url(display)\n\n        # Escape for HTML link text and href attribute\n        href_escaped = _escape_html(href)\n        display_escaped = _escape_html(display)\n\n        # Determine extra params string\n        if callable(extra_params):\n            extra = extra_params(href)\n        else:\n            extra = extra_params\n        if extra:\n            extra = \" \" + extra.strip()\n        else:\n            extra = \"\"\n\n        return f'<a href=\"{href_escaped}\"{extra}>{display_escaped}</a>'\n\n    # Use re.sub with replacer callback to replace urls with linkified html\n    result = pattern.sub(replacer, text)\n    return result", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 457, in <module>\n  File \"<string>\", line 456, in test_4\nAssertionError\n", "passed": false}
{"task_id": 270, "prediction_id": 4, "generation": "import re\nfrom typing import Union, List, Callable\n\nfrom tornado.escape import squeeze, xhtml_escape\nfrom tornado.util import to_unicode\n\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n    # Normalize to unicode string\n    text = to_unicode(text)\n\n    # Pre-squeeze whitespace to avoid matching urls with newlines/spaces inside\n    text = squeeze(text)\n\n    # Pattern components:\n    # - protocol: (http|https)://\n    # - www: www.\n    # - url allowed chars: use a safe set avoiding trailing punctuation\n    # The pattern roughly matches the _URL_RE from file context but adjusted.\n    # We'll build a pattern that matches:\n    #   - If require_protocol is True: URLs starting with permitted protocols + ://\n    #   - Else: Also match www. prefix without protocol.\n    # We'll capture the url to linkify and also capture trailing punctuation separately\n    # to avoid including them in the link.\n\n    # Build protocols pattern\n    protocols = [re.escape(p) for p in permitted_protocols]\n    list_protocols = \"|\".join(protocols)\n\n    # Regex explanation:\n    # 1) Protocol part (optional if require_protocol False)\n    # 2) www. prefix (optional if require_protocol False)\n    # 3) domain or IP and path/query parts\n    # 4) trailing punctuation separated (to avoid including in link)\n    # Allowed URL chars are taken as anything except whitespace and some punctuation that usually ends URLs.\n    #\n    # We match the entire url to be linked but do not include trailing punctuation like .,!? or closing paren etc\n    # such punctuation may be part of the enclosing sentence.\n\n    if require_protocol:\n        # URL must start with protocol://\n        regex = re.compile(\n            r\"(?P<url>(\"\n            r\"(?P<proto>\" + list_protocols + r\")://\"\n            r\"[^\\s<>'\\\"()]+\"\n            r\"))\",\n            re.IGNORECASE,\n        )\n    else:\n        # Accept either protocol:// or www.\n        regex = re.compile(\n            r\"(?P<url>(\"\n            r\"(?:(?P<proto>\" + list_protocols + r\")://|www\\.)\"\n            r\"[^\\s<>'\\\"()]+\"\n            r\"))\",\n            re.IGNORECASE,\n        )\n\n    # Function to shorten displayed URL, if shorten==True\n    def _shorten_url(url: str) -> str:\n        # Basic shortening: show scheme + domain + /... for long urls,\n        # or truncate long path/query but keep domain.\n        # We'll show up to 50 chars, then '...'\n        max_len = 50\n        if len(url) <= max_len:\n            return url\n        # Try to keep scheme + domain + part of path\n        # Find '://' position\n        scheme_sep_pos = url.find(\"://\")\n        if scheme_sep_pos == -1:\n            # no scheme, maybe www.*\n            if url.startswith(\"www.\"):\n                rest = url[4:]\n                if len(rest) > max_len - 7:  # 7 includes www. and ...\n                    return \"www.\" + rest[: max_len - 7] + \"...\"\n                else:\n                    return url\n            else:\n                # no scheme, no www.\n                return url[: max_len - 3] + \"...\"\n        else:\n            scheme = url[: scheme_sep_pos + 3]  # include '://'\n            rest = url[scheme_sep_pos + 3 :]\n            # Truncate rest if too long\n            if len(rest) > max_len - len(scheme) - 3:\n                return scheme + rest[: max_len - len(scheme) - 3] + \"...\"\n            else:\n                return url\n\n    def _replace(match: re.Match) -> str:\n        url = match.group(\"url\")\n        proto = match.group(\"proto\")\n\n        # Verify protocol if present\n        if proto:\n            proto_lower = proto.lower()\n            if proto_lower not in permitted_protocols:\n                return url  # do not linkify URLs with disallowed protocol\n        else:\n            # If no protocol (e.g. www...), permit only if require_protocol is False\n            if require_protocol:\n                return url\n\n        # In case url starts with www., prepend http:// for href to be valid\n        href = url\n        if not proto:\n            if url.startswith(\"www.\"):\n                href = \"http://\" + url\n\n        # Escape href and display text\n        escaped_href = xhtml_escape(href)\n\n        if shorten:\n            display = _shorten_url(url)\n        else:\n            display = url\n        escaped_display = xhtml_escape(display)\n\n        # Determine extra params string\n        if callable(extra_params):\n            extra = extra_params(href)\n        else:\n            extra = extra_params\n        if extra:\n            extra = \" \" + extra.strip()\n        else:\n            extra = \"\"\n\n        return f'<a href=\"{escaped_href}\"{extra}>{escaped_display}</a>'\n\n    # Replace all matches in text by linkified version\n    result = regex.sub(_replace, text)\n    return result", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 270, in <module>\nImportError: cannot import name 'to_unicode' from 'tornado.util' (/input/test-apps/tornado/tornado/util.py)\n", "passed": false}
