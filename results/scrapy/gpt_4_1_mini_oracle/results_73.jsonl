{"task_id": 73, "prediction_id": 0, "generation": "import re\nfrom typing import Optional, Iterable, Tuple, Union\nfrom scrapy.http.response.text import TextResponse\nfrom w3lib.html import get_meta_refresh as w3lib_get_meta_refresh\n\n\ndef get_meta_refresh(\n    response: \"TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n    # Use w3lib.html.get_meta_refresh which returns (delay, url) or (None, None)\n    # We parse the response.text to find meta refresh tags and ignore ones inside ignore_tags.\n    # The w3lib function does not handle ignoring tags, so we must do that manually.\n\n    # To ignore tags, we remove those tags' content from the response text before parsing.\n    # Build a pattern to remove the ignored tags and their content:\n    if ignore_tags is None:\n        cleaned_html = response.text\n    else:\n        # Create a regex that matches opening and closing ignored tags and their content (non-greedy)\n        # e.g. <script ...>...</script>, <noscript ...>...</noscript>\n        pattern = (\n            r'(?is)<(' + '|'.join(re.escape(tag) for tag in ignore_tags) + r')[^>]*>.*?</\\1>'\n        )\n        cleaned_html = re.sub(pattern, '', response.text)\n\n    # Use w3lib's get_meta_refresh on the cleaned html and the response url\n    return w3lib_get_meta_refresh(cleaned_html, response.url)", "message": "passed", "passed": true}
{"task_id": 73, "prediction_id": 1, "generation": "from typing import Optional, Iterable, Tuple, Union\nfrom scrapy.http.response.text import TextResponse\nimport re\nfrom w3lib.html import remove_tags_with_content, get_base_url\n\ndef get_meta_refresh(\n    response: \"TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n    # Defensive fallback: no content means no refresh\n    if not response.body:\n        return None, None\n\n    # Get text content from response, limited or fully (using response.text)\n    text = response.text\n\n    # Remove contents of ignored tags to avoid false positives\n    if ignore_tags:\n        # remove_tags_with_content removes tag's content by regex and currently\n        # accepts either string or iterable of strings as tags (according to w3lib.html)\n        text = remove_tags_with_content(text, ignore_tags)\n\n    # We parse meta tags looking for http-equiv=refresh (case-insensitive)\n    # Pattern attempt: <meta[^>]+http-equiv=[\"']?refresh[\"']?[^>]*content=[\"']?([^\\s\"'>]+)[\"']?[^>]*>\n    # Actually, we want to find <meta ... http-equiv=refresh ... content=\"X; url=Y\" ...>\n    # We'll use a simple regex to capture content attribute value when http-equiv=refresh appears\n    \n    # Regex in two steps:\n\n    meta_regex = re.compile(\n        r'<meta[^>]+http-equiv\\s*=\\s*[\"\\']?refresh[\"\\']?[^>]*content\\s*=\\s*[\"\\']?([^\"\\'>]+)[\"\\']?[^>]*>',\n        re.IGNORECASE,\n    )\n\n    match = meta_regex.search(text)\n    if not match:\n        return None, None\n\n    content_value = match.group(1).strip()\n\n    # content attribute format: e.g. \"5; url=http://example.com\"\n    # or just \"5\" for refresh after 5 seconds with no URL\n    # parse timeout and optional URL\n\n    # Split by ';' to separate timeout and url part\n    parts = [p.strip() for p in content_value.split(';', 1)]\n    try:\n        wait = float(parts[0])\n    except ValueError:\n        return None, None\n\n    url = None\n    if len(parts) == 2:\n        # parse url part, expected form \"url=...\"\n        url_part = parts[1].lower()\n        if url_part.startswith('url='):\n            url_raw = parts[1][4:].strip()  # keep original case after \"url=\"\n            # Resolve relative URLs using response.url as base\n            url = response.urljoin(url_raw)\n        else:\n            # Sometimes there might be non-standard content, just ignore that part\n            url = None\n\n    return wait, url", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 195, in <module>\n  File \"<string>\", line 186, in test_1\nAssertionError\n", "passed": false}
{"task_id": 73, "prediction_id": 2, "generation": "from typing import Optional, Iterable, Union, Tuple\nfrom scrapy.http.response.text import TextResponse\nfrom w3lib.html import get_meta_refresh as w3lib_get_meta_refresh\n\n\ndef get_meta_refresh(\n    response: \"TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n    # Use w3lib.html.get_meta_refresh to parse the meta refresh content\n    return w3lib_get_meta_refresh(response.text, ignore_tags=ignore_tags)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 344, in <module>\n  File \"<string>\", line 338, in test_42\nAssertionError\n", "passed": false}
{"task_id": 73, "prediction_id": 3, "generation": "from typing import Iterable, Optional, Tuple, Union\nfrom scrapy.http.response.text import TextResponse\nfrom w3lib.html import get_meta_refresh as w3lib_get_meta_refresh\n\n\ndef get_meta_refresh(\n    response: \"TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n    # Use w3lib.html.get_meta_refresh passing in response text and the ignore_tags as the ignored elements\n    # Return the result directly, which is a tuple of (delay: float, url: str) or (None, None) if not found\n    return w3lib_get_meta_refresh(response.text, ignored_tags=ignore_tags)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 131, in <module>\n  File \"<string>\", line 122, in test_0\n  File \"<string>\", line 65, in get_meta_refresh\nTypeError: get_meta_refresh() got an unexpected keyword argument 'ignored_tags'\n", "passed": false}
{"task_id": 73, "prediction_id": 4, "generation": "from typing import Optional, Iterable, Tuple, Union\nfrom scrapy.http.response.text import TextResponse\nfrom w3lib.html import get_meta_refresh as w3lib_get_meta_refresh\n\ndef get_meta_refresh(\n    response: TextResponse,\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n    # Use w3lib.html.get_meta_refresh which already implements\n    # parsing of meta refresh tags from HTML content,\n    # passing the response.text and response.encoding.\n    # The ignore_tags param can be used to instruct the parsing to ignore\n    # tags like script and noscript (as per default)\n    #\n    # Return is either (None, None) if no meta refresh was found,\n    # or (delay, url) tuple, where delay is a float number of seconds and url is str.\n    return w3lib_get_meta_refresh(response.text, response.encoding, ignore_tags=ignore_tags)", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 350, in <module>\n  File \"<string>\", line 344, in test_42\nAssertionError\n", "passed": false}
