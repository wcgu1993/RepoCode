{"task_id": 112, "prediction_id": 0, "generation": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    results = []\n    fragments = domain.split('.')\n    # Starting from full domain, strip leftmost label one by one\n    for i in range(len(fragments) - 1):\n        subdomain = \".\".join(fragments[i:])\n        results.append(subdomain)\n    results.append(fragments[-1])  # just the top-level label (rarely useful, but done for completeness)\n\n    # remove duplicates if domain is single label, ensure at least the full domain\n    results = list(dict.fromkeys(results))  # preserve order, remove duplicates\n\n    # Add dot-prefixed variants\n    results += ['.' + d for d in results]\n\n    # The example expects a list of 4 items for a 3-label domain:\n    # ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n    # but our above code may add extra entries like the last TLD alone.\n    # Let's adapt to only emit domains with at least 2 labels.\n\n    # So let's redo with that logic:\n\ndef potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    parts = domain.split('.')\n    results = []\n    # Only consider suffixes with at least 2 parts (e.g. example.com)\n    for i in range(len(parts) - 1):\n        subdomain = '.'.join(parts[i:])\n        results.append(subdomain)\n    # Add dot-prefixed variants\n    results += ['.' + d for d in results]\n    return results", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 398, in <module>\n  File \"<string>\", line 396, in test_92\nAssertionError\n", "passed": false}
{"task_id": 112, "prediction_id": 1, "generation": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    matches = []\n    parts = domain.split('.')\n    for i in range(len(parts) - 1):\n        subdomain = '.'.join(parts[i:])\n        matches.append(subdomain)\n    for i in range(len(parts) - 1):\n        subdomain = '.' + '.'.join(parts[i:])\n        matches.append(subdomain)\n    return matches", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 370, in <module>\n  File \"<string>\", line 368, in test_92\nAssertionError\n", "passed": false}
{"task_id": 112, "prediction_id": 2, "generation": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    parts = domain.split('.')\n    matches = []\n    # From longest to shortest domain suffixes with at least one dot\n    for i in range(len(parts) - 1):\n        subdomain = '.'.join(parts[i:])\n        matches.append(subdomain)\n    # Add dotted versions of each domain as well\n    dotted_matches = ['.' + d for d in matches]\n    return matches + dotted_matches", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 370, in <module>\n  File \"<string>\", line 368, in test_92\nAssertionError\n", "passed": false}
{"task_id": 112, "prediction_id": 3, "generation": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    parts = domain.split('.')\n    if len(parts) == 1:\n        # No subdomain parts\n        base_domains = [domain]\n    else:\n        # Generate all possible suffix domains excluding empty parts\n        base_domains = ['.'.join(parts[i:]) for i in range(len(parts))]\n    matches = []\n    for d in base_domains:\n        matches.append(d)\n    for d in base_domains:\n        matches.append('.' + d)\n    return matches", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 228, in <module>\n  File \"<string>\", line 226, in test_3\nAssertionError\n", "passed": false}
{"task_id": 112, "prediction_id": 4, "generation": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n    parts = domain.split('.')\n    matches = []\n    # Generate all possible suffixes starting from the full domain down to the top-level domain + one label\n    for i in range(len(parts) - 1):\n        subdomain = '.'.join(parts[i:])\n        matches.append(subdomain)\n    # Add dotted variants\n    matches += ['.' + m for m in matches]\n    return matches", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 370, in <module>\n  File \"<string>\", line 368, in test_92\nAssertionError\n", "passed": false}
