{"task_id": 99, "prediction_id": 0, "generation": "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode, quote\n\ndef escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    # Parse the url to split into its components\n    parsed = urlparse(url)\n\n    fragment = parsed.fragment\n    # Check if the fragment is AJAX crawlable (starts with '!')\n    if not fragment.startswith('!'):\n        # Return url as-is if fragment doesn't start with '!'\n        return url\n\n    # Remove leading '!' from fragment\n    escaped_fragment = fragment[1:]\n\n    # Parse the query string into a list of pairs\n    query_params = parse_qsl(parsed.query, keep_blank_values=True)\n\n    # Append the _escaped_fragment_ parameter with URL-encoded escaped_fragment\n    # We must URL encode escaped_fragment value as per the examples\n    # But urlencode will do it if passed as a param value\n    query_params.append(('_escaped_fragment_', escaped_fragment))\n\n    # Build the new query string\n    new_query = urlencode(query_params)\n\n    # Build the new url parts: keep the original components but replace fragment with \"\"\n    new_parts = (\n        parsed.scheme,\n        parsed.netloc,\n        parsed.path,\n        parsed.params,\n        new_query,\n        ''  # Remove fragment after transforming it\n    )\n\n    # Rebuild the url from parts\n    new_url = urlunparse(new_parts)\n    return new_url", "message": "passed", "passed": true}
{"task_id": 99, "prediction_id": 1, "generation": "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode, quote\n\ndef escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    # Parse the url into components\n    parsed = urlparse(url)\n    fragment = parsed.fragment\n\n    # Check if fragment starts with '!'\n    if not fragment.startswith('!'):\n        # Not an AJAX crawlable fragment, return as-is\n        return url\n\n    # Extract the part after '!' in fragment\n    fragment_data = fragment[1:]\n\n    # Parse existing query parameters into a list of tuples\n    query_params = parse_qsl(parsed.query, keep_blank_values=True)\n\n    # Append _escaped_fragment_ parameter with the fragment data (percent-encoded)\n    # According to the examples, the fragment_data is URL-encoded, so we must quote it\n    escaped_fragment_value = quote(fragment_data, safe='')\n    \n    # Remove any existing _escaped_fragment_ parameters to avoid duplicates\n    query_params = [(k, v) for k, v in query_params if k != '_escaped_fragment_']\n\n    query_params.append(('_escaped_fragment_', escaped_fragment_value))\n\n    # Rebuild query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Build new URL with updated query and empty fragment\n    new_url = urlunparse((\n        parsed.scheme,\n        parsed.netloc,\n        parsed.path,\n        parsed.params,\n        new_query,\n        ''  # fragment cleared\n    ))\n\n    # If original url had no scheme and netloc (like in examples), urlparse sets scheme, netloc empty\n    # The output in examples shows no scheme but www.example.com is in path.\n    # So if scheme and netloc are empty, it means input is without scheme\n    # reconstruct accordingly by replacing scheme/netloc with '' and the original prefix preserved in path\n    \n    if not parsed.scheme and not parsed.netloc:\n        # The input was something like www.example.com/ajax.html#!key=value\n        # urlparse parsed > path = www.example.com/ajax.html, fragment = ...\n        # In this case, build url string manually:\n        # split new_url after netloc (which is empty), join everything after scheme ('') + '://' (absent)\n        # but urlunparse returns URL with empty scheme and netloc means new_url starts with path\n\n        # So new_url is something like:\n        # '' + '' + '/ajax.html' + '' + '?_escaped_fragment_=...' + ''\n        # Actually it will be: '/ajax.html?_escaped_fragment_=...'\n        # But original path contains 'www.example.com/ajax.html' interpreted as path only\n\n        # So just return new_url as is\n\n        return new_url\n\n    return new_url", "message": "failed: Traceback (most recent call last):\n  File \"/codegendata/human-eval/human_eval/execution.py\", line 57, in unsafe_execute\n    exec(check_program, exec_globals)\n  File \"<string>\", line 243, in <module>\n  File \"<string>\", line 241, in test_0\nAssertionError\n", "passed": false}
{"task_id": 99, "prediction_id": 2, "generation": "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n\n\ndef escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    parsed = urlparse(url)\n\n    # Check if fragment starts with '!'\n    if not parsed.fragment.startswith('!'):\n        # Not an AJAX crawlable fragment, return URL as is\n        return url\n\n    # Remove leading '!' from fragment for escaped fragment\n    fragment_data = parsed.fragment[1:]  # can be empty string\n\n    # Parse existing query parameters into list of tuples to preserve order\n    query_params = parse_qsl(parsed.query, keep_blank_values=True)\n\n    # Add or replace _escaped_fragment_\n    # Instead of replacing, per spec, we just add it at end\n    query_params.append(('_escaped_fragment_', fragment_data))\n\n    # Build new query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Assemble new URL without fragment (to replace #!fragment by query param)\n    new_parsed = parsed._replace(query=new_query, fragment='')\n\n    return urlunparse(new_parsed)", "message": "passed", "passed": true}
{"task_id": 99, "prediction_id": 3, "generation": "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode, quote\n\n\ndef escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    parsed = urlparse(url)\n\n    # Only act if fragment starts with '!'\n    if not parsed.fragment.startswith('!'):\n        # Not an AJAX crawlable fragment, return as is\n        return url\n\n    # Remove the leading '!' from the fragment\n    fragment_value = parsed.fragment[1:]\n\n    # Prepare the _escaped_fragment_ query parameter (URL-encoded)\n    escaped_fragment = quote(fragment_value, safe='')\n\n    # Parse existing query parameters into a list of pairs\n    query_params = parse_qsl(parsed.query, keep_blank_values=True)\n\n    # Add or replace _escaped_fragment_ parameter\n    # But since _escaped_fragment_ is probably unique, just append it\n    # (spec does not say about replacements. The examples add it.)\n    query_params.append(('_escaped_fragment_', fragment_value))\n\n    # Rebuild query string with the new parameter, encoding the fragment value properly\n    # urlencode will encode values, so we pass fragment_value raw and let urlencode encode it.\n    new_query = urlencode(query_params)\n\n    # Build new URL without the fragment (removing original #! fragment)\n    new_parsed = parsed._replace(query=new_query, fragment='')\n\n    return urlunparse(new_parsed)", "message": "passed", "passed": true}
{"task_id": 99, "prediction_id": 4, "generation": "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n\ndef escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    parsed = urlparse(url)\n    fragment = parsed.fragment\n\n    # Check if fragment starts with '!'\n    if not fragment.startswith('!'):\n        # not an ajax crawlable url, return as is\n        return url\n\n    # Remove leading '!' from fragment\n    escaped_fragment = fragment[1:]\n\n    # Parse existing query parameters into a list of tuples\n    query_params = parse_qsl(parsed.query, keep_blank_values=True)\n    # Append the _escaped_fragment_ param\n    query_params.append(('_escaped_fragment_', escaped_fragment))\n\n    # Rebuild the query string\n    new_query = urlencode(query_params, doseq=True)\n\n    # Build the new URL without the fragment and with updated query\n    new_parts = (\n        parsed.scheme,\n        parsed.netloc,\n        parsed.path,\n        parsed.params,\n        new_query,\n        ''  # fragment removed\n    )\n    new_url = urlunparse(new_parts)\n    # If the original url had no scheme/netloc (e.g. \"www.example.com/...\")\n    # urlparse treats it as path, so the scheme/netloc would be empty.\n    # To keep the same behavior, if scheme/netloc are empty but original url\n    # does not start with scheme delimiter, construct manually:\n    if not parsed.scheme and not parsed.netloc and '://' not in url:\n        # urlparse in this case treats the entire url as path\n        # So just rebuild manually:\n        # Split original url into path and the rest (query + fragment)\n        # We already removed fragment and appended to query\n        # So let's reconstruct accordingly\n        # The path + ? + new_query\n        path = parsed.path\n        if new_query:\n            return path + '?' + new_query\n        else:\n            return path\n    return new_url", "message": "passed", "passed": true}
