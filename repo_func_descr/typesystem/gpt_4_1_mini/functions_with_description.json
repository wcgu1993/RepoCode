[{"file": "./dataset/RepoExec/test-apps/typesystem/setup.py", "function": "get_version", "line_number": 13, "body": "def get_version(package):\n    \"\"\"\n    Return package version as listed in `__version__` in `init.py`.\n    \"\"\"\n    init_py = open(os.path.join(package, '__init__.py')).read()\n    return re.search(\"__version__ = ['\\\"]([^'\\\"]+)['\\\"]\", init_py).group(1)", "is_method": false, "function_description": "Function that extracts and returns the version string of a specified Python package by reading its `__init__.py` file. Useful for programmatically checking package versions without importing them."}, {"file": "./dataset/RepoExec/test-apps/typesystem/setup.py", "function": "get_packages", "line_number": 21, "body": "def get_packages(package):\n    \"\"\"\n    Return root package and all sub-packages.\n    \"\"\"\n    return [dirpath\n            for dirpath, dirnames, filenames in os.walk(package)\n            if os.path.exists(os.path.join(dirpath, '__init__.py'))]", "is_method": false, "function_description": "Utility function that returns the root package and all its sub-packages by identifying directories containing an __init__.py file, useful for package discovery and module organization tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate_or_error", "line_number": 53, "body": "def validate_or_error(\n        self, value: typing.Any, *, strict: bool = False\n    ) -> ValidationResult:\n        try:\n            value = self.validate(value, strict=strict)\n        except ValidationError as error:\n            return ValidationResult(value=None, error=error)\n        return ValidationResult(value=value, error=None)", "is_method": true, "class_name": "Field", "function_description": "Utility method of the Field class that validates a given value and returns a ValidationResult encapsulating the validated value or any validation error encountered. It supports optional strict validation modes for precise data checking."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "serialize", "line_number": 62, "body": "def serialize(self, obj: typing.Any) -> typing.Any:\n        return obj", "is_method": true, "class_name": "Field", "function_description": "Returns the input object unchanged, serving as a placeholder for serialization in the Field class."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "has_default", "line_number": 65, "body": "def has_default(self) -> bool:\n        return hasattr(self, \"default\")", "is_method": true, "class_name": "Field", "function_description": "Utility method in the Field class that checks if the field has a default value set. It enables other functions to conditionally handle fields based on the presence of defaults."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "get_default_value", "line_number": 68, "body": "def get_default_value(self) -> typing.Any:\n        default = getattr(self, \"default\", None)\n        if callable(default):\n            return default()\n        return default", "is_method": true, "class_name": "Field", "function_description": "Returns the default value for the field, calling it if the default is a callable. This allows retrieval of static defaults or dynamically generated values."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validation_error", "line_number": 74, "body": "def validation_error(self, code: str) -> ValidationError:\n        text = self.get_error_text(code)\n        return ValidationError(text=text, code=code)", "is_method": true, "class_name": "Field", "function_description": "Creates and returns a ValidationError object with a specific error code and corresponding descriptive message for this Field, enabling consistent error handling during validation processes."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "get_error_text", "line_number": 78, "body": "def get_error_text(self, code: str) -> str:\n        return self.errors[code].format(**self.__dict__)", "is_method": true, "class_name": "Field", "function_description": "Returns a formatted error message corresponding to a given error code, using the Field instance's attributes for message customization. This supports dynamic and specific error reporting within the Field context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "__or__", "line_number": 81, "body": "def __or__(self, other: \"Field\") -> \"Union\":\n        if isinstance(self, Union):\n            any_of = self.any_of\n        else:\n            any_of = [self]\n\n        if isinstance(other, Union):\n            any_of += other.any_of\n        else:\n            any_of += [other]\n\n        return Union(any_of=any_of)", "is_method": true, "class_name": "Field", "function_description": "Combines two Field instances into a Union that represents a choice between them, facilitating flexible type or schema definitions by merging multiple field options into one unified representation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 143, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None and self.allow_blank and not strict:\n            # Leniently cast nulls to empty strings if allow_blank.\n            return \"\"\n        elif value is None:\n            raise self.validation_error(\"null\")\n        elif self.format in FORMATS and FORMATS[self.format].is_native_type(value):\n            return value\n        elif not isinstance(value, str):\n            raise self.validation_error(\"type\")\n\n        # The null character is always invalid.\n        value = value.replace(\"\\0\", \"\")\n\n        # Strip leading/trailing whitespace by default.\n        if self.trim_whitespace:\n            value = value.strip()\n\n        if not self.allow_blank and not value:\n            if self.allow_null and not strict:\n                # Leniently cast empty strings (after trimming) to null if allow_null.\n                return None\n            raise self.validation_error(\"blank\")\n\n        if self.min_length is not None:\n            if len(value) < self.min_length:\n                raise self.validation_error(\"min_length\")\n\n        if self.max_length is not None:\n            if len(value) > self.max_length:\n                raise self.validation_error(\"max_length\")\n\n        if self.pattern_regex is not None:\n            if not self.pattern_regex.search(value):\n                raise self.validation_error(\"pattern\")\n\n        if self.format in FORMATS:\n            return FORMATS[self.format].validate(value)\n\n        return value", "is_method": true, "class_name": "String", "function_description": "Core validation method of the String class that verifies and sanitizes input against nullability, length, pattern, format, and whitespace rules, returning a correctly typed string or raising detailed validation errors. It supports flexible strictness and blank handling for diverse string validation needs."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "serialize", "line_number": 186, "body": "def serialize(self, obj: typing.Any) -> typing.Any:\n        if self.format in FORMATS:\n            return FORMATS[self.format].serialize(obj)\n        return obj", "is_method": true, "class_name": "String", "function_description": "Utility method in the String class that serializes an object according to the instance's specified format if supported; otherwise, it returns the object unchanged."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 238, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value == \"\" and self.allow_null and not strict:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n        elif isinstance(value, bool):\n            raise self.validation_error(\"type\")\n        elif (\n            self.numeric_type is int\n            and isinstance(value, float)\n            and not value.is_integer()\n        ):\n            raise self.validation_error(\"integer\")\n        elif not isinstance(value, (int, float)) and strict:\n            raise self.validation_error(\"type\")\n\n        try:\n            if isinstance(value, str):\n                # Casting to a decimal first gives more lenient parsing.\n                value = decimal.Decimal(value)\n            if self.numeric_type is not None:\n                value = self.numeric_type(value)\n        except (TypeError, ValueError, decimal.InvalidOperation):\n            raise self.validation_error(\"type\")\n\n        if not isfinite(value):\n            # inf, -inf, nan, are all invalid.\n            raise self.validation_error(\"finite\")\n\n        if self.precision is not None:\n            numeric_type = self.numeric_type or type(value)\n            quantize_val = decimal.Decimal(self.precision)\n            decimal_val = decimal.Decimal(value)\n            decimal_val = decimal_val.quantize(\n                quantize_val, rounding=decimal.ROUND_HALF_UP\n            )\n            value = numeric_type(decimal_val)\n\n        if self.minimum is not None and value < self.minimum:\n            raise self.validation_error(\"minimum\")\n\n        if self.exclusive_minimum is not None and value <= self.exclusive_minimum:\n            raise self.validation_error(\"exclusive_minimum\")\n\n        if self.maximum is not None and value > self.maximum:\n            raise self.validation_error(\"maximum\")\n\n        if self.exclusive_maximum is not None and value >= self.exclusive_maximum:\n            raise self.validation_error(\"exclusive_maximum\")\n\n        if self.multiple_of is not None:\n            if isinstance(self.multiple_of, int):\n                if value % self.multiple_of:\n                    raise self.validation_error(\"multiple_of\")\n            else:\n                if not (value * (1 / self.multiple_of)).is_integer():\n                    raise self.validation_error(\"multiple_of\")\n\n        return value", "is_method": true, "class_name": "Number", "function_description": "Core service method of the Number class that validates and optionally converts input values against numeric constraints like type, range boundaries, precision, and multiples, ensuring the values meet specified numeric rules before use."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "serialize", "line_number": 312, "body": "def serialize(self, obj: typing.Any) -> typing.Any:\n        return None if obj is None else float(obj)", "is_method": true, "class_name": "Decimal", "function_description": "This method converts a given object to a float if it is not None, facilitating serialization of decimal-compatible values into float format for data processing or storage."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 331, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n\n        elif value is None:\n            raise self.validation_error(\"null\")\n\n        elif not isinstance(value, bool):\n            if strict:\n                raise self.validation_error(\"type\")\n\n            if isinstance(value, str):\n                value = value.lower()\n\n            if self.allow_null and value in self.coerce_null_values:\n                return None\n\n            try:\n                value = self.coerce_values[value]\n            except (KeyError, TypeError):\n                raise self.validation_error(\"type\")\n\n        return value", "is_method": true, "class_name": "Boolean", "function_description": "Validates and converts input to a boolean value based on configuration, handling nulls, type coercion, and strict type enforcement for robust boolean input validation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 376, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n        elif value not in Uniqueness([key for key, value in self.choices]):\n            if value == \"\":\n                if self.allow_null and not strict:\n                    return None\n                raise self.validation_error(\"required\")\n            raise self.validation_error(\"choice\")\n        return value", "is_method": true, "class_name": "Choice", "function_description": "Method of the Choice class that checks if a given value is valid among predefined choices, handling null allowances and strict mode, ensuring input conforms to expected options or raising validation errors."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 446, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n        elif not isinstance(value, (dict, typing.Mapping)):\n            raise self.validation_error(\"type\")\n\n        validated = {}\n        error_messages = []\n\n        # Ensure all property keys are strings.\n        for key in value.keys():\n            if not isinstance(key, str):\n                text = self.get_error_text(\"invalid_key\")\n                message = Message(text=text, code=\"invalid_key\", index=[key])\n                error_messages.append(message)\n            elif self.property_names is not None:\n                _, error = self.property_names.validate_or_error(key)\n                if error is not None:\n                    text = self.get_error_text(\"invalid_property\")\n                    message = Message(text=text, code=\"invalid_property\", index=[key])\n                    error_messages.append(message)\n\n        # Min/Max properties\n        if self.min_properties is not None:\n            if len(value) < self.min_properties:\n                if self.min_properties == 1:\n                    raise self.validation_error(\"empty\")\n                else:\n                    raise self.validation_error(\"min_properties\")\n        if self.max_properties is not None:\n            if len(value) > self.max_properties:\n                raise self.validation_error(\"max_properties\")\n\n        # Required properties\n        for key in self.required:\n            if key not in value:\n                text = self.get_error_text(\"required\")\n                message = Message(text=text, code=\"required\", index=[key])\n                error_messages.append(message)\n\n        # Properties\n        for key, child_schema in self.properties.items():\n            if key not in value:\n                if child_schema.has_default():\n                    validated[key] = child_schema.get_default_value()\n                continue\n            item = value[key]\n            child_value, error = child_schema.validate_or_error(item, strict=strict)\n            if not error:\n                validated[key] = child_value\n            else:\n                error_messages += error.messages(add_prefix=key)\n\n        # Pattern properties\n        if self.pattern_properties:\n            for key in list(value.keys()):\n                for pattern, child_schema in self.pattern_properties.items():\n                    if isinstance(key, str) and re.search(pattern, key):\n                        item = value[key]\n                        child_value, error = child_schema.validate_or_error(\n                            item, strict=strict\n                        )\n                        if not error:\n                            validated[key] = child_value\n                        else:\n                            error_messages += error.messages(add_prefix=key)\n\n        # Additional properties\n        validated_keys = set(validated.keys())\n        error_keys = set(\n            [message.index[0] for message in error_messages if message.index]\n        )\n\n        remaining = [\n            key for key in value.keys() if key not in validated_keys | error_keys\n        ]\n\n        if self.additional_properties is True:\n            for key in remaining:\n                validated[key] = value[key]\n        elif self.additional_properties is False:\n            for key in remaining:\n                text = self.get_error_text(\"invalid_property\")\n                message = Message(text=text, code=\"invalid_property\", key=key)\n                error_messages.append(message)\n        elif self.additional_properties is not None:\n            assert isinstance(self.additional_properties, Field)\n            child_schema = self.additional_properties\n            for key in remaining:\n                item = value[key]\n                child_value, error = child_schema.validate_or_error(item, strict=strict)\n                if not error:\n                    validated[key] = child_value\n                else:\n                    error_messages += error.messages(add_prefix=key)\n\n        if error_messages:\n            raise ValidationError(messages=error_messages)\n\n        return validated", "is_method": true, "class_name": "Object", "function_description": "Validates and sanitizes a dictionary against defined schema rules, including property types, required keys, and constraints, raising detailed errors for violations. Useful for enforcing and normalizing structured data compliance in applications."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 602, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n        elif not isinstance(value, list):\n            raise self.validation_error(\"type\")\n\n        if (\n            self.min_items is not None\n            and self.min_items == self.max_items\n            and len(value) != self.min_items\n        ):\n            raise self.validation_error(\"exact_items\")\n        if self.min_items is not None and len(value) < self.min_items:\n            if self.min_items == 1:\n                raise self.validation_error(\"empty\")\n            raise self.validation_error(\"min_items\")\n        elif self.max_items is not None and len(value) > self.max_items:\n            raise self.validation_error(\"max_items\")\n\n        # Ensure all items are of the right type.\n        validated = []\n        error_messages: typing.List[Message] = []\n        if self.unique_items:\n            seen_items = Uniqueness()\n\n        for pos, item in enumerate(value):\n            validator = None\n            if isinstance(self.items, list):\n                if pos < len(self.items):\n                    validator = self.items[pos]\n                elif isinstance(self.additional_items, Field):\n                    validator = self.additional_items\n            elif self.items is not None:\n                validator = self.items\n\n            if validator is None:\n                validated.append(item)\n            else:\n                item, error = validator.validate_or_error(item, strict=strict)\n                if error:\n                    error_messages += error.messages(add_prefix=pos)\n                else:\n                    validated.append(item)\n\n            if self.unique_items:\n                if item in seen_items:\n                    text = self.get_error_text(\"unique_items\")\n                    message = Message(text=text, code=\"unique_items\", key=pos)\n                    error_messages.append(message)\n                else:\n                    seen_items.add(item)\n\n        if error_messages:\n            raise ValidationError(messages=error_messages)\n\n        return validated", "is_method": true, "class_name": "Array", "function_description": "Core method of the Array class that validates a given value as a list, enforcing constraints like item type, length bounds, uniqueness, and nullability, and returns the validated list or raises detailed validation errors."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "serialize", "line_number": 661, "body": "def serialize(self, obj: typing.Any) -> typing.Any:\n        if obj is None:\n            return None\n\n        if isinstance(self.items, list):\n            return [\n                serializer.serialize(value)\n                for serializer, value in zip(self.items, obj)\n            ]\n\n        if self.items is None:\n            return obj\n\n        return [self.items.serialize(value) for value in obj]", "is_method": true, "class_name": "Array", "function_description": "Method of the Array class that converts input data into a serialized format, handling nested structures or single serializers to prepare data for storage or transmission."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 707, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n\n        candidate_errors = []\n        for child in self.any_of:\n            validated, error = child.validate_or_error(value, strict=strict)\n            if error is None:\n                return validated\n            else:\n                # If a child returned anything other than a type error, then\n                # it is a candidate for returning as the primary error.\n                messages = error.messages()\n                if (\n                    len(messages) != 1\n                    or messages[0].code != \"type\"\n                    or messages[0].index\n                ):\n                    candidate_errors.append(error)\n\n        if len(candidate_errors) == 1:\n            # If exactly one child was of the correct type, then we can use\n            # the error from the child.\n            raise candidate_errors[0]\n        raise self.validation_error(\"union\")", "is_method": true, "class_name": "Union", "function_description": "Core method of the Union class that validates a value against multiple possible types or schemas, returning the first successful validation or raising detailed errors if none match. It supports strict checking and nullable values."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 741, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        return value", "is_method": true, "class_name": "Any", "function_description": "This function returns the input value as-is without validation. It can serve as a default or placeholder validation method in various contexts."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/fields.py", "function": "validate", "line_number": 757, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        if value != self.const:\n            if self.const is None:\n                raise self.validation_error(\"only_null\")\n            raise self.validation_error(\"const\")\n        return value", "is_method": true, "class_name": "Const", "function_description": "Utility method of the Const class that validates whether a given value matches a predefined constant, raising a validation error if it does not. It ensures input adheres strictly to a specified constant value."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/unique.py", "function": "__contains__", "line_number": 20, "body": "def __contains__(self, item: typing.Any) -> bool:\n        item = self.make_hashable(item)\n        return item in self._set", "is_method": true, "class_name": "Uniqueness", "function_description": "Checks if an item exists within the Uniqueness collection by converting it to a hashable form. Enables quick membership testing for potentially unhashable input elements."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/unique.py", "function": "add", "line_number": 24, "body": "def add(self, item: typing.Any) -> None:\n        item = self.make_hashable(item)\n        self._set.add(item)", "is_method": true, "class_name": "Uniqueness", "function_description": "Core method of the Uniqueness class that adds items to an internal set after ensuring they are hashable, supporting efficient uniqueness tracking of diverse elements."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/unique.py", "function": "make_hashable", "line_number": 28, "body": "def make_hashable(self, element: typing.Any) -> typing.Any:\n        \"\"\"\n        Coerce a primitive into a uniquely hashable type, for uniqueness checks.\n        \"\"\"\n\n        # Only primitive types can be handled.\n        assert (element is None) or isinstance(\n            element, (bool, int, float, str, list, dict)\n        )\n\n        if element is True:\n            # Need to make `True` distinct from `1`.\n            return self.TRUE\n        elif element is False:\n            # Need to make `False` distinct from `0`.\n            return self.FALSE\n        elif isinstance(element, list):\n            # Represent lists using a two-tuple of ('list', (item, item, ...))\n            return (\"list\", tuple([self.make_hashable(item) for item in element]))\n        elif isinstance(element, dict):\n            # Represent dicts using a two-tuple of ('dict', ((key, val), (key, val), ...))\n            return (\n                \"dict\",\n                tuple(\n                    [\n                        (self.make_hashable(key), self.make_hashable(value))\n                        for key, value in element.items()\n                    ]\n                ),\n            )\n\n        return element", "is_method": true, "class_name": "Uniqueness", "function_description": "Transforms primitive data types into consistent, uniquely hashable representations to enable reliable uniqueness checks, including special handling for booleans and nested lists or dictionaries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "render_fields", "line_number": 46, "body": "def render_fields(self) -> str:\n        html = \"\"\n        for field_name, field in self.schema.fields.items():\n            value = None if self.values is None else self.values.get(field_name)\n            error = None if self.errors is None else self.errors.get(field_name)\n            html += self.render_field(\n                field_name=field_name, field=field, value=value, error=error\n            )\n        return html", "is_method": true, "class_name": "Form", "function_description": "Generates and returns HTML for all form fields based on the schema, current values, and validation errors. This method facilitates dynamic form rendering with appropriate data and error displays."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "render_field", "line_number": 56, "body": "def render_field(\n        self,\n        *,\n        field_name: str,\n        field: Field,\n        value: typing.Any = None,\n        error: str = None,\n    ) -> str:\n        field_id_prefix = \"form-\" + self.schema.__name__.lower() + \"-\"\n        field_id = field_id_prefix + field_name.replace(\"_\", \"-\")\n        label = field.title or field_name\n        allow_empty = field.allow_null or getattr(field, \"allow_blank\", False)\n        required = not field.has_default() and not allow_empty\n        input_type = self.input_type_for_field(field)\n        template_name = self.template_for_field(field)\n        template = self.env.get_template(template_name)\n        value = \"\" if input_type == \"password\" else value\n        return template.render(\n            {\n                \"field_id\": field_id,\n                \"field_name\": field_name,\n                \"field\": field,\n                \"label\": label,\n                \"required\": required,\n                \"input_type\": input_type,\n                \"value\": value,\n                \"error\": error,\n            }\n        )", "is_method": true, "class_name": "Form", "function_description": "Renders an individual form field as an HTML string with appropriate attributes, labels, and error messages based on the field\u2019s properties and current value. This enables dynamic form generation consistent with the form\u2019s schema."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "template_for_field", "line_number": 86, "body": "def template_for_field(self, field: Field) -> str:\n        assert not isinstance(\n            field, Object\n        ), \"Forms do not support rendering Object fields\"\n\n        if isinstance(field, Choice):\n            return \"forms/select.html\"\n        elif isinstance(field, Boolean):\n            return \"forms/checkbox.html\"\n        if isinstance(field, String) and field.format == \"text\":\n            return \"forms/textarea.html\"\n        return \"forms/input.html\"", "is_method": true, "class_name": "Form", "function_description": "Returns the appropriate HTML template path for rendering a given form field based on its type, facilitating dynamic form field display in the Form context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "input_type_for_field", "line_number": 99, "body": "def input_type_for_field(self, field: Field) -> str:\n        format = getattr(field, \"format\", None)\n        if not format:\n            return \"text\"\n        return self.FORMAT_TO_INPUTTYPE.get(format, \"text\")", "is_method": true, "class_name": "Form", "function_description": "Determines the HTML input type for a given form field based on its format attribute, defaulting to \"text\" when unspecified or unrecognized. This aids in rendering appropriate input elements in form interfaces."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "__str__", "line_number": 105, "body": "def __str__(self) -> str:\n        return self.render_fields()", "is_method": true, "class_name": "Form", "function_description": "Returns a string representation of the Form by rendering its fields, enabling easy display or printing of the form's current state."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "__html__", "line_number": 108, "body": "def __html__(self) -> \"jinja2.Markup\":\n        return jinja2.Markup(self.render_fields())", "is_method": true, "class_name": "Form", "function_description": "This method generates the HTML representation of a Form by rendering its fields, enabling seamless integration with Jinja2 templates for web display. It provides a convenient way to embed form content directly into HTML output."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "load_template_env", "line_number": 120, "body": "def load_template_env(\n        self, *, directory: str = None, package: str = None\n    ) -> \"jinja2.Environment\":\n        if directory is not None and package is None:\n            loader: jinja2.BaseLoader = jinja2.FileSystemLoader(directory)\n        elif directory is None and package is not None:\n            loader = jinja2.PackageLoader(package, \"templates\")\n        else:\n            assert directory is not None\n            assert package is not None\n            loader = jinja2.ChoiceLoader(\n                [\n                    jinja2.FileSystemLoader(directory),\n                    jinja2.PackageLoader(package, \"templates\"),\n                ]\n            )\n        return jinja2.Environment(loader=loader, autoescape=True)", "is_method": true, "class_name": "Jinja2Forms", "function_description": "Provides a configured Jinja2 environment for loading templates from specified file system directories, Python packages, or both, facilitating flexible template management within the Jinja2Forms class."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/forms.py", "function": "Form", "line_number": 138, "body": "def Form(\n        self,\n        schema: typing.Type[Schema],\n        *,\n        values: dict = None,\n        errors: ValidationError = None,\n    ) -> Form:  # type: ignore\n        return Form(env=self.env, schema=schema, values=values, errors=errors)", "is_method": true, "class_name": "Jinja2Forms", "function_description": "Creates and returns a Form instance based on a given schema, with optional initial values and validation errors. It enables form generation and validation handling within the Jinja2Forms context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "set_definitions", "line_number": 32, "body": "def set_definitions(field: Field, definitions: SchemaDefinitions) -> None:\n    \"\"\"\n    Recursively set the definitions that string-referenced `Reference` fields\n    should use.\n    \"\"\"\n    if isinstance(field, Reference) and field.definitions is None:\n        field.definitions = definitions\n    elif isinstance(field, Array):\n        if field.items is not None:\n            if isinstance(field.items, (tuple, list)):\n                for child in field.items:\n                    set_definitions(child, definitions)\n            else:\n                set_definitions(field.items, definitions)\n    elif isinstance(field, Object):\n        for child in field.properties.values():\n            set_definitions(child, definitions)", "is_method": false, "function_description": "Recursively assigns schema definitions to all reference fields within a nested field structure, ensuring that `Reference` fields correctly link to their intended schema definitions. Useful for schema validation and resolution in complex data models."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__getitem__", "line_number": 13, "body": "def __getitem__(self, key: typing.Any) -> typing.Any:\n        return self._definitions[key]", "is_method": true, "class_name": "SchemaDefinitions", "function_description": "Provides dictionary-like access to retrieve schema definitions by key from the internal definitions collection within the SchemaDefinitions class."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__iter__", "line_number": 16, "body": "def __iter__(self) -> typing.Iterator[typing.Any]:\n        return iter(self._definitions)", "is_method": true, "class_name": "SchemaDefinitions", "function_description": "Provides an iterator over the schema definitions contained in the SchemaDefinitions class, allowing iteration through all stored definitions."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__len__", "line_number": 19, "body": "def __len__(self) -> int:\n        return len(self._definitions)", "is_method": true, "class_name": "SchemaDefinitions", "function_description": "Returns the number of schema definitions stored in the SchemaDefinitions collection. This allows other functions to quickly determine the size of the schema set."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__setitem__", "line_number": 22, "body": "def __setitem__(self, key: typing.Any, value: typing.Any) -> None:\n        assert (\n            key not in self._definitions\n        ), r\"Definition for {key!r} has already been set.\"\n        self._definitions[key] = value", "is_method": true, "class_name": "SchemaDefinitions", "function_description": "Core method of SchemaDefinitions that adds a new definition keyed by an identifier, ensuring no duplicate keys are overwritten to maintain unique schema entries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__delitem__", "line_number": 28, "body": "def __delitem__(self, key: typing.Any) -> None:\n        del self._definitions[key]", "is_method": true, "class_name": "SchemaDefinitions", "function_description": "Removes a schema definition identified by the given key from the SchemaDefinitions collection, supporting dictionary-like deletion of entries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__new__", "line_number": 52, "body": "def __new__(\n        cls: type,\n        name: str,\n        bases: typing.Sequence[type],\n        attrs: dict,\n        definitions: SchemaDefinitions = None,\n    ) -> type:\n        fields: typing.Dict[str, Field] = {}\n\n        for key, value in list(attrs.items()):\n            if isinstance(value, Field):\n                attrs.pop(key)\n                fields[key] = value\n\n        # If this class is subclassing other Schema classes, add their fields.\n        for base in reversed(bases):\n            base_fields = getattr(base, \"fields\", {})\n            for key, value in base_fields.items():\n                if isinstance(value, Field) and key not in fields:\n                    fields[key] = value\n\n        # Add the definitions to any `Reference` fields that we're including.\n        if definitions is not None:\n            for field in fields.values():\n                set_definitions(field, definitions)\n\n        # \u00a0Sort fields by their actual position in the source code,\n        # using `Field._creation_counter`\n        attrs[\"fields\"] = dict(\n            sorted(fields.items(), key=lambda item: item[1]._creation_counter)\n        )\n\n        new_type = super(SchemaMetaclass, cls).__new__(  # type: ignore\n            cls, name, bases, attrs\n        )\n        if definitions is not None:\n            definitions[name] = new_type\n        return new_type", "is_method": true, "class_name": "SchemaMetaclass", "function_description": "Creates a new schema class by collecting and organizing Field attributes from the class and its bases, applying schema definitions, and maintaining field order. It enables consistent schema construction with inherited fields and reference resolution."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "make_validator", "line_number": 134, "body": "def make_validator(cls: typing.Type[\"Schema\"], *, strict: bool = False) -> Field:\n        required = [key for key, value in cls.fields.items() if not value.has_default()]\n        return Object(\n            properties=cls.fields,\n            required=required,\n            additional_properties=False if strict else None,\n        )", "is_method": true, "class_name": "Schema", "function_description": "Core function of the Schema class that creates a validation schema object describing required fields and property constraints. It enables strict or flexible validation of data structures based on the schema's field definitions."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "validate", "line_number": 143, "body": "def validate(\n        cls: typing.Type[\"Schema\"], value: typing.Any, *, strict: bool = False\n    ) -> \"Schema\":\n        validator = cls.make_validator(strict=strict)\n        value = validator.validate(value, strict=strict)\n        return cls(value)", "is_method": true, "class_name": "Schema", "function_description": "Validates an input value against the schema's rules and returns a schema instance with the validated data. Useful for ensuring data integrity before processing or storage."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "validate_or_error", "line_number": 151, "body": "def validate_or_error(\n        cls: typing.Type[\"Schema\"], value: typing.Any, *, strict: bool = False\n    ) -> ValidationResult:\n        try:\n            value = cls.validate(value, strict=strict)\n        except ValidationError as error:\n            return ValidationResult(value=None, error=error)\n        return ValidationResult(value=value, error=None)", "is_method": true, "class_name": "Schema", "function_description": "Core method of the Schema class that validates a value against the schema, returning a ValidationResult with either the validated value or validation error for controlled error handling."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "is_sparse", "line_number": 161, "body": "def is_sparse(self) -> bool:\n        # A schema is sparsely populated if it does not include attributes\n        # for all its fields.\n        return bool([key for key in self.fields.keys() if not hasattr(self, key)])", "is_method": true, "class_name": "Schema", "function_description": "Utility method of the Schema class that determines if the schema is sparsely populated by checking for missing attribute definitions corresponding to its fields."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__eq__", "line_number": 166, "body": "def __eq__(self, other: typing.Any) -> bool:\n        if not isinstance(other, self.__class__):\n            return False\n\n        for key in self.fields.keys():\n            if getattr(self, key) != getattr(other, key):\n                return False\n        return True", "is_method": true, "class_name": "Schema", "function_description": "Compares two Schema instances for equality by checking if they are the same class and have identical values in all defined fields. This supports consistent schema comparison in data validation or transformation workflows."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__getitem__", "line_number": 175, "body": "def __getitem__(self, key: typing.Any) -> typing.Any:\n        try:\n            field = self.fields[key]\n            value = getattr(self, key)\n        except (KeyError, AttributeError):\n            raise KeyError(key) from None\n        else:\n            return field.serialize(value)", "is_method": true, "class_name": "Schema", "function_description": "Provides dictionary-like access to schema fields by key, returning the serialized value of the corresponding field if it exists, or raising a KeyError otherwise. Useful for retrieving processed field data consistently."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__iter__", "line_number": 184, "body": "def __iter__(self) -> typing.Iterator[str]:\n        for key in self.fields:\n            if hasattr(self, key):\n                yield key", "is_method": true, "class_name": "Schema", "function_description": "Provides an iterator over the attribute names present in the Schema instance that correspond to its defined fields. This enables easy iteration through all valid field names of the schema object."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__len__", "line_number": 189, "body": "def __len__(self) -> int:\n        return len([key for key in self.fields if hasattr(self, key)])", "is_method": true, "class_name": "Schema", "function_description": "Returns the count of Schema attributes that correspond to its defined fields, indicating how many fields are currently set on the instance."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "__repr__", "line_number": 192, "body": "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        arguments = {\n            key: getattr(self, key) for key in self.fields.keys() if hasattr(self, key)\n        }\n        argument_str = \", \".join(\n            [f\"{key}={value!r}\" for key, value in arguments.items()]\n        )\n        sparse_indicator = \" [sparse]\" if self.is_sparse else \"\"\n        return f\"{class_name}({argument_str}){sparse_indicator}\"", "is_method": true, "class_name": "Schema", "function_description": "Provides a string representation of a Schema instance showing its fields and values, including a sparse data indicator if applicable, aiding in debugging and display."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "target_string", "line_number": 223, "body": "def target_string(self) -> str:\n        if not hasattr(self, \"_target_string\"):\n            self._target_string = self._target.__name__\n        return self._target_string", "is_method": true, "class_name": "Reference", "function_description": "Returns the name of the target function or callable associated with this Reference instance, caching it for future access. This supports identification or logging of the referenced callable."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "target", "line_number": 229, "body": "def target(self) -> typing.Union[Field, typing.Type[Schema]]:\n        if not hasattr(self, \"_target\"):\n            assert (\n                self.definitions is not None\n            ), \"String reference missing 'definitions'.\"\n            self._target = self.definitions[self.to]\n        return self._target", "is_method": true, "class_name": "Reference", "function_description": "Provides access to the resolved target object or schema referred to by this Reference instance, ensuring the reference is linked to its definition for validation or processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "validate", "line_number": 237, "body": "def validate(self, value: typing.Any, *, strict: bool = False) -> typing.Any:\n        if value is None and self.allow_null:\n            return None\n        elif value is None:\n            raise self.validation_error(\"null\")\n        return self.target.validate(value, strict=strict)", "is_method": true, "class_name": "Reference", "function_description": "Method of the Reference class that validates a given value against the target schema, enforcing null allowance rules and supporting strict validation mode. It ensures input adherence to expected data constraints."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/schemas.py", "function": "serialize", "line_number": 244, "body": "def serialize(self, obj: typing.Any) -> typing.Any:\n        if obj is None:\n            return None\n        return dict(obj)", "is_method": true, "class_name": "Reference", "function_description": "Utility method in the Reference class that converts an input object to a dictionary representation, returning None if the input is None. It facilitates consistent serialization of objects for further processing or storage."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/composites.py", "function": "validate", "line_number": 19, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        raise self.validation_error(\"never\")", "is_method": true, "class_name": "NeverMatch", "function_description": "This function always raises a validation error, effectively rejecting any input. It serves as a validator that never permits successful validation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/composites.py", "function": "validate", "line_number": 41, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        candidate = None\n        match_count = 0\n        for child in self.one_of:\n            validated, error = child.validate_or_error(value, strict=strict)\n            if error is None:\n                match_count += 1\n                candidate = validated\n\n        if match_count == 1:\n            return candidate\n        elif match_count > 1:\n            raise self.validation_error(\"multiple_matches\")\n        raise self.validation_error(\"no_match\")", "is_method": true, "class_name": "OneOf", "function_description": "Core method of the OneOf class that validates a value against multiple validators, ensuring it matches exactly one. It returns the validated value or raises an error if there are no or multiple matches."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/composites.py", "function": "validate", "line_number": 70, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        for child in self.all_of:\n            child.validate(value, strict=strict)\n        return value", "is_method": true, "class_name": "AllOf", "function_description": "Core validator method of the AllOf class that ensures a value meets all validation criteria defined by its child validators, optionally enforcing strict validation rules."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/composites.py", "function": "validate", "line_number": 90, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        _, error = self.negated.validate_or_error(value, strict=strict)\n        if error:\n            return value\n        raise self.validation_error(\"negated\")", "is_method": true, "class_name": "Not", "function_description": "Function that validates a value by ensuring it does not satisfy the conditions of another validator; it returns the value if validation fails and raises an error if it passes, effectively enforcing the negation of a validation rule."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/composites.py", "function": "validate", "line_number": 117, "body": "def validate(self, value: typing.Any, strict: bool = False) -> typing.Any:\n        _, error = self.if_clause.validate_or_error(value, strict=strict)\n        if error is None:\n            return self.then_clause.validate(value, strict=strict)\n        else:\n            return self.else_clause.validate(value, strict=strict)", "is_method": true, "class_name": "IfThenElse", "function_description": "Core method of the IfThenElse class that validates a value by applying conditional logic: it returns the then_clause validation if the if_clause passes, otherwise it applies the else_clause validation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "from_json_schema", "line_number": 110, "body": "def from_json_schema(\n    data: typing.Union[bool, dict], definitions: SchemaDefinitions = None\n) -> Field:\n    if isinstance(data, bool):\n        return {True: Any(), False: NeverMatch()}[data]\n\n    if definitions is None:\n        definitions = SchemaDefinitions()\n        for key, value in data.get(\"definitions\", {}).items():\n            ref = f\"#/definitions/{key}\"\n            definitions[ref] = from_json_schema(value, definitions=definitions)\n\n    if \"$ref\" in data:\n        return ref_from_json_schema(data, definitions=definitions)\n\n    constraints = []  # typing.List[Field]\n    if any([property_name in data for property_name in TYPE_CONSTRAINTS]):\n        constraints.append(type_from_json_schema(data, definitions=definitions))\n    if \"enum\" in data:\n        constraints.append(enum_from_json_schema(data, definitions=definitions))\n    if \"const\" in data:\n        constraints.append(const_from_json_schema(data, definitions=definitions))\n    if \"allOf\" in data:\n        constraints.append(all_of_from_json_schema(data, definitions=definitions))\n    if \"anyOf\" in data:\n        constraints.append(any_of_from_json_schema(data, definitions=definitions))\n    if \"oneOf\" in data:\n        constraints.append(one_of_from_json_schema(data, definitions=definitions))\n    if \"not\" in data:\n        constraints.append(not_from_json_schema(data, definitions=definitions))\n    if \"if\" in data:\n        constraints.append(if_then_else_from_json_schema(data, definitions=definitions))\n\n    if len(constraints) == 1:\n        return constraints[0]\n    elif len(constraints) > 1:\n        return AllOf(constraints)\n    return Any()", "is_method": false, "function_description": "Function that converts a JSON Schema (boolean or dictionary) into a Field object representing its validation constraints, supporting complex schema constructs and recursive definitions for schema validation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "type_from_json_schema", "line_number": 150, "body": "def type_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    \"\"\"\n    Build a typed field or union of typed fields from a JSON schema object.\n    \"\"\"\n    type_strings, allow_null = get_valid_types(data)\n\n    if len(type_strings) > 1:\n        items = [\n            from_json_schema_type(\n                data, type_string=type_string, allow_null=False, definitions=definitions\n            )\n            for type_string in type_strings\n        ]\n        return Union(any_of=items, allow_null=allow_null)\n\n    if len(type_strings) == 0:\n        return {True: Const(None), False: NeverMatch()}[allow_null]\n\n    type_string = type_strings.pop()\n    return from_json_schema_type(\n        data, type_string=type_string, allow_null=allow_null, definitions=definitions\n    )", "is_method": false, "function_description": "Constructs a typed field or a union of typed fields based on a JSON schema, supporting nullable types and complex schema definitions. This facilitates type validation and parsing according to JSON schema specifications."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "get_valid_types", "line_number": 174, "body": "def get_valid_types(data: dict) -> typing.Tuple[typing.Set[str], bool]:\n    \"\"\"\n    Returns a two-tuple of `(type_strings, allow_null)`.\n    \"\"\"\n\n    type_strings = data.get(\"type\", [])\n    if isinstance(type_strings, str):\n        type_strings = {type_strings}\n    else:\n        type_strings = set(type_strings)\n\n    if not type_strings:\n        type_strings = {\"null\", \"boolean\", \"object\", \"array\", \"number\", \"string\"}\n\n    if \"number\" in type_strings:\n        type_strings.discard(\"integer\")\n\n    allow_null = False\n    if \"null\" in type_strings:\n        allow_null = True\n        type_strings.remove(\"null\")\n\n    return (type_strings, allow_null)", "is_method": false, "function_description": "Function that interprets a type definition from a dictionary, returning a set of valid type names and a flag indicating if null values are allowed. Useful for type validation and schema interpretation in data processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "from_json_schema_type", "line_number": 199, "body": "def from_json_schema_type(\n    data: dict, type_string: str, allow_null: bool, definitions: SchemaDefinitions\n) -> Field:\n    \"\"\"\n    Build a typed field from a JSON schema object.\n    \"\"\"\n\n    if type_string == \"number\":\n        kwargs = {\n            \"allow_null\": allow_null,\n            \"minimum\": data.get(\"minimum\", None),\n            \"maximum\": data.get(\"maximum\", None),\n            \"exclusive_minimum\": data.get(\"exclusiveMinimum\", None),\n            \"exclusive_maximum\": data.get(\"exclusiveMaximum\", None),\n            \"multiple_of\": data.get(\"multipleOf\", None),\n            \"default\": data.get(\"default\", NO_DEFAULT),\n        }\n        return Float(**kwargs)\n\n    elif type_string == \"integer\":\n        kwargs = {\n            \"allow_null\": allow_null,\n            \"minimum\": data.get(\"minimum\", None),\n            \"maximum\": data.get(\"maximum\", None),\n            \"exclusive_minimum\": data.get(\"exclusiveMinimum\", None),\n            \"exclusive_maximum\": data.get(\"exclusiveMaximum\", None),\n            \"multiple_of\": data.get(\"multipleOf\", None),\n            \"default\": data.get(\"default\", NO_DEFAULT),\n        }\n        return Integer(**kwargs)\n\n    elif type_string == \"string\":\n        min_length = data.get(\"minLength\", 0)\n        kwargs = {\n            \"allow_null\": allow_null,\n            \"allow_blank\": min_length == 0,\n            \"min_length\": min_length if min_length > 1 else None,\n            \"max_length\": data.get(\"maxLength\", None),\n            \"format\": data.get(\"format\"),\n            \"pattern\": data.get(\"pattern\", None),\n            \"default\": data.get(\"default\", NO_DEFAULT),\n        }\n        return String(**kwargs)\n\n    elif type_string == \"boolean\":\n        kwargs = {\"allow_null\": allow_null, \"default\": data.get(\"default\", NO_DEFAULT)}\n        return Boolean(**kwargs)\n\n    elif type_string == \"array\":\n        items = data.get(\"items\", None)\n        if items is None:\n            items_argument: typing.Union[None, Field, typing.List[Field]] = None\n        elif isinstance(items, list):\n            items_argument = [\n                from_json_schema(item, definitions=definitions) for item in items\n            ]\n        else:\n            items_argument = from_json_schema(items, definitions=definitions)\n\n        additional_items = data.get(\"additionalItems\", None)\n        if additional_items is None:\n            additional_items_argument: typing.Union[bool, Field] = True\n        elif isinstance(additional_items, bool):\n            additional_items_argument = additional_items\n        else:\n            additional_items_argument = from_json_schema(\n                additional_items, definitions=definitions\n            )\n\n        kwargs = {\n            \"allow_null\": allow_null,\n            \"min_items\": data.get(\"minItems\", 0),\n            \"max_items\": data.get(\"maxItems\", None),\n            \"additional_items\": additional_items_argument,\n            \"items\": items_argument,\n            \"unique_items\": data.get(\"uniqueItems\", False),\n            \"default\": data.get(\"default\", NO_DEFAULT),\n        }\n        return Array(**kwargs)\n\n    elif type_string == \"object\":\n        properties = data.get(\"properties\", None)\n        if properties is None:\n            properties_argument: typing.Optional[typing.Dict[str, Field]] = None\n        else:\n            properties_argument = {\n                key: from_json_schema(value, definitions=definitions)\n                for key, value in properties.items()\n            }\n\n        pattern_properties = data.get(\"patternProperties\", None)\n        if pattern_properties is None:\n            pattern_properties_argument: typing.Optional[typing.Dict[str, Field]] = (\n                None\n            )\n        else:\n            pattern_properties_argument = {\n                key: from_json_schema(value, definitions=definitions)\n                for key, value in pattern_properties.items()\n            }\n\n        additional_properties = data.get(\"additionalProperties\", None)\n        if additional_properties is None:\n            additional_properties_argument: typing.Union[None, bool, Field] = (None)\n        elif isinstance(additional_properties, bool):\n            additional_properties_argument = additional_properties\n        else:\n            additional_properties_argument = from_json_schema(\n                additional_properties, definitions=definitions\n            )\n\n        property_names = data.get(\"propertyNames\", None)\n        if property_names is None:\n            property_names_argument: typing.Optional[Field] = None\n        else:\n            property_names_argument = from_json_schema(\n                property_names, definitions=definitions\n            )\n\n        kwargs = {\n            \"allow_null\": allow_null,\n            \"properties\": properties_argument,\n            \"pattern_properties\": pattern_properties_argument,\n            \"additional_properties\": additional_properties_argument,\n            \"property_names\": property_names_argument,\n            \"min_properties\": data.get(\"minProperties\", None),\n            \"max_properties\": data.get(\"maxProperties\", None),\n            \"required\": data.get(\"required\", None),\n            \"default\": data.get(\"default\", NO_DEFAULT),\n        }\n        return Object(**kwargs)\n\n    assert False, f\"Invalid argument type_string={type_string!r}\"", "is_method": false, "function_description": "Function that converts JSON schema type definitions into corresponding typed field objects, supporting constraints and nested schemas, enabling dynamic schema-driven data validation and processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "ref_from_json_schema", "line_number": 334, "body": "def ref_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    reference_string = data[\"$ref\"]\n    assert reference_string.startswith(\"#/\"), \"Unsupported $ref style in document.\"\n    return Reference(to=reference_string, definitions=definitions)", "is_method": false, "function_description": "Function that creates a reference Field from a JSON schema\u2019s $ref string, linking it to schema definitions for resolving referenced schema components."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "enum_from_json_schema", "line_number": 340, "body": "def enum_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    choices = [(item, item) for item in data[\"enum\"]]\n    kwargs = {\"choices\": choices, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return Choice(**kwargs)", "is_method": false, "function_description": "Function that creates a choice-based field from a JSON schema enum definition, enabling validation against predefined enumeration values with optional default selection."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "const_from_json_schema", "line_number": 346, "body": "def const_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    const = data[\"const\"]\n    kwargs = {\"const\": const, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return Const(**kwargs)", "is_method": false, "function_description": "Function that creates a constant constraint Field from a JSON schema snippet, enabling schema-driven validation with fixed value enforcement."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "all_of_from_json_schema", "line_number": 352, "body": "def all_of_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    all_of = [from_json_schema(item, definitions=definitions) for item in data[\"allOf\"]]\n    kwargs = {\"all_of\": all_of, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return AllOf(**kwargs)", "is_method": false, "function_description": "Function that converts a JSON Schema \"allOf\" composite definition into a corresponding Field object by processing each subschema and aggregating them. It enables structured validation of combined schema constraints."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "any_of_from_json_schema", "line_number": 358, "body": "def any_of_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    any_of = [from_json_schema(item, definitions=definitions) for item in data[\"anyOf\"]]\n    kwargs = {\"any_of\": any_of, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return Union(**kwargs)", "is_method": false, "function_description": "Constructs a Union field representing a JSON schema's \"anyOf\" composition, combining multiple schema variations into one adaptable field with an optional default value. Useful for interpreting flexible JSON schema definitions into code."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "one_of_from_json_schema", "line_number": 364, "body": "def one_of_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    one_of = [from_json_schema(item, definitions=definitions) for item in data[\"oneOf\"]]\n    kwargs = {\"one_of\": one_of, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return OneOf(**kwargs)", "is_method": false, "function_description": "Constructs a Field representing a JSON Schema \"oneOf\" composition by converting each schema option into Field objects. Useful for parsing schemas that validate data against multiple alternative schemas."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "not_from_json_schema", "line_number": 370, "body": "def not_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    negated = from_json_schema(data[\"not\"], definitions=definitions)\n    kwargs = {\"negated\": negated, \"default\": data.get(\"default\", NO_DEFAULT)}\n    return Not(**kwargs)", "is_method": false, "function_description": "Function that creates a negated field representation from a JSON schema's \"not\" clause, enabling schema validation logic that excludes specified patterns or types."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "if_then_else_from_json_schema", "line_number": 376, "body": "def if_then_else_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    if_clause = from_json_schema(data[\"if\"], definitions=definitions)\n    then_clause = (\n        from_json_schema(data[\"then\"], definitions=definitions)\n        if \"then\" in data\n        else None\n    )\n    else_clause = (\n        from_json_schema(data[\"else\"], definitions=definitions)\n        if \"else\" in data\n        else None\n    )\n    kwargs = {\n        \"if_clause\": if_clause,\n        \"then_clause\": then_clause,\n        \"else_clause\": else_clause,\n        \"default\": data.get(\"default\", NO_DEFAULT),\n    }\n    return IfThenElse(**kwargs)", "is_method": false, "function_description": "Constructs an IfThenElse field object from a JSON schema by parsing conditional \"if\", \"then\", and \"else\" clauses, enabling dynamic schema validation based on specified conditions."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "to_json_schema", "line_number": 397, "body": "def to_json_schema(\n    arg: typing.Union[Field, typing.Type[Schema]], _definitions: dict = None\n) -> typing.Union[bool, dict]:\n\n    if isinstance(arg, Any):\n        return True\n    elif isinstance(arg, NeverMatch):\n        return False\n\n    data: dict = {}\n    is_root = _definitions is None\n    definitions = {} if _definitions is None else _definitions\n\n    if isinstance(arg, Field):\n        field = arg\n    elif isinstance(arg, SchemaDefinitions):\n        field = None\n        for key, value in arg.items():\n            definitions[key] = to_json_schema(value, _definitions=definitions)\n    else:\n        field = arg.make_validator()\n\n    if isinstance(field, Reference):\n        data[\"$ref\"] = f\"#/definitions/{field.target_string}\"\n        definitions[field.target_string] = to_json_schema(\n            field.target, _definitions=definitions\n        )\n\n    elif isinstance(field, String):\n        data[\"type\"] = [\"string\", \"null\"] if field.allow_null else \"string\"\n        data.update(get_standard_properties(field))\n        if field.min_length is not None or not field.allow_blank:\n            data[\"minLength\"] = field.min_length or 1\n        if field.max_length is not None:\n            data[\"maxLength\"] = field.max_length\n        if field.pattern_regex is not None:\n            if field.pattern_regex.flags != re.RegexFlag.UNICODE:\n                flags = re.RegexFlag(field.pattern_regex.flags)\n                raise ValueError(\n                    f\"Cannot convert regular expression with non-standard flags \"\n                    f\"to JSON schema: {flags!s}\"\n                )\n            data[\"pattern\"] = field.pattern_regex.pattern\n        if field.format is not None:\n            data[\"format\"] = field.format\n\n    elif isinstance(field, (Integer, Float, Decimal)):\n        base_type = \"integer\" if isinstance(field, Integer) else \"number\"\n        data[\"type\"] = [base_type, \"null\"] if field.allow_null else base_type\n        data.update(get_standard_properties(field))\n        if field.minimum is not None:\n            data[\"minimum\"] = field.minimum\n        if field.maximum is not None:\n            data[\"maximum\"] = field.maximum\n        if field.exclusive_minimum is not None:\n            data[\"exclusiveMinimum\"] = field.exclusive_minimum\n        if field.exclusive_maximum is not None:\n            data[\"exclusiveMaximum\"] = field.exclusive_maximum\n        if field.multiple_of is not None:\n            data[\"multipleOf\"] = field.multiple_of\n\n    elif isinstance(field, Boolean):\n        data[\"type\"] = [\"boolean\", \"null\"] if field.allow_null else \"boolean\"\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, Array):\n        data[\"type\"] = [\"array\", \"null\"] if field.allow_null else \"array\"\n        data.update(get_standard_properties(field))\n        if field.min_items is not None:\n            data[\"minItems\"] = field.min_items\n        if field.max_items is not None:\n            data[\"maxItems\"] = field.max_items\n        if field.items is not None:\n            if isinstance(field.items, (list, tuple)):\n                data[\"items\"] = [\n                    to_json_schema(item, _definitions=definitions)\n                    for item in field.items\n                ]\n            else:\n                data[\"items\"] = to_json_schema(field.items, _definitions=definitions)\n        if field.additional_items is not None:\n            if isinstance(field.additional_items, bool):\n                data[\"additionalItems\"] = field.additional_items\n            else:\n                data[\"additionalItems\"] = to_json_schema(\n                    field.additional_items, _definitions=definitions\n                )\n        if field.unique_items is not False:\n            data[\"uniqueItems\"] = True\n\n    elif isinstance(field, Object):\n        data[\"type\"] = [\"object\", \"null\"] if field.allow_null else \"object\"\n        data.update(get_standard_properties(field))\n        if field.properties:\n            data[\"properties\"] = {\n                key: to_json_schema(value, _definitions=definitions)\n                for key, value in field.properties.items()\n            }\n        if field.pattern_properties:\n            data[\"patternProperties\"] = {\n                key: to_json_schema(value, _definitions=definitions)\n                for key, value in field.pattern_properties.items()\n            }\n        if field.additional_properties is not None:\n            if isinstance(field.additional_properties, bool):\n                data[\"additionalProperties\"] = field.additional_properties\n            else:\n                data[\"additionalProperties\"] = to_json_schema(\n                    field.additional_properties, _definitions=definitions\n                )\n        if field.property_names is not None:\n            data[\"propertyNames\"] = to_json_schema(\n                field.property_names, _definitions=definitions\n            )\n        if field.max_properties is not None:\n            data[\"maxProperties\"] = field.max_properties\n        if field.min_properties is not None:\n            data[\"minProperties\"] = field.min_properties\n        if field.required:\n            data[\"required\"] = field.required\n\n    elif isinstance(field, Choice):\n        data[\"enum\"] = [key for key, value in field.choices]\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, Const):\n        data[\"const\"] = field.const\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, Union):\n        data[\"anyOf\"] = [\n            to_json_schema(item, _definitions=definitions) for item in field.any_of\n        ]\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, OneOf):\n        data[\"oneOf\"] = [\n            to_json_schema(item, _definitions=definitions) for item in field.one_of\n        ]\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, AllOf):\n        data[\"allOf\"] = [\n            to_json_schema(item, _definitions=definitions) for item in field.all_of\n        ]\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, IfThenElse):\n        data[\"if\"] = to_json_schema(field.if_clause, _definitions=definitions)\n        if field.then_clause is not None:\n            data[\"then\"] = to_json_schema(field.then_clause, _definitions=definitions)\n        if field.else_clause is not None:\n            data[\"else\"] = to_json_schema(field.else_clause, _definitions=definitions)\n        data.update(get_standard_properties(field))\n\n    elif isinstance(field, Not):\n        data[\"not\"] = to_json_schema(field.negated, _definitions=definitions)\n        data.update(get_standard_properties(field))\n\n    elif field is not None:\n        name = type(field).__qualname__\n        raise ValueError(f\"Cannot convert field type {name!r} to JSON Schema\")\n\n    if is_root and definitions:\n        data[\"definitions\"] = definitions\n    return data", "is_method": false, "function_description": "Function that converts a data validation field or schema into its corresponding JSON Schema representation, supporting complex types, references, and constraints. It enables interoperability by exporting schema definitions usable in JSON-based validation or documentation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/json_schema.py", "function": "get_standard_properties", "line_number": 565, "body": "def get_standard_properties(field: Field) -> dict:\n    data = {}\n    if field.has_default():\n        data[\"default\"] = field.default\n    return data", "is_method": false, "function_description": "Utility function that extracts and returns standard attributes, such as default values, from a given field object."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__eq__", "line_number": 11, "body": "def __eq__(self, other: typing.Any) -> bool:\n        return (\n            isinstance(other, Position)\n            and self.line_no == other.line_no\n            and self.column_no == other.column_no\n            and self.char_index == other.char_index\n        )", "is_method": true, "class_name": "Position", "function_description": "Defines equality comparison for Position instances by checking if all positional attributes (line number, column number, character index) match, enabling precise position equivalence checks in text processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__repr__", "line_number": 19, "body": "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        return f\"{class_name}(line_no={self.line_no}, column_no={self.column_no}, char_index={self.char_index})\"", "is_method": true, "class_name": "Position", "function_description": "Provides a readable string representation of a Position object showing line number, column number, and character index for easier debugging and logging."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__eq__", "line_number": 72, "body": "def __eq__(self, other: typing.Any) -> bool:\n        return isinstance(other, Message) and (\n            self.text == other.text\n            and self.code == other.code\n            and self.index == other.index\n            and self.start_position == other.start_position\n            and self.end_position == other.end_position\n        )", "is_method": true, "class_name": "Message", "function_description": "Overrides equality comparison to determine if two Message instances have identical content and metadata, enabling precise message comparison in processing workflows."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__hash__", "line_number": 81, "body": "def __hash__(self) -> int:\n        ident = (self.code, tuple(self.index))\n        return hash(ident)", "is_method": true, "class_name": "Message", "function_description": "Provides a hash representation of a Message instance based on its code and index, enabling its use in hash-based collections like sets or dictionaries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__repr__", "line_number": 85, "body": "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        index_str = f\", index={self.index!r}\" if self.index else \"\"\n        if self.start_position is None:\n            position_str = \"\"\n        elif self.start_position == self.end_position:\n            position_str = f\", position={self.start_position!r}\"\n        else:\n            position_str = f\", start_position={self.start_position!r}, end_position={self.end_position!r}\"\n        return f\"{class_name}(text={self.text!r}, code={self.code!r}{index_str}{position_str})\"", "is_method": true, "class_name": "Message", "function_description": "Provides a string representation of a Message instance showing its text, code, optional index, and position details for clear and informative debugging or logging output."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "messages", "line_number": 157, "body": "def messages(\n        self, *, add_prefix: typing.Union[str, int] = None\n    ) -> typing.List[Message]:\n        \"\"\"\n        Return a list of all the messages.\n\n        add_prefix - An optional key to add to the index of all returned messages.\n                     Useful in nested objects when validation needs to accumulate\n                     all the child messages for each item in the parent object.\n        \"\"\"\n        if add_prefix is not None:\n            return [\n                Message(\n                    text=message.text,\n                    code=message.code,\n                    index=[add_prefix] + message.index,\n                )\n                for message in self._messages\n            ]\n        return list(self._messages)", "is_method": true, "class_name": "BaseError", "function_description": "Provides a list of all error messages, optionally prefixing their indices to support contextualized aggregation in nested validation scenarios. Useful for collecting and organizing validation feedback across hierarchical data structures."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__iter__", "line_number": 178, "body": "def __iter__(self) -> typing.Iterator:\n        return iter(self._message_dict)", "is_method": true, "class_name": "BaseError", "function_description": "Provides iteration over the BaseError's internal message dictionary, allowing users to traverse stored error messages easily. This facilitates access to the error details maintained within the class instance."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__len__", "line_number": 181, "body": "def __len__(self) -> int:\n        return len(self._message_dict)", "is_method": true, "class_name": "BaseError", "function_description": "Returns the number of entries in the error's message dictionary, providing a way to quantify the error details stored in the BaseError instance."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__getitem__", "line_number": 184, "body": "def __getitem__(self, key: typing.Any) -> typing.Union[str, dict]:\n        return self._message_dict[key]", "is_method": true, "class_name": "BaseError", "function_description": "Allows dictionary-like access to the error's message dictionary, returning the value associated with a given key. This enables convenient retrieval of error details stored within the BaseError instance."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__eq__", "line_number": 187, "body": "def __eq__(self, other: typing.Any) -> bool:\n        return isinstance(other, ValidationError) and self._messages == other._messages", "is_method": true, "class_name": "BaseError", "function_description": "Overrides equality to compare a BaseError instance with a ValidationError by checking if their error message contents match. This allows consistent error comparison based on validation messages."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__hash__", "line_number": 190, "body": "def __hash__(self) -> int:\n        ident = tuple(hash(m) for m in self._messages)\n        return hash(ident)", "is_method": true, "class_name": "BaseError", "function_description": "Provides a hash value for the BaseError instance based on its messages, enabling its use in hash-based collections like sets or dictionaries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__repr__", "line_number": 194, "body": "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        if len(self._messages) == 1 and not self._messages[0].index:\n            message = self._messages[0]\n            return f\"{class_name}(text={message.text!r}, code={message.code!r})\"\n        return f\"{class_name}({self._messages!r})\"", "is_method": true, "class_name": "BaseError", "function_description": "Provides a string representation of the BaseError instance, summarizing its messages for clearer debugging and logging. This aids in quickly understanding error details during development or error handling."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__str__", "line_number": 201, "body": "def __str__(self) -> str:\n        if len(self._messages) == 1 and not self._messages[0].index:\n            return self._messages[0].text\n        return str(dict(self))", "is_method": true, "class_name": "BaseError", "function_description": "Provides a string representation of the BaseError instance, summarizing its messages. It returns a simple message if only one is present without an index, otherwise it returns all messages as a dictionary."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__iter__", "line_number": 243, "body": "def __iter__(self) -> typing.Iterator:\n        yield self.value\n        yield self.error", "is_method": true, "class_name": "ValidationResult", "function_description": "Allows unpacking or iteration over ValidationResult to access its value and error attributes sequentially, facilitating easy extraction of validation outcomes."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__bool__", "line_number": 247, "body": "def __bool__(self) -> bool:\n        return self.error is None", "is_method": true, "class_name": "ValidationResult", "function_description": "Returns True if the ValidationResult instance has no errors, indicating successful validation; otherwise, returns False. This allows easy boolean checks of validation status."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/base.py", "function": "__repr__", "line_number": 250, "body": "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        if self.error is not None:\n            return f\"{class_name}(error={self.error!r})\"\n        return f\"{class_name}(value={self.value!r})\"", "is_method": true, "class_name": "ValidationResult", "function_description": "Provides a string representation of the ValidationResult instance, displaying either its error or validated value for clear debugging and logging."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "validation_error", "line_number": 30, "body": "def validation_error(self, code: str) -> ValidationError:\n        text = self.errors[code].format(**self.__dict__)\n        return ValidationError(text=text, code=code)", "is_method": true, "class_name": "BaseFormat", "function_description": "Creates a ValidationError instance with a formatted error message based on a given error code and the current object's attributes. It standardizes error reporting within the BaseFormat class."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "is_native_type", "line_number": 50, "body": "def is_native_type(self, value: typing.Any) -> bool:\n        return isinstance(value, datetime.date)", "is_method": true, "class_name": "DateFormat", "function_description": "Checks if a given value is a native date type. This method helps identify whether an object represents a date within the DateFormat class context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "validate", "line_number": 53, "body": "def validate(self, value: typing.Any) -> datetime.date:\n        match = DATE_REGEX.match(value)\n        if not match:\n            raise self.validation_error(\"format\")\n\n        kwargs = {k: int(v) for k, v in match.groupdict().items()}\n        try:\n            return datetime.date(**kwargs)\n        except ValueError:\n            raise self.validation_error(\"invalid\")", "is_method": true, "class_name": "DateFormat", "function_description": "Provides validation for date strings by checking their format and converting them into datetime.date objects, raising errors for incorrect or invalid date values. This function ensures input dates conform to expected patterns for reliable date handling."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "serialize", "line_number": 64, "body": "def serialize(self, obj: typing.Any) -> typing.Union[str, None]:\n        if obj is None:\n            return None\n\n        assert isinstance(obj, datetime.date)\n\n        return obj.isoformat()", "is_method": true, "class_name": "DateFormat", "function_description": "Converts a date object into its ISO 8601 string representation or returns None if the input is None. This facilitates standardized date formatting for serialization tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "is_native_type", "line_number": 79, "body": "def is_native_type(self, value: typing.Any) -> bool:\n        return isinstance(value, datetime.time)", "is_method": true, "class_name": "TimeFormat", "function_description": "Utility method of the TimeFormat class that checks whether a given value is a native datetime.time object, enabling type validation in time-related processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "validate", "line_number": 82, "body": "def validate(self, value: typing.Any) -> datetime.time:\n        match = TIME_REGEX.match(value)\n        if not match:\n            raise self.validation_error(\"format\")\n\n        groups = match.groupdict()\n        if groups[\"microsecond\"]:\n            groups[\"microsecond\"] = groups[\"microsecond\"].ljust(6, \"0\")\n\n        kwargs = {k: int(v) for k, v in groups.items() if v is not None}\n        try:\n            return datetime.time(tzinfo=None, **kwargs)\n        except ValueError:\n            raise self.validation_error(\"invalid\")", "is_method": true, "class_name": "TimeFormat", "function_description": "Method of the TimeFormat class that validates and converts a string into a datetime.time object, ensuring correct time formatting and raising errors for invalid inputs. It supports precise time parsing including microseconds."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "serialize", "line_number": 97, "body": "def serialize(self, obj: typing.Any) -> typing.Union[str, None]:\n        if obj is None:\n            return None\n\n        assert isinstance(obj, datetime.time)\n\n        return obj.isoformat()", "is_method": true, "class_name": "TimeFormat", "function_description": "Utility method of the TimeFormat class that converts a datetime.time object into its ISO 8601 string representation, or returns None if the input is None."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "is_native_type", "line_number": 112, "body": "def is_native_type(self, value: typing.Any) -> bool:\n        return isinstance(value, datetime.datetime)", "is_method": true, "class_name": "DateTimeFormat", "function_description": "Determines if a given value is a native datetime object. This method helps identify whether a value is inherently of datetime type within the DateTimeFormat class context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "validate", "line_number": 115, "body": "def validate(self, value: typing.Any) -> datetime.datetime:\n        match = DATETIME_REGEX.match(value)\n        if not match:\n            raise self.validation_error(\"format\")\n\n        groups = match.groupdict()\n        if groups[\"microsecond\"]:\n            groups[\"microsecond\"] = groups[\"microsecond\"].ljust(6, \"0\")\n\n        tzinfo_str = groups.pop(\"tzinfo\")\n        if tzinfo_str == \"Z\":\n            tzinfo = datetime.timezone.utc\n        elif tzinfo_str is not None:\n            offset_mins = int(tzinfo_str[-2:]) if len(tzinfo_str) > 3 else 0\n            offset_hours = int(tzinfo_str[1:3])\n            delta = datetime.timedelta(hours=offset_hours, minutes=offset_mins)\n            if tzinfo_str[0] == \"-\":\n                delta = -delta\n            tzinfo = datetime.timezone(delta)\n        else:\n            tzinfo = None\n\n        kwargs = {k: int(v) for k, v in groups.items() if v is not None}\n        try:\n            return datetime.datetime(**kwargs, tzinfo=tzinfo)  # type: ignore\n        except ValueError:\n            raise self.validation_error(\"invalid\")", "is_method": true, "class_name": "DateTimeFormat", "function_description": "Validates and converts a string into a timezone-aware datetime object if it matches the expected format, raising an error for invalid formats or values. Useful for ensuring datetime strings conform to a specific pattern before processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "serialize", "line_number": 143, "body": "def serialize(self, obj: typing.Any) -> typing.Union[str, None]:\n        if obj is None:\n            return None\n\n        assert isinstance(obj, datetime.datetime)\n\n        value = obj.isoformat()\n\n        if value.endswith(\"+00:00\"):\n            value = value[:-6] + \"Z\"\n\n        return value", "is_method": true, "class_name": "DateTimeFormat", "function_description": "Utility method of the DateTimeFormat class that converts datetime objects into ISO 8601 string representations, formatting UTC offsets as 'Z' for standardized serialization. It returns None for null inputs."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "is_native_type", "line_number": 160, "body": "def is_native_type(self, value: typing.Any) -> bool:\n        return isinstance(value, uuid.UUID)", "is_method": true, "class_name": "UUIDFormat", "function_description": "Utility method of the UUIDFormat class that checks if a given value is a native UUID type. It helps validate whether a value is an instance of UUID."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "validate", "line_number": 163, "body": "def validate(self, value: typing.Any) -> uuid.UUID:\n        match = UUID_REGEX.match(value)\n        if not match:\n            raise self.validation_error(\"format\")\n\n        return uuid.UUID(value)", "is_method": true, "class_name": "UUIDFormat", "function_description": "Utility method of the UUIDFormat class that verifies if a value matches the UUID format and converts it to a UUID object, raising an error for invalid formats. It ensures input values are valid UUIDs for further processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/formats.py", "function": "serialize", "line_number": 170, "body": "def serialize(self, obj: typing.Any) -> str:\n        return str(obj)", "is_method": true, "class_name": "UUIDFormat", "function_description": "Utility method in UUIDFormat that converts any given object to its string representation, facilitating standardized serialization of UUID-related data."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/positional_validation.py", "function": "validate_with_positions", "line_number": 9, "body": "def validate_with_positions(\n    *, token: Token, validator: typing.Union[Field, typing.Type[Schema]]\n) -> typing.Any:\n    try:\n        return validator.validate(token.value)\n    except ValidationError as error:\n        messages = []\n        for message in error.messages():\n            if message.code == \"required\":\n                field = message.index[-1]\n                token = token.lookup(message.index[:-1])\n                text = f\"The field {field!r} is required.\"\n            else:\n                token = token.lookup(message.index)\n                text = message.text\n\n            positional_message = Message(\n                text=text,\n                code=message.code,\n                index=message.index,\n                start_position=token.start,\n                end_position=token.end,\n            )\n            messages.append(positional_message)\n        messages = sorted(\n            messages, key=lambda m: m.start_position.char_index  # type: ignore\n        )\n        raise ValidationError(messages=messages)", "is_method": false, "function_description": "This function validates a token's value against a schema or field validator and provides detailed validation error messages including precise token position information for accurate error reporting. It aids in contextual error handling during data validation processes."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "_get_position", "line_number": 17, "body": "def _get_position(content: str, index: int) -> Position:\n    return Position(\n        line_no=content.count(\"\\n\", 0, index) + 1,\n        column_no=index - content.rfind(\"\\n\", 0, index),\n        char_index=index,\n    )", "is_method": false, "function_description": "Utility function that calculates the line number, column number, and character index of a given position in text content, facilitating precise location tracking within strings."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "tokenize_yaml", "line_number": 25, "body": "def tokenize_yaml(content: typing.Union[str, bytes]) -> Token:\n    assert yaml is not None, \"'pyyaml' must be installed.\"\n\n    if isinstance(content, bytes):\n        str_content = content.decode(\"utf-8\", \"ignore\")\n    else:\n        str_content = content\n\n    if not str_content.strip():\n        # Handle the empty string case explicitly for clear error messaging.\n        position = Position(column_no=1, line_no=1, char_index=0)\n        raise ParseError(text=\"No content.\", code=\"no_content\", position=position)\n\n    class CustomSafeLoader(SafeLoader):\n        pass\n\n    def construct_mapping(loader: \"yaml.Loader\", node: \"yaml.Node\") -> DictToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        mapping = loader.construct_mapping(node)\n        return DictToken(mapping, start, end - 1, content=str_content)\n\n    def construct_sequence(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ListToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_sequence(node)\n        return ListToken(value, start, end - 1, content=str_content)\n\n    def construct_scalar(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_scalar(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_int(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_int(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_float(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_float(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_bool(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_bool(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_null(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_null(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, construct_mapping\n    )\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_SEQUENCE_TAG, construct_sequence\n    )\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_SCALAR_TAG, construct_scalar\n    )\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:int\", construct_int)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:float\", construct_float)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:bool\", construct_bool)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:null\", construct_null)\n\n    try:\n        return yaml.load(str_content, CustomSafeLoader)\n    except (yaml.scanner.ScannerError, yaml.parser.ParserError) as exc:  # type: ignore\n        # Handle cases that result in a YAML parse error.\n        text = exc.problem + \".\"\n        position = _get_position(str_content, index=exc.problem_mark.index)\n        raise ParseError(text=text, code=\"parse_error\", position=position)", "is_method": false, "function_description": "Function that parses YAML content into a structured token hierarchy capturing detailed position and type information, facilitating precise YAML analysis and error handling in downstream applications."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "validate_yaml", "line_number": 112, "body": "def validate_yaml(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a YAML string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A YAML string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n    assert yaml is not None, \"'pyyaml' must be installed.\"\n\n    token = tokenize_yaml(content)\n    return validate_with_positions(token=token, validator=validator)", "is_method": false, "function_description": "Function that parses and validates YAML content against a specified schema or field, returning the parsed value along with detailed error messages indicating exact positions of validation issues. It supports precise error reporting for YAML parsing and validation failures."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_mapping", "line_number": 41, "body": "def construct_mapping(loader: \"yaml.Loader\", node: \"yaml.Node\") -> DictToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        mapping = loader.construct_mapping(node)\n        return DictToken(mapping, start, end - 1, content=str_content)", "is_method": false, "function_description": "Constructs a mapping dictionary from a YAML node, wrapping it with position metadata for precise content tracking during YAML parsing or processing."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_sequence", "line_number": 47, "body": "def construct_sequence(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ListToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_sequence(node)\n        return ListToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "This function constructs a sequence from a YAML node while capturing its start and end positions, returning a custom token that includes the sequence content and positional metadata for downstream processing or analysis."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_scalar", "line_number": 53, "body": "def construct_scalar(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_scalar(node)\n        return ScalarToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "Utility function that constructs a scalar token from a YAML node, capturing its value along with start and end positions for accurate parsing or tokenization tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_int", "line_number": 59, "body": "def construct_int(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_int(node)\n        return ScalarToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "Constructs a scalar token representing an integer from a YAML node, capturing its value and position within the source content. Useful for parsing and tokenizing YAML integer values with positional metadata."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_float", "line_number": 65, "body": "def construct_float(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_float(node)\n        return ScalarToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "Function that constructs a floating-point scalar token from YAML node data, capturing its value and position details. It supports YAML parsing by converting nodes into typed float tokens with location metadata."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_bool", "line_number": 71, "body": "def construct_bool(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_bool(node)\n        return ScalarToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "Function constructs a boolean scalar token from a YAML node, capturing its value and position in the source content for parsing or processing tasks. It supports precise handling of boolean data during YAML loading."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_yaml.py", "function": "construct_null", "line_number": 77, "body": "def construct_null(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_null(node)\n        return ScalarToken(value, start, end - 1, content=str_content)", "is_method": false, "function_description": "Creates a ScalarToken representing a YAML null value from a node, capturing its position in the source content. This function supports YAML parsing by converting null nodes into token objects with location metadata."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "_TokenizingJSONObject", "line_number": 20, "body": "def _TokenizingJSONObject(\n    s_and_end: typing.Tuple[str, int],\n    strict: bool,\n    scan_once: typing.Callable[[str, int], typing.Tuple[Token, int]],\n    memo: dict,\n    content: str,\n    _w: typing.Callable = WHITESPACE.match,\n    _ws: str = WHITESPACE_STR,\n) -> typing.Tuple[dict, int]:\n    s, end = s_and_end\n    pairs: typing.List[typing.Tuple[Token, Token]] = []\n    pairs_append = pairs.append\n    memo_get = memo.setdefault\n    # Use a slice to prevent IndexError from being raised, the following\n    # check will raise a more specific ValueError if the string is empty\n    nextchar = s[end : end + 1]\n    # Normally we expect nextchar == '\"'\n    if nextchar != '\"':\n        if nextchar in _ws:\n            end = _w(s, end).end()\n            nextchar = s[end : end + 1]\n        # Trivial empty object\n        if nextchar == \"}\":\n            return {}, end + 1\n        elif nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end\n            )\n    end += 1\n    while True:\n        start = end - 1\n        key, end = scanstring(s, end, strict)\n        key = memo_get(key, key)\n        key = ScalarToken(memo_get(key, key), start, end - 1, content)\n        # To skip some function call overhead we optimize the fast paths where\n        # the JSON key separator is \": \" or just \":\".\n        if s[end : end + 1] != \":\":\n            end = _w(s, end).end()\n            if s[end : end + 1] != \":\":\n                raise JSONDecodeError(\"Expecting ':' delimiter\", s, end)\n        end += 1\n\n        try:\n            if s[end] in _ws:\n                end += 1\n                if s[end] in _ws:\n                    end = _w(s, end + 1).end()\n        except IndexError:\n            pass\n\n        try:\n            value, end = scan_once(s, end)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        pairs_append((key, value))\n        try:\n            nextchar = s[end]\n            if nextchar in _ws:\n                end = _w(s, end + 1).end()\n                nextchar = s[end]\n        except IndexError:\n            nextchar = \"\"\n        end += 1\n\n        if nextchar == \"}\":\n            break\n        elif nextchar != \",\":\n            raise JSONDecodeError(\"Expecting ',' delimiter\", s, end - 1)\n        end = _w(s, end).end()\n        nextchar = s[end : end + 1]\n        end += 1\n        if nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end - 1\n            )\n    return dict(pairs), end", "is_method": false, "function_description": "Core JSON parsing utility that tokenizes a JSON object from a string, producing a dictionary of key-value tokens and tracking parsing progress for use in a JSON decoding process with strict format enforcement."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "_make_scanner", "line_number": 98, "body": "def _make_scanner(\n    context: typing.Any, content: str\n) -> typing.Callable[[str, int], typing.Tuple[Token, int]]:\n    parse_object = _TokenizingJSONObject\n    parse_array = context.parse_array\n    parse_string = context.parse_string\n    match_number = NUMBER_RE.match\n    strict = context.strict\n    parse_float = context.parse_float\n    parse_int = context.parse_int\n    memo = context.memo\n\n    def _scan_once(string: str, idx: int) -> typing.Tuple[Token, int]:\n        try:\n            nextchar = string[idx]\n        except IndexError:\n            raise StopIteration(idx) from None\n\n        if nextchar == '\"':\n            value, end = parse_string(string, idx + 1, strict)\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"{\":\n            value, end = parse_object(\n                (string, idx + 1), strict, _scan_once, memo, content\n            )\n            return DictToken(value, idx, end - 1, content), end\n        elif nextchar == \"[\":\n            value, end = parse_array((string, idx + 1), _scan_once)\n            return ListToken(value, idx, end - 1, content), end\n        elif nextchar == \"n\" and string[idx : idx + 4] == \"null\":\n            value, end = None, idx + 4\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"t\" and string[idx : idx + 4] == \"true\":\n            value, end = True, idx + 4\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"f\" and string[idx : idx + 5] == \"false\":\n            value, end = False, idx + 5\n            return ScalarToken(value, idx, end - 1, content), end\n\n        m = match_number(string, idx)\n        if m is not None:\n            integer, frac, exp = m.groups()\n            if frac or exp:\n                res = parse_float(integer + (frac or \"\") + (exp or \"\"))\n            else:\n                res = parse_int(integer)\n            value, end = res, m.end()\n            return ScalarToken(value, idx, end - 1, content), end\n        else:  # pragma: no cover\n            raise StopIteration(idx)\n\n    def scan_once(string: str, idx: int) -> typing.Tuple[Token, int]:\n        try:\n            return _scan_once(string, idx)\n        finally:\n            memo.clear()\n\n    return scan_once", "is_method": false, "function_description": "Internal helper function that creates a scanner callable to tokenize JSON content from a string, supporting different JSON types and enabling incremental parsing within a given parsing context."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "tokenize_json", "line_number": 165, "body": "def tokenize_json(content: typing.Union[str, bytes]) -> Token:\n    if isinstance(content, bytes):\n        content = content.decode(\"utf-8\", \"ignore\")\n\n    if not content.strip():\n        # Handle the empty string case explicitly for clear error messaging.\n        position = Position(column_no=1, line_no=1, char_index=0)\n        raise ParseError(text=\"No content.\", code=\"no_content\", position=position)\n\n    decoder = _TokenizingDecoder(content=content)\n    try:\n        return decoder.decode(content)\n    except JSONDecodeError as exc:\n        # Handle cases that result in a JSON parse error.\n        position = Position(column_no=exc.colno, line_no=exc.lineno, char_index=exc.pos)\n        raise ParseError(text=exc.msg + \".\", code=\"parse_error\", position=position)", "is_method": false, "function_description": "Function that parses a JSON string or bytes input into a tokenized representation, raising detailed errors for empty or invalid JSON content. It provides a structured way to tokenize JSON for downstream processing or validation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "validate_json", "line_number": 183, "body": "def validate_json(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a JSON string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A JSON string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n    token = tokenize_json(content)\n    return validate_with_positions(token=token, validator=validator)", "is_method": false, "function_description": "Function that parses and validates a JSON string or bytes using the specified schema or field, returning the validated value along with detailed error messages indicating exact failure positions."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "_scan_once", "line_number": 110, "body": "def _scan_once(string: str, idx: int) -> typing.Tuple[Token, int]:\n        try:\n            nextchar = string[idx]\n        except IndexError:\n            raise StopIteration(idx) from None\n\n        if nextchar == '\"':\n            value, end = parse_string(string, idx + 1, strict)\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"{\":\n            value, end = parse_object(\n                (string, idx + 1), strict, _scan_once, memo, content\n            )\n            return DictToken(value, idx, end - 1, content), end\n        elif nextchar == \"[\":\n            value, end = parse_array((string, idx + 1), _scan_once)\n            return ListToken(value, idx, end - 1, content), end\n        elif nextchar == \"n\" and string[idx : idx + 4] == \"null\":\n            value, end = None, idx + 4\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"t\" and string[idx : idx + 4] == \"true\":\n            value, end = True, idx + 4\n            return ScalarToken(value, idx, end - 1, content), end\n        elif nextchar == \"f\" and string[idx : idx + 5] == \"false\":\n            value, end = False, idx + 5\n            return ScalarToken(value, idx, end - 1, content), end\n\n        m = match_number(string, idx)\n        if m is not None:\n            integer, frac, exp = m.groups()\n            if frac or exp:\n                res = parse_float(integer + (frac or \"\") + (exp or \"\"))\n            else:\n                res = parse_int(integer)\n            value, end = res, m.end()\n            return ScalarToken(value, idx, end - 1, content), end\n        else:  # pragma: no cover\n            raise StopIteration(idx)", "is_method": false, "function_description": "Internal helper function that parses a single JSON token from a string starting at a given index, identifying and returning the token type and its position for use in JSON parsing operations."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokenize_json.py", "function": "scan_once", "line_number": 149, "body": "def scan_once(string: str, idx: int) -> typing.Tuple[Token, int]:\n        try:\n            return _scan_once(string, idx)\n        finally:\n            memo.clear()", "is_method": false, "function_description": "Utility function that scans a string from a given index to produce a token and update the index, ensuring memoization is cleared after each scan to maintain stateless behavior."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "string", "line_number": 25, "body": "def string(self) -> str:\n        return self._content[self._start_index : self._end_index + 1]", "is_method": true, "class_name": "Token", "function_description": "Returns the substring of the original content represented by this Token instance. This method provides the exact text span that the token covers within the source content."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "value", "line_number": 29, "body": "def value(self) -> typing.Any:\n        return self._get_value()", "is_method": true, "class_name": "Token", "function_description": "Returns the underlying value of the token, providing access to its stored content or data."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "start", "line_number": 33, "body": "def start(self) -> Position:\n        return self._get_position(self._start_index)", "is_method": true, "class_name": "Token", "function_description": "Returns the starting position of the token within the source text, providing a reference point useful for syntax highlighting, error reporting, or parsing tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "end", "line_number": 37, "body": "def end(self) -> Position:\n        return self._get_position(self._end_index)", "is_method": true, "class_name": "Token", "function_description": "Utility method of the Token class that returns the ending position of the token in the source text. It provides precise token boundary information for text processing tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "lookup", "line_number": 40, "body": "def lookup(self, index: list) -> \"Token\":\n        \"\"\"\n        Given an index, lookup a child token within this structure.\n        \"\"\"\n        token = self\n        for key in index:\n            token = token._get_child_token(key)\n        return token", "is_method": true, "class_name": "Token", "function_description": "Utility method of the Token class that traverses nested child tokens based on a given index list, returning the token located at the specified path for hierarchical token retrieval."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "lookup_key", "line_number": 49, "body": "def lookup_key(self, index: list) -> \"Token\":\n        \"\"\"\n        Given an index, lookup a token for a dictionary key within this structure.\n        \"\"\"\n        token = self.lookup(index[:-1])\n        return token._get_key_token(index[-1])", "is_method": true, "class_name": "Token", "function_description": "Utility method of the Token class that retrieves a token corresponding to a dictionary key specified by an index path, enabling hierarchical token access within nested structures."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_position", "line_number": 56, "body": "def _get_position(self, index: int) -> Position:\n        content = self._content[: index + 1]\n        lines = content.splitlines()\n        line_no = max(len(lines), 1)\n        column_no = 1 if not lines else max(len(lines[-1]), 1)\n        return Position(line_no, column_no, index)", "is_method": true, "class_name": "Token", "function_description": "Returns the line and column position corresponding to a specified character index within the token's content, facilitating precise location tracking in text processing tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "__repr__", "line_number": 63, "body": "def __repr__(self) -> str:\n        return \"%s(%s)\" % (self.__class__.__name__, repr(self.string))", "is_method": true, "class_name": "Token", "function_description": "Returns a string representation of the Token instance showing the class name and the token\u2019s text, useful for debugging and logging."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "__eq__", "line_number": 66, "body": "def __eq__(self, other: typing.Any) -> bool:\n        return isinstance(other, Token) and (\n            self._get_value() == other._get_value()\n            and self._start_index == other._start_index\n            and self._end_index == other._end_index\n        )", "is_method": true, "class_name": "Token", "function_description": "Provides equality comparison between Token instances based on their value and position, enabling accurate identification of identical tokens within text processing tasks."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "__hash__", "line_number": 75, "body": "def __hash__(self) -> typing.Any:\n        return hash(self._value)", "is_method": true, "class_name": "ScalarToken", "function_description": "Provides a hash representation of the ScalarToken instance based on its internal value, enabling its use in hash-based collections like sets or dictionaries."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_value", "line_number": 78, "body": "def _get_value(self) -> typing.Any:\n        return self._value", "is_method": true, "class_name": "ScalarToken", "function_description": "Core utility method of the ScalarToken class that provides access to the stored scalar value. It enables retrieval of the token's underlying data for further processing or evaluation."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_value", "line_number": 88, "body": "def _get_value(self) -> typing.Any:\n        return {\n            key_token._get_value(): value_token._get_value()\n            for key_token, value_token in self._value.items()\n        }", "is_method": true, "class_name": "DictToken", "function_description": "Private method of the DictToken class that recursively extracts and returns the underlying dictionary by resolving values of its key and value tokens. It enables access to the actual data represented by the tokenized dictionary."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_child_token", "line_number": 94, "body": "def _get_child_token(self, key: typing.Any) -> Token:\n        return self._child_tokens[key]", "is_method": true, "class_name": "DictToken", "function_description": "Retrieves a specific child token associated with the given key from the DictToken\u2019s internal collection. This allows access to nested tokens within a dictionary-like token structure."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_key_token", "line_number": 97, "body": "def _get_key_token(self, key: typing.Any) -> Token:\n        return self._child_keys[key]", "is_method": true, "class_name": "DictToken", "function_description": "Returns the token associated with a given key from the internal child keys of the DictToken instance. This function provides direct access to the token representation of dictionary keys."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_value", "line_number": 102, "body": "def _get_value(self) -> typing.Any:\n        return [token._get_value() for token in self._value]", "is_method": true, "class_name": "ListToken", "function_description": "Returns a list of underlying values by recursively extracting values from contained tokens, supporting access to the raw data represented by the ListToken."}, {"file": "./dataset/RepoExec/test-apps/typesystem/typesystem/tokenize/tokens.py", "function": "_get_child_token", "line_number": 105, "body": "def _get_child_token(self, key: typing.Any) -> Token:\n        return self._value[key]", "is_method": true, "class_name": "ListToken", "function_description": "Utility method of ListToken that retrieves a child token by key from the internal token list, facilitating access to individual tokens within a composite token structure."}, {"file": "./dataset/RepoExec/test-apps/typesystem/examples/form/app.py", "function": "__str__", "line_number": 28, "body": "def __str__(self):\n        breakfast = (\n            \"(with breakfast)\" if self.include_breakfast else \"(without breakfast)\"\n        )\n        return f\"Booking for {self.room} from {self.start_date} to {self.end_date}\"", "is_method": true, "class_name": "BookingSchema", "function_description": "Provides a readable string representation of a booking, summarizing room details and reservation dates, including breakfast inclusion status. Useful for displaying booking information in user interfaces or logs."}]