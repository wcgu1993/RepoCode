[{"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pretty.py", "function": "pf", "line_number": 27, "body": "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)", "is_method": false, "function_description": "Utility function that pretty-prints data with syntax coloring, enhancing readability in iPython environments by formatting and highlighting code or objects."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pretty.py", "function": "pp", "line_number": 43, "body": "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()", "is_method": false, "function_description": "Function that pretty-prints Python objects with syntax highlighting, supporting output to various destinations for improved readability in interactive environments."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/debug.py", "function": "interact", "line_number": 5, "body": "def interact(banner='(debug shell)'):\n    # Get our current frame\n    curr_frame = inspect.currentframe()\n\n    try:\n        # Get previous frame (caller)\n        calling_frame = curr_frame.f_back\n\n        # Create merged dict of globals() with locals() from previous frame\n        calling_vars = calling_frame.f_globals.copy()\n        calling_vars.update(calling_frame.f_locals)\n\n        # Enter interactive console\n        code.interact(local=calling_vars, banner=banner)\n    finally:\n        del curr_frame", "is_method": false, "function_description": "Function that opens an interactive Python shell using the caller\u2019s local and global variables, allowing on-the-fly debugging or exploration within the caller\u2019s context."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "get_tree_node", "line_number": 6, "body": "def get_tree_node(mapping, key, default=_sentinel, parent=False):\n    \"\"\"\n    Fetch arbitrary node from a tree-like mapping structure with traversal help:\n    Dimension can be specified via ':'\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to lookup, allowing for : notation\n        default object: Default value. If set to `:module:_sentinel`, raise KeyError if not found.\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Value at specified key\n    \"\"\"\n    key = key.split(':')\n    if parent:\n        key = key[:-1]\n\n    # TODO Unlist my shit. Stop calling me please.\n\n    node = mapping\n    for node in key.split(':'):\n        try:\n            node = node[node]\n        except KeyError as exc:\n            node = default\n            break\n\n    if node is _sentinel:\n        raise exc\n    return node", "is_method": false, "function_description": "Function that retrieves a nested node or its parent from a tree-structured mapping using colon-separated keys, with optional default value support for missing entries. It simplifies accessing deep hierarchical data in nested mappings."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "set_tree_node", "line_number": 39, "body": "def set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node", "is_method": false, "function_description": "Utility function that sets a value at a specified node in a hierarchical mapping using colon-delimited keys, facilitating easy updates within nested tree-like data structures."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "tree", "line_number": 59, "body": "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "is_method": false, "function_description": "Function that provides a self-referential nested defaultdict, enabling easy creation of arbitrarily deep tree-like data structures without explicit initialization."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "_namespace_key", "line_number": 80, "body": "def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key", "is_method": true, "class_name": "Tree", "function_description": "Internal method of the Tree class that prefixes a given key with a namespace if provided, enabling organized and hierarchical key management within different namespaces."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "__setitem__", "line_number": 87, "body": "def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)", "is_method": true, "class_name": "Tree", "function_description": "This method sets a value in the tree at a specified key, optionally within a namespace, enabling hierarchical or scoped assignment of tree nodes. It provides a dictionary-like interface for updating tree data structures."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "__getitem__", "line_number": 91, "body": "def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)", "is_method": true, "class_name": "Tree", "function_description": "Core method of the Tree class that retrieves a node by key, optionally within a namespace, returning a default value if the key is not found. It provides convenient indexed access to tree elements."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "accumulate", "line_number": 7, "body": "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "is_method": false, "function_description": "Function that generates running accumulated results from an iterable using a specified binary function (addition by default), useful for progressive calculations like running sums or products."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "consume", "line_number": 32, "body": "def consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)", "is_method": false, "function_description": "Function that efficiently advances an iterator by a specified number of steps or exhausts it completely, optimizing iteration speed especially in CPython environments."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "dedupe_iter", "line_number": 45, "body": "def dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item", "is_method": false, "function_description": "Function that iteratively removes duplicate items from an input iterator by tracking seen elements with hashes, yielding only unique items in the original order. Useful for filtering duplicates from any iterable data source."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "dedupe", "line_number": 65, "body": "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)", "is_method": false, "function_description": "Utility function that wraps another iterable-returning function to automatically remove duplicate items from its output during iteration, ensuring unique elements are yielded without altering the original function."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/files.py", "function": "islurp", "line_number": 12, "body": "def islurp(filename, mode='r', iter_by=LINEMODE, allow_stdin=True, expanduser=True, expandvars=True):\n    \"\"\"\n    Read [expanded] `filename` and yield each (line | chunk).\n\n    :param str filename: File path\n    :param str mode: Use this mode to open `filename`, ala `r` for text (default), `rb` for binary, etc.\n    :param int iter_by: Iterate by this many bytes at a time. Default is by line.\n    :param bool allow_stdin: If Truthy and filename is `-`, read from `sys.stdin`.\n    :param bool expanduser: If Truthy, expand `~` in `filename`\n    :param bool expandvars: If Truthy, expand env vars in `filename`\n    \"\"\"\n    if iter_by == 'LINEMODE':\n        iter_by = LINEMODE\n\n    fh = None\n    try:\n        if filename == '-' and allow_stdin:\n            fh = sys.stdin\n        else:\n            if expanduser:\n                filename = os.path.expanduser(filename)\n            if expandvars:\n                filename = os.path.expandvars(filename)\n\n            fh = open(filename, mode)\n            fh_next = fh.readline if iter_by == LINEMODE else functools.partial(fh.read, iter_by)\n\n        while True:\n            buf = fh_next()\n            if buf == '':  # EOF\n                break\n            yield buf\n    finally:\n        if fh and fh != sys.stdin:\n            fh.close()", "is_method": false, "function_description": "Utility function that reads a given file or standard input and yields its content incrementally by lines or fixed-size chunks, with support for path expansions and customizable reading mode."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/files.py", "function": "burp", "line_number": 55, "body": "def burp(filename, contents, mode='w', allow_stdout=True, expanduser=True, expandvars=True):\n    \"\"\"\n    Write `contents` to `filename`.\n    \"\"\"\n    if filename == '-' and allow_stdout:\n        sys.stdout.write(contents)\n    else:\n        if expanduser:\n            filename = os.path.expanduser(filename)\n        if expandvars:\n            filename = os.path.expandvars(filename)\n\n        with open(filename, mode) as fh:\n            fh.write(contents)", "is_method": false, "function_description": "Function that writes given contents to a specified file, optionally expanding environment variables and user home shortcuts, or outputs to standard output if filename is '-'. Useful for flexible file writing and command-line output handling."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pythree.py", "function": "ensure_encoded_bytes", "line_number": 4, "body": "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)", "is_method": false, "function_description": "Utility function that ensures an input is returned as a bytes-like object, encoding strings to bytes if necessary, facilitating consistent byte-level data handling across functions."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pythree.py", "function": "ensure_decoded_text", "line_number": 19, "body": "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s", "is_method": false, "function_description": "Function that ensures input is in decoded string form, decoding byte-like inputs to text based on specified encoding, while passing through already decoded strings unchanged. Useful for safely handling mixed string and byte data inputs."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/meth.py", "function": "bind", "line_number": 1, "body": "def bind(instance, func, as_name):\n    \"\"\"\n    Turn a function to a bound method on an instance\n\n    >>> class Foo(object):\n    ...     def __init__(self, x, y):\n    ...         self.x = x\n    ...         self.y = y\n    >>> foo = Foo(2, 3)\n    >>> my_unbound_method = lambda self: self.x * self.y\n    >>> bind(foo, my_unbound_method, 'multiply')\n    >>> foo.multiply()  # noinspection PyUnresolvedReferences\n    6\n\n    :param object instance: some object\n    :param callable func: unbound method (i.e. a function that takes `self` argument, that you now\n        want to be bound to this class as a method)\n    :param str as_name: name of the method to create on the object\n    \"\"\"\n    setattr(instance, as_name, func.__get__(instance, instance.__class__))", "is_method": false, "function_description": "Utility function that dynamically attaches a standalone function as a bound method to a specific object instance, enabling the instance to call that function as if it were its own method. Useful for adding behavior to objects at runtime."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__attrs_post_init__", "line_number": 29, "body": "def __attrs_post_init__(self):\n        if self._initial:\n            self.update(self._initial)\n            delattr(self, '_initial')", "is_method": true, "class_name": "MetaSet", "function_description": "Post-initialization method of MetaSet that applies initial data updates once on object creation, then removes the initialization attribute to prevent re-application."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__contains__", "line_number": 34, "body": "def __contains__(self, item):\n        return item in self._store", "is_method": true, "class_name": "MetaSet", "function_description": "Checks if an item exists within the MetaSet's internal storage, enabling membership testing for efficient containment queries."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__iter__", "line_number": 37, "body": "def __iter__(self):\n        return iter(self._store)", "is_method": true, "class_name": "MetaSet", "function_description": "Enables iteration over the MetaSet's internal storage, allowing users to traverse its contained elements in a standard Pythonic manner."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__len__", "line_number": 40, "body": "def __len__(self):\n        return len(self._store)", "is_method": true, "class_name": "MetaSet", "function_description": "Returns the number of items stored in the MetaSet instance. Useful for quickly determining the size of the collection managed by MetaSet."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "add", "line_number": 43, "body": "def add(self, value):\n        self._meta[value] = self._meta_func(value, self=self)\n        self._store.add(value)", "is_method": true, "class_name": "MetaSet", "function_description": "Utility method of MetaSet that adds a value by storing it and updating its metadata using a custom metadata function."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "discard", "line_number": 47, "body": "def discard(self, value):\n        self._meta.pop(value, None)\n        self._store.discard(value)", "is_method": true, "class_name": "MetaSet", "function_description": "Removes the specified value from both the internal metadata and the main data store, effectively discarding it from the MetaSet. This supports synchronizing removals across metadata and stored elements."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "update", "line_number": 51, "body": "def update(self, iterable):\n        \"\"\"Add all values from an iterable (such as a list or file).\"\"\"\n        # Must comsume generator fully on py3k\n        consume(map(self.add, iterable))", "is_method": true, "class_name": "MetaSet", "function_description": "Adds all elements from a given iterable to the MetaSet, effectively updating the set with multiple new items at once."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "_asdict", "line_number": 56, "body": "def _asdict(self):\n        return copy.copy(self._meta)", "is_method": true, "class_name": "MetaSet", "function_description": "Returns a shallow copy of the MetaSet instance's internal metadata dictionary, providing access to its stored key-value pairs."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "added_at", "line_number": 65, "body": "def added_at(self):\n        return self._meta", "is_method": true, "class_name": "TimedValueSet", "function_description": "Returns the metadata indicating when the value was added. This method provides access to the timestamp or related information associated with the stored value."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/urls.py", "function": "update_query_params", "line_number": 9, "body": "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, query_string, fragment = urlparse.urlsplit(url)\n\n    query_params = urlparse.parse_qs(query_string)\n    query_params.update(**params)\n\n    new_query_string = urlencode(query_params, doseq=doseq)\n\n    new_url = urlparse.urlunsplit([scheme, netloc, path, new_query_string, fragment])\n    return new_url", "is_method": false, "function_description": "Function that updates or adds query parameters in a given URL, returning the modified URL string. It facilitates dynamic URL manipulation for web requests or API calls by modifying query strings seamlessly."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "expand", "line_number": 7, "body": "def expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val", "is_method": false, "function_description": "Function that expands environment variables and user home shortcuts in a string, returning the fully resolved file path or value."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "parse_env_file_contents", "line_number": 13, "body": "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    for line in lines:\n        m1 = re.match(r'\\A([A-Za-z_0-9]+)=(.*)\\Z', line)\n\n        if m1:\n            key, val = m1.group(1), m1.group(2)\n\n            m2 = re.match(r\"\\A'(.*)'\\Z\", val)\n            if m2:\n                val = m2.group(1)\n\n            m3 = re.match(r'\\A\"(.*)\"\\Z', val)\n            if m3:\n                val = re.sub(r'\\\\(.)', r'\\1', m3.group(1))\n\n            yield key, val", "is_method": false, "function_description": "Parses lines from an environment file, extracting key-value pairs while handling quoted values and escaped characters. It enables loading environment variables from textual representations for configuration purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "load_env_file", "line_number": 44, "body": "def load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes", "is_method": false, "function_description": "Utility function that parses environment variable definitions from given lines, applies variable expansions, updates a target environment mapping, and returns the ordered set of processed variables and their values. Useful for programmatically loading or simulating .env files into environment contexts."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "_namespace_from_calling_context", "line_number": 24, "body": "def _namespace_from_calling_context():\n    \"\"\"\n    Derive a namespace from the module containing the caller's caller.\n\n    :return: the fully qualified python name of a module.\n    :rtype: str\n    \"\"\"\n    # Not py3k compat\n    # return inspect.currentframe(2).f_globals[\"__name__\"]\n    # TODO Does this work in both py2/3?\n    return inspect.stack()[2][0].f_globals[\"__name__\"]", "is_method": false, "function_description": "Returns the fully qualified module name of the caller's caller, enabling identification of the calling context for dynamic namespace resolution or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "configure", "line_number": 81, "body": "def configure(config=None, env_var='LOGGING', default=DEFAULT_CONFIG):\n    \"\"\"\n\n    >>> log = logging.getLogger(__name__)\n    >>> configure()\n    >>> log.info('test')\n\n    \"\"\"\n    cfg = get_config(config, env_var, default)\n\n    try:\n        logging.config.dictConfig(cfg)\n    except TypeError as exc:\n        try:\n            logging.basicConfig(**cfg)\n        except Exception as inner_exc:\n            raise inner_exc from exc", "is_method": false, "function_description": "Function that sets up logging configuration using provided settings, environment variables, or a default, enabling flexible and adaptable logging setup for applications."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "get_config", "line_number": 100, "body": "def get_config(given=None, env_var=None, default=None):\n    config = given\n\n    if not config and env_var:\n        config = os.environ.get(env_var)\n\n    if not config and default:\n        config = default\n\n    if config is None:\n        raise ValueError('Invalid logging config: %s' % config)\n\n    if isinstance(config, _PyInfo.string_types):\n        import json\n\n        try:\n            config = json.loads(config)\n        except ValueError:\n            import yaml\n\n            try:\n                config = yaml.load(config)\n            except ValueError:\n                raise ValueError(\n                    \"Could not parse logging config as bare, json,\"\n                    \" or yaml: %s\" % config\n                )\n\n    return config", "is_method": false, "function_description": "Utility function that retrieves a logging configuration from an explicit argument, environment variable, or default value, and parses it from JSON or YAML formats for flexible logging setup."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "_ensure_configured", "line_number": 134, "body": "def _ensure_configured(_has_configured=_CONFIGURED):\n    if _has_configured:\n        return\n\n    configure()\n    _has_configured.append(True)", "is_method": false, "function_description": "Internal utility function that ensures necessary configuration is performed once, preventing redundant setup calls in the program."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "get_logger", "line_number": 142, "body": "def get_logger(name=None):\n    \"\"\"\n    >>> log = get_logger()\n    >>> log.info('test')\n\n    >>> log = get_logger('test2')\n    >>> log.info('test2')\n    \"\"\"\n    _ensure_configured()\n\n    if not name:\n        name = _namespace_from_calling_context()\n\n    return logging.getLogger(name)", "is_method": false, "function_description": "Utility function that returns a configured logger instance by name, defaulting to the caller's context if no name is provided, facilitating consistent logging across the application."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "logger_level", "line_number": 163, "body": "def logger_level(logger, level):\n    \"\"\"Set logger level to `level` within a context block. Don't use this except for debugging please, it's gross.\"\"\"\n    initial = logger.level\n    logger.level = level\n    try:\n        yield\n    finally:\n        logger.level = initial", "is_method": false, "function_description": "Context manager that temporarily sets a logger\u2019s level within a code block, allowing controlled logging verbosity primarily useful for debugging purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "format_dict_recursively", "line_number": 178, "body": "def format_dict_recursively(\n        mapping, raise_unresolvable=True, strip_unresolvable=False, conversions={\n            'True': True,\n            'False': False\n        }\n):\n    \"\"\"Format each string value of dictionary using values contained within\n    itself, keeping track of dependencies as required.\n\n    Also converts any formatted values according to conversions dict.\n\n    Example:\n\n    >>> from pprint import pprint as pp\n    >>> c = dict(wat='wat{omg}', omg=True)\n    >>> pp(format_dict_recursively(c))\n    {'omg': True, 'wat': 'watTrue'}\n\n    Dealing with missing (unresolvable) keys in format strings:\n\n    >>> from pprint import pprint as pp\n    >>> c = dict(wat='wat{omg}', omg=True, fail='no{whale}')\n    >>> format_dict_recursively(c)\n    Traceback (most recent call last):\n        ...\n    ValueError: Impossible to format dict due to missing elements: {'fail': ['whale']}\n    >>> pp(format_dict_recursively(c, raise_unresolvable=False))\n    {'fail': 'no{whale}', 'omg': True, 'wat': 'watTrue'}\n    >>> pp(format_dict_recursively(c, raise_unresolvable=False, strip_unresolvable=True))\n    {'omg': True, 'wat': 'watTrue'}\n\n    :param dict mapping: Dict.\n    :param bool raise_unresolvable: Upon True, raises ValueError upon an unresolvable key.\n    :param bool strip_unresolvable: Upon True, strips unresolvable keys.\n    :param dict conversions: Mapping of {from: to}.\n    \"\"\"\n    if conversions is None:\n        conversions = {}\n\n    ret = {}\n\n    # Create dependency mapping\n    deps = {}\n    for k, v in mapping.items():\n        # Do not include multiline values in this to avoid KeyErrors on actual\n        # .format below\n        if isinstance(v, six.string_types) and '\\n' not in v:\n            # Map key -> [*deps]\n            # This is a bit naive, but it works well.\n            deps[k] = re.findall(r'\\{(\\w+)\\}', v)\n        else:\n            ret[k] = v\n\n    while len(ret) != len(mapping):\n        ret_key_count_at_start = len(ret)\n        sret = set(ret)\n        keys = set(mapping) - sret\n\n        for k in keys:\n            needed = (x not in ret for x in deps[k])\n            if any(needed):\n                continue\n\n            ret[k] = mapping[k].format(**ret)\n\n            if ret[k] in conversions:\n                ret[k] = conversions[ret[k]]\n\n        # We have done all that we can here.\n        if ret_key_count_at_start == len(ret):\n            if not raise_unresolvable:\n                if not strip_unresolvable:\n                    # backfill\n                    ret.update({k: mapping[k] for k in keys})\n                break\n\n            missing = {k: [x for x in deps[k] if x not in ret]}\n            raise ValueError('Impossible to format dict due to missing elements: %r' % missing)\n\n    return ret", "is_method": false, "function_description": "Function that recursively formats string values in a dictionary using the dictionary's own keys, optionally handling unresolved placeholders by raising errors, stripping them, or preserving original strings, with support for value conversions. Useful for dynamically generating interdependent configuration or templated data."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__repr__", "line_number": 60, "body": "def __repr__(self):\n        if not self.__fancy_repr:\n            return '%s' % dict(self)\n\n        mapping = self.__mapping\n        if self.__dictify_repr:\n            mapping = dict(mapping)\n\n        return '<%s %s>' % (self.__class__.__name__, mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Provides a string representation of the ProxyMutableMapping object, optionally showing a detailed or simplified view of its underlying mapping for easier debugging and display purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "_set_mapping", "line_number": 70, "body": "def _set_mapping(self, mapping):\n        self.__mapping = mapping", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Core utility method of ProxyMutableMapping that assigns a new underlying mapping, allowing dynamic replacement of the data store the proxy wraps."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__contains__", "line_number": 73, "body": "def __contains__(self, item):\n        return item in self.__mapping", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Implements membership testing to check if a key exists within the underlying mapping of the ProxyMutableMapping class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getitem__", "line_number": 76, "body": "def __getitem__(self, item):\n        return self.__mapping[item]", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Core method of ProxyMutableMapping that accesses and returns the value associated with a given key from the underlying mapping. It enables dictionary-like retrieval behavior in the proxy object."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 79, "body": "def __setitem__(self, key, value):\n        self.__mapping[key] = value", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Implements item assignment for ProxyMutableMapping, allowing clients to set or update key-value pairs in the underlying mapping. This supports standard dictionary-like mutation behavior."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__delitem__", "line_number": 82, "body": "def __delitem__(self, key):\n        del self.__mapping[key]", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Implements deletion of an item by key from the underlying mapping within ProxyMutableMapping, enabling removal of entries through dictionary-like syntax."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__iter__", "line_number": 85, "body": "def __iter__(self):\n        return iter(self.__mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Provides an iterator over the underlying mapping's keys, enabling iteration through the ProxyMutableMapping's elements."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__len__", "line_number": 88, "body": "def __len__(self):\n        return len(self.__mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Returns the number of items in the underlying mapping, providing the current size of the ProxyMutableMapping instance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_trans__", "line_number": 98, "body": "def __key_trans__(self, key, store=False, get=False, contains=False, delete=False):\n        return key", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Simple utility method in HookableProxyMutableMapping that returns the provided key unchanged, potentially serving as a hook for key transformation in mapping operations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_allowed__", "line_number": 101, "body": "def __key_allowed__(self, key):\n        return True", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Always allows any key by returning True, providing an unrestricted key validation service for the HookableProxyMutableMapping class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__iter__", "line_number": 104, "body": "def __iter__(self):\n        orig_iter = super(HookableProxyMutableMapping, self).__iter__()\n        return (self.__key_remove_prefix__(key) for key in orig_iter if self.__key_allowed__(key))", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Overrides the iteration behavior to yield only allowed keys with a specific prefix removed, enabling controlled and customized dictionary key access in HookableProxyMutableMapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__contains__", "line_number": 108, "body": "def __contains__(self, item):\n        item = self.__key_trans__(item, contains=True)\n        return super(HookableProxyMutableMapping, self).__contains__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Overrides the containment check to apply a key transformation before verifying if an item exists in the underlying mapping. This enables customized key handling for membership tests."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getitem__", "line_number": 112, "body": "def __getitem__(self, item):\n        item = self.__key_trans__(item, get=True)\n        return super(HookableProxyMutableMapping, self).__getitem__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Core method of HookableProxyMutableMapping that retrieves a value for a given key, applying a key transformation before access to support custom key handling or preprocessing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 116, "body": "def __setitem__(self, item, value):\n        item = self.__key_trans__(item, store=True)\n        return super(HookableProxyMutableMapping, self).__setitem__(item, value)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Overrides setting an item to apply a key transformation before storing it, enabling customized key handling within the HookableProxyMutableMapping data structure."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__delitem__", "line_number": 120, "body": "def __delitem__(self, item):\n        item = self.__key_trans__(item, delete=True)\n        return super(HookableProxyMutableMapping, self).__delitem__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Overrides item deletion in a mutable mapping, applying a key transformation before removal. Useful for customized deletion behavior in data structures requiring key preprocessing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_trans__", "line_number": 143, "body": "def __key_trans__(self, key, store=False, get=False, contains=False, delete=False):\n        if store:\n            return self.__key_remove_prefix__(key)\n        return self.__key_add_prefix__(key)", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Utility method in PrefixedProxyMutableMapping that transforms keys by adding or removing a prefix based on the operation context, facilitating consistent key handling in the proxied mapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_allowed__", "line_number": 148, "body": "def __key_allowed__(self, key):\n        if self.__only_prefixed:\n            if isinstance(key, six.string_types):\n                if not key.startswith(self.__prefix):\n                    return False\n            else:\n                return False\n        return True", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Method of PrefixedProxyMutableMapping that determines if a given key is allowed based on whether it has the required prefix, enforcing key restrictions for controlled dictionary access."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_add_prefix__", "line_number": 157, "body": "def __key_add_prefix__(self, key):\n        return self.__prefix + key", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Utility method of PrefixedProxyMutableMapping that prepends a predefined prefix to a given key, supporting consistent key namespacing within the mapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_remove_prefix__", "line_number": 160, "body": "def __key_remove_prefix__(self, key):\n        return key[self.__prefix_len:]", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Utility method in PrefixedProxyMutableMapping that removes a predefined prefix from a given key, facilitating key transformation for proxy dictionary operations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 168, "body": "def __setitem__(self, key, val):\n        if isinstance(val, dict) and key in self:\n            self._unique += 1\n            key += str(self._unique)\n        dict.__setitem__(self, key, val)", "is_method": true, "class_name": "MultiDict", "function_description": "Overrides item assignment in MultiDict to ensure keys remain unique by appending a counter if a dictionary value is assigned to an existing key. This prevents key collisions when storing multiple dictionary values."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getattr__", "line_number": 313, "body": "def __getattr__(self, key):\n        if not key.startswith('_'):\n            try:\n                value = self.__mapping[key]\n\n                if self.__recursion and isinstance(value, collections.Mapping) and not isinstance(value, self._wrap_as):\n                    value = self.__class__(value)\n\n                return value\n            except KeyError:\n                # in py3 I'd chain these\n                raise AttributeError(key)", "is_method": true, "class_name": "ProxyMutableAttrDict", "function_description": "Provides attribute-style access to stored dictionary keys, recursively wrapping nested mappings to allow dot notation for nested data retrieval within ProxyMutableAttrDict instances."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setattr__", "line_number": 326, "body": "def __setattr__(self, key, value):\n        if not key.startswith('_'):\n            if self.__recursion and isinstance(value, collections.Mapping) and not isinstance(value, self._wrap_as):\n                value = self.__class__(value)\n\n            try:\n                self[key] = value\n            except KeyError:\n                # in py3 I'd chain these\n                raise AttributeError(key)\n\n        return super(ProxyMutableAttrDict, self).__setattr__(key, value)", "is_method": true, "class_name": "ProxyMutableAttrDict", "function_description": "Set attribute values with automatic wrapping of nested mappings into ProxyMutableAttrDict instances, enabling dictionary-like objects to support attribute-style assignment seamlessly."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_trans__", "line_number": 374, "body": "def __key_trans__(self, key, store=False, get=False, contains=False, delete=False):\n        self._handle_pid()\n        return key", "is_method": true, "class_name": "ProcessLocal", "function_description": "Private method of the ProcessLocal class that prepares a key for internal storage operations, ensuring process identification is handled before key usage. It supports various key-related operations like storing, retrieving, checking, or deleting data."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "_handle_pid", "line_number": 378, "body": "def _handle_pid(self, new_pid=os.getpid):\n        if callable(new_pid):\n            new_pid = new_pid()\n\n        if self.__pid__ != new_pid:\n            self.__pid__, self.__mapping = new_pid, self.__mapping_factory()\n            self._set_mapping(self.__mapping)", "is_method": true, "class_name": "ProcessLocal", "function_description": "Private method in ProcessLocal that updates internal state when the process ID changes, ensuring process-specific data isolation by resetting mappings accordingly."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 394, "body": "def __setitem__(self, key, value):\n        if key in self:\n            del self[key]\n\n        return collections.OrderedDict.__setitem__(self, key, value)", "is_method": true, "class_name": "LastUpdatedOrderedDict", "function_description": "Overrides item assignment to ensure updated keys are moved to the end, maintaining order by last update time. Useful for tracking entries by their most recent update in an ordered dictionary."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__repr__", "line_number": 409, "body": "def __repr__(self):\n        return '%s(%r)' % (self.__class__.__name__, collections.OrderedDict(self))", "is_method": true, "class_name": "OrderedCounter", "function_description": "Specialized representation method for OrderedCounter that displays its contents as an ordered dictionary, aiding in clear and ordered visualization of counted elements."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__reduce__", "line_number": 412, "body": "def __reduce__(self):\n        return self.__class__, (collections.OrderedDict(self), )", "is_method": true, "class_name": "OrderedCounter", "function_description": "Special method supporting serialization by returning the class and its ordered dictionary data, enabling OrderedCounter instances to be pickled and restored accurately."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "cachedmethod", "line_number": 20, "body": "def cachedmethod(cache, key=_default, lock=None, typed=_default, cached_exception=None):\n    \"\"\"Decorator to wrap a class or instance method with a memoizing\n    callable that saves results in a cache.\n\n    You can also specify a cached exception to cache and re-throw as well.\n\n    Originally from cachetools, but modified to support caching certain exceptions.\n    \"\"\"\n    if key is not _default and not callable(key):\n        key, typed = _default, key\n    if typed is not _default:\n        warnings.warn(\n            \"Passing 'typed' to cachedmethod() is deprecated, \"\n            \"use 'key=typedkey' instead\", DeprecationWarning, 2\n        )\n\n    def decorator(method):\n        # pass method to default key function for backwards compatibilty\n        if key is _default:\n            makekey = functools.partial(cachetools.typedkey if typed else cachetools.hashkey, method)\n        else:\n            makekey = key  # custom key function always receive method args\n\n        @six.wraps(method)\n        def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret\n\n        # deprecated wrapper attribute\n        def getter(self):\n            warnings.warn('%s.cache is deprecated' % method.__name__, DeprecationWarning, 2)\n            return cache(self)\n\n        wrapper.cache = getter\n        return wrapper\n\n    return decorator", "is_method": false, "function_description": "Decorator that memoizes a method\u2019s results in a cache, optionally caching and re-raising specified exceptions for improved performance and error handling in class or instance methods."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "lazyproperty", "line_number": 91, "body": "def lazyproperty(fn):\n    \"\"\"\n    Lazy/Cached property.\n    \"\"\"\n    attr_name = '_lazy_' + fn.__name__\n\n    @property\n    def _lazyprop(self):\n        if not hasattr(self, attr_name):\n            setattr(self, attr_name, fn(self))\n        return getattr(self, attr_name)\n\n    return _lazyprop", "is_method": false, "function_description": "Utility decorator that converts a method into a lazily evaluated property, caching its result after the first access to improve performance by avoiding redundant computations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "throw", "line_number": 14, "body": "def throw(self):\n        raise self.ex", "is_method": true, "class_name": "CachedException", "function_description": "Simple method in CachedException that raises the stored exception when called, allowing deferred or repeated exception throwing as needed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "decorator", "line_number": 36, "body": "def decorator(method):\n        # pass method to default key function for backwards compatibilty\n        if key is _default:\n            makekey = functools.partial(cachetools.typedkey if typed else cachetools.hashkey, method)\n        else:\n            makekey = key  # custom key function always receive method args\n\n        @six.wraps(method)\n        def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret\n\n        # deprecated wrapper attribute\n        def getter(self):\n            warnings.warn('%s.cache is deprecated' % method.__name__, DeprecationWarning, 2)\n            return cache(self)\n\n        wrapper.cache = getter\n        return wrapper", "is_method": false, "function_description": "Decorator function that wraps a method to provide caching with optional locking, key customization, and exception handling, improving performance by reusing previous call results within a class instance's cache."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "wrapper", "line_number": 44, "body": "def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret", "is_method": false, "function_description": "This function provides a caching mechanism for method calls, returning cached results when available and computing plus storing results when not. It handles concurrency and exception caching to optimize repeated method executions."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__repr__", "line_number": 16, "body": "def __repr__(self):\n        return '{cls_name}({name})'.format(cls_name=self.__class__.__name__, name=self.name)", "is_method": true, "class_name": "Timer", "function_description": "Provides a readable string representation of the Timer instance by displaying its class name and associated name attribute. Useful for debugging and logging to identify timer objects clearly."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__enter__", "line_number": 19, "body": "def __enter__(self):\n        self.start = time.time()\n        return self", "is_method": true, "class_name": "Timer", "function_description": "Enables Timer instances to be used with the context manager protocol by starting the timer upon entering the context. This facilitates automatic tracking of elapsed time for code blocks within the with statement."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__exit__", "line_number": 23, "body": "def __exit__(self, *args):\n        self.end = time.time()\n        self.secs = self.end - self.start\n        self.msecs = self.secs * 1000  # millisecs\n\n        if self.verbose:\n            _LOG.debug('%s: Elapsed time: %f ms', self, self.msecs)", "is_method": true, "class_name": "Timer", "function_description": "Destructor method of the Timer class that stops timing, calculates elapsed time in seconds and milliseconds, and optionally logs the duration if verbose mode is enabled."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/rand.py", "function": "rand_hex", "line_number": 4, "body": "def rand_hex(length=8):\n    \"\"\"\n    Create a random hex string of a specific length performantly.\n\n    :param int length: length of hex string to generate\n    :return: random hex string\n    \"\"\"\n    return '%0{}x'.format(length) % random.randrange(16**length)", "is_method": false, "function_description": "Function that generates a random hexadecimal string of the specified length, useful for creating unique identifiers or tokens in a performant manner."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/excs.py", "function": "ok", "line_number": 5, "body": "def ok(*exceptions):\n    \"\"\"Context manager to pass exceptions.\n    :param exceptions: Exceptions to pass\n    \"\"\"\n    try:\n        yield\n    except Exception as e:\n        if isinstance(e, exceptions):\n            pass\n        else:\n            raise e", "is_method": false, "function_description": "Context manager that suppresses specified exceptions within its block, allowing code to continue execution when these exceptions occur while propagating others."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/path.py", "function": "join_each", "line_number": 4, "body": "def join_each(parent, iterable):\n    for p in iterable:\n        yield os.path.join(parent, p)", "is_method": false, "function_description": "Utility function that generates paths by joining a parent directory with each element in an iterable, simplifying batch construction of file or folder paths."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "multiplex", "line_number": 5, "body": "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues", "is_method": false, "function_description": "Function that splits a single input queue into multiple output queues, duplicating each incoming item across all outputs for concurrent consumption. Useful for distributing data streams to multiple consumers in parallel."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "push", "line_number": 25, "body": "def push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)", "is_method": false, "function_description": "Continuously transfers items from an input queue to an output queue, enabling seamless data passing between concurrent processes or threads."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "merge", "line_number": 31, "body": "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q", "is_method": false, "function_description": "Function merges multiple input queues into a single output queue, enabling concurrent consumption of their combined items. It facilitates unified processing of multiple data streams in asynchronous or multithreaded contexts."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "lazyperclassproperty", "line_number": 25, "body": "def lazyperclassproperty(fn):\n    \"\"\"\n    Lazy/Cached class property that stores separate instances per class/inheritor so there's no overlap.\n    \"\"\"\n\n    @classproperty\n    def _lazyclassprop(cls):\n        attr_name = '_%s_lazy_%s' % (cls.__name__, fn.__name__)\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, fn(cls))\n        return getattr(cls, attr_name)\n\n    return _lazyclassprop", "is_method": false, "function_description": "Decorator that creates a class-level property with lazy evaluation, caching a separate value for each class or subclass to prevent shared state across the inheritance hierarchy. Useful for expensive computations or resources tied uniquely to each class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "lazyclassproperty", "line_number": 40, "body": "def lazyclassproperty(fn):\n    \"\"\"\n    Lazy/Cached class property.\n    \"\"\"\n    attr_name = '_lazy_' + fn.__name__\n\n    @classproperty\n    def _lazyclassprop(cls):\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, fn(cls))\n        return getattr(cls, attr_name)\n\n    return _lazyclassprop", "is_method": false, "function_description": "Utility decorator that defines a lazily evaluated class property cached on first access, enabling efficient reuse of class-level computed values without recomputation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "__get__", "line_number": 9, "body": "def __get__(self, obj, owner):\n        return self.f(owner)", "is_method": true, "class_name": "roclassproperty", "function_description": "Utility method in roclassproperty that allows accessing a class-level property by invoking its associated function with the class as the argument."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "__set__", "line_number": 21, "body": "def __set__(self, obj, value):\n        return self.func(obj, value)", "is_method": true, "class_name": "setterproperty", "function_description": "Setter method in setterproperty class that delegates setting an attribute's value by invoking a stored function, facilitating controlled attribute assignment behavior."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/tlds.py", "function": "split_domain_into_subdomains", "line_number": 11, "body": "def split_domain_into_subdomains(domain, split_tld=False):\n    \"\"\"\n    Walks up a domain by subdomain.\n\n    >>> split_domain_into_subdomains('this.is.a.test.skywww.net')\n    ['this.is.a.test.skywww.net', 'is.a.test.skywww.net', 'a.test.skywww.net', 'test.skywww.net', 'skywww.net']\n\n    \"\"\"\n    import tldextract\n\n    # Requires unicode\n    domain = ensure_decoded_text(domain)\n\n    # Do not request latest TLS list on init == suffix_list_urls=False\n    global _tldex\n    if _tldex is None:\n        _tldex = tldextract.TLDExtract(suffix_list_urls=False)\n\n    tx = _tldex(domain)\n\n    domains = []\n    if tx.subdomain:\n        domains.extend(tx.subdomain.split('.'))\n\n    # tx.registered_domain returns only if domain AND suffix are not none\n    # There are cases where we have domain and not suffix; ie short hostnames\n    registered_domain = [tx.domain]\n    if tx.suffix:\n        registered_domain.append(tx.suffix)\n\n    if split_tld:\n        domains.extend(registered_domain)\n    else:\n        domains.append('.'.join(registered_domain))\n\n    # Musical chairs. Change places!\n    domains.reverse()\n\n    def join_dom(a, b):\n        return '.'.join([b, a])\n\n    # Take each part and add it to the previous part, returning all results\n    domains = list(accumulate(domains, func=join_dom))\n    # Change places!\n    domains.reverse()\n\n    return domains", "is_method": false, "function_description": "Function that decomposes a domain into all its hierarchical subdomains, optionally splitting the top-level domain, useful for domain parsing and analysis tasks like security or web analytics."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/tlds.py", "function": "join_dom", "line_number": 49, "body": "def join_dom(a, b):\n        return '.'.join([b, a])", "is_method": false, "function_description": "Utility function that concatenates two strings with a period, placing the second argument before the first in the resulting string. It can be used for creating dot-separated identifiers or keys."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/python.py", "function": "__len__", "line_number": 31, "body": "def __len__(self):\n                    return 1 << 31", "is_method": true, "class_name": "X", "function_description": "Returns a fixed large integer representing the length or size of an object, typically used to indicate an effectively unlimited or maximum count."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__setattr__", "line_number": 8, "body": "def __setattr__(self, key, value):\n        obj = self.__dict__.get(key, None)\n        if type(obj) is classproperty:\n            return obj.__set__(self, value)\n        return super().__setattr__(key, value)", "is_method": true, "class_name": "ClassPropertyMeta", "function_description": "Overrides attribute assignment to support setting values on class-level properties defined via classproperty, while defaulting to normal behavior for other attributes. It enables mutable class property behavior in the ClassPropertyMeta metaclass."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__get__", "line_number": 58, "body": "def __get__(self, instance, owner=None):\n        if not issubclass(type(owner), ClassPropertyMeta):\n            raise TypeError(f\"Class {owner} does not extend from the required \" f\"ClassPropertyMeta metaclass\")\n        return self.fget.__get__(None, owner)()", "is_method": true, "class_name": "rwclassproperty", "function_description": "Provides controlled access to a class-level property, ensuring the owning class uses a specific metaclass before invoking the property's getter method. Useful for enforcing access patterns to class properties with metaclass constraints."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__set__", "line_number": 63, "body": "def __set__(self, owner, value):\n        if not self.fset:\n            raise AttributeError(\"can't set attribute\")\n        if type(owner) is not ClassPropertyMeta:\n            owner = type(owner)\n        return self.fset.__get__(None, owner)(value)", "is_method": true, "class_name": "rwclassproperty", "function_description": "Provides controlled setting behavior for a class-level property, enforcing setter presence and adapting owner type before invoking the setter function."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "setter", "line_number": 70, "body": "def setter(self, fset):\n        self.fset = self._fix_function(fset)\n        return self", "is_method": true, "class_name": "rwclassproperty", "function_description": "Method of rwclassproperty that assigns and processes a setter function for the property, enabling controlled modification behavior at the class level."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "_fix_function", "line_number": 77, "body": "def _fix_function(cls, fn):\n        if not isinstance(fn, cls._fn_types):\n            raise TypeError(\"Getter or setter must be a function\")\n        # Always wrap in classmethod so we can call its __get__ and not\n        # have to deal with difference between raw functions.\n        if not isinstance(fn, (classmethod, staticmethod)):\n            return classmethod(fn)\n        return fn", "is_method": true, "class_name": "rwclassproperty", "function_description": "Utility function within rwclassproperty that validates and wraps a function as a classmethod, ensuring consistent behavior for getter or setter methods in the property implementation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_get_set", "line_number": 95, "body": "def test_get_set(self):\n        get_only_cls = MagicMock()\n        get_set_get_cls = MagicMock()\n        get_set_set_cls = MagicMock()\n\n        class Z(object, metaclass=classproperty.meta):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                get_only_cls(cls)\n                return sentinel.get_only\n\n            @classproperty\n            def get_set(cls):\n                get_set_get_cls(cls)\n                return cls._get_set\n\n            @get_set.setter\n            def get_set(cls, value):\n                get_set_set_cls(cls)\n                cls._get_set = value\n\n        for c, msg in [(Z, \"class\"), (Z(), \"instance\")]:\n            with self.subTest(msg=msg):\n                # Reset\n                Z._get_set = sentinel.nothing\n\n                # Test get_only\n                self.assertEqual(sentinel.get_only, c.get_only)\n                get_only_cls.assert_called_once_with(Z)\n                get_only_cls.reset_mock()\n\n                # Should return our initial \"nothing\" value\n                self.assertEqual(sentinel.nothing, c.get_set)\n                get_set_get_cls.assert_called_once_with(Z)\n                get_set_get_cls.reset_mock()\n\n                # Now test the set\n                c.get_set = sentinel.get_set_val\n                get_set_set_cls.assert_called_once_with(Z)\n                get_set_set_cls.reset_mock()\n\n                self.assertEqual(sentinel.get_set_val, c.get_set)\n                get_set_get_cls.assert_called_once_with(Z)\n                get_set_get_cls.reset_mock()", "is_method": true, "class_name": "TestClassProperty", "function_description": "Tests the behavior of a class-level property supporting both getter and setter methods, verifying access and assignment through class and instance references. It ensures the custom classproperty decorator correctly handles get-only and get-set scenarios."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_read_only", "line_number": 142, "body": "def test_read_only(self):\n        class Z(object, metaclass=classproperty.meta):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                return sentinel.get_only\n\n        self.assertEqual(sentinel.get_only, Z.get_only)\n        with self.assertRaises(AttributeError):\n            Z.get_only = 123", "is_method": true, "class_name": "TestClassProperty", "function_description": "Tests that a class property defined as read-only raises an error on assignment and returns the expected sentinel value. It validates the immutability and correct retrieval of a read-only class property."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_proper_metaclass", "line_number": 154, "body": "def test_proper_metaclass(self):\n        class Z(object):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                return sentinel.get_only\n\n        with self.assertRaises(TypeError):\n            self.assertEqual(\"should not resolve\", Z.get_only)", "is_method": true, "class_name": "TestClassProperty", "function_description": "This method tests that a class property raises a TypeError when accessed improperly, validating the correct behavior of the metaclass mechanism within the TestClassProperty context."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_only", "line_number": 104, "body": "def get_only(cls):\n                get_only_cls(cls)\n                return sentinel.get_only", "is_method": true, "class_name": "Z", "function_description": "Returns a sentinel value associated with the given class, typically used to enforce or indicate restricted access."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_set", "line_number": 109, "body": "def get_set(cls):\n                get_set_get_cls(cls)\n                return cls._get_set", "is_method": true, "class_name": "Z", "function_description": "Returns the class-level _get_set attribute after performing a preparation step using get_set_get_cls. This method provides access to a shared set associated with the class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_only", "line_number": 147, "body": "def get_only(cls):\n                return sentinel.get_only", "is_method": true, "class_name": "Z", "function_description": "This class method provides access to a unique sentinel value representing an exclusive or singular state, useful for signaling or flagging in various contexts."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_only", "line_number": 159, "body": "def get_only(cls):\n                return sentinel.get_only", "is_method": true, "class_name": "Z", "function_description": "Returns a unique sentinel value indicating a singular or exclusive state within the class context. This method provides a standard reference for \"only\" conditions across the application."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "make_lazy", "line_number": 24, "body": "def make_lazy(module_path):\n    \"\"\"\n    Mark that this module should not be imported until an\n    attribute is needed off of it.\n    \"\"\"\n    sys_modules = sys.modules  # cache in the locals\n\n    # store our 'instance' data in the closure.\n    module = NonLocal(None)\n\n    class LazyModule(_LazyModuleMarker):\n        \"\"\"\n        A standin for a module to prevent it from being imported\n        \"\"\"\n        def __mro__(self):\n            \"\"\"\n            Override the __mro__ to fool `isinstance`.\n            \"\"\"\n            # We don't use direct subclassing because `ModuleType` has an\n            # incompatible metaclass base with object (they are both in c)\n            # and we are overridding __getattribute__.\n            # By putting a __mro__ method here, we can pass `isinstance`\n            # checks without ever invoking our __getattribute__ function.\n            return (LazyModule, ModuleType)\n\n        def __getattribute__(self, attr):\n            \"\"\"\n            Override __getattribute__ to hide the implementation details.\n            \"\"\"\n            if module.value is None:\n                del sys_modules[module_path]\n                module.value = __import__(module_path)\n\n                sys_modules[module_path] = __import__(module_path)\n\n            return getattr(module.value, attr)\n\n    sys_modules[module_path] = LazyModule()", "is_method": false, "function_description": "Utility function that defers importing a specified module until one of its attributes is accessed, optimizing startup performance by implementing lazy loading of modules."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "__mro__", "line_number": 38, "body": "def __mro__(self):\n            \"\"\"\n            Override the __mro__ to fool `isinstance`.\n            \"\"\"\n            # We don't use direct subclassing because `ModuleType` has an\n            # incompatible metaclass base with object (they are both in c)\n            # and we are overridding __getattribute__.\n            # By putting a __mro__ method here, we can pass `isinstance`\n            # checks without ever invoking our __getattribute__ function.\n            return (LazyModule, ModuleType)", "is_method": true, "class_name": "LazyModule", "function_description": "Provides a custom method to spoof the method resolution order (MRO) for `isinstance` checks, enabling the LazyModule to appear as a subclass of ModuleType without direct inheritance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "__getattribute__", "line_number": 49, "body": "def __getattribute__(self, attr):\n            \"\"\"\n            Override __getattribute__ to hide the implementation details.\n            \"\"\"\n            if module.value is None:\n                del sys_modules[module_path]\n                module.value = __import__(module_path)\n\n                sys_modules[module_path] = __import__(module_path)\n\n            return getattr(module.value, attr)", "is_method": true, "class_name": "LazyModule", "function_description": "Core method of LazyModule that lazily imports and initializes a module upon attribute access, abstracting import details and ensuring the module is loaded only when needed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "lazy_compile", "line_number": 165, "body": "def lazy_compile(*args, **kwargs):\n    \"\"\"Create a proxy object which will compile the regex on demand.\n\n    :return: a LazyRegex proxy object.\n    \"\"\"\n    return LazyRegex(args, kwargs)", "is_method": false, "function_description": "This function provides a lazy initialization service by returning a proxy that compiles a regular expression only when needed, optimizing performance for regex operations that may not be used immediately."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "install_lazy_compile", "line_number": 173, "body": "def install_lazy_compile():\n    \"\"\"Make lazy_compile the default compile mode for regex compilation.\n\n    This overrides re.compile with lazy_compile. To restore the original\n    functionality, call reset_compile().\n    \"\"\"\n    re.compile = lazy_compile", "is_method": false, "function_description": "Replaces Python's default regex compile function with a lazy compilation mode, enabling deferred regex compilation for potential performance benefits. It can be reverted by calling a reset function."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "reset_compile", "line_number": 182, "body": "def reset_compile():\n    \"\"\"Restore the original function to re.compile().\n\n    It is safe to call reset_compile() multiple times, it will always\n    restore re.compile() to the value that existed at import time.\n    Though the first call will reset back to the original (it doesn't\n    track nesting level)\n    \"\"\"\n    re.compile = _real_re_compile", "is_method": false, "function_description": "Function that restores the original re.compile function to its initial imported state, ensuring safe repeated resets without tracking nested modifications. Useful for undoing any monkey-patching of re.compile in code."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_format", "line_number": 39, "body": "def _format(self):\n        s = getattr(self, '_preformatted_string', None)\n        if s is not None:\n            # contains a preformatted message\n            return s\n        try:\n            fmt = self._get_format_string()\n            if fmt:\n                d = dict(self.__dict__)\n                s = fmt % d\n                # __str__() should always return a 'str' object\n                # never a 'unicode' object.\n                return s\n        except Exception as e:\n            pass # just bind to 'e' for formatting below\n        else:\n            e = None\n        return 'Unprintable exception %s: dict=%r, fmt=%r, error=%r' \\\n            % (self.__class__.__name__,\n               self.__dict__,\n               getattr(self, '_fmt', None),\n               e)", "is_method": true, "class_name": "InvalidPattern", "function_description": "Generates a formatted string representation of the InvalidPattern instance, using a predefined format or preformatted message, and safely handles formatting errors to provide a fallback description."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__unicode__", "line_number": 62, "body": "def __unicode__(self):\n        u = self._format()\n        if isinstance(u, str):\n            # Try decoding the str using the default encoding.\n            u = unicode(u)\n        elif not isinstance(u, unicode):\n            # Try to make a unicode object from it, because __unicode__ must\n            # return a unicode object.\n            u = unicode(u)\n        return u", "is_method": true, "class_name": "InvalidPattern", "function_description": "Returns a Unicode representation of the InvalidPattern instance, ensuring the output is always a Unicode string regardless of the original format. This supports consistent string handling and display in environments expecting Unicode."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__str__", "line_number": 73, "body": "def __str__(self):\n        s = self._format()\n        if isinstance(s, unicode):\n            s = s.encode('utf8')\n        else:\n            # __str__ must return a str.\n            s = str(s)\n        return s", "is_method": true, "class_name": "InvalidPattern", "function_description": "Returns the string representation of an InvalidPattern instance, ensuring the output is a properly encoded string for consistent display or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__repr__", "line_number": 82, "body": "def __repr__(self):\n        return '%s(%s)' % (self.__class__.__name__, str(self))", "is_method": true, "class_name": "InvalidPattern", "function_description": "Provides a string representation of an InvalidPattern instance showing its class name and string content for clear identification during debugging or logging."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_get_format_string", "line_number": 85, "body": "def _get_format_string(self):\n        \"\"\"Return format string for this exception or None\"\"\"\n        fmt = getattr(self, '_fmt', None)\n        if fmt is not None:\n            from bzrlib.i18n import gettext\n            return gettext(unicode(fmt))", "is_method": true, "class_name": "InvalidPattern", "function_description": "Returns a localized format string for the exception if defined, supporting internationalization of error messages within the InvalidPattern class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__eq__", "line_number": 92, "body": "def __eq__(self, other):\n        if self.__class__ is not other.__class__:\n            return NotImplemented\n        return self.__dict__ == other.__dict__", "is_method": true, "class_name": "InvalidPattern", "function_description": "Overrides equality to compare two InvalidPattern instances based on their attributes, enabling accurate equality checks between objects of this class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_compile_and_collapse", "line_number": 124, "body": "def _compile_and_collapse(self):\n        \"\"\"Actually compile the requested regex\"\"\"\n        self._real_regex = self._real_re_compile(*self._regex_args,\n                                                 **self._regex_kwargs)\n        for attr in self._regex_attributes_to_copy:\n            setattr(self, attr, getattr(self._real_regex, attr))", "is_method": true, "class_name": "LazyRegex", "function_description": "Internal method of LazyRegex that compiles the regex pattern and copies key regex attributes to the instance, enabling deferred regex compilation and attribute access upon demand."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_real_re_compile", "line_number": 131, "body": "def _real_re_compile(self, *args, **kwargs):\n        \"\"\"Thunk over to the original re.compile\"\"\"\n        try:\n            return _real_re_compile(*args, **kwargs)\n        except re.error as e:\n            # raise InvalidPattern instead of re.error as this gives a\n            # cleaner message to the user.\n            raise InvalidPattern('\"' + args[0] + '\" ' +str(e))", "is_method": true, "class_name": "LazyRegex", "function_description": "Core utility of LazyRegex that wraps Python\u2019s re.compile to compile regex patterns while providing clearer error messages by raising InvalidPattern on compilation errors."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__getstate__", "line_number": 140, "body": "def __getstate__(self):\n        \"\"\"Return the state to use when pickling.\"\"\"\n        return {\n            \"args\": self._regex_args,\n            \"kwargs\": self._regex_kwargs,\n            }", "is_method": true, "class_name": "LazyRegex", "function_description": "The __getstate__ method returns the internal state necessary for pickling the LazyRegex object, enabling serialization by capturing its initialization arguments. This supports saving and restoring LazyRegex instances."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__setstate__", "line_number": 147, "body": "def __setstate__(self, dict):\n        \"\"\"Restore from a pickled state.\"\"\"\n        self._real_regex = None\n        setattr(self, \"_regex_args\", dict[\"args\"])\n        setattr(self, \"_regex_kwargs\", dict[\"kwargs\"])", "is_method": true, "class_name": "LazyRegex", "function_description": "Restores the internal state of a LazyRegex object from a serialized form, preparing it for use by reinitializing necessary attributes after unpickling."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__getattr__", "line_number": 153, "body": "def __getattr__(self, attr):\n        \"\"\"Return a member from the proxied regex object.\n\n        If the regex hasn't been compiled yet, compile it\n        \"\"\"\n        if self._real_regex is None:\n            self._compile_and_collapse()\n        # Once we have compiled, the only time we should come here\n        # is actually if the attribute is missing.\n        return getattr(self._real_regex, attr)", "is_method": true, "class_name": "LazyRegex", "function_description": "Provides attribute access to the underlying regex object, compiling the regex lazily on first use, ensuring seamless interaction with regex methods while delaying compilation until necessary."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "finditer_public", "line_number": 202, "body": "def finditer_public(pattern, string, flags=0):\n        if isinstance(pattern, LazyRegex):\n            return pattern.finditer(string)\n        else:\n            return _real_re_compile(pattern, flags).finditer(string)", "is_method": false, "function_description": "Utility function that returns an iterator over all non-overlapping matches for a pattern in a string, supporting both lazy and regular regex patterns for flexible regex matching."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "disallow_proxying", "line_number": 194, "body": "def disallow_proxying():\n    \"\"\"Disallow lazily imported modules to be used as proxies.\n\n    Calling this function might cause problems with concurrent imports\n    in multithreaded environments, but will help detecting wasteful\n    indirection, so it should be called when executing unit tests.\n\n    Only lazy imports that happen after this call are affected.\n    \"\"\"\n    ScopeReplacer._should_proxy = False", "is_method": false, "function_description": "Function that disables lazy-import proxies to help detect unnecessary indirection, mainly intended for use during unit testing to catch inefficiencies in module importing behavior."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "lazy_import", "line_number": 449, "body": "def lazy_import(scope, text, lazy_import_class=None):\n    \"\"\"Create lazy imports for all of the imports in text.\n\n    This is typically used as something like::\n\n        from bzrlib.lazy_import import lazy_import\n        lazy_import(globals(), '''\n        from bzrlib import (\n            foo,\n            bar,\n            baz,\n            )\n        import bzrlib.branch\n        import bzrlib.transport\n        ''')\n\n    Then 'foo, bar, baz' and 'bzrlib' will exist as lazy-loaded\n    objects which will be replaced with a real object on first use.\n\n    In general, it is best to only load modules in this way. This is\n    because other objects (functions/classes/variables) are frequently\n    used without accessing a member, which means we cannot tell they\n    have been used.\n    \"\"\"\n    # This is just a helper around ImportProcessor.lazy_import\n    proc = ImportProcessor(lazy_import_class=lazy_import_class)\n    return proc.lazy_import(scope, text)", "is_method": false, "function_description": "Utility function that sets up lazy loading for multiple imports from given code text, allowing specified modules and objects to be imported only when first accessed, thereby improving initial load performance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_format", "line_number": 62, "body": "def _format(self):\n        s = getattr(self, '_preformatted_string', None)\n        if s is not None:\n            # contains a preformatted message\n            return s\n        try:\n            fmt = self._get_format_string()\n            if fmt:\n                d = dict(self.__dict__)\n                s = fmt % d\n                # __str__() should always return a 'str' object\n                # never a 'unicode' object.\n                return s\n        except Exception as e:\n            pass # just bind to 'e' for formatting below\n        else:\n            e = None\n        return 'Unprintable exception %s: dict=%r, fmt=%r, error=%r' \\\n            % (self.__class__.__name__,\n               self.__dict__,\n               getattr(self, '_fmt', None),\n               e)", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Utility method of the IllegalUseOfScopeReplacer class that generates a formatted string representation of the instance, falling back to a detailed error message if formatting fails or no preformatted string is set."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__unicode__", "line_number": 85, "body": "def __unicode__(self):\n        u = self._format()\n        if isinstance(u, str):\n            # Try decoding the str using the default encoding.\n            u = unicode(u)\n        elif not isinstance(u, unicode):\n            # Try to make a unicode object from it, because __unicode__ must\n            # return a unicode object.\n            u = unicode(u)\n        return u", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns a Unicode string representation of the object, ensuring the output is properly decoded or converted to Unicode as required by the method."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__str__", "line_number": 96, "body": "def __str__(self):\n        s = self._format()\n        if isinstance(s, unicode):\n            s = s.encode('utf8')\n        else:\n            # __str__ must return a str.\n            s = str(s)\n        return s", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns a string representation of the IllegalUseOfScopeReplacer instance, ensuring the result is properly encoded as a byte string or standard string depending on its initial format."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__repr__", "line_number": 105, "body": "def __repr__(self):\n        return '%s(%s)' % (self.__class__.__name__, str(self))", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns a string representation of the IllegalUseOfScopeReplacer instance showing its class name and current string content. This aids in debugging by providing a clear, informative summary of the object."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_get_format_string", "line_number": 108, "body": "def _get_format_string(self):\n        \"\"\"Return format string for this exception or None\"\"\"\n        fmt = getattr(self, '_fmt', None)\n        if fmt is not None:\n            from bzrlib.i18n import gettext\n            return gettext(unicode(fmt))", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns the localized format string for the exception if defined, supporting internationalization of error messages within the IllegalUseOfScopeReplacer context."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__eq__", "line_number": 115, "body": "def __eq__(self, other):\n        if self.__class__ is not other.__class__:\n            return NotImplemented\n        return self.__dict__ == other.__dict__", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Defines equality comparison for IllegalUseOfScopeReplacer instances by checking if both have the same class and identical attribute values. This enables accurate instance comparison based on their internal state."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_resolve", "line_number": 151, "body": "def _resolve(self):\n        \"\"\"Return the real object for which this is a placeholder\"\"\"\n        name = object.__getattribute__(self, '_name')\n        real_obj = object.__getattribute__(self, '_real_obj')\n        if real_obj is None:\n            # No obj generated previously, so generate from factory and scope.\n            factory = object.__getattribute__(self, '_factory')\n            scope = object.__getattribute__(self, '_scope')\n            obj = factory(self, scope, name)\n            if obj is self:\n                raise IllegalUseOfScopeReplacer(name, msg=\"Object tried\"\n                    \" to replace itself, check it's not using its own scope.\")\n\n            # Check if another thread has jumped in while obj was generated.\n            real_obj = object.__getattribute__(self, '_real_obj')\n            if real_obj is None:\n                # Still no prexisting obj, so go ahead and assign to scope and\n                # return. There is still a small window here where races will\n                # not be detected, but safest to avoid additional locking.\n                object.__setattr__(self, '_real_obj', obj)\n                scope[name] = obj\n                return obj\n\n        # Raise if proxying is disabled as obj has already been generated.\n        if not ScopeReplacer._should_proxy:\n            raise IllegalUseOfScopeReplacer(\n                name, msg=\"Object already replaced, did you assign it\"\n                          \" to another variable?\")\n        return real_obj", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Core method of ScopeReplacer that resolves and returns the actual object behind a placeholder, generating it if necessary, while ensuring thread safety and preventing illegal self-replacement within a scoped factory context."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__getattribute__", "line_number": 181, "body": "def __getattribute__(self, attr):\n        obj = object.__getattribute__(self, '_resolve')()\n        return getattr(obj, attr)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Overrides attribute access to delegate it dynamically to another object resolved at runtime, enabling flexible proxy behavior within the ScopeReplacer class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__setattr__", "line_number": 185, "body": "def __setattr__(self, attr, value):\n        obj = object.__getattribute__(self, '_resolve')()\n        return setattr(obj, attr, value)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Overrides attribute setting to redirect assignments to a dynamically resolved target object, enabling seamless attribute updates on a proxied or underlying instance within ScopeReplacer."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__call__", "line_number": 189, "body": "def __call__(self, *args, **kwargs):\n        obj = object.__getattribute__(self, '_resolve')()\n        return obj(*args, **kwargs)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Core method of ScopeReplacer that delegates calls to a dynamically resolved target object, enabling flexible method invocation with runtime binding."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_import", "line_number": 268, "body": "def _import(self, scope, name):\n        children = object.__getattribute__(self, '_import_replacer_children')\n        member = object.__getattribute__(self, '_member')\n        module_path = object.__getattribute__(self, '_module_path')\n        module_python_path = '.'.join(module_path)\n        if member is not None:\n            module = __import__(module_python_path, scope, scope, [member], level=0)\n            return getattr(module, member)\n        else:\n            module = __import__(module_python_path, scope, scope, [], level=0)\n            for path in module_path[1:]:\n                module = getattr(module, path)\n\n        # Prepare the children to be imported\n        for child_name, (child_path, child_member, grandchildren) in \\\n                children.iteritems():\n            # Using self.__class__, so that children get children classes\n            # instantiated. (This helps with instrumented tests)\n            cls = object.__getattribute__(self, '__class__')\n            cls(module.__dict__, name=child_name,\n                module_path=child_path, member=child_member,\n                children=grandchildren)\n        return module", "is_method": true, "class_name": "ImportReplacer", "function_description": "Core method of ImportReplacer that dynamically imports a module or its member, recursively initializing child import replacers to mirror nested imports, facilitating controlled or instrumented import behavior."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "lazy_import", "line_number": 311, "body": "def lazy_import(self, scope, text):\n        \"\"\"Convert the given text into a bunch of lazy import objects.\n\n        This takes a text string, which should be similar to normal python\n        import markup.\n        \"\"\"\n        self._build_map(text)\n        self._convert_imports(scope)", "is_method": true, "class_name": "ImportProcessor", "function_description": "Core method of ImportProcessor that processes import statements from a text string into lazy import objects within a given scope, facilitating deferred or on-demand module imports."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_imports", "line_number": 320, "body": "def _convert_imports(self, scope):\n        # Now convert the map into a set of imports\n        for name, info in self.imports.iteritems():\n            self._lazy_import_class(scope, name=name, module_path=info[0],\n                                    member=info[1], children=info[2])", "is_method": true, "class_name": "ImportProcessor", "function_description": "Internal method of ImportProcessor that processes stored import information to set up lazy imports within the given scope, supporting dynamic and efficient module loading."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_build_map", "line_number": 326, "body": "def _build_map(self, text):\n        \"\"\"Take a string describing imports, and build up the internal map\"\"\"\n        for line in self._canonicalize_import_text(text):\n            if line.startswith('import '):\n                self._convert_import_str(line)\n            elif line.startswith('from '):\n                self._convert_from_str(line)\n            else:\n                raise errors.InvalidImportLine(line,\n                    \"doesn't start with 'import ' or 'from '\")", "is_method": true, "class_name": "ImportProcessor", "function_description": "Internal method of ImportProcessor that parses import statements from text to construct an internal mapping of imports for further processing or analysis."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_import_str", "line_number": 337, "body": "def _convert_import_str(self, import_str):\n        \"\"\"This converts a import string into an import map.\n\n        This only understands 'import foo, foo.bar, foo.bar.baz as bing'\n\n        :param import_str: The import string to process\n        \"\"\"\n        if not import_str.startswith('import '):\n            raise ValueError('bad import string %r' % (import_str,))\n        import_str = import_str[len('import '):]\n\n        for path in import_str.split(','):\n            path = path.strip()\n            if not path:\n                continue\n            as_hunks = path.split(' as ')\n            if len(as_hunks) == 2:\n                # We have 'as' so this is a different style of import\n                # 'import foo.bar.baz as bing' creates a local variable\n                # named 'bing' which points to 'foo.bar.baz'\n                name = as_hunks[1].strip()\n                module_path = as_hunks[0].strip().split('.')\n                if name in self.imports:\n                    raise errors.ImportNameCollision(name)\n                # No children available in 'import foo as bar'\n                self.imports[name] = (module_path, None, {})\n            else:\n                # Now we need to handle\n                module_path = path.split('.')\n                name = module_path[0]\n                if name not in self.imports:\n                    # This is a new import that we haven't seen before\n                    module_def = ([name], None, {})\n                    self.imports[name] = module_def\n                else:\n                    module_def = self.imports[name]\n\n                cur_path = [name]\n                cur = module_def[2]\n                for child in module_path[1:]:\n                    cur_path.append(child)\n                    if child in cur:\n                        cur = cur[child][2]\n                    else:\n                        next = (cur_path[:], None, {})\n                        cur[child] = next\n                        cur = next[2]", "is_method": true, "class_name": "ImportProcessor", "function_description": "Converts a simple Python import statement string into a nested map representing imported modules and their aliases, enabling structured tracking of imports within the ImportProcessor."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_from_str", "line_number": 385, "body": "def _convert_from_str(self, from_str):\n        \"\"\"This converts a 'from foo import bar' string into an import map.\n\n        :param from_str: The import string to process\n        \"\"\"\n        if not from_str.startswith('from '):\n            raise ValueError('bad from/import %r' % from_str)\n        from_str = from_str[len('from '):]\n\n        from_module, import_list = from_str.split(' import ')\n\n        from_module_path = from_module.split('.')\n\n        for path in import_list.split(','):\n            path = path.strip()\n            if not path:\n                continue\n            as_hunks = path.split(' as ')\n            if len(as_hunks) == 2:\n                # We have 'as' so this is a different style of import\n                # 'import foo.bar.baz as bing' creates a local variable\n                # named 'bing' which points to 'foo.bar.baz'\n                name = as_hunks[1].strip()\n                module = as_hunks[0].strip()\n            else:\n                name = module = path\n            if name in self.imports:\n                raise errors.ImportNameCollision(name)\n            self.imports[name] = (from_module_path, module, {})", "is_method": true, "class_name": "ImportProcessor", "function_description": "Utility method of ImportProcessor that parses a \"from ... import ...\" statement string and maps imported names to their corresponding module paths, enabling structured tracking of import relationships with collision detection."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_canonicalize_import_text", "line_number": 415, "body": "def _canonicalize_import_text(self, text):\n        \"\"\"Take a list of imports, and split it into regularized form.\n\n        This is meant to take regular import text, and convert it to\n        the forms that the rest of the converters prefer.\n        \"\"\"\n        out = []\n        cur = None\n        continuing = False\n\n        for line in text.split('\\n'):\n            line = line.strip()\n            loc = line.find('#')\n            if loc != -1:\n                line = line[:loc].strip()\n\n            if not line:\n                continue\n            if cur is not None:\n                if line.endswith(')'):\n                    out.append(cur + ' ' + line[:-1])\n                    cur = None\n                else:\n                    cur += ' ' + line\n            else:\n                if '(' in line and ')' not in line:\n                    cur = line.replace('(', '')\n                else:\n                    out.append(line.replace('(', '').replace(')', ''))\n        if cur is not None:\n            raise errors.InvalidImportLine(cur, 'Unmatched parenthesis')\n        return out", "is_method": true, "class_name": "ImportProcessor", "function_description": "Processes multiline import statements to produce a standardized list of import lines, handling line continuations and removing comments for consistent parsing in import conversion workflows."}]