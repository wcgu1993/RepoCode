[{"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pretty.py", "function": "pf", "line_number": 27, "body": "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)", "is_method": false, "function_description": "Pretty formats a Python object into a string and applies syntax highlighting with coloring, enhancing readability for interactive environments like IPython."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pretty.py", "function": "pp", "line_number": 43, "body": "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()", "is_method": false, "function_description": "Provides a pretty-printing service that formats Python objects for enhanced readability. It applies syntax highlighting and coloring to the output, directing it to a specified file or console."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/debug.py", "function": "interact", "line_number": 5, "body": "def interact(banner='(debug shell)'):\n    # Get our current frame\n    curr_frame = inspect.currentframe()\n\n    try:\n        # Get previous frame (caller)\n        calling_frame = curr_frame.f_back\n\n        # Create merged dict of globals() with locals() from previous frame\n        calling_vars = calling_frame.f_globals.copy()\n        calling_vars.update(calling_frame.f_locals)\n\n        # Enter interactive console\n        code.interact(local=calling_vars, banner=banner)\n    finally:\n        del curr_frame", "is_method": false, "function_description": "Launches an interactive Python shell at the point of invocation, providing direct access to the calling scope's variables for debugging."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "set_tree_node", "line_number": 39, "body": "def set_tree_node(mapping, key, value):\n    \"\"\"\n    Set arbitrary node on a tree-like mapping structure, allowing for : notation to signify dimension.\n\n    Arguments:\n        mapping collections.Mapping: Mapping to fetch from\n        key str|unicode: Key to set, allowing for : notation\n        value str|unicode: Value to set `key` to\n        parent bool: If True, return parent node. Defaults to False.\n\n    Returns:\n        object: Parent node.\n\n    \"\"\"\n    basename, dirname = key.rsplit(':', 2)\n    parent_node = get_tree_node(mapping, dirname)\n    parent_node[basename] = value\n    return parent_node", "is_method": false, "function_description": "Sets a specific node's value within a nested, tree-like mapping structure. It uses a path-like key to navigate to the target location before assigning the value."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "tree", "line_number": 59, "body": "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n    return collections.defaultdict(tree)", "is_method": false, "function_description": "This function creates a self-nesting dictionary (a \"tree\") that automatically generates new sub-dictionaries for non-existent keys. It's useful for dynamically building hierarchical data structures of arbitrary depth."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "_namespace_key", "line_number": 80, "body": "def _namespace_key(self, key, namespace=_sentinel):\n        if namespace is _sentinel:\n            namespace = self.namespace\n        if namespace:\n            key = '%s:%s' % (namespace, key)\n        return key", "is_method": true, "class_name": "Tree", "function_description": "Provides a utility to generate a namespaced key by prepending a specified or default namespace. This ensures unique key identification within the tree's data structure."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "__setitem__", "line_number": 87, "body": "def __setitem__(self, key, value, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return set_tree_node(self, key, value)", "is_method": true, "class_name": "Tree", "function_description": "Enables direct assignment of values to nodes within the Tree object using bracket notation. It supports key-namespacing for hierarchical data management."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/trees.py", "function": "__getitem__", "line_number": 91, "body": "def __getitem__(self, key, default=_sentinel, namespace=None):\n        key = self._namespace_key(key, namespace=namespace)\n        return get_tree_node(self, key, default=default)", "is_method": true, "class_name": "Tree", "function_description": "Enables dictionary-like access to retrieve a node from the tree. It supports namespaced keys and returns a default value if the node is not found."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "accumulate", "line_number": 7, "body": "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "is_method": false, "function_description": "Generates a sequence of cumulative results from an iterable. It applies a specified binary function (defaulting to addition) to the running total and each subsequent element."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "consume", "line_number": 32, "body": "def consume(iterator, n=None):\n    \"\"\"\n    Efficiently advance an iterator n-steps ahead. If n is none, consume entirely.\n    Consumes at C level (and therefore speed) in cpython.\n    \"\"\"\n    if n is None:\n        # feed the entire iterator into a zero-length deque\n        collections.deque(iterator, maxlen=0)\n    else:\n        # advance to the empty slice starting at position n\n        next(itertools.islice(iterator, n, n), None)", "is_method": false, "function_description": "This function efficiently advances an iterator by 'n' steps, or fully consumes it if 'n' is not specified. It provides a fast way to skip elements or discard an iterator's remaining contents."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "dedupe_iter", "line_number": 45, "body": "def dedupe_iter(iterator, hashfunc=hash):\n    \"\"\"\"\n    Deduplicates an iterator iteratively using hashed values in a set.\n    Not exactly memory efficient because of that of course.\n    If you have a large dataset with high cardinality look at HyperLogLog instead.\n\n    :return generator: Iterator of deduplicated results.\n    \"\"\"\n    done = set()\n    for item in iterator:\n        hashed = hashfunc(item)\n\n        if hashed in done:\n            continue\n\n        done.add(hashed)\n        yield item", "is_method": false, "function_description": "This function deduplicates items from an iterator by yielding only the first occurrence of each unique element. It provides a unique sequence on-the-fly, based on item hash values."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/iters.py", "function": "dedupe", "line_number": 65, "body": "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)", "is_method": false, "function_description": "This decorator automatically removes duplicate elements from the iterable output of the function it decorates. It ensures that all items yielded by the wrapped function are unique."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/files.py", "function": "islurp", "line_number": 12, "body": "def islurp(filename, mode='r', iter_by=LINEMODE, allow_stdin=True, expanduser=True, expandvars=True):\n    \"\"\"\n    Read [expanded] `filename` and yield each (line | chunk).\n\n    :param str filename: File path\n    :param str mode: Use this mode to open `filename`, ala `r` for text (default), `rb` for binary, etc.\n    :param int iter_by: Iterate by this many bytes at a time. Default is by line.\n    :param bool allow_stdin: If Truthy and filename is `-`, read from `sys.stdin`.\n    :param bool expanduser: If Truthy, expand `~` in `filename`\n    :param bool expandvars: If Truthy, expand env vars in `filename`\n    \"\"\"\n    if iter_by == 'LINEMODE':\n        iter_by = LINEMODE\n\n    fh = None\n    try:\n        if filename == '-' and allow_stdin:\n            fh = sys.stdin\n        else:\n            if expanduser:\n                filename = os.path.expanduser(filename)\n            if expandvars:\n                filename = os.path.expandvars(filename)\n\n            fh = open(filename, mode)\n            fh_next = fh.readline if iter_by == LINEMODE else functools.partial(fh.read, iter_by)\n\n        while True:\n            buf = fh_next()\n            if buf == '':  # EOF\n                break\n            yield buf\n    finally:\n        if fh and fh != sys.stdin:\n            fh.close()", "is_method": false, "function_description": "Provides an iterator to read a file or stdin, yielding its content line by line or in specified chunks. It supports path and environment variable expansion for robust file handling."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/files.py", "function": "burp", "line_number": 55, "body": "def burp(filename, contents, mode='w', allow_stdout=True, expanduser=True, expandvars=True):\n    \"\"\"\n    Write `contents` to `filename`.\n    \"\"\"\n    if filename == '-' and allow_stdout:\n        sys.stdout.write(contents)\n    else:\n        if expanduser:\n            filename = os.path.expanduser(filename)\n        if expandvars:\n            filename = os.path.expandvars(filename)\n\n        with open(filename, mode) as fh:\n            fh.write(contents)", "is_method": false, "function_description": "Writes provided string content to a specified file or standard output. It supports path expansion for user home directories and environment variables."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pythree.py", "function": "ensure_encoded_bytes", "line_number": 4, "body": "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)", "is_method": false, "function_description": "Ensures an input value is represented as bytes, converting strings to bytes using a specified encoding if necessary. This provides a consistent bytes-like object for further processing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/pythree.py", "function": "ensure_decoded_text", "line_number": 19, "body": "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s", "is_method": false, "function_description": "This function ensures an input is a decoded text string. It converts byte strings to a text type using the specified encoding, otherwise returning the input unchanged for consistent processing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/meth.py", "function": "bind", "line_number": 1, "body": "def bind(instance, func, as_name):\n    \"\"\"\n    Turn a function to a bound method on an instance\n\n    >>> class Foo(object):\n    ...     def __init__(self, x, y):\n    ...         self.x = x\n    ...         self.y = y\n    >>> foo = Foo(2, 3)\n    >>> my_unbound_method = lambda self: self.x * self.y\n    >>> bind(foo, my_unbound_method, 'multiply')\n    >>> foo.multiply()  # noinspection PyUnresolvedReferences\n    6\n\n    :param object instance: some object\n    :param callable func: unbound method (i.e. a function that takes `self` argument, that you now\n        want to be bound to this class as a method)\n    :param str as_name: name of the method to create on the object\n    \"\"\"\n    setattr(instance, as_name, func.__get__(instance, instance.__class__))", "is_method": false, "function_description": "Dynamically attaches a given function as a new bound method to an object instance. This allows the function to be called on the instance, automatically receiving `self`."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__attrs_post_init__", "line_number": 29, "body": "def __attrs_post_init__(self):\n        if self._initial:\n            self.update(self._initial)\n            delattr(self, '_initial')", "is_method": true, "class_name": "MetaSet", "function_description": "Initializes the MetaSet instance by incorporating initial elements provided during construction. It ensures the temporary `_initial` attribute is then removed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__contains__", "line_number": 34, "body": "def __contains__(self, item):\n        return item in self._store", "is_method": true, "class_name": "MetaSet", "function_description": "Provides membership testing for the MetaSet instance. It allows using the 'in' operator to efficiently check if an element exists within the set."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__iter__", "line_number": 37, "body": "def __iter__(self):\n        return iter(self._store)", "is_method": true, "class_name": "MetaSet", "function_description": "Enables instances of MetaSet to be iterable. It provides an iterator over the MetaSet's internal collection of elements, allowing direct use in loops and other iterable contexts."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "__len__", "line_number": 40, "body": "def __len__(self):\n        return len(self._store)", "is_method": true, "class_name": "MetaSet", "function_description": "Provides the number of elements contained within the MetaSet instance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "add", "line_number": 43, "body": "def add(self, value):\n        self._meta[value] = self._meta_func(value, self=self)\n        self._store.add(value)", "is_method": true, "class_name": "MetaSet", "function_description": "Adds a value to the MetaSet, simultaneously computing and storing its associated metadata."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "discard", "line_number": 47, "body": "def discard(self, value):\n        self._meta.pop(value, None)\n        self._store.discard(value)", "is_method": true, "class_name": "MetaSet", "function_description": "Removes a specified value from both the primary set-like storage and its associated metadata within the MetaSet instance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "update", "line_number": 51, "body": "def update(self, iterable):\n        \"\"\"Add all values from an iterable (such as a list or file).\"\"\"\n        # Must comsume generator fully on py3k\n        consume(map(self.add, iterable))", "is_method": true, "class_name": "MetaSet", "function_description": "This method efficiently adds all elements from a given iterable to the `MetaSet`. It allows for bulk population or extension of the set's contents."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "_asdict", "line_number": 56, "body": "def _asdict(self):\n        return copy.copy(self._meta)", "is_method": true, "class_name": "MetaSet", "function_description": "Provides a shallow copy of the `MetaSet`'s internal metadata. This ensures safe external access to the object's state without allowing direct modification."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/sets.py", "function": "added_at", "line_number": 65, "body": "def added_at(self):\n        return self._meta", "is_method": true, "class_name": "TimedValueSet", "function_description": "Retrieves the timestamp or associated metadata indicating when the TimedValueSet was added. It provides a way to track the set's creation time."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/urls.py", "function": "update_query_params", "line_number": 9, "body": "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, query_string, fragment = urlparse.urlsplit(url)\n\n    query_params = urlparse.parse_qs(query_string)\n    query_params.update(**params)\n\n    new_query_string = urlencode(query_params, doseq=doseq)\n\n    new_url = urlparse.urlunsplit([scheme, netloc, path, new_query_string, fragment])\n    return new_url", "is_method": false, "function_description": "Updates or adds new query parameters to a given URL. This function simplifies the dynamic modification of URLs, useful for web requests or generating links."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "expand", "line_number": 7, "body": "def expand(val: str) -> str:\n    val = os.path.expandvars(val)\n    val = os.path.expanduser(val)\n    return val", "is_method": false, "function_description": "Expands environment variables and user home directory shortcuts within a given string. This function resolves platform-specific path notations for robust file system operations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "parse_env_file_contents", "line_number": 13, "body": "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n    for line in lines:\n        m1 = re.match(r'\\A([A-Za-z_0-9]+)=(.*)\\Z', line)\n\n        if m1:\n            key, val = m1.group(1), m1.group(2)\n\n            m2 = re.match(r\"\\A'(.*)'\\Z\", val)\n            if m2:\n                val = m2.group(1)\n\n            m3 = re.match(r'\\A\"(.*)\"\\Z', val)\n            if m3:\n                val = re.sub(r'\\\\(.)', r'\\1', m3.group(1))\n\n            yield key, val", "is_method": false, "function_description": "Parses lines of text, typically from an environment file, to extract and yield key-value pairs, handling quoted and escaped values. This enables loading configurations from `.env` style files."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/env.py", "function": "load_env_file", "line_number": 44, "body": "def load_env_file(lines: typing.Iterable[str], write_environ: typing.MutableMapping = os.environ) -> collections.OrderedDict:\n    \"\"\"\n    Loads (and returns) an env file specified by `filename` into the mapping `environ`.\n\n    >>> lines = ['TEST=${HOME}/yeee-$PATH', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../.../yeee-...:...'),\n             ('THISIS', '.../a/test'),\n             ('YOLO',\n              '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n    \"\"\"\n    values = parse_env_file_contents(lines)\n\n    changes = collections.OrderedDict()\n\n    for k, v in values:\n        v = expand(v)\n\n        changes[k] = v\n\n        if write_environ is not None:\n            write_environ[k] = v\n\n    return changes", "is_method": false, "function_description": "Loads and expands environment variable definitions from an iterable of lines. It applies these definitions to a specified environment mapping, like `os.environ`, and returns the changes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "_namespace_from_calling_context", "line_number": 24, "body": "def _namespace_from_calling_context():\n    \"\"\"\n    Derive a namespace from the module containing the caller's caller.\n\n    :return: the fully qualified python name of a module.\n    :rtype: str\n    \"\"\"\n    # Not py3k compat\n    # return inspect.currentframe(2).f_globals[\"__name__\"]\n    # TODO Does this work in both py2/3?\n    return inspect.stack()[2][0].f_globals[\"__name__\"]", "is_method": false, "function_description": "Retrieves the fully qualified module name of the calling function's caller. This provides contextual information about the module initiating a sequence of calls."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "configure", "line_number": 81, "body": "def configure(config=None, env_var='LOGGING', default=DEFAULT_CONFIG):\n    \"\"\"\n\n    >>> log = logging.getLogger(__name__)\n    >>> configure()\n    >>> log.info('test')\n\n    \"\"\"\n    cfg = get_config(config, env_var, default)\n\n    try:\n        logging.config.dictConfig(cfg)\n    except TypeError as exc:\n        try:\n            logging.basicConfig(**cfg)\n        except Exception as inner_exc:\n            raise inner_exc from exc", "is_method": false, "function_description": "Configures the application's logging system. It applies settings from a provided dictionary, environment variable, or default, streamlining logging initialization."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "get_config", "line_number": 100, "body": "def get_config(given=None, env_var=None, default=None):\n    config = given\n\n    if not config and env_var:\n        config = os.environ.get(env_var)\n\n    if not config and default:\n        config = default\n\n    if config is None:\n        raise ValueError('Invalid logging config: %s' % config)\n\n    if isinstance(config, _PyInfo.string_types):\n        import json\n\n        try:\n            config = json.loads(config)\n        except ValueError:\n            import yaml\n\n            try:\n                config = yaml.load(config)\n            except ValueError:\n                raise ValueError(\n                    \"Could not parse logging config as bare, json,\"\n                    \" or yaml: %s\" % config\n                )\n\n    return config", "is_method": false, "function_description": "This function retrieves a configuration value, prioritizing an explicit input, then an environment variable, and finally a default. It robustly parses string configurations as JSON or YAML, providing flexible application setup."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "_ensure_configured", "line_number": 134, "body": "def _ensure_configured(_has_configured=_CONFIGURED):\n    if _has_configured:\n        return\n\n    configure()\n    _has_configured.append(True)", "is_method": false, "function_description": "Ensures a critical configuration or setup routine is executed exactly once during the program's lifecycle, preventing redundant initialization calls."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "get_logger", "line_number": 142, "body": "def get_logger(name=None):\n    \"\"\"\n    >>> log = get_logger()\n    >>> log.info('test')\n\n    >>> log = get_logger('test2')\n    >>> log.info('test2')\n    \"\"\"\n    _ensure_configured()\n\n    if not name:\n        name = _namespace_from_calling_context()\n\n    return logging.getLogger(name)", "is_method": false, "function_description": "Provides a properly configured Python logger instance, automatically naming it based on the calling context if unspecified. This simplifies obtaining loggers for various parts of an application."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/log.py", "function": "logger_level", "line_number": 163, "body": "def logger_level(logger, level):\n    \"\"\"Set logger level to `level` within a context block. Don't use this except for debugging please, it's gross.\"\"\"\n    initial = logger.level\n    logger.level = level\n    try:\n        yield\n    finally:\n        logger.level = initial", "is_method": false, "function_description": "This function temporarily sets a logger's level for a specific code block and restores it afterward. It's designed for debugging to control log verbosity."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "format_dict_recursively", "line_number": 178, "body": "def format_dict_recursively(\n        mapping, raise_unresolvable=True, strip_unresolvable=False, conversions={\n            'True': True,\n            'False': False\n        }\n):\n    \"\"\"Format each string value of dictionary using values contained within\n    itself, keeping track of dependencies as required.\n\n    Also converts any formatted values according to conversions dict.\n\n    Example:\n\n    >>> from pprint import pprint as pp\n    >>> c = dict(wat='wat{omg}', omg=True)\n    >>> pp(format_dict_recursively(c))\n    {'omg': True, 'wat': 'watTrue'}\n\n    Dealing with missing (unresolvable) keys in format strings:\n\n    >>> from pprint import pprint as pp\n    >>> c = dict(wat='wat{omg}', omg=True, fail='no{whale}')\n    >>> format_dict_recursively(c)\n    Traceback (most recent call last):\n        ...\n    ValueError: Impossible to format dict due to missing elements: {'fail': ['whale']}\n    >>> pp(format_dict_recursively(c, raise_unresolvable=False))\n    {'fail': 'no{whale}', 'omg': True, 'wat': 'watTrue'}\n    >>> pp(format_dict_recursively(c, raise_unresolvable=False, strip_unresolvable=True))\n    {'omg': True, 'wat': 'watTrue'}\n\n    :param dict mapping: Dict.\n    :param bool raise_unresolvable: Upon True, raises ValueError upon an unresolvable key.\n    :param bool strip_unresolvable: Upon True, strips unresolvable keys.\n    :param dict conversions: Mapping of {from: to}.\n    \"\"\"\n    if conversions is None:\n        conversions = {}\n\n    ret = {}\n\n    # Create dependency mapping\n    deps = {}\n    for k, v in mapping.items():\n        # Do not include multiline values in this to avoid KeyErrors on actual\n        # .format below\n        if isinstance(v, six.string_types) and '\\n' not in v:\n            # Map key -> [*deps]\n            # This is a bit naive, but it works well.\n            deps[k] = re.findall(r'\\{(\\w+)\\}', v)\n        else:\n            ret[k] = v\n\n    while len(ret) != len(mapping):\n        ret_key_count_at_start = len(ret)\n        sret = set(ret)\n        keys = set(mapping) - sret\n\n        for k in keys:\n            needed = (x not in ret for x in deps[k])\n            if any(needed):\n                continue\n\n            ret[k] = mapping[k].format(**ret)\n\n            if ret[k] in conversions:\n                ret[k] = conversions[ret[k]]\n\n        # We have done all that we can here.\n        if ret_key_count_at_start == len(ret):\n            if not raise_unresolvable:\n                if not strip_unresolvable:\n                    # backfill\n                    ret.update({k: mapping[k] for k in keys})\n                break\n\n            missing = {k: [x for x in deps[k] if x not in ret]}\n            raise ValueError('Impossible to format dict due to missing elements: %r' % missing)\n\n    return ret", "is_method": false, "function_description": "Recursively formats string values within a dictionary by resolving internal references. It handles dependencies and applies optional type conversions to the formatted results."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__repr__", "line_number": 60, "body": "def __repr__(self):\n        if not self.__fancy_repr:\n            return '%s' % dict(self)\n\n        mapping = self.__mapping\n        if self.__dictify_repr:\n            mapping = dict(mapping)\n\n        return '<%s %s>' % (self.__class__.__name__, mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Provides a configurable string representation of the proxy, showing its underlying mapping for debugging and inspection purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "_set_mapping", "line_number": 70, "body": "def _set_mapping(self, mapping):\n        self.__mapping = mapping", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Internally sets or updates the underlying mutable mapping object that this proxy class operates on."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__contains__", "line_number": 73, "body": "def __contains__(self, item):\n        return item in self.__mapping", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "This method determines if an item is present within the proxy's encapsulated mapping. It enables the use of the 'in' operator for membership testing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getitem__", "line_number": 76, "body": "def __getitem__(self, item):\n        return self.__mapping[item]", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Provides dictionary-style retrieval of items from the internal wrapped mapping. It enables direct read access to the proxied data by key."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 79, "body": "def __setitem__(self, key, value):\n        self.__mapping[key] = value", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Allows setting new key-value pairs or updating existing ones in the underlying mapping. This enables the proxy object to behave like a standard mutable mapping for item assignment."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__delitem__", "line_number": 82, "body": "def __delitem__(self, key):\n        del self.__mapping[key]", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Enables item deletion by key for the `ProxyMutableMapping` instance. It delegates the deletion operation to an encapsulated internal mapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__iter__", "line_number": 85, "body": "def __iter__(self):\n        return iter(self.__mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "Enables direct iteration over the `ProxyMutableMapping` object. It provides access to the keys of its encapsulated mapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__len__", "line_number": 88, "body": "def __len__(self):\n        return len(self.__mapping)", "is_method": true, "class_name": "ProxyMutableMapping", "function_description": "This method provides the standard `len()` behavior for the proxy mapping. It returns the number of items contained within the proxied collection."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_allowed__", "line_number": 101, "body": "def __key_allowed__(self, key):\n        return True", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Determines if a given key is allowed in the mapping. This default implementation always permits all keys without restriction."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__iter__", "line_number": 104, "body": "def __iter__(self):\n        orig_iter = super(HookableProxyMutableMapping, self).__iter__()\n        return (self.__key_remove_prefix__(key) for key in orig_iter if self.__key_allowed__(key))", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Enables iteration over the proxy mapping. It provides a filtered and transformed view of the underlying keys by removing prefixes and checking if they are allowed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__contains__", "line_number": 108, "body": "def __contains__(self, item):\n        item = self.__key_trans__(item, contains=True)\n        return super(HookableProxyMutableMapping, self).__contains__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "This method determines if a key is present in the mapping. It first applies a transformation to the key, enabling custom lookup behaviors before delegating the containment check."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getitem__", "line_number": 112, "body": "def __getitem__(self, item):\n        item = self.__key_trans__(item, get=True)\n        return super(HookableProxyMutableMapping, self).__getitem__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Enables dictionary-like item retrieval for the proxy mapping. It transparently transforms the provided key before fetching the corresponding value from the underlying storage."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 116, "body": "def __setitem__(self, item, value):\n        item = self.__key_trans__(item, store=True)\n        return super(HookableProxyMutableMapping, self).__setitem__(item, value)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Sets a key-value pair in the mapping after applying a specific transformation to the key. This extends standard item assignment with custom key processing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__delitem__", "line_number": 120, "body": "def __delitem__(self, item):\n        item = self.__key_trans__(item, delete=True)\n        return super(HookableProxyMutableMapping, self).__delitem__(item)", "is_method": true, "class_name": "HookableProxyMutableMapping", "function_description": "Removes an item from the underlying mapping. It first applies a transformation to the key, enabling custom key handling before deletion."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_trans__", "line_number": 143, "body": "def __key_trans__(self, key, store=False, get=False, contains=False, delete=False):\n        if store:\n            return self.__key_remove_prefix__(key)\n        return self.__key_add_prefix__(key)", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "This internal method transforms keys for a prefixed mapping, adding a prefix for retrieval or removing it for storage. It ensures consistent key representation for operations within the mapping."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_allowed__", "line_number": 148, "body": "def __key_allowed__(self, key):\n        if self.__only_prefixed:\n            if isinstance(key, six.string_types):\n                if not key.startswith(self.__prefix):\n                    return False\n            else:\n                return False\n        return True", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Determines if a given key is valid for the mapping, enforcing a configured prefix requirement for string keys if enabled. This ensures only properly prefixed keys can be used."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_add_prefix__", "line_number": 157, "body": "def __key_add_prefix__(self, key):\n        return self.__prefix + key", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Provides a utility to prepend a stored prefix to a given key string. This ensures keys within the `PrefixedProxyMutableMapping` adhere to a consistent naming scheme."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__key_remove_prefix__", "line_number": 160, "body": "def __key_remove_prefix__(self, key):\n        return key[self.__prefix_len:]", "is_method": true, "class_name": "PrefixedProxyMutableMapping", "function_description": "Removes the object's configured prefix from the start of a given key string. This normalizes keys for internal operations within the `PrefixedProxyMutableMapping`."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 168, "body": "def __setitem__(self, key, val):\n        if isinstance(val, dict) and key in self:\n            self._unique += 1\n            key += str(self._unique)\n        dict.__setitem__(self, key, val)", "is_method": true, "class_name": "MultiDict", "function_description": "Enables item assignment for `MultiDict`. When assigning a dictionary value to an existing key, it generates a unique key to store the new item, preventing overwrites."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__getattr__", "line_number": 313, "body": "def __getattr__(self, key):\n        if not key.startswith('_'):\n            try:\n                value = self.__mapping[key]\n\n                if self.__recursion and isinstance(value, collections.Mapping) and not isinstance(value, self._wrap_as):\n                    value = self.__class__(value)\n\n                return value\n            except KeyError:\n                # in py3 I'd chain these\n                raise AttributeError(key)", "is_method": true, "class_name": "ProxyMutableAttrDict", "function_description": "Enables attribute-style retrieval of dictionary values for the `ProxyMutableAttrDict` instance. It also recursively converts nested mappings into `ProxyMutableAttrDict` objects for deep attribute access."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setattr__", "line_number": 326, "body": "def __setattr__(self, key, value):\n        if not key.startswith('_'):\n            if self.__recursion and isinstance(value, collections.Mapping) and not isinstance(value, self._wrap_as):\n                value = self.__class__(value)\n\n            try:\n                self[key] = value\n            except KeyError:\n                # in py3 I'd chain these\n                raise AttributeError(key)\n\n        return super(ProxyMutableAttrDict, self).__setattr__(key, value)", "is_method": true, "class_name": "ProxyMutableAttrDict", "function_description": "This method enables attribute-style assignment for a dictionary-like object. It recursively converts assigned dictionary values into `ProxyMutableAttrDict` instances and routes assignments to dictionary item updates."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "_handle_pid", "line_number": 378, "body": "def _handle_pid(self, new_pid=os.getpid):\n        if callable(new_pid):\n            new_pid = new_pid()\n\n        if self.__pid__ != new_pid:\n            self.__pid__, self.__mapping = new_pid, self.__mapping_factory()\n            self._set_mapping(self.__mapping)", "is_method": true, "class_name": "ProcessLocal", "function_description": "This method of ProcessLocal synchronizes the instance's state with the current process. It detects PID changes and resets process-specific internal data, ensuring integrity in multiprocessing environments."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__setitem__", "line_number": 394, "body": "def __setitem__(self, key, value):\n        if key in self:\n            del self[key]\n\n        return collections.OrderedDict.__setitem__(self, key, value)", "is_method": true, "class_name": "LastUpdatedOrderedDict", "function_description": "Sets or updates an item, moving existing keys to the end of the dictionary. This maintains an order based on the last time an item was set."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__repr__", "line_number": 409, "body": "def __repr__(self):\n        return '%s(%r)' % (self.__class__.__name__, collections.OrderedDict(self))", "is_method": true, "class_name": "OrderedCounter", "function_description": "Provides an unambiguous string representation of the OrderedCounter instance. It shows the class name and its ordered contents, primarily for debugging and object inspection."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/mappings.py", "function": "__reduce__", "line_number": 412, "body": "def __reduce__(self):\n        return self.__class__, (collections.OrderedDict(self), )", "is_method": true, "class_name": "OrderedCounter", "function_description": "Enables the serialization of an `OrderedCounter` object for pickling. It specifies how to reconstruct the object by preserving its ordered contents during deserialization."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "cachedmethod", "line_number": 20, "body": "def cachedmethod(cache, key=_default, lock=None, typed=_default, cached_exception=None):\n    \"\"\"Decorator to wrap a class or instance method with a memoizing\n    callable that saves results in a cache.\n\n    You can also specify a cached exception to cache and re-throw as well.\n\n    Originally from cachetools, but modified to support caching certain exceptions.\n    \"\"\"\n    if key is not _default and not callable(key):\n        key, typed = _default, key\n    if typed is not _default:\n        warnings.warn(\n            \"Passing 'typed' to cachedmethod() is deprecated, \"\n            \"use 'key=typedkey' instead\", DeprecationWarning, 2\n        )\n\n    def decorator(method):\n        # pass method to default key function for backwards compatibilty\n        if key is _default:\n            makekey = functools.partial(cachetools.typedkey if typed else cachetools.hashkey, method)\n        else:\n            makekey = key  # custom key function always receive method args\n\n        @six.wraps(method)\n        def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret\n\n        # deprecated wrapper attribute\n        def getter(self):\n            warnings.warn('%s.cache is deprecated' % method.__name__, DeprecationWarning, 2)\n            return cache(self)\n\n        wrapper.cache = getter\n        return wrapper\n\n    return decorator", "is_method": false, "function_description": "A decorator that memoizes class or instance method results and specified exceptions. It avoids redundant computations, significantly improving method performance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "lazyproperty", "line_number": 91, "body": "def lazyproperty(fn):\n    \"\"\"\n    Lazy/Cached property.\n    \"\"\"\n    attr_name = '_lazy_' + fn.__name__\n\n    @property\n    def _lazyprop(self):\n        if not hasattr(self, attr_name):\n            setattr(self, attr_name, fn(self))\n        return getattr(self, attr_name)\n\n    return _lazyprop", "is_method": false, "function_description": "This decorator creates a property that is computed only once upon first access, then caches and returns the result for subsequent calls. It optimizes performance for expensive attribute computations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "throw", "line_number": 14, "body": "def throw(self):\n        raise self.ex", "is_method": true, "class_name": "CachedException", "function_description": "Re-raises the exception previously stored within this `CachedException` instance. It provides a mechanism to defer and then propagate an error."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "decorator", "line_number": 36, "body": "def decorator(method):\n        # pass method to default key function for backwards compatibilty\n        if key is _default:\n            makekey = functools.partial(cachetools.typedkey if typed else cachetools.hashkey, method)\n        else:\n            makekey = key  # custom key function always receive method args\n\n        @six.wraps(method)\n        def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret\n\n        # deprecated wrapper attribute\n        def getter(self):\n            warnings.warn('%s.cache is deprecated' % method.__name__, DeprecationWarning, 2)\n            return cache(self)\n\n        wrapper.cache = getter\n        return wrapper", "is_method": false, "function_description": "This decorator provides a caching mechanism for class methods, storing and retrieving their results to improve performance. It executes the method only when the result is not already cached."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "_lazyprop", "line_number": 98, "body": "def _lazyprop(self):\n        if not hasattr(self, attr_name):\n            setattr(self, attr_name, fn(self))\n        return getattr(self, attr_name)", "is_method": false, "function_description": "This method provides a lazy property, computing an attribute's value only when first accessed. It caches the result, ensuring subsequent calls retrieve the stored value efficiently without re-computation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "wrapper", "line_number": 44, "body": "def wrapper(self, *args, **kwargs):\n            c = cache(self)\n            ret = _sentinel\n\n            if c is not None:\n                k = makekey(self, *args, **kwargs)\n                try:\n                    if lock is not None:\n                        with lock(self):\n                            ret = c[k]\n                    else:\n                        ret = c[k]\n                except KeyError:\n                    pass  # key not found\n\n            if ret is _sentinel:\n                try:\n                    ret = method(self, *args, **kwargs)\n                except cached_exception as e:\n                    ret = CachedException(e)\n\n                if c is not None:\n                    try:\n                        if lock is not None:\n                            with lock(self):\n                                c[k] = ret\n                        else:\n                            c[k] = ret\n                    except ValueError:\n                        pass  # value too large\n\n            if isinstance(ret, CachedException):\n                ret()\n            else:\n                return ret", "is_method": false, "function_description": "Provides a caching layer for a method. It retrieves results from a cache or, if not found, executes the method, stores its output (including exceptions), and returns it, ensuring efficient re-use of computations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/memo.py", "function": "getter", "line_number": 81, "body": "def getter(self):\n            warnings.warn('%s.cache is deprecated' % method.__name__, DeprecationWarning, 2)\n            return cache(self)", "is_method": false, "function_description": "Provides deprecated access to a cache, signaling that its use is no longer recommended."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__repr__", "line_number": 16, "body": "def __repr__(self):\n        return '{cls_name}({name})'.format(cls_name=self.__class__.__name__, name=self.name)", "is_method": true, "class_name": "Timer", "function_description": "Provides an unambiguous, reconstructible string representation of the Timer object. This is useful for debugging and logging its state."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__enter__", "line_number": 19, "body": "def __enter__(self):\n        self.start = time.time()\n        return self", "is_method": true, "class_name": "Timer", "function_description": "This method initializes the timer, recording the start time when the `Timer` object is entered within a `with` statement. It sets up the context for measuring elapsed time."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/timers.py", "function": "__exit__", "line_number": 23, "body": "def __exit__(self, *args):\n        self.end = time.time()\n        self.secs = self.end - self.start\n        self.msecs = self.secs * 1000  # millisecs\n\n        if self.verbose:\n            _LOG.debug('%s: Elapsed time: %f ms', self, self.msecs)", "is_method": true, "class_name": "Timer", "function_description": "This method completes the timing operation when exiting a `with` block. It calculates and optionally logs the total elapsed time in milliseconds."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/rand.py", "function": "rand_hex", "line_number": 4, "body": "def rand_hex(length=8):\n    \"\"\"\n    Create a random hex string of a specific length performantly.\n\n    :param int length: length of hex string to generate\n    :return: random hex string\n    \"\"\"\n    return '%0{}x'.format(length) % random.randrange(16**length)", "is_method": false, "function_description": "Generates a random hexadecimal string of a specified length. This utility is useful for creating unique identifiers, tokens, or temporary names."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/excs.py", "function": "ok", "line_number": 5, "body": "def ok(*exceptions):\n    \"\"\"Context manager to pass exceptions.\n    :param exceptions: Exceptions to pass\n    \"\"\"\n    try:\n        yield\n    except Exception as e:\n        if isinstance(e, exceptions):\n            pass\n        else:\n            raise e", "is_method": false, "function_description": "Provides a context manager to silently ignore specific exceptions within its block. It ensures other unexpected exceptions are still raised."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/path.py", "function": "join_each", "line_number": 4, "body": "def join_each(parent, iterable):\n    for p in iterable:\n        yield os.path.join(parent, p)", "is_method": false, "function_description": "Generates full file or directory paths by joining a parent path with each item in an iterable. This generator is useful for constructing a list of complete paths."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "multiplex", "line_number": 5, "body": "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues", "is_method": false, "function_description": "Converts a single input queue into multiple output queues, duplicating each item across all of them. This enables broadcasting a stream of data to several independent consumers."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "push", "line_number": 25, "body": "def push(in_q, out_q):\n    while True:\n        x = in_q.get()\n        out_q.put(x)", "is_method": false, "function_description": "Continuously transfers items from an input queue to an output queue. This function acts as a simple data relay, forwarding elements between different processing stages."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "merge", "line_number": 31, "body": "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q", "is_method": false, "function_description": "This function merges items from multiple input queues into a single output queue. It provides a unified data stream for concurrent processing."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/queues.py", "function": "f", "line_number": 13, "body": "def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)", "is_method": false, "function_description": "Continuously retrieves items from an input queue and broadcasts each item to multiple output queues. This function acts as a message distributor or fan-out mechanism."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "lazyperclassproperty", "line_number": 25, "body": "def lazyperclassproperty(fn):\n    \"\"\"\n    Lazy/Cached class property that stores separate instances per class/inheritor so there's no overlap.\n    \"\"\"\n\n    @classproperty\n    def _lazyclassprop(cls):\n        attr_name = '_%s_lazy_%s' % (cls.__name__, fn.__name__)\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, fn(cls))\n        return getattr(cls, attr_name)\n\n    return _lazyclassprop", "is_method": false, "function_description": "Decorator that creates a lazy, cached class property. It ensures each class in an inheritance hierarchy has its own distinct, computed-once value for the property, preventing overlap."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "lazyclassproperty", "line_number": 40, "body": "def lazyclassproperty(fn):\n    \"\"\"\n    Lazy/Cached class property.\n    \"\"\"\n    attr_name = '_lazy_' + fn.__name__\n\n    @classproperty\n    def _lazyclassprop(cls):\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, fn(cls))\n        return getattr(cls, attr_name)\n\n    return _lazyclassprop", "is_method": false, "function_description": "This decorator creates a class property whose value is computed only upon first access. It then caches this result directly on the class for all subsequent retrievals, ensuring efficient, lazy evaluation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "__get__", "line_number": 9, "body": "def __get__(self, obj, owner):\n        return self.f(owner)", "is_method": true, "class_name": "roclassproperty", "function_description": "Allows an attribute to behave as a read-only property of a class. It retrieves the property's value by executing a bound function on the class."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "__set__", "line_number": 21, "body": "def __set__(self, obj, value):\n        return self.func(obj, value)", "is_method": true, "class_name": "setterproperty", "function_description": "Manages attribute assignment for objects, ensuring a custom setter function is called when a `setterproperty` attribute receives a new value. It enables controlled attribute modification."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/props.py", "function": "_lazyclassprop", "line_number": 47, "body": "def _lazyclassprop(cls):\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, fn(cls))\n        return getattr(cls, attr_name)", "is_method": false, "function_description": "This internal helper creates a lazy class property. It computes and sets the property's value on the class only upon its first access, caching it for subsequent retrievals."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/tlds.py", "function": "split_domain_into_subdomains", "line_number": 11, "body": "def split_domain_into_subdomains(domain, split_tld=False):\n    \"\"\"\n    Walks up a domain by subdomain.\n\n    >>> split_domain_into_subdomains('this.is.a.test.skywww.net')\n    ['this.is.a.test.skywww.net', 'is.a.test.skywww.net', 'a.test.skywww.net', 'test.skywww.net', 'skywww.net']\n\n    \"\"\"\n    import tldextract\n\n    # Requires unicode\n    domain = ensure_decoded_text(domain)\n\n    # Do not request latest TLS list on init == suffix_list_urls=False\n    global _tldex\n    if _tldex is None:\n        _tldex = tldextract.TLDExtract(suffix_list_urls=False)\n\n    tx = _tldex(domain)\n\n    domains = []\n    if tx.subdomain:\n        domains.extend(tx.subdomain.split('.'))\n\n    # tx.registered_domain returns only if domain AND suffix are not none\n    # There are cases where we have domain and not suffix; ie short hostnames\n    registered_domain = [tx.domain]\n    if tx.suffix:\n        registered_domain.append(tx.suffix)\n\n    if split_tld:\n        domains.extend(registered_domain)\n    else:\n        domains.append('.'.join(registered_domain))\n\n    # Musical chairs. Change places!\n    domains.reverse()\n\n    def join_dom(a, b):\n        return '.'.join([b, a])\n\n    # Take each part and add it to the previous part, returning all results\n    domains = list(accumulate(domains, func=join_dom))\n    # Change places!\n    domains.reverse()\n\n    return domains", "is_method": false, "function_description": "Generates a list of progressively shorter domain strings by removing one subdomain component at a time. It effectively walks up the domain hierarchy from a fully qualified domain name."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/tlds.py", "function": "join_dom", "line_number": 49, "body": "def join_dom(a, b):\n        return '.'.join([b, a])", "is_method": false, "function_description": "Joins two strings with a dot, placing the second string before the first. This creates hierarchical identifiers, such as domain names."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__setattr__", "line_number": 8, "body": "def __setattr__(self, key, value):\n        obj = self.__dict__.get(key, None)\n        if type(obj) is classproperty:\n            return obj.__set__(self, value)\n        return super().__setattr__(key, value)", "is_method": true, "class_name": "ClassPropertyMeta", "function_description": "This method customizes attribute assignment for classes managed by `ClassPropertyMeta`. It enables `classproperty` descriptors to control how their values are set, rather than direct assignment."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__get__", "line_number": 58, "body": "def __get__(self, instance, owner=None):\n        if not issubclass(type(owner), ClassPropertyMeta):\n            raise TypeError(f\"Class {owner} does not extend from the required \" f\"ClassPropertyMeta metaclass\")\n        return self.fget.__get__(None, owner)()", "is_method": true, "class_name": "rwclassproperty", "function_description": "Provides the dynamic value of a class-level property by executing its registered getter function. Ensures proper metaclass usage for class property management."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "__set__", "line_number": 63, "body": "def __set__(self, owner, value):\n        if not self.fset:\n            raise AttributeError(\"can't set attribute\")\n        if type(owner) is not ClassPropertyMeta:\n            owner = type(owner)\n        return self.fset.__get__(None, owner)(value)", "is_method": true, "class_name": "rwclassproperty", "function_description": "Provides the mechanism to set a read-write class property. It invokes the designated setter function on the class, allowing direct assignment to the property."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "setter", "line_number": 70, "body": "def setter(self, fset):\n        self.fset = self._fix_function(fset)\n        return self", "is_method": true, "class_name": "rwclassproperty", "function_description": "Configures the setter function for the class property, defining how the property's value is modified upon assignment."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "_fix_function", "line_number": 77, "body": "def _fix_function(cls, fn):\n        if not isinstance(fn, cls._fn_types):\n            raise TypeError(\"Getter or setter must be a function\")\n        # Always wrap in classmethod so we can call its __get__ and not\n        # have to deal with difference between raw functions.\n        if not isinstance(fn, (classmethod, staticmethod)):\n            return classmethod(fn)\n        return fn", "is_method": true, "class_name": "rwclassproperty", "function_description": "Normalizes a function (e.g., getter/setter) by validating its type and ensuring it's a `classmethod`. This prepares functions for consistent class-level property handling within `rwclassproperty`."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_get_set", "line_number": 95, "body": "def test_get_set(self):\n        get_only_cls = MagicMock()\n        get_set_get_cls = MagicMock()\n        get_set_set_cls = MagicMock()\n\n        class Z(object, metaclass=classproperty.meta):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                get_only_cls(cls)\n                return sentinel.get_only\n\n            @classproperty\n            def get_set(cls):\n                get_set_get_cls(cls)\n                return cls._get_set\n\n            @get_set.setter\n            def get_set(cls, value):\n                get_set_set_cls(cls)\n                cls._get_set = value\n\n        for c, msg in [(Z, \"class\"), (Z(), \"instance\")]:\n            with self.subTest(msg=msg):\n                # Reset\n                Z._get_set = sentinel.nothing\n\n                # Test get_only\n                self.assertEqual(sentinel.get_only, c.get_only)\n                get_only_cls.assert_called_once_with(Z)\n                get_only_cls.reset_mock()\n\n                # Should return our initial \"nothing\" value\n                self.assertEqual(sentinel.nothing, c.get_set)\n                get_set_get_cls.assert_called_once_with(Z)\n                get_set_get_cls.reset_mock()\n\n                # Now test the set\n                c.get_set = sentinel.get_set_val\n                get_set_set_cls.assert_called_once_with(Z)\n                get_set_set_cls.reset_mock()\n\n                self.assertEqual(sentinel.get_set_val, c.get_set)\n                get_set_get_cls.assert_called_once_with(Z)\n                get_set_get_cls.reset_mock()", "is_method": true, "class_name": "TestClassProperty", "function_description": "This test method verifies the correct behavior of the `classproperty` decorator. It ensures both getter-only and getter-setter class properties function as expected when accessed via class or instance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_read_only", "line_number": 142, "body": "def test_read_only(self):\n        class Z(object, metaclass=classproperty.meta):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                return sentinel.get_only\n\n        self.assertEqual(sentinel.get_only, Z.get_only)\n        with self.assertRaises(AttributeError):\n            Z.get_only = 123", "is_method": true, "class_name": "TestClassProperty", "function_description": "This test method verifies that a `classproperty` is read-only. It asserts that class properties can be accessed but cannot be modified after their definition."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "test_proper_metaclass", "line_number": 154, "body": "def test_proper_metaclass(self):\n        class Z(object):\n            _get_set = sentinel.nothing\n\n            @classproperty\n            def get_only(cls):\n                return sentinel.get_only\n\n        with self.assertRaises(TypeError):\n            self.assertEqual(\"should not resolve\", Z.get_only)", "is_method": true, "class_name": "TestClassProperty", "function_description": "This unit test verifies the `@classproperty` decorator's behavior. It asserts that attempting to access a specific class property raises a `TypeError` as expected, validating its error handling."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_only", "line_number": 147, "body": "def get_only(cls):\n                return sentinel.get_only", "is_method": true, "class_name": "Z", "function_description": "Provides a unique, singleton marker object (`sentinel.get_only`) for internal use. This object typically signifies a specific operational mode or default behavior."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/ext/rwclassproperty.py", "function": "get_only", "line_number": 159, "body": "def get_only(cls):\n                return sentinel.get_only", "is_method": true, "class_name": "Z", "function_description": "Provides a specific sentinel object, `sentinel.get_only`, for use as a unique flag or constant within the system."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "make_lazy", "line_number": 24, "body": "def make_lazy(module_path):\n    \"\"\"\n    Mark that this module should not be imported until an\n    attribute is needed off of it.\n    \"\"\"\n    sys_modules = sys.modules  # cache in the locals\n\n    # store our 'instance' data in the closure.\n    module = NonLocal(None)\n\n    class LazyModule(_LazyModuleMarker):\n        \"\"\"\n        A standin for a module to prevent it from being imported\n        \"\"\"\n        def __mro__(self):\n            \"\"\"\n            Override the __mro__ to fool `isinstance`.\n            \"\"\"\n            # We don't use direct subclassing because `ModuleType` has an\n            # incompatible metaclass base with object (they are both in c)\n            # and we are overridding __getattribute__.\n            # By putting a __mro__ method here, we can pass `isinstance`\n            # checks without ever invoking our __getattribute__ function.\n            return (LazyModule, ModuleType)\n\n        def __getattribute__(self, attr):\n            \"\"\"\n            Override __getattribute__ to hide the implementation details.\n            \"\"\"\n            if module.value is None:\n                del sys_modules[module_path]\n                module.value = __import__(module_path)\n\n                sys_modules[module_path] = __import__(module_path)\n\n            return getattr(module.value, attr)\n\n    sys_modules[module_path] = LazyModule()", "is_method": false, "function_description": "Defers the import of a specified module until one of its attributes is accessed. This optimizes application startup time and reduces memory consumption by loading modules only when needed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "__mro__", "line_number": 38, "body": "def __mro__(self):\n            \"\"\"\n            Override the __mro__ to fool `isinstance`.\n            \"\"\"\n            # We don't use direct subclassing because `ModuleType` has an\n            # incompatible metaclass base with object (they are both in c)\n            # and we are overridding __getattribute__.\n            # By putting a __mro__ method here, we can pass `isinstance`\n            # checks without ever invoking our __getattribute__ function.\n            return (LazyModule, ModuleType)", "is_method": true, "class_name": "LazyModule", "function_description": "Overrides the Method Resolution Order to make `LazyModule` instances appear as `ModuleType` for `isinstance` checks. This allows type validation without invoking `__getattribute__`."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/simple_import.py", "function": "__getattribute__", "line_number": 49, "body": "def __getattribute__(self, attr):\n            \"\"\"\n            Override __getattribute__ to hide the implementation details.\n            \"\"\"\n            if module.value is None:\n                del sys_modules[module_path]\n                module.value = __import__(module_path)\n\n                sys_modules[module_path] = __import__(module_path)\n\n            return getattr(module.value, attr)", "is_method": true, "class_name": "LazyModule", "function_description": "This method transparently loads the module on-demand when an attribute is accessed. It ensures the actual module is imported only upon first use, then retrieves the requested attribute."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "lazy_compile", "line_number": 165, "body": "def lazy_compile(*args, **kwargs):\n    \"\"\"Create a proxy object which will compile the regex on demand.\n\n    :return: a LazyRegex proxy object.\n    \"\"\"\n    return LazyRegex(args, kwargs)", "is_method": false, "function_description": "Creates a proxy object that delays regular expression compilation until it is accessed, optimizing performance."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "install_lazy_compile", "line_number": 173, "body": "def install_lazy_compile():\n    \"\"\"Make lazy_compile the default compile mode for regex compilation.\n\n    This overrides re.compile with lazy_compile. To restore the original\n    functionality, call reset_compile().\n    \"\"\"\n    re.compile = lazy_compile", "is_method": false, "function_description": "Configures the `re` module to use `lazy_compile` as the default method for regular expression compilation. This modifies global `re.compile` behavior for all subsequent regex operations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "reset_compile", "line_number": 182, "body": "def reset_compile():\n    \"\"\"Restore the original function to re.compile().\n\n    It is safe to call reset_compile() multiple times, it will always\n    restore re.compile() to the value that existed at import time.\n    Though the first call will reset back to the original (it doesn't\n    track nesting level)\n    \"\"\"\n    re.compile = _real_re_compile", "is_method": false, "function_description": "This function restores the `re.compile` function to its original state, as it was at import time. It undoes any prior modifications, ensuring consistent regular expression compilation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_format", "line_number": 39, "body": "def _format(self):\n        s = getattr(self, '_preformatted_string', None)\n        if s is not None:\n            # contains a preformatted message\n            return s\n        try:\n            fmt = self._get_format_string()\n            if fmt:\n                d = dict(self.__dict__)\n                s = fmt % d\n                # __str__() should always return a 'str' object\n                # never a 'unicode' object.\n                return s\n        except Exception as e:\n            pass # just bind to 'e' for formatting below\n        else:\n            e = None\n        return 'Unprintable exception %s: dict=%r, fmt=%r, error=%r' \\\n            % (self.__class__.__name__,\n               self.__dict__,\n               getattr(self, '_fmt', None),\n               e)", "is_method": true, "class_name": "InvalidPattern", "function_description": "This method generates a formatted string representation of the exception instance. It attempts to use a predefined format or falls back to a generic message, ensuring a printable error description."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__unicode__", "line_number": 62, "body": "def __unicode__(self):\n        u = self._format()\n        if isinstance(u, str):\n            # Try decoding the str using the default encoding.\n            u = unicode(u)\n        elif not isinstance(u, unicode):\n            # Try to make a unicode object from it, because __unicode__ must\n            # return a unicode object.\n            u = unicode(u)\n        return u", "is_method": true, "class_name": "InvalidPattern", "function_description": "Provides a Unicode string representation for the `InvalidPattern` object. It ensures the formatted string is consistently returned as a unicode object, primarily for Python 2.x compatibility."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__str__", "line_number": 73, "body": "def __str__(self):\n        s = self._format()\n        if isinstance(s, unicode):\n            s = s.encode('utf8')\n        else:\n            # __str__ must return a str.\n            s = str(s)\n        return s", "is_method": true, "class_name": "InvalidPattern", "function_description": "Provides a human-readable string representation of the `InvalidPattern` object. This method is crucial for displaying informative error messages or for logging."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__repr__", "line_number": 82, "body": "def __repr__(self):\n        return '%s(%s)' % (self.__class__.__name__, str(self))", "is_method": true, "class_name": "InvalidPattern", "function_description": "Provides a formal, unambiguous string representation of an `InvalidPattern` object. This is typically used for debugging and developer introspection."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_get_format_string", "line_number": 85, "body": "def _get_format_string(self):\n        \"\"\"Return format string for this exception or None\"\"\"\n        fmt = getattr(self, '_fmt', None)\n        if fmt is not None:\n            from bzrlib.i18n import gettext\n            return gettext(unicode(fmt))", "is_method": true, "class_name": "InvalidPattern", "function_description": "This method retrieves a localized format string associated with the `InvalidPattern` exception, or None if not set. This string is used to render the exception message."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__eq__", "line_number": 92, "body": "def __eq__(self, other):\n        if self.__class__ is not other.__class__:\n            return NotImplemented\n        return self.__dict__ == other.__dict__", "is_method": true, "class_name": "InvalidPattern", "function_description": "Compares two `InvalidPattern` objects for equality by checking if they are of the same type and have identical attribute values."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_compile_and_collapse", "line_number": 124, "body": "def _compile_and_collapse(self):\n        \"\"\"Actually compile the requested regex\"\"\"\n        self._real_regex = self._real_re_compile(*self._regex_args,\n                                                 **self._regex_kwargs)\n        for attr in self._regex_attributes_to_copy:\n            setattr(self, attr, getattr(self._real_regex, attr))", "is_method": true, "class_name": "LazyRegex", "function_description": "This internal method compiles the deferred regular expression and transfers its attributes to the `LazyRegex` object. This makes the lazy object behave as the actual compiled regex."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "_real_re_compile", "line_number": 131, "body": "def _real_re_compile(self, *args, **kwargs):\n        \"\"\"Thunk over to the original re.compile\"\"\"\n        try:\n            return _real_re_compile(*args, **kwargs)\n        except re.error as e:\n            # raise InvalidPattern instead of re.error as this gives a\n            # cleaner message to the user.\n            raise InvalidPattern('\"' + args[0] + '\" ' +str(e))", "is_method": true, "class_name": "LazyRegex", "function_description": "This method compiles a regular expression using the standard library. It converts `re.error` exceptions to `InvalidPattern` for clearer user feedback on malformed patterns."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__getstate__", "line_number": 140, "body": "def __getstate__(self):\n        \"\"\"Return the state to use when pickling.\"\"\"\n        return {\n            \"args\": self._regex_args,\n            \"kwargs\": self._regex_kwargs,\n            }", "is_method": true, "class_name": "LazyRegex", "function_description": "This method provides the necessary internal state for pickling a `LazyRegex` object. It ensures the object can be correctly serialized and deserialized."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__setstate__", "line_number": 147, "body": "def __setstate__(self, dict):\n        \"\"\"Restore from a pickled state.\"\"\"\n        self._real_regex = None\n        setattr(self, \"_regex_args\", dict[\"args\"])\n        setattr(self, \"_regex_kwargs\", dict[\"kwargs\"])", "is_method": true, "class_name": "LazyRegex", "function_description": "This method restores the configuration of a `LazyRegex` object during unpickling. It prepares the object to lazily recompile its regular expression upon first use after deserialization."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "__getattr__", "line_number": 153, "body": "def __getattr__(self, attr):\n        \"\"\"Return a member from the proxied regex object.\n\n        If the regex hasn't been compiled yet, compile it\n        \"\"\"\n        if self._real_regex is None:\n            self._compile_and_collapse()\n        # Once we have compiled, the only time we should come here\n        # is actually if the attribute is missing.\n        return getattr(self._real_regex, attr)", "is_method": true, "class_name": "LazyRegex", "function_description": "Provides transparent access to attributes of the underlying regex object. It ensures the regex is compiled on demand when any of its attributes are first accessed."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_regex.py", "function": "finditer_public", "line_number": 202, "body": "def finditer_public(pattern, string, flags=0):\n        if isinstance(pattern, LazyRegex):\n            return pattern.finditer(string)\n        else:\n            return _real_re_compile(pattern, flags).finditer(string)", "is_method": false, "function_description": "Provides an iterator over all non-overlapping matches of a regular expression pattern within a string. It supports both standard regex patterns and specialized LazyRegex objects for flexible pattern matching."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "disallow_proxying", "line_number": 194, "body": "def disallow_proxying():\n    \"\"\"Disallow lazily imported modules to be used as proxies.\n\n    Calling this function might cause problems with concurrent imports\n    in multithreaded environments, but will help detecting wasteful\n    indirection, so it should be called when executing unit tests.\n\n    Only lazy imports that happen after this call are affected.\n    \"\"\"\n    ScopeReplacer._should_proxy = False", "is_method": false, "function_description": "Disables proxying for subsequent lazy module imports. This aids in unit testing to detect wasteful indirection and improve import efficiency."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "lazy_import", "line_number": 449, "body": "def lazy_import(scope, text, lazy_import_class=None):\n    \"\"\"Create lazy imports for all of the imports in text.\n\n    This is typically used as something like::\n\n        from bzrlib.lazy_import import lazy_import\n        lazy_import(globals(), '''\n        from bzrlib import (\n            foo,\n            bar,\n            baz,\n            )\n        import bzrlib.branch\n        import bzrlib.transport\n        ''')\n\n    Then 'foo, bar, baz' and 'bzrlib' will exist as lazy-loaded\n    objects which will be replaced with a real object on first use.\n\n    In general, it is best to only load modules in this way. This is\n    because other objects (functions/classes/variables) are frequently\n    used without accessing a member, which means we cannot tell they\n    have been used.\n    \"\"\"\n    # This is just a helper around ImportProcessor.lazy_import\n    proc = ImportProcessor(lazy_import_class=lazy_import_class)\n    return proc.lazy_import(scope, text)", "is_method": false, "function_description": "Defers the actual import of modules within a given scope until they are first accessed. This technique improves application startup performance by avoiding unnecessary initial loading."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_format", "line_number": 62, "body": "def _format(self):\n        s = getattr(self, '_preformatted_string', None)\n        if s is not None:\n            # contains a preformatted message\n            return s\n        try:\n            fmt = self._get_format_string()\n            if fmt:\n                d = dict(self.__dict__)\n                s = fmt % d\n                # __str__() should always return a 'str' object\n                # never a 'unicode' object.\n                return s\n        except Exception as e:\n            pass # just bind to 'e' for formatting below\n        else:\n            e = None\n        return 'Unprintable exception %s: dict=%r, fmt=%r, error=%r' \\\n            % (self.__class__.__name__,\n               self.__dict__,\n               getattr(self, '_fmt', None),\n               e)", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "As an internal helper, this method generates a descriptive string representation of the `IllegalUseOfScopeReplacer` object's state. It robustly handles formatting, providing fallback information when issues occur."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__unicode__", "line_number": 85, "body": "def __unicode__(self):\n        u = self._format()\n        if isinstance(u, str):\n            # Try decoding the str using the default encoding.\n            u = unicode(u)\n        elif not isinstance(u, unicode):\n            # Try to make a unicode object from it, because __unicode__ must\n            # return a unicode object.\n            u = unicode(u)\n        return u", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns a Unicode string representation of the object. It ensures the output is always a Unicode type, handling various internal string formats."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__str__", "line_number": 96, "body": "def __str__(self):\n        s = self._format()\n        if isinstance(s, unicode):\n            s = s.encode('utf8')\n        else:\n            # __str__ must return a str.\n            s = str(s)\n        return s", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Returns a string representation of the `IllegalUseOfScopeReplacer` instance, suitable for display or logging. It formats the object's content and ensures proper string encoding."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__repr__", "line_number": 105, "body": "def __repr__(self):\n        return '%s(%s)' % (self.__class__.__name__, str(self))", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Provides a clear, unambiguous string representation of an `IllegalUseOfScopeReplacer` object. This is primarily for developer introspection and debugging purposes."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_get_format_string", "line_number": 108, "body": "def _get_format_string(self):\n        \"\"\"Return format string for this exception or None\"\"\"\n        fmt = getattr(self, '_fmt', None)\n        if fmt is not None:\n            from bzrlib.i18n import gettext\n            return gettext(unicode(fmt))", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "Provides the localized message format for the exception instance. It returns None if no specific format string is set."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__eq__", "line_number": 115, "body": "def __eq__(self, other):\n        if self.__class__ is not other.__class__:\n            return NotImplemented\n        return self.__dict__ == other.__dict__", "is_method": true, "class_name": "IllegalUseOfScopeReplacer", "function_description": "This method defines object equality for `IllegalUseOfScopeReplacer` instances. It returns true if both objects are of the exact same class and possess identical attribute dictionaries."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_resolve", "line_number": 151, "body": "def _resolve(self):\n        \"\"\"Return the real object for which this is a placeholder\"\"\"\n        name = object.__getattribute__(self, '_name')\n        real_obj = object.__getattribute__(self, '_real_obj')\n        if real_obj is None:\n            # No obj generated previously, so generate from factory and scope.\n            factory = object.__getattribute__(self, '_factory')\n            scope = object.__getattribute__(self, '_scope')\n            obj = factory(self, scope, name)\n            if obj is self:\n                raise IllegalUseOfScopeReplacer(name, msg=\"Object tried\"\n                    \" to replace itself, check it's not using its own scope.\")\n\n            # Check if another thread has jumped in while obj was generated.\n            real_obj = object.__getattribute__(self, '_real_obj')\n            if real_obj is None:\n                # Still no prexisting obj, so go ahead and assign to scope and\n                # return. There is still a small window here where races will\n                # not be detected, but safest to avoid additional locking.\n                object.__setattr__(self, '_real_obj', obj)\n                scope[name] = obj\n                return obj\n\n        # Raise if proxying is disabled as obj has already been generated.\n        if not ScopeReplacer._should_proxy:\n            raise IllegalUseOfScopeReplacer(\n                name, msg=\"Object already replaced, did you assign it\"\n                          \" to another variable?\")\n        return real_obj", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Core utility method of the `ScopeReplacer` class. It resolves the placeholder by providing the real object, generating it via a factory if it doesn't already exist and storing it in the scope."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__getattribute__", "line_number": 181, "body": "def __getattribute__(self, attr):\n        obj = object.__getattribute__(self, '_resolve')()\n        return getattr(obj, attr)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "This method enables dynamic attribute resolution for a `ScopeReplacer` instance, transparently redirecting all attribute access to a resolved underlying object. It allows the replacer to act as a dynamic proxy."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__setattr__", "line_number": 185, "body": "def __setattr__(self, attr, value):\n        obj = object.__getattribute__(self, '_resolve')()\n        return setattr(obj, attr, value)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "This method intercepts attribute assignments to the `ScopeReplacer` instance. It transparently redirects these assignments to a dynamically resolved underlying object, effectively providing proxy attribute setting."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "__call__", "line_number": 189, "body": "def __call__(self, *args, **kwargs):\n        obj = object.__getattribute__(self, '_resolve')()\n        return obj(*args, **kwargs)", "is_method": true, "class_name": "ScopeReplacer", "function_description": "Makes the `ScopeReplacer` instance callable, acting as a proxy. It dynamically resolves and then invokes a target object with the provided arguments at the time of the call."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_import", "line_number": 268, "body": "def _import(self, scope, name):\n        children = object.__getattribute__(self, '_import_replacer_children')\n        member = object.__getattribute__(self, '_member')\n        module_path = object.__getattribute__(self, '_module_path')\n        module_python_path = '.'.join(module_path)\n        if member is not None:\n            module = __import__(module_python_path, scope, scope, [member], level=0)\n            return getattr(module, member)\n        else:\n            module = __import__(module_python_path, scope, scope, [], level=0)\n            for path in module_path[1:]:\n                module = getattr(module, path)\n\n        # Prepare the children to be imported\n        for child_name, (child_path, child_member, grandchildren) in \\\n                children.iteritems():\n            # Using self.__class__, so that children get children classes\n            # instantiated. (This helps with instrumented tests)\n            cls = object.__getattribute__(self, '__class__')\n            cls(module.__dict__, name=child_name,\n                module_path=child_path, member=child_member,\n                children=grandchildren)\n        return module", "is_method": true, "class_name": "ImportReplacer", "function_description": "This internal method of `ImportReplacer` executes a custom import, retrieving modules or members. It then recursively prepares and injects child import replacements into the imported module's namespace."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "lazy_import", "line_number": 311, "body": "def lazy_import(self, scope, text):\n        \"\"\"Convert the given text into a bunch of lazy import objects.\n\n        This takes a text string, which should be similar to normal python\n        import markup.\n        \"\"\"\n        self._build_map(text)\n        self._convert_imports(scope)", "is_method": true, "class_name": "ImportProcessor", "function_description": "Converts import-like text into lazy import objects. It then applies these objects to a specified scope, enabling deferred module loading for improved efficiency."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_imports", "line_number": 320, "body": "def _convert_imports(self, scope):\n        # Now convert the map into a set of imports\n        for name, info in self.imports.iteritems():\n            self._lazy_import_class(scope, name=name, module_path=info[0],\n                                    member=info[1], children=info[2])", "is_method": true, "class_name": "ImportProcessor", "function_description": "Processes predefined import specifications, converting them into lazy imports within a given scope. This dynamically makes modules and classes available for use by the system.\nProcesses predefined import specifications, converting them into lazy imports within a given scope. This dynamically makes modules and classes available for use by the system."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_build_map", "line_number": 326, "body": "def _build_map(self, text):\n        \"\"\"Take a string describing imports, and build up the internal map\"\"\"\n        for line in self._canonicalize_import_text(text):\n            if line.startswith('import '):\n                self._convert_import_str(line)\n            elif line.startswith('from '):\n                self._convert_from_str(line)\n            else:\n                raise errors.InvalidImportLine(line,\n                    \"doesn't start with 'import ' or 'from '\")", "is_method": true, "class_name": "ImportProcessor", "function_description": "Parses a string containing Python import statements to build the `ImportProcessor`'s internal map, converting each import into a structured representation."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_import_str", "line_number": 337, "body": "def _convert_import_str(self, import_str):\n        \"\"\"This converts a import string into an import map.\n\n        This only understands 'import foo, foo.bar, foo.bar.baz as bing'\n\n        :param import_str: The import string to process\n        \"\"\"\n        if not import_str.startswith('import '):\n            raise ValueError('bad import string %r' % (import_str,))\n        import_str = import_str[len('import '):]\n\n        for path in import_str.split(','):\n            path = path.strip()\n            if not path:\n                continue\n            as_hunks = path.split(' as ')\n            if len(as_hunks) == 2:\n                # We have 'as' so this is a different style of import\n                # 'import foo.bar.baz as bing' creates a local variable\n                # named 'bing' which points to 'foo.bar.baz'\n                name = as_hunks[1].strip()\n                module_path = as_hunks[0].strip().split('.')\n                if name in self.imports:\n                    raise errors.ImportNameCollision(name)\n                # No children available in 'import foo as bar'\n                self.imports[name] = (module_path, None, {})\n            else:\n                # Now we need to handle\n                module_path = path.split('.')\n                name = module_path[0]\n                if name not in self.imports:\n                    # This is a new import that we haven't seen before\n                    module_def = ([name], None, {})\n                    self.imports[name] = module_def\n                else:\n                    module_def = self.imports[name]\n\n                cur_path = [name]\n                cur = module_def[2]\n                for child in module_path[1:]:\n                    cur_path.append(child)\n                    if child in cur:\n                        cur = cur[child][2]\n                    else:\n                        next = (cur_path[:], None, {})\n                        cur[child] = next\n                        cur = next[2]", "is_method": true, "class_name": "ImportProcessor", "function_description": "Converts a Python `import` string into a structured internal representation. It parses module paths, handles aliases, and builds a hierarchical map of imported names for the ImportProcessor."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_convert_from_str", "line_number": 385, "body": "def _convert_from_str(self, from_str):\n        \"\"\"This converts a 'from foo import bar' string into an import map.\n\n        :param from_str: The import string to process\n        \"\"\"\n        if not from_str.startswith('from '):\n            raise ValueError('bad from/import %r' % from_str)\n        from_str = from_str[len('from '):]\n\n        from_module, import_list = from_str.split(' import ')\n\n        from_module_path = from_module.split('.')\n\n        for path in import_list.split(','):\n            path = path.strip()\n            if not path:\n                continue\n            as_hunks = path.split(' as ')\n            if len(as_hunks) == 2:\n                # We have 'as' so this is a different style of import\n                # 'import foo.bar.baz as bing' creates a local variable\n                # named 'bing' which points to 'foo.bar.baz'\n                name = as_hunks[1].strip()\n                module = as_hunks[0].strip()\n            else:\n                name = module = path\n            if name in self.imports:\n                raise errors.ImportNameCollision(name)\n            self.imports[name] = (from_module_path, module, {})", "is_method": true, "class_name": "ImportProcessor", "function_description": "Parses a Python 'from ... import ...' statement string. It extracts and maps the imported names to their source modules, enabling an ImportProcessor to manage and resolve import declarations."}, {"file": "./dataset/RepoExec/test-apps/pytutils/pytutils/lazy/lazy_import.py", "function": "_canonicalize_import_text", "line_number": 415, "body": "def _canonicalize_import_text(self, text):\n        \"\"\"Take a list of imports, and split it into regularized form.\n\n        This is meant to take regular import text, and convert it to\n        the forms that the rest of the converters prefer.\n        \"\"\"\n        out = []\n        cur = None\n        continuing = False\n\n        for line in text.split('\\n'):\n            line = line.strip()\n            loc = line.find('#')\n            if loc != -1:\n                line = line[:loc].strip()\n\n            if not line:\n                continue\n            if cur is not None:\n                if line.endswith(')'):\n                    out.append(cur + ' ' + line[:-1])\n                    cur = None\n                else:\n                    cur += ' ' + line\n            else:\n                if '(' in line and ')' not in line:\n                    cur = line.replace('(', '')\n                else:\n                    out.append(line.replace('(', '').replace(')', ''))\n        if cur is not None:\n            raise errors.InvalidImportLine(cur, 'Unmatched parenthesis')\n        return out", "is_method": true, "class_name": "ImportProcessor", "function_description": "This private method within `ImportProcessor` standardizes raw import text. It regularizes multi-line imports and cleans up formatting for consistent downstream processing."}]