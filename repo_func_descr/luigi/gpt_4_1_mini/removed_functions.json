[{"file": "./dataset/RepoExec/test-apps/luigi/examples/top_artists_spark.py", "function": "main", "line_number": 9, "body": "def main(argv):\n    input_paths = argv[1].split(',')\n    output_path = argv[2]\n\n    spark = SparkSession.builder.getOrCreate()\n\n    streams = spark.read.option('sep', '\\t').csv(input_paths[0])\n    for stream_path in input_paths[1:]:\n        streams.union(spark.read.option('sep', '\\t').csv(stream_path))\n\n    # The second field is the artist\n    counts = streams \\\n        .map(lambda row: (row[1], 1)) \\\n        .reduceByKey(operator.add)\n\n    counts.write.option('sep', '\\t').csv(output_path)", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/execution_summary.py", "function": "_summary_dict", "line_number": 390, "body": "def _summary_dict(worker):\n    set_tasks = _partition_tasks(worker)\n    set_tasks[\"run_by_other_worker\"] = _get_run_by_other_worker(worker)\n    _populate_unknown_statuses(set_tasks)\n    return set_tasks", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/worker.py", "function": "close", "line_number": 355, "body": "def close(self):\n        pass", "is_method": true, "class_name": "SingleProcessPool", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/worker.py", "function": "join", "line_number": 358, "body": "def join(self):\n        pass", "is_method": true, "class_name": "SingleProcessPool", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task.py", "function": "disable_hard_timeout", "line_number": 208, "body": "def disable_hard_timeout(self):\n        \"\"\"\n        Override this positive integer to have different ``disable_hard_timeout`` at task level.\n        Check :ref:`scheduler-config`\n        \"\"\"\n        return None", "is_method": true, "class_name": "Task", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task.py", "function": "run", "line_number": 655, "body": "def run(self):\n        \"\"\"\n        The task run method, to be overridden in a subclass.\n\n        See :ref:`Task.run`\n        \"\"\"\n        pass", "is_method": true, "class_name": "Task", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task.py", "function": "on_success", "line_number": 678, "body": "def on_success(self):\n        \"\"\"\n        Override for doing custom completion handling for a larger class of tasks\n\n        This method gets called when :py:meth:`run` completes without raising any exceptions.\n\n        The returned value is json encoded and sent to the scheduler as the `expl` argument.\n\n        Default behavior is to send an None value\"\"\"\n        pass", "is_method": true, "class_name": "Task", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task.py", "function": "wrapped", "line_number": 260, "body": "def wrapped(callback):\n            cls._event_callbacks.setdefault(cls, {}).setdefault(event, set()).add(callback)\n            return callback", "is_method": true, "class_name": "Task", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/scheduler.py", "function": "_rpc_method", "line_number": 95, "body": "def _rpc_method(fn):\n        # If request args are passed, return this function again for use as\n        # the decorator function with the request args attached.\n        args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = inspect.getfullargspec(fn)\n        assert not varargs\n        first_arg, *all_args = args\n        assert first_arg == 'self'\n        defaults = dict(zip(reversed(all_args), reversed(defaults or ())))\n        required_args = frozenset(arg for arg in all_args if arg not in defaults)\n        fn_name = fn.__name__\n\n        @functools.wraps(fn)\n        def rpc_func(self, *args, **kwargs):\n            actual_args = defaults.copy()\n            actual_args.update(dict(zip(all_args, args)))\n            actual_args.update(kwargs)\n            if not all(arg in actual_args for arg in required_args):\n                raise TypeError('{} takes {} arguments ({} given)'.format(\n                    fn_name, len(all_args), len(actual_args)))\n            return self._request('/api/{}'.format(fn_name), actual_args, **request_args)\n\n        RPC_METHODS[fn_name] = rpc_func\n        return fn", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/scheduler.py", "function": "rpc_func", "line_number": 107, "body": "def rpc_func(self, *args, **kwargs):\n            actual_args = defaults.copy()\n            actual_args.update(dict(zip(all_args, args)))\n            actual_args.update(kwargs)\n            if not all(arg in actual_args for arg in required_args):\n                raise TypeError('{} takes {} arguments ({} given)'.format(\n                    fn_name, len(all_args), len(actual_args)))\n            return self._request('/api/{}'.format(fn_name), actual_args, **request_args)", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/scheduler.py", "function": "dep_func", "line_number": 1358, "body": "def dep_func(t):\n                return t.deps", "is_method": true, "class_name": "Scheduler", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/setup_logging.py", "function": "_cli", "line_number": 148, "body": "def _cli(cls, opts):\n        return False", "is_method": true, "class_name": "InterfaceLogging", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "exists", "line_number": 47, "body": "def exists(self):\n        \"\"\"\n        Returns ``True`` if the :py:class:`Target` exists and ``False`` otherwise.\n        \"\"\"\n        pass", "is_method": true, "class_name": "Target", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "exists", "line_number": 98, "body": "def exists(self, path):\n        \"\"\"\n        Return ``True`` if file or directory at ``path`` exist, ``False`` otherwise\n\n        :param str path: a path within the FileSystem to check for existence.\n        \"\"\"\n        pass", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "remove", "line_number": 107, "body": "def remove(self, path, recursive=True, skip_trash=True):\n        \"\"\" Remove file or directory at location ``path``\n\n        :param str path: a path within the FileSystem to remove.\n        :param bool recursive: if the path is a directory, recursively remove the directory and all\n                               of its descendants. Defaults to ``True``.\n        \"\"\"\n        pass", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "mkdir", "line_number": 116, "body": "def mkdir(self, path, parents=True, raise_if_exists=False):\n        \"\"\"\n        Create directory at location ``path``\n\n        Creates the directory at ``path`` and implicitly create parent\n        directories if they do not already exist.\n\n        :param str path: a path within the FileSystem to create as a directory.\n        :param bool parents: Create parent directories when necessary. When\n                             parents=False and the parent directory doesn't\n                             exist, raise luigi.target.MissingParentDirectory\n        :param bool raise_if_exists: raise luigi.target.FileAlreadyExists if\n                                     the folder already exists.\n        \"\"\"\n        raise NotImplementedError(\"mkdir() not implemented on {0}\".format(self.__class__.__name__))", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "isdir", "line_number": 132, "body": "def isdir(self, path):\n        \"\"\"\n        Return ``True`` if the location at ``path`` is a directory. If not, return ``False``.\n\n        :param str path: a path within the FileSystem to check as a directory.\n\n        *Note*: This method is optional, not all FileSystem subclasses implements it.\n        \"\"\"\n        raise NotImplementedError(\"isdir() not implemented on {0}\".format(self.__class__.__name__))", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "listdir", "line_number": 142, "body": "def listdir(self, path):\n        \"\"\"Return a list of files rooted in path.\n\n        This returns an iterable of the files rooted at ``path``. This is intended to be a\n        recursive listing.\n\n        :param str path: a path within the FileSystem to list.\n\n        *Note*: This method is optional, not all FileSystem subclasses implements it.\n        \"\"\"\n        raise NotImplementedError(\"listdir() not implemented on {0}\".format(self.__class__.__name__))", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "move", "line_number": 154, "body": "def move(self, path, dest):\n        \"\"\"\n        Move a file, as one would expect.\n        \"\"\"\n        raise NotImplementedError(\"move() not implemented on {0}\".format(self.__class__.__name__))", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "copy", "line_number": 180, "body": "def copy(self, path, dest):\n        \"\"\"\n        Copy a file or a directory with contents.\n        Currently, LocalFileSystem and MockFileSystem support only single file\n        copying but S3Client copies either a file or a directory as required.\n        \"\"\"\n        raise NotImplementedError(\"copy() not implemented on {0}\".\n                                  format(self.__class__.__name__))", "is_method": true, "class_name": "FileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "open", "line_number": 227, "body": "def open(self, mode):\n        \"\"\"\n        Open the FileSystem target.\n\n        This method returns a file-like object which can either be read from or written to depending\n        on the specified mode.\n\n        :param str mode: the mode `r` opens the FileSystemTarget in read-only mode, whereas `w` will\n                         open the FileSystemTarget in write mode. Subclasses can implement\n                         additional options. Using `b` is not supported; initialize with\n                         `format=Nop` instead.\n        \"\"\"\n        pass", "is_method": true, "class_name": "FileSystemTarget", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/target.py", "function": "move_to_final_destination", "line_number": 333, "body": "def move_to_final_destination(self):\n        raise NotImplementedError()", "is_method": true, "class_name": "AtomicLocalFile", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_register.py", "function": "instantiate", "line_number": 78, "body": "def instantiate():\n            return super(Register, cls).__call__(*args, **kwargs)", "is_method": true, "class_name": "Register", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/date_interval.py", "function": "to_string", "line_number": 90, "body": "def to_string(self):\n        raise NotImplementedError", "is_method": true, "class_name": "DateInterval", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/date_interval.py", "function": "from_date", "line_number": 94, "body": "def from_date(cls, d):\n        ''' Abstract class method.\n\n        For instance, ``Month.from_date(datetime.date(2012, 6, 6))`` returns a ``Month(2012, 6)``.'''\n        raise NotImplementedError", "is_method": true, "class_name": "DateInterval", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/date_interval.py", "function": "parse", "line_number": 101, "body": "def parse(cls, s):\n        ''' Abstract class method.\n\n        For instance, ``Year.parse(\"2014\")`` returns a ``Year(2014)``.'''\n        raise NotImplementedError", "is_method": true, "class_name": "DateInterval", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_scheduled", "line_number": 58, "body": "def task_scheduled(self, task):\n        pass", "is_method": true, "class_name": "TaskHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_finished", "line_number": 62, "body": "def task_finished(self, task, successful):\n        pass", "is_method": true, "class_name": "TaskHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_started", "line_number": 66, "body": "def task_started(self, task, worker_host):\n        pass", "is_method": true, "class_name": "TaskHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_scheduled", "line_number": 74, "body": "def task_scheduled(self, task):\n        pass", "is_method": true, "class_name": "NopHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_finished", "line_number": 77, "body": "def task_finished(self, task, successful):\n        pass", "is_method": true, "class_name": "NopHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/task_history.py", "function": "task_started", "line_number": 80, "body": "def task_started(self, task, worker_host):\n        pass", "is_method": true, "class_name": "NopHistory", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/parameter.py", "function": "date_format", "line_number": 361, "body": "def date_format(self):\n        \"\"\"\n        Override me with a :py:meth:`~datetime.date.strftime` string.\n        \"\"\"\n        pass", "is_method": true, "class_name": "_DateParameterBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/parameter.py", "function": "date_format", "line_number": 506, "body": "def date_format(self):\n        \"\"\"\n        Override me with a :py:meth:`~datetime.date.strftime` string.\n        \"\"\"\n        pass", "is_method": true, "class_name": "_DatetimeParameterBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/parameter.py", "function": "_timedelta", "line_number": 514, "body": "def _timedelta(self):\n        \"\"\"\n        How to move one interval of this type forward (i.e. not counting self.interval).\n        \"\"\"\n        pass", "is_method": true, "class_name": "_DatetimeParameterBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_started", "line_number": 36, "body": "def handle_task_started(self, task):\n        pass", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_failed", "line_number": 40, "body": "def handle_task_failed(self, task):\n        pass", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_disabled", "line_number": 44, "body": "def handle_task_disabled(self, task, config):\n        pass", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_done", "line_number": 48, "body": "def handle_task_done(self, task):\n        pass", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "generate_latest", "line_number": 51, "body": "def generate_latest(self):\n        return", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "configure_http_handler", "line_number": 54, "body": "def configure_http_handler(self, http_handler):\n        pass", "is_method": true, "class_name": "MetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_started", "line_number": 65, "body": "def handle_task_started(self, task):\n        pass", "is_method": true, "class_name": "NoMetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_failed", "line_number": 68, "body": "def handle_task_failed(self, task):\n        pass", "is_method": true, "class_name": "NoMetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_disabled", "line_number": 71, "body": "def handle_task_disabled(self, task, config):\n        pass", "is_method": true, "class_name": "NoMetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/metrics.py", "function": "handle_task_done", "line_number": 74, "body": "def handle_task_done(self, task):\n        pass", "is_method": true, "class_name": "NoMetricsCollector", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/format.py", "function": "pipe_reader", "line_number": 347, "body": "def pipe_reader(cls, input_pipe):\n        raise NotImplementedError()", "is_method": true, "class_name": "Format", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/format.py", "function": "pipe_writer", "line_number": 351, "body": "def pipe_writer(cls, output_pipe):\n        raise NotImplementedError()", "is_method": true, "class_name": "Format", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/mock.py", "function": "mkdir", "line_number": 92, "body": "def mkdir(self, path, parents=True, raise_if_exists=False):\n        \"\"\"\n        mkdir is a noop.\n        \"\"\"\n        pass", "is_method": true, "class_name": "MockFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/mock.py", "function": "write", "line_number": 137, "body": "def write(self, data):\n                if mock_target._mirror_on_stderr:\n                    if self._write_line:\n                        sys.stderr.write(fn + \": \")\n                    if bytes:\n                        sys.stderr.write(data.decode('utf8'))\n                    else:\n                        sys.stderr.write(data)\n                    if (data[-1]) == '\\n':\n                        self._write_line = True\n                    else:\n                        self._write_line = False\n                super(Buffer, self).write(data)", "is_method": true, "class_name": "Buffer", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "datetime_to_parameter", "line_number": 125, "body": "def datetime_to_parameter(self, dt):\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "parameter_to_datetime", "line_number": 128, "body": "def parameter_to_datetime(self, p):\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "datetime_to_parameters", "line_number": 131, "body": "def datetime_to_parameters(self, dt):\n        \"\"\"\n        Given a date-time, will produce a dictionary of of-params combined with the ranged task parameter\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "parameters_to_datetime", "line_number": 137, "body": "def parameters_to_datetime(self, p):\n        \"\"\"\n        Given a dictionary of parameters, will extract the ranged task parameter value\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "moving_start", "line_number": 143, "body": "def moving_start(self, now):\n        \"\"\"\n        Returns a datetime from which to ensure contiguousness in the case when\n        start is None or unfeasibly far back.\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "moving_stop", "line_number": 150, "body": "def moving_stop(self, now):\n        \"\"\"\n        Returns a datetime till which to ensure contiguousness in the case when\n        stop is None or unfeasibly far forward.\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/range.py", "function": "finite_datetimes", "line_number": 157, "body": "def finite_datetimes(self, finite_start, finite_stop):\n        \"\"\"\n        Returns the individual datetimes in interval [finite_start, finite_stop)\n        for which task completeness should be required, as a sorted list.\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "RangeBase", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/tools/deps_tree.py", "function": "main", "line_number": 66, "body": "def main():\n    cmdline_args = sys.argv[1:]\n    with CmdlineParser.global_instance(cmdline_args) as cp:\n        task = cp.get_task_obj()\n        print(print_tree(task))", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/sge.py", "function": "work", "line_number": 266, "body": "def work(self):\n        \"\"\"Override this method, rather than ``run()``,  for your actual work.\"\"\"\n        pass", "is_method": true, "class_name": "SGEJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/sqla.py", "function": "open", "line_number": 268, "body": "def open(self, mode):\n        raise NotImplementedError(\"Cannot open() SQLAlchemyTarget\")", "is_method": true, "class_name": "SQLAlchemyTarget", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/sqla.py", "function": "table", "line_number": 294, "body": "def table(self):\n        return None", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/esindex.py", "function": "http_auth", "line_number": 268, "body": "def http_auth(self):\n        \"\"\"\n        ES optional http auth information as either \u2018:\u2019 separated string or a tuple,\n        e.g. `('user', 'pass')` or `\"user:pass\"`.\n        \"\"\"\n        return None", "is_method": true, "class_name": "CopyToIndex", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/esindex.py", "function": "index", "line_number": 277, "body": "def index(self):\n        \"\"\"\n        The target index.\n\n        May exist or not.\n        \"\"\"\n        return None", "is_method": true, "class_name": "CopyToIndex", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/scalding.py", "function": "jar", "line_number": 259, "body": "def jar(self):\n        \"\"\"\n        Path to the jar file for this Scalding Job\n\n        Either one of source() or jar() must be specified.\n        \"\"\"\n        return None", "is_method": true, "class_name": "ScaldingJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/kubernetes.py", "function": "name", "line_number": 126, "body": "def name(self):\n        \"\"\"\n        A name for this job. This task will automatically append a UUID to the\n        name before to submit to Kubernetes.\n        \"\"\"\n        raise NotImplementedError(\"subclass must define name\")", "is_method": true, "class_name": "KubernetesJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/kubernetes.py", "function": "spec_schema", "line_number": 143, "body": "def spec_schema(self):\n        \"\"\"\n        Kubernetes Job spec schema in JSON format, an example follows.\n\n        .. code-block:: javascript\n\n            {\n                \"containers\": [{\n                    \"name\": \"pi\",\n                    \"image\": \"perl\",\n                    \"command\": [\"perl\",  \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n                }],\n                \"restartPolicy\": \"Never\"\n            }\n\n        **restartPolicy**\n\n        - If restartPolicy is not defined, it will be set to \"Never\" by default.\n        - **Warning**: restartPolicy=OnFailure will bypass max_retrials, and restart\n          the container until success, with the risk of blocking the Luigi task.\n\n        For more informations please refer to:\n        http://kubernetes.io/docs/user-guide/pods/multi-container/#the-spec-schema\n        \"\"\"\n        raise NotImplementedError(\"subclass must define spec_schema\")", "is_method": true, "class_name": "KubernetesJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/kubernetes.py", "function": "signal_complete", "line_number": 241, "body": "def signal_complete(self):\n        \"\"\"Signal job completion for scheduler and dependent tasks.\n\n         Touching a system file is an easy way to signal completion. example::\n         .. code-block:: python\n\n         with self.output().open('w') as output_file:\n             output_file.write('')\n        \"\"\"\n        pass", "is_method": true, "class_name": "KubernetesJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/kubernetes.py", "function": "output", "line_number": 393, "body": "def output(self):\n        \"\"\"\n        An output target is necessary for checking job completion unless\n        an alternative complete method is defined.\n\n        Example::\n\n            return luigi.LocalTarget(os.path.join('/tmp', 'example'))\n\n        \"\"\"\n        pass", "is_method": true, "class_name": "KubernetesJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "table_location", "line_number": 123, "body": "def table_location(self, table, database='default', partition=None):\n        \"\"\"\n        Returns location of db.table (or db.table.partition). partition is a dict of partition key to\n        value.\n        \"\"\"\n        pass", "is_method": true, "class_name": "HiveClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "table_schema", "line_number": 131, "body": "def table_schema(self, table, database='default'):\n        \"\"\"\n        Returns list of [(name, type)] for each column in database.table.\n        \"\"\"\n        pass", "is_method": true, "class_name": "HiveClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "table_exists", "line_number": 138, "body": "def table_exists(self, table, database='default', partition=None):\n        \"\"\"\n        Returns true if db.table (or db.table.partition) exists. partition is a dict of partition key to\n        value.\n        \"\"\"\n        pass", "is_method": true, "class_name": "HiveClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "partition_spec", "line_number": 146, "body": "def partition_spec(self, partition):\n        \"\"\" Turn a dict into a string partition specification \"\"\"\n        pass", "is_method": true, "class_name": "HiveClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "table_schema", "line_number": 289, "body": "def table_schema(self, table, database='default'):\n        return NotImplemented", "is_method": true, "class_name": "WarehouseHiveClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hive.py", "function": "query", "line_number": 352, "body": "def query(self):\n        \"\"\" Text of query to run in hive \"\"\"\n        raise RuntimeError(\"Must implement query!\")", "is_method": true, "class_name": "HiveQueryTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/bigquery.py", "function": "query", "line_number": 592, "body": "def query(self):\n        \"\"\"The query, in text form.\"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "BigQueryRunQueryTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/bigquery.py", "function": "view", "line_number": 660, "body": "def view(self):\n        \"\"\"The SQL query for the view, in text form.\"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "BigQueryCreateViewTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/lsf.py", "function": "init_local", "line_number": 173, "body": "def init_local(self):\n        \"\"\"\n        Implement any work to setup any internal datastructure etc here.\n        You can add extra input using the requires_local/input_local methods.\n        Anything you set on the object will be pickled and available on the compute nodes.\n        \"\"\"\n        pass", "is_method": true, "class_name": "LSFJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/lsf.py", "function": "work", "line_number": 194, "body": "def work(self):\n        \"\"\"\n        Subclass this for where you're doing your actual work.\n\n        Why not run(), like other tasks? Because we need run to always be\n        something that the Worker can call, and that's the real logical place to\n        do LSF scheduling.\n        So, the work will happen in work().\n        \"\"\"\n        pass", "is_method": true, "class_name": "LSFJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/lsf.py", "function": "__del__", "line_number": 344, "body": "def __del__(self):\n        pass", "is_method": true, "class_name": "LSFJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/target.py", "function": "new_method", "line_number": 56, "body": "def new_method(self, *args, **kwargs):\n            return self._chained_call(method_name, *args, **kwargs)", "is_method": true, "class_name": "CascadingClient", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/redshift.py", "function": "prune_table", "line_number": 187, "body": "def prune_table(self):\n        \"\"\"\n        Override to set equal to the name of the table which is to be pruned.\n        Intended to be used in conjunction with prune_column and prune_date\n        i.e. copy to temp table, prune production table to prune_column with a date greater than prune_date, then insert into production table from temp table\n        \"\"\"\n        return None", "is_method": true, "class_name": "S3CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/redshift.py", "function": "prune_column", "line_number": 196, "body": "def prune_column(self):\n        \"\"\"\n        Override to set equal to the column of the prune_table which is to be compared\n        Intended to be used in conjunction with prune_table and prune_date\n        i.e. copy to temp table, prune production table to prune_column with a date greater than prune_date, then insert into production table from temp table\n        \"\"\"\n        return None", "is_method": true, "class_name": "S3CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/redshift.py", "function": "host", "line_number": 630, "body": "def host(self):\n        return None", "is_method": true, "class_name": "KillOpenRedshiftSessions", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/redshift.py", "function": "database", "line_number": 635, "body": "def database(self):\n        return None", "is_method": true, "class_name": "KillOpenRedshiftSessions", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/redshift.py", "function": "user", "line_number": 640, "body": "def user(self):\n        return None", "is_method": true, "class_name": "KillOpenRedshiftSessions", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/presto.py", "function": "partition", "line_number": 237, "body": "def partition(self):\n        return None", "is_method": true, "class_name": "PrestoTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/presto.py", "function": "session_props", "line_number": 245, "body": "def session_props(self):\n        return None", "is_method": true, "class_name": "PrestoTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/presto.py", "function": "requests_session", "line_number": 249, "body": "def requests_session(self):\n        return None", "is_method": true, "class_name": "PrestoTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pig.py", "function": "output", "line_number": 87, "body": "def output(self):\n        raise NotImplementedError(\"subclass should define output path\")", "is_method": true, "class_name": "PigJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pig.py", "function": "pig_script_path", "line_number": 90, "body": "def pig_script_path(self):\n        \"\"\"\n        Return the path to the Pig script to be run.\n        \"\"\"\n        raise NotImplementedError(\"subclass should define pig_script_path\")", "is_method": true, "class_name": "PigJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/docker_runner.py", "function": "name", "line_number": 77, "body": "def name(self):\n        return None", "is_method": true, "class_name": "DockerTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/docker_runner.py", "function": "container_options", "line_number": 81, "body": "def container_options(self):\n        return {}", "is_method": true, "class_name": "DockerTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/docker_runner.py", "function": "docker_url", "line_number": 106, "body": "def docker_url(self):\n        return None", "is_method": true, "class_name": "DockerTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/docker_runner.py", "function": "mount_tmp", "line_number": 118, "body": "def mount_tmp(self):\n        return True", "is_method": true, "class_name": "DockerTask", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "job_runner", "line_number": 687, "body": "def job_runner(self):\n        pass", "is_method": true, "class_name": "BaseHadoopJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "init_local", "line_number": 705, "body": "def init_local(self):\n        \"\"\"\n        Implement any work to setup any internal datastructure etc here.\n\n        You can add extra input using the requires_local/input_local methods.\n\n        Anything you set on the object will be pickled and available on the Hadoop nodes.\n        \"\"\"\n        pass", "is_method": true, "class_name": "BaseHadoopJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "init_hadoop", "line_number": 715, "body": "def init_hadoop(self):\n        pass", "is_method": true, "class_name": "BaseHadoopJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "init_mapper", "line_number": 792, "body": "def init_mapper(self):\n        pass", "is_method": true, "class_name": "JobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "init_combiner", "line_number": 795, "body": "def init_combiner(self):\n        pass", "is_method": true, "class_name": "JobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "init_reducer", "line_number": 798, "body": "def init_reducer(self):\n        pass", "is_method": true, "class_name": "JobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "tracking_url_callback", "line_number": 342, "body": "def tracking_url_callback(x): return None", "is_method": false, "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop.py", "function": "tracking_url_callback", "line_number": 303, "body": "def tracking_url_callback(x):\n                            return None", "is_method": false, "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/postgres.py", "function": "open", "line_number": 229, "body": "def open(self, mode):\n        raise NotImplementedError(\"Cannot open() PostgresTarget\")", "is_method": true, "class_name": "PostgresTarget", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/ecs.py", "function": "command", "line_number": 147, "body": "def command(self):\n        \"\"\"\n        Command passed to the containers\n\n        Override to return list of dicts with keys 'name' and 'command',\n        describing the container names and commands to pass to the container.\n        Directly corresponds to the `overrides` parameter of runTask API. For\n        example::\n\n            [\n                {\n                    'name': 'myContainer',\n                    'command': ['/bin/sleep', '60']\n                }\n            ]\n\n        \"\"\"\n        pass", "is_method": true, "class_name": "ECSTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "table", "line_number": 187, "body": "def table(self):\n        return None", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "port", "line_number": 191, "body": "def port(self):\n        return None", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "output", "line_number": 234, "body": "def output(self):\n        raise NotImplementedError(\"This method must be overridden\")", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "post_copy", "line_number": 254, "body": "def post_copy(self, connection):\n        \"\"\"\n        Override to perform custom queries.\n\n        Any code here will be formed in the same transaction as the main copy, just after copying data.\n        Example use cases include cleansing data in temp table prior to insertion into real table.\n        \"\"\"\n        pass", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "copy", "line_number": 264, "body": "def copy(self, cursor, file):\n        raise NotImplementedError(\"This method must be overridden\")", "is_method": true, "class_name": "CopyToTable", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "host", "line_number": 297, "body": "def host(self):\n        \"\"\"\n        Host of the RDBMS. Implementation should support `hostname:port`\n        to encode port.\n        \"\"\"\n        return None", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "database", "line_number": 313, "body": "def database(self):\n        return None", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "table", "line_number": 328, "body": "def table(self):\n        return None", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "query", "line_number": 333, "body": "def query(self):\n        return None", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "run", "line_number": 348, "body": "def run(self):\n        raise NotImplementedError(\"This method must be overridden\")", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/rdbms.py", "function": "output", "line_number": 352, "body": "def output(self):\n        \"\"\"\n        Override with an RDBMS Target (e.g. PostgresTarget or RedshiftTarget) to record execution in a marker table\n        \"\"\"\n        raise NotImplementedError(\"This method must be overridden\")", "is_method": true, "class_name": "Query", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/external_program.py", "function": "program_args", "line_number": 91, "body": "def program_args(self):\n        \"\"\"\n        Override this method to map your task parameters to the program arguments\n\n        :return: list to pass as ``args`` to :py:class:`subprocess.Popen`\n        \"\"\"\n        raise NotImplementedError", "is_method": true, "class_name": "ExternalProgramTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop_jar.py", "function": "main", "line_number": 139, "body": "def main(self):\n        \"\"\"\n        optional main method for this Hadoop Job.\n        \"\"\"\n        return None", "is_method": true, "class_name": "HadoopJarJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hadoop_jar.py", "function": "ssh", "line_number": 156, "body": "def ssh(self):\n        \"\"\"\n        Set this to run hadoop command remotely via ssh. It needs to be a dict that looks like\n        {\"host\": \"myhost\", \"key_file\": None, \"username\": None, [\"no_host_key_check\": False]}\n        \"\"\"\n        return None", "is_method": true, "class_name": "HadoopJarJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "runner", "line_number": 40, "body": "def runner(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "project", "line_number": 45, "body": "def project(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "zone", "line_number": 50, "body": "def zone(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "region", "line_number": 55, "body": "def region(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "staging_location", "line_number": 60, "body": "def staging_location(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "temp_location", "line_number": 65, "body": "def temp_location(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "gcp_temp_location", "line_number": 70, "body": "def gcp_temp_location(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "num_workers", "line_number": 75, "body": "def num_workers(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "autoscaling_algorithm", "line_number": 80, "body": "def autoscaling_algorithm(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "max_num_workers", "line_number": 85, "body": "def max_num_workers(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "disk_size_gb", "line_number": 90, "body": "def disk_size_gb(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "worker_machine_type", "line_number": 95, "body": "def worker_machine_type(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "worker_disk_type", "line_number": 100, "body": "def worker_disk_type(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "job_name", "line_number": 105, "body": "def job_name(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "service_account", "line_number": 110, "body": "def service_account(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "network", "line_number": 115, "body": "def network(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "subnetwork", "line_number": 120, "body": "def subnetwork(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "labels", "line_number": 125, "body": "def labels(self):\n        pass", "is_method": true, "class_name": "DataflowParamKeys", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "dataflow_executable", "line_number": 239, "body": "def dataflow_executable(self):\n        \"\"\"\n        Command representing the Dataflow executable to be run.\n        For example:\n\n        return ['java', 'com.spotify.luigi.MyClass', '-Xmx256m']\n        \"\"\"\n        pass", "is_method": true, "class_name": "BeamDataflowJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "before_run", "line_number": 257, "body": "def before_run(self):\n        \"\"\"\n        Hook that gets called right before the Dataflow job is launched.\n        Can be used to setup any temporary files/tables, validate input, etc.\n        \"\"\"\n        pass", "is_method": true, "class_name": "BeamDataflowJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "on_successful_run", "line_number": 264, "body": "def on_successful_run(self):\n        \"\"\"\n        Callback that gets called right after the Dataflow job has finished\n        successfully but before validate_output is run.\n        \"\"\"\n        pass", "is_method": true, "class_name": "BeamDataflowJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "on_successful_output_validation", "line_number": 290, "body": "def on_successful_output_validation(self):\n        \"\"\"\n        Callback that gets called after the Dataflow job has finished\n        successfully if validate_output returns True.\n        \"\"\"\n        pass", "is_method": true, "class_name": "BeamDataflowJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/beam_dataflow.py", "function": "cleanup_on_error", "line_number": 297, "body": "def cleanup_on_error(self, error):\n        \"\"\"\n        Callback that gets called after the Dataflow job has finished\n        unsuccessfully, or validate_output returns False.\n        \"\"\"\n        pass", "is_method": true, "class_name": "BeamDataflowJobTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pai.py", "function": "code_dir", "line_number": 213, "body": "def code_dir(self):\n        \"\"\"Code directory existing on HDFS, should not contain any data and should be less than 200MB, optional\"\"\"\n        return None", "is_method": true, "class_name": "PaiTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pai.py", "function": "output", "line_number": 307, "body": "def output(self):\n        return luigi.contrib.hdfs.HdfsTarget(self.output())", "is_method": true, "class_name": "PaiTask", "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/dropbox.py", "function": "wrapped", "line_number": 43, "body": "def wrapped(self, path, *args, **kwargs):\n        if path != '/' and path.endswith('/'):\n            logger.warning(\"Dropbox paths should NOT have trailing slashes. This causes additional API calls\")\n            logger.warning(\"Consider modifying your calls to {}, so that they don't use paths than end with '/'\".format(func.__name__))\n\n            if self._exists_and_is_dir(path[:-1]):\n                path = path[:-1]\n\n        return func(self, path, *args, **kwargs)", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/dropbox.py", "function": "wrapped", "line_number": 58, "body": "def wrapped(self, path, *args, **kwargs):\n        if path != '/' and path.endswith('/'):\n            path = path[:-1]\n        return func(self, path, *args, **kwargs)", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/spark.py", "function": "app_options", "line_number": 67, "body": "def app_options(self):\n        \"\"\"\n        Subclass this method to map your task parameters to the app's arguments\n\n        \"\"\"\n        return []", "is_method": true, "class_name": "SparkSubmitTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/spark.py", "function": "pyspark_python", "line_number": 75, "body": "def pyspark_python(self):\n        return None", "is_method": true, "class_name": "SparkSubmitTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/spark.py", "function": "pyspark_driver_python", "line_number": 79, "body": "def pyspark_driver_python(self):\n        return None", "is_method": true, "class_name": "SparkSubmitTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/spark.py", "function": "setup", "line_number": 295, "body": "def setup(self, conf):\n        \"\"\"\n        Called by the pyspark_runner with a SparkConf instance that will be used to instantiate the SparkContext\n\n        :param conf: SparkConf\n        \"\"\"", "is_method": true, "class_name": "PySparkTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/spark.py", "function": "main", "line_number": 305, "body": "def main(self, sc, *args):\n        \"\"\"\n        Called by the pyspark_runner with a SparkContext and any arguments returned by ``app_options()``\n\n        :param sc: SparkContext\n        :param args: arguments list\n        \"\"\"\n        raise NotImplementedError(\"subclass should define a main method\")", "is_method": true, "class_name": "PySparkTask", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/opener.py", "function": "get_target", "line_number": 186, "body": "def get_target(cls, scheme, path, fragment, username,\n                   password, hostname, port, query, **kwargs):\n        \"\"\"Override this method to use values from the parsed uri to initialize\n        the expected target.\n\n        \"\"\"\n        raise NotImplementedError(\"get_target must be overridden\")", "is_method": true, "class_name": "Opener", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/azureblob.py", "function": "seek", "line_number": 219, "body": "def seek(self, offset, whence=None):\n        pass", "is_method": true, "class_name": "ReadableAzureBlobFile", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pyspark_runner.py", "function": "__enter__", "line_number": 46, "body": "def __enter__(self):\n        pass", "is_method": true, "class_name": "_SparkEntryPoint", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/pyspark_runner.py", "function": "__exit__", "line_number": 50, "body": "def __exit__(self, exc_type, exc_val, exc_tb):\n        pass", "is_method": true, "class_name": "_SparkEntryPoint", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/webhdfs_client.py", "function": "chmod", "line_number": 134, "body": "def chmod(self, path, permissions, recursive=False):\n        \"\"\"\n        Raise a NotImplementedError exception.\n        \"\"\"\n        raise NotImplementedError(\"Webhdfs in luigi doesn't implement chmod\")", "is_method": true, "class_name": "WebHdfsClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/webhdfs_client.py", "function": "chown", "line_number": 140, "body": "def chown(self, path, owner, group, recursive=False):\n        \"\"\"\n        Raise a NotImplementedError exception.\n        \"\"\"\n        raise NotImplementedError(\"Webhdfs in luigi doesn't implement chown\")", "is_method": true, "class_name": "WebHdfsClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/webhdfs_client.py", "function": "count", "line_number": 146, "body": "def count(self, path):\n        \"\"\"\n        Raise a NotImplementedError exception.\n        \"\"\"\n        raise NotImplementedError(\"Webhdfs in luigi doesn't implement count\")", "is_method": true, "class_name": "WebHdfsClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/webhdfs_client.py", "function": "copy", "line_number": 152, "body": "def copy(self, path, destination):\n        \"\"\"\n        Raise a NotImplementedError exception.\n        \"\"\"\n        raise NotImplementedError(\"Webhdfs in luigi doesn't implement copy\")", "is_method": true, "class_name": "WebHdfsClient", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/clients.py", "function": "result", "line_number": 51, "body": "def result(*args, **kwargs):\n        return getattr(get_autoconfig_client(), method_name)(*args, **kwargs)", "is_method": false, "function_description": "Not sure"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "remove", "line_number": 56, "body": "def remove(self, path, recursive=True, skip_trash=False):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "chmod", "line_number": 60, "body": "def chmod(self, path, permissions, recursive=False):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "chown", "line_number": 64, "body": "def chown(self, path, owner, group, recursive=False):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "count", "line_number": 68, "body": "def count(self, path):\n        \"\"\"\n        Count contents in a directory\n        \"\"\"\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "copy", "line_number": 75, "body": "def copy(self, path, destination):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "put", "line_number": 79, "body": "def put(self, local_path, destination):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "get", "line_number": 83, "body": "def get(self, path, local_destination):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "mkdir", "line_number": 87, "body": "def mkdir(self, path, parents=True, raise_if_exists=False):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "listdir", "line_number": 91, "body": "def listdir(self, path, ignore_directories=False, ignore_files=False,\n                include_size=False, include_type=False, include_time=False, recursive=False):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}, {"file": "./dataset/RepoExec/test-apps/luigi/luigi/contrib/hdfs/abstract_client.py", "function": "touchz", "line_number": 96, "body": "def touchz(self, path):\n        pass", "is_method": true, "class_name": "HdfsFileSystem", "function_description": "Not Implemented"}]