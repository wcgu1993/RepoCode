[{"file": "./dataset/RepoExec/test-apps/tornado/setup.py", "function": "run", "line_number": 79, "body": "def run(self):\n        try:\n            build_ext.run(self)\n        except Exception:\n            e = sys.exc_info()[1]\n            sys.stdout.write(\"%s\\n\" % str(e))\n            warnings.warn(\n                self.warning_message\n                % (\n                    \"Extension modules\",\n                    \"There was an issue with \"\n                    \"your platform configuration\"\n                    \" - see above.\",\n                )\n            )", "is_method": true, "class_name": "custom_build_ext", "function_description": "Custom build_ext method that runs the standard build process and gracefully handles exceptions by printing error details and issuing a platform configuration warning. It helps diagnose build issues in extension module compilation."}, {"file": "./dataset/RepoExec/test-apps/tornado/setup.py", "function": "build_extension", "line_number": 95, "body": "def build_extension(self, ext):\n        name = ext.name\n        try:\n            build_ext.build_extension(self, ext)\n        except Exception:\n            e = sys.exc_info()[1]\n            sys.stdout.write(\"%s\\n\" % str(e))\n            warnings.warn(\n                self.warning_message\n                % (\n                    \"The %s extension \" \"module\" % (name,),\n                    \"The output above \"\n                    \"this warning shows how \"\n                    \"the compilation \"\n                    \"failed.\",\n                )\n            )", "is_method": true, "class_name": "custom_build_ext", "function_description": "Overrides extension building to catch and report compilation errors with a custom warning message, improving feedback during build failures in the custom_build_ext class."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/vm/windows/bootstrap.py", "function": "download_to_cache", "line_number": 43, "body": "def download_to_cache(url, local_name=None):\n    if local_name is None:\n        local_name = url.split('/')[-1]\n    filename = os.path.join(TMPDIR, local_name)\n    if not os.path.exists(filename):\n        data = urllib.urlopen(url).read()\n        with open(filename, 'wb') as f:\n            f.write(data)\n    return filename", "is_method": false, "function_description": "Utility function that downloads a file from a given URL and caches it locally, avoiding redundant downloads by returning the cached file path when available."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/vm/windows/bootstrap.py", "function": "main", "line_number": 54, "body": "def main():\n    if not os.path.exists(TMPDIR):\n        os.mkdir(TMPDIR)\n    os.chdir(TMPDIR)\n    for exe, url in PYTHON_VERSIONS:\n        if os.path.exists(exe):\n            print(\"%s already exists, skipping\" % exe)\n            continue\n        print(\"Installing %s\" % url)\n        filename = download_to_cache(url)\n        # http://blog.jaraco.com/2012/01/how-i-install-python-on-windows.html\n        subprocess.check_call(['msiexec', '/i', filename,\n                               'ALLUSERS=1', '/passive'])\n\n    if not os.path.exists(EASY_INSTALL):\n        filename = download_to_cache('http://python-distribute.org/distribute_setup.py')\n        subprocess.check_call([sys.executable, filename])\n\n    subprocess.check_call([EASY_INSTALL] + PY_PACKAGES)", "is_method": false, "function_description": "Sets up a Python development environment by downloading and installing specified Python versions and required packages, ensuring necessary directories and tools are available."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/circlerefs/circlerefs.py", "function": "find_circular_references", "line_number": 17, "body": "def find_circular_references(garbage=None):\n    def inner(level):\n        for item in level:\n            item_id = id(item)\n            if item_id not in garbage_ids:\n                continue\n            if item_id in visited_ids:\n                continue\n            if item_id in stack_ids:\n                candidate = stack[stack.index(item):]\n                candidate.append(item)\n                found.append(candidate)\n                continue\n\n            stack.append(item)\n            stack_ids.add(item_id)\n            inner(gc.get_referents(item))\n            stack.pop()\n            stack_ids.remove(item_id)\n            visited_ids.add(item_id)\n\n    garbage = garbage or gc.garbage\n    found = []\n    stack = []\n    stack_ids = set()\n    garbage_ids = set(map(id, garbage))\n    visited_ids = set()\n\n    inner(garbage)\n    inner = None\n    return found", "is_method": false, "function_description": "Function that detects and returns all circular references within a given set of objects, useful for identifying memory leaks caused by reference cycles in Python garbage collection."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/circlerefs/circlerefs.py", "function": "get", "line_number": 52, "body": "def get(self):\n        self.write(\"Collected: {}\\n\".format(gc.collect()))\n        self.write(\"Garbage: {}\\n\".format(len(gc.garbage)))\n        for circular in find_circular_references():\n            print('\\n==========\\n Circular \\n==========')\n            for item in circular:\n                print('    ', repr(item))\n            for item in circular:\n                if isinstance(item, types.FrameType):\n                    print('\\nLocals:', item.f_locals)\n                    print('\\nTraceback:', repr(item))\n                    traceback.print_stack(item)", "is_method": true, "class_name": "CollectHandler", "function_description": "Provides diagnostic information on Python's garbage collection by triggering a collection cycle, reporting collected objects, and identifying reference cycles with detailed stack traces for debugging memory leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/circlerefs/circlerefs.py", "function": "get", "line_number": 68, "body": "def get(self):\n        self.write('ok\\n')", "is_method": true, "class_name": "DummyHandler", "function_description": "Simple HTTP GET handler method that responds with a basic confirmation message, useful for health checks or connectivity tests in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/circlerefs/circlerefs.py", "function": "get", "line_number": 74, "body": "def get(self):\n        raise web.Finish('ok\\n')", "is_method": true, "class_name": "DummyAsyncHandler", "function_description": "This method immediately terminates the request with a simple 'ok' response, serving as a placeholder or test handler in asynchronous web contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/gen_benchmark.py", "function": "e2", "line_number": 21, "body": "def e2(callback):\n    callback()", "is_method": false, "function_description": "A utility function that executes a provided callback function immediately. It can be used to invoke any function passed to it without arguments."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/gen_benchmark.py", "function": "main", "line_number": 42, "body": "def main():\n    parse_command_line()\n    t = Timer(e1)\n    results = t.timeit(options.num) / options.num\n    print('engine: %0.3f ms per iteration' % (results * 1000))\n    t = Timer(c1)\n    results = t.timeit(options.num) / options.num\n    print('coroutine: %0.3f ms per iteration' % (results * 1000))", "is_method": false, "function_description": "Main entry point that benchmarks and prints the average execution time per iteration for two code snippets, enabling performance comparison between them."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/chunk_benchmark.py", "function": "main", "line_number": 30, "body": "def main():\n    parse_command_line()\n    app = Application([('/', ChunkHandler)])\n    app.listen(options.port, address='127.0.0.1')\n\n    def callback(response):\n        response.rethrow()\n        assert len(response.body) == (options.num_chunks * options.chunk_size)\n        logging.warning(\"fetch completed in %s seconds\", response.request_time)\n        IOLoop.current().stop()\n\n    logging.warning(\"Starting fetch with curl client\")\n    curl_client = CurlAsyncHTTPClient()\n    curl_client.fetch('http://localhost:%d/' % options.port,\n                      callback=callback)\n    IOLoop.current().start()\n\n    logging.warning(\"Starting fetch with simple client\")\n    simple_client = SimpleAsyncHTTPClient()\n    simple_client.fetch('http://localhost:%d/' % options.port,\n                        callback=callback)\n    IOLoop.current().start()", "is_method": false, "function_description": "Starts a local HTTP server and performs asynchronous fetches using two different clients, logging completion time for each. It demonstrates server setup and client request handling for testing or benchmarking purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/chunk_benchmark.py", "function": "get", "line_number": 23, "body": "def get(self):\n        for i in xrange(options.num_chunks):\n            self.write('A' * options.chunk_size)\n            self.flush()\n        self.finish()", "is_method": true, "class_name": "ChunkHandler", "function_description": "This method streams a specified number of fixed-size data chunks as continuous output, supporting chunked data delivery or real-time response scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/benchmark.py", "function": "handle_sigchld", "line_number": 58, "body": "def handle_sigchld(sig, frame):\n    IOLoop.current().add_callback_from_signal(IOLoop.current().stop)", "is_method": false, "function_description": "Registers a callback to safely stop the current IOLoop upon receiving a SIGCHLD signal, facilitating proper handling of child process termination in asynchronous applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/benchmark.py", "function": "run", "line_number": 70, "body": "def run():\n    io_loop = IOLoop(make_current=True)\n    app = Application([(\"/\", RootHandler)])\n    port = random.randrange(options.min_port, options.max_port)\n    app.listen(port, address='127.0.0.1')\n    signal.signal(signal.SIGCHLD, handle_sigchld)\n    args = [\"ab\"]\n    args.extend([\"-n\", str(options.n)])\n    args.extend([\"-c\", str(options.c)])\n    if options.keepalive:\n        args.append(\"-k\")\n    if options.quiet:\n        # just stops the progress messages printed to stderr\n        args.append(\"-q\")\n    args.append(\"http://127.0.0.1:%d/\" % port)\n    subprocess.Popen(args)\n    io_loop.start()\n    io_loop.close()\n    io_loop.clear_current()", "is_method": false, "function_description": "Function that starts an asynchronous web server on a random local port and runs a load testing tool against it with specified parameters, managing server lifecycle and signal handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/benchmark.py", "function": "get", "line_number": 51, "body": "def get(self):\n        self.write(\"Hello, world\")", "is_method": true, "class_name": "RootHandler", "function_description": "Simple HTTP GET handler method that responds with a greeting message, serving as a basic endpoint in a web application for connectivity or sanity checks."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "headers_parse_re", "line_number": 41, "body": "def headers_parse_re(headers: str) -> HTTPHeaders:\n    h = HTTPHeaders()\n    for line in _CRLF_RE.split(headers):\n        if line:\n            h.parse_line(line)\n    return h", "is_method": false, "function_description": "Utility function that parses raw HTTP header strings into an HTTPHeaders object, enabling structured access to individual header fields for further processing or inspection."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "headers_parse_simple", "line_number": 49, "body": "def headers_parse_simple(headers: str) -> HTTPHeaders:\n    h = HTTPHeaders()\n    for line in headers.split(\"\\n\"):\n        if line.endswith(\"\\r\"):\n            line = line[:-1]\n        if line:\n            h.parse_line(line)\n    return h", "is_method": false, "function_description": "Function that parses a raw HTTP headers string into a structured HTTPHeaders object by processing each header line. It facilitates converting plain header text into an accessible, programmatic format for HTTP handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "run_headers_split", "line_number": 59, "body": "def run_headers_split():\n    regex_time = timeit.timeit(lambda: headers_split_re(_TEST_HEADERS), number=100000)\n    print(\"regex\", regex_time)\n\n    simple_time = timeit.timeit(\n        lambda: headers_split_simple(_TEST_HEADERS), number=100000\n    )\n    print(\"str.split\", simple_time)\n\n    print(\"speedup\", regex_time / simple_time)", "is_method": false, "function_description": "Measures and compares the execution time of two different header splitting functions, providing performance insights on regex-based versus simple string split methods. Useful for benchmarking and optimizing text parsing approaches."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "run_headers_full", "line_number": 71, "body": "def run_headers_full():\n    regex_time = timeit.timeit(lambda: headers_parse_re(_TEST_HEADERS), number=10000)\n    print(\"regex\", regex_time)\n\n    simple_time = timeit.timeit(\n        lambda: headers_parse_simple(_TEST_HEADERS), number=10000\n    )\n    print(\"str.split\", simple_time)\n\n    print(\"speedup\", regex_time / simple_time)", "is_method": false, "function_description": "Function that benchmarks and compares the execution time of two header parsing methods, reporting their relative performance. It serves to evaluate and optimize parsing strategies based on speed."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "main", "line_number": 94, "body": "def main():\n    parse_command_line()\n\n    try:\n        func = Benchmark(options.benchmark).func\n    except ValueError:\n        known_benchmarks = [benchmark.value for benchmark in Benchmark]\n        print(\n            \"Unknown benchmark: '{}', supported values are: {}\"\n            .format(options.benchmark, \", \".join(known_benchmarks))\n        )\n        return\n\n    for _ in range(options.num_runs):\n        func()", "is_method": false, "function_description": "Primary function that parses CLI options, validates a benchmark choice, and runs the associated benchmark function multiple times as specified by user input. It automates benchmark execution with error handling for invalid inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/benchmark/parsing_benchmark.py", "function": "__new__", "line_number": 84, "body": "def __new__(cls, arg_value: str, func: Callable[[], None]):\n        member = object.__new__(cls)\n        member._value_ = arg_value\n        member.func = func\n        return member", "is_method": true, "class_name": "Benchmark", "function_description": "Creates and returns a new Benchmark instance associating a string identifier with a callable function, enabling encapsulation of benchmark tasks within enumeration members."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/websocket/server.py", "function": "on_message", "line_number": 10, "body": "def on_message(self, message):\n        self.write_message(message, binary=isinstance(message, bytes))", "is_method": true, "class_name": "EchoHandler", "function_description": "Handles incoming messages by sending them back unchanged, supporting both text and binary formats; useful for echoing data in communication protocols."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/websocket/server.py", "function": "get_compression_options", "line_number": 13, "body": "def get_compression_options(self):\n        return {}", "is_method": true, "class_name": "EchoHandler", "function_description": "Returns an empty dictionary indicating no compression options are configured or available."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/websocket/client.py", "function": "run_tests", "line_number": 13, "body": "def run_tests():\n    url = options.url + '/getCaseCount'\n    control_ws = yield websocket_connect(url, None)\n    num_tests = int((yield control_ws.read_message()))\n    logging.info('running %d cases', num_tests)\n    msg = yield control_ws.read_message()\n    assert msg is None\n\n    for i in range(1, num_tests + 1):\n        logging.info('running test case %d', i)\n        url = options.url + '/runCase?case=%d&agent=%s' % (i, options.name)\n        test_ws = yield websocket_connect(url, None, compression_options={})\n        while True:\n            message = yield test_ws.read_message()\n            if message is None:\n                break\n            test_ws.write_message(message, binary=isinstance(message, bytes))\n\n    url = options.url + '/updateReports?agent=%s' % options.name\n    update_ws = yield websocket_connect(url, None)\n    msg = yield update_ws.read_message()\n    assert msg is None\n    IOLoop.instance().stop()", "is_method": false, "function_description": "Function that coordinates running a suite of websocket-based test cases from a specified URL, relays their messages, and triggers report updates, typically used for automated testing workflows involving websocket connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get", "line_number": 16, "body": "def get(self):\n        self.write(\"Hello world\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Simple HTTP GET request handler method that responds with a greeting message, useful for testing or confirming server responsiveness in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get", "line_number": 21, "body": "def get(self, path):\n        self.redirect(path, status=int(self.get_argument('status', '302')))", "is_method": true, "class_name": "RedirectHandler", "function_description": "Handles HTTP GET requests by redirecting to the specified path using a given or default HTTP status code, facilitating URL redirection within a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "post", "line_number": 26, "body": "def post(self):\n        assert self.get_argument('foo') == 'bar'\n        self.redirect('/hello', status=303)", "is_method": true, "class_name": "PostHandler", "function_description": "Handles an HTTP POST request by validating a specific form parameter and then redirects the client to a predetermined URL with a 303 status code."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get", "line_number": 34, "body": "def get(self):\n        self.write('hello ')\n        yield gen.Task(self.flush)\n        self.write('world')\n        yield gen.Task(self.flush)\n        self.finish()", "is_method": true, "class_name": "ChunkedHandler", "function_description": "This method sends a chunked HTTP response split into two parts: first \"hello \", then \"world\". It enables streaming response handling by flushing data progressively before completing the request."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get", "line_number": 43, "body": "def get(self, computed_etag):\n        self.write(computed_etag)", "is_method": true, "class_name": "CacheHandler", "function_description": "This function writes the given computed_etag to the cache store. It appears intended to update cache state but does not return any data."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "compute_etag", "line_number": 46, "body": "def compute_etag(self):\n        return self._write_buffer[0]", "is_method": true, "class_name": "CacheHandler", "function_description": "Returns the first element of the internal write buffer, typically used as an entity tag (ETag) for cache validation or version tracking."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_handlers", "line_number": 51, "body": "def get_handlers(self):\n        return [\n            ('/hello', HelloHandler),\n            ('/redirect(/.*)', RedirectHandler),\n            ('/post', PostHandler),\n            ('/chunked', ChunkedHandler),\n            ('/cache/(.*)', CacheHandler),\n        ]", "is_method": true, "class_name": "TestMixin", "function_description": "Provides a list of URL route-handler pairs for mapping specific web paths to their corresponding request handlers within the TestMixin class, facilitating request routing in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_app_kwargs", "line_number": 60, "body": "def get_app_kwargs(self):\n        return dict(static_path='.')", "is_method": true, "class_name": "TestMixin", "function_description": "Returns a dictionary of keyword arguments for app configuration, specifically defining the static file path. This utility supports setting up app parameters consistently across tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_allowed_warnings", "line_number": 63, "body": "def get_allowed_warnings(self):\n        return [\n            # We can't set a non-heuristic freshness at the framework level,\n            # so just ignore this warning\n            rs.FRESHNESS_HEURISTIC,\n            # For our small test responses the Content-Encoding header\n            # wipes out any gains from compression\n            rs.CONNEG_GZIP_BAD,\n        ]", "is_method": true, "class_name": "TestMixin", "function_description": "Returns a list of specific warning codes that are permissible within the testing context, helping to filter out expected non-critical warnings during test execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_allowed_errors", "line_number": 73, "body": "def get_allowed_errors(self):\n        return []", "is_method": true, "class_name": "TestMixin", "function_description": "Provides a method to specify which errors are permitted or handled, returning an empty list by default. This can be overridden to define custom allowable errors for testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "check_url", "line_number": 76, "body": "def check_url(self, path, method='GET', body=None, headers=None,\n                  expected_status=200, allowed_warnings=None,\n                  allowed_errors=None):\n        url = self.get_url(path)\n        red = self.run_redbot(url, method, body, headers)\n        if not red.response.complete:\n            if isinstance(red.response.http_error, Exception):\n                logging.warning((red.response.http_error.desc, vars(red.response.http_error), url))\n                raise red.response.http_error.res_error\n            else:\n                raise Exception(\"unknown error; incomplete response\")\n        self.assertEqual(int(red.response.status_code), expected_status)\n\n        allowed_warnings = (allowed_warnings or []) + self.get_allowed_warnings()\n        allowed_errors = (allowed_errors or []) + self.get_allowed_errors()\n\n        errors = []\n        warnings = []\n        for msg in red.response.notes:\n            if msg.level == 'bad':\n                logger = logging.error\n                if not isinstance(msg, tuple(allowed_errors)):\n                    errors.append(msg)\n            elif msg.level == 'warning':\n                logger = logging.warning\n                if not isinstance(msg, tuple(allowed_warnings)):\n                    warnings.append(msg)\n            elif msg.level in ('good', 'info', 'uri'):\n                logger = logging.info\n            else:\n                raise Exception('unknown level' + msg.level)\n            logger('%s: %s (%s)', msg.category, msg.show_summary('en'),\n                   msg.__class__.__name__)\n            logger(msg.show_text('en'))\n\n        self.assertEqual(len(warnings) + len(errors), 0,\n                         'Had %d unexpected warnings and %d errors' %\n                         (len(warnings), len(errors)))", "is_method": true, "class_name": "TestMixin", "function_description": "Method of TestMixin that validates a URL by executing an HTTP request, checking the response status, and asserting no unexpected errors or warnings occurred during the request validation. It helps ensure web resources comply with expected standards or behaviors."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "run_redbot", "line_number": 115, "body": "def run_redbot(self, url, method, body, headers):\n        red = HttpResource(url, method=method, req_body=body,\n                           req_hdrs=headers)\n\n        def work():\n            red.run(thor.stop)\n            thor.run()\n            self.io_loop.add_callback(self.stop)\n\n        thread = threading.Thread(target=work)\n        thread.start()\n        self.wait()\n        thread.join()\n        return red", "is_method": true, "class_name": "TestMixin", "function_description": "Method in TestMixin that executes an HTTP request using Redbot asynchronously and manages its lifecycle to completion, returning the HTTP resource with the results for further inspection or testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_hello", "line_number": 130, "body": "def test_hello(self):\n        self.check_url('/hello')", "is_method": true, "class_name": "TestMixin", "function_description": "Simple test method in TestMixin that verifies access to the '/hello' URL endpoint through an internal URL checking utility."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_static", "line_number": 133, "body": "def test_static(self):\n        # TODO: 304 responses SHOULD return the same etag that a full\n        # response would.  We currently do for If-None-Match, but not\n        # for If-Modified-Since (because IMS does not otherwise\n        # require us to read the file from disk)\n        self.check_url('/static/red_test.py',\n                       allowed_warnings=[rs.MISSING_HDRS_304])", "is_method": true, "class_name": "TestMixin", "function_description": "This test method verifies the server's handling of 304 responses for static files, focusing on ETag consistency and allowed warning management during URL checks. It supports ensuring correct HTTP caching behavior in testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_static_versioned_url", "line_number": 141, "body": "def test_static_versioned_url(self):\n        self.check_url('/static/red_test.py?v=1234',\n                       allowed_warnings=[rs.MISSING_HDRS_304])", "is_method": true, "class_name": "TestMixin", "function_description": "Tests that a static file URL with a version query parameter is correctly handled, allowing specific warnings. It validates URL handling behavior within the TestMixin context."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_redirect", "line_number": 145, "body": "def test_redirect(self):\n        self.check_url('/redirect/hello', expected_status=302)", "is_method": true, "class_name": "TestMixin", "function_description": "Simple test method in TestMixin that verifies the URL '/redirect/hello' correctly issues a 302 redirect response. It ensures proper redirect behavior in web application testing contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_permanent_redirect", "line_number": 148, "body": "def test_permanent_redirect(self):\n        self.check_url('/redirect/hello?status=301', expected_status=301)", "is_method": true, "class_name": "TestMixin", "function_description": "Tests that a URL correctly issues a permanent redirect (HTTP status 301), validating redirect behavior in web applications or APIs."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_404", "line_number": 151, "body": "def test_404(self):\n        self.check_url('/404', expected_status=404)", "is_method": true, "class_name": "TestMixin", "function_description": "Simple test method in TestMixin that verifies accessing the '/404' URL returns a 404 status code as expected, ensuring proper handling of not found errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_post", "line_number": 154, "body": "def test_post(self):\n        body = 'foo=bar'\n        # Without an explicit Content-Length redbot will try to send the\n        # request chunked.\n        self.check_url(\n            '/post', method='POST', body=body,\n            headers=[('Content-Length', str(len(body))),\n                     ('Content-Type', 'application/x-www-form-urlencoded')],\n            expected_status=303)", "is_method": true, "class_name": "TestMixin", "function_description": "Utility test method in TestMixin that performs a POST request with form data to verify server response and redirection behavior for given URL endpoints."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_chunked", "line_number": 164, "body": "def test_chunked(self):\n        self.check_url('/chunked')", "is_method": true, "class_name": "TestMixin", "function_description": "Simple test method in TestMixin that verifies the accessibility or response of the '/chunked' URL endpoint. It serves as a utility for automated testing of this specific web resource."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_strong_etag_match", "line_number": 167, "body": "def test_strong_etag_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=304)", "is_method": true, "class_name": "TestMixin", "function_description": "Method in TestMixin that verifies correct handling of conditional GET requests by testing if a server responds with 304 Not Modified when the provided ETag matches the computed one."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_multiple_strong_etag_match", "line_number": 175, "body": "def test_multiple_strong_etag_match(self):\n        computed_etag = '\"xyzzy1\"'\n        etags = '\"xyzzy1\", \"xyzzy2\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=304)", "is_method": true, "class_name": "TestMixin", "function_description": "Test method in TestMixin that verifies correct 304 response when the request\u2019s If-None-Match header matches one of multiple strong ETag values."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_strong_etag_not_match", "line_number": 183, "body": "def test_strong_etag_not_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy1\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=200)", "is_method": true, "class_name": "TestMixin", "function_description": "Method in TestMixin that verifies HTTP GET requests with a non-matching strong ETag return a 200 status, ensuring correct cache validation behavior when the client's ETag does not match the server\u2019s."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_multiple_strong_etag_not_match", "line_number": 191, "body": "def test_multiple_strong_etag_not_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy1\", \"xyzzy2\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=200)", "is_method": true, "class_name": "TestMixin", "function_description": "TestMixin method that verifies server responses to GET requests when multiple ETag headers do not match the computed ETag, ensuring correct cache validation behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_wildcard_etag", "line_number": 199, "body": "def test_wildcard_etag(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '*'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=304,\n            allowed_warnings=[rs.MISSING_HDRS_304])", "is_method": true, "class_name": "TestMixin", "function_description": "Tests handling of wildcard ETag headers by verifying the response status when a resource is requested with If-None-Match set to '*', ensuring proper cache validation behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_weak_etag_match", "line_number": 208, "body": "def test_weak_etag_match(self):\n        computed_etag = '\"xyzzy1\"'\n        etags = 'W/\"xyzzy1\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=304)", "is_method": true, "class_name": "TestMixin", "function_description": "Tests that a weak ETag in a request's If-None-Match header correctly triggers a 304 Not Modified response, verifying proper handling of weak ETag matching in HTTP caching."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_multiple_weak_etag_match", "line_number": 216, "body": "def test_multiple_weak_etag_match(self):\n        computed_etag = '\"xyzzy2\"'\n        etags = 'W/\"xyzzy1\", W/\"xyzzy2\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=304)", "is_method": true, "class_name": "TestMixin", "function_description": "This test method verifies that a resource correctly responds with a 304 status when an HTTP GET request includes an If-None-Match header containing multiple weak ETags matching the computed ETag. It ensures proper handling of weak ETag conditional requests in caching mechanisms."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_weak_etag_not_match", "line_number": 224, "body": "def test_weak_etag_not_match(self):\n        computed_etag = '\"xyzzy2\"'\n        etags = 'W/\"xyzzy1\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=200)", "is_method": true, "class_name": "TestMixin", "function_description": "Tests that a weak ETag header that does not match the computed ETag results in a 200 OK response, verifying correct handling of conditional HTTP GET requests in cache validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "test_multiple_weak_etag_not_match", "line_number": 232, "body": "def test_multiple_weak_etag_not_match(self):\n        computed_etag = '\"xyzzy3\"'\n        etags = 'W/\"xyzzy1\", W/\"xyzzy2\"'\n        self.check_url(\n            '/cache/' + computed_etag, method='GET',\n            headers=[('If-None-Match', etags)],\n            expected_status=200)", "is_method": true, "class_name": "TestMixin", "function_description": "Method in TestMixin that verifies HTTP GET requests return a 200 status when the computed weak ETag does not match any provided weak ETags, ensuring correct cache validation behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_app", "line_number": 242, "body": "def get_app(self):\n        return Application(self.get_handlers(), **self.get_app_kwargs())", "is_method": true, "class_name": "DefaultHTTPTest", "function_description": "Creates and returns a configured web application instance using predefined handlers and settings. This method facilitates initializing the application for testing HTTP interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_app", "line_number": 247, "body": "def get_app(self):\n        return Application(self.get_handlers(), gzip=True, **self.get_app_kwargs())", "is_method": true, "class_name": "GzipHTTPTest", "function_description": "Returns a web application instance configured with gzip compression enabled, facilitating efficient HTTP responses by compressing data."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/redbot/red_test.py", "function": "get_allowed_errors", "line_number": 250, "body": "def get_allowed_errors(self):\n        return super().get_allowed_errors() + [\n            # TODO: The Etag is supposed to change when Content-Encoding is\n            # used.  This should be fixed, but it's difficult to do with the\n            # way GZipContentEncoding fits into the pipeline, and in practice\n            # it doesn't seem likely to cause any problems as long as we're\n            # using the correct Vary header.\n            rs.VARY_ETAG_DOESNT_CHANGE,\n        ]", "is_method": true, "class_name": "GzipHTTPTest", "function_description": "Extends the base class's allowed error list by including a specific allowance for an ETag behavior related to Content-Encoding with gzip, supporting tolerant HTTP behavior during gzip encoding tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/cython/pythonmodule.py", "function": "hello", "line_number": 5, "body": "def hello():\n    yield gen.sleep(0.001)\n    raise gen.Return(\"hello\")", "is_method": false, "function_description": "This function asynchronously pauses briefly before returning the string \"hello,\" providing a simple asynchronous greeting generator."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/cython/cythonapp_test.py", "function": "test_native_coroutine", "line_number": 10, "body": "def test_native_coroutine(self):\n        x = yield cythonapp.native_coroutine()\n        self.assertEqual(x, \"goodbye\")", "is_method": true, "class_name": "CythonCoroutineTest", "function_description": "Tests that the native coroutine returns the expected result \"goodbye,\" verifying coroutine behavior within the CythonCoroutineTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/cython/cythonapp_test.py", "function": "test_decorated_coroutine", "line_number": 15, "body": "def test_decorated_coroutine(self):\n        x = yield cythonapp.decorated_coroutine()\n        self.assertEqual(x, \"goodbye\")", "is_method": true, "class_name": "CythonCoroutineTest", "function_description": "Test method in CythonCoroutineTest that verifies the output of a decorated coroutine matches the expected result \"goodbye\"."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/cython/cythonapp_test.py", "function": "test_arg_replacer_function", "line_number": 21, "body": "def test_arg_replacer_function(self):\n        replacer = ArgReplacer(cythonapp.function_with_args, 'two')\n        args = (1, 'old', 3)\n        kwargs = {}\n        self.assertEqual(replacer.get_old_value(args, kwargs), 'old')\n        self.assertEqual(replacer.replace('new', args, kwargs),\n                         ('old', [1, 'new', 3], {}))", "is_method": true, "class_name": "CythonArgReplacerTest", "function_description": "Test method in CythonArgReplacerTest verifying that ArgReplacer correctly retrieves and replaces a specified argument's value in both positional and keyword arguments."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/cython/cythonapp_test.py", "function": "test_arg_replacer_method", "line_number": 29, "body": "def test_arg_replacer_method(self):\n        replacer = ArgReplacer(cythonapp.AClass().method_with_args, 'two')\n        args = (1, 'old', 3)\n        kwargs = {}\n        self.assertEqual(replacer.get_old_value(args, kwargs), 'old')\n        self.assertEqual(replacer.replace('new', args, kwargs),\n                         ('old', [1, 'new', 3], {}))", "is_method": true, "class_name": "CythonArgReplacerTest", "function_description": "Test method in CythonArgReplacerTest that verifies functionality of ArgReplacer for extracting and replacing a specific argument in method calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/mypy/bad.py", "function": "get", "line_number": 5, "body": "def get(self) -> str:  # Deliberate type error\n        return \"foo\"", "is_method": true, "class_name": "MyHandler", "function_description": "Simple method of the MyHandler class that returns the fixed string \"foo\". It can be used as a placeholder or test response in request handling scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/test/mypy/good.py", "function": "get", "line_number": 6, "body": "def get(self) -> None:\n        self.write(\"foo\")", "is_method": true, "class_name": "MyHandler", "function_description": "Writes a fixed string \"foo\" as a response to a GET request. It serves as a simple handler method for returning static content in a web context."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_unicode_literal.py", "function": "transform", "line_number": 17, "body": "def transform(self, node, results):\n        arg = results[\"arg\"]\n        node.replace(String('u' + arg.value, prefix=node.prefix))", "is_method": true, "class_name": "FixUnicodeLiteral", "function_description": "Transforms a string node by prefixing it with 'u' to represent a Unicode literal, updating the node accordingly. This supports converting string representations to Unicode format within code transformations."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_future_imports.py", "function": "is_docstring", "line_number": 10, "body": "def is_docstring(stmt):\n    return isinstance(stmt, pytree.Node) and stmt.children[0].type == token.STRING", "is_method": false, "function_description": "Checks whether a given syntax tree node represents a docstring by verifying its type and structure. This function helps identify docstring statements within parsed Python code."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_future_imports.py", "function": "start_tree", "line_number": 19, "body": "def start_tree(self, tree, filename):\n        self.found_future_import = False", "is_method": true, "class_name": "FixFutureImports", "function_description": "Resets the state indicating whether future imports have been found when beginning to process a new syntax tree in the FixFutureImports context."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_future_imports.py", "function": "new_future_import", "line_number": 22, "body": "def new_future_import(self, old):\n        new = FromImport(\"__future__\",\n                         [Name(\"absolute_import\", prefix=\" \"), Comma(),\n                          Name(\"division\", prefix=\" \"), Comma(),\n                          Name(\"print_function\", prefix=\" \")])\n        if old is not None:\n            new.prefix = old.prefix\n        return new", "is_method": true, "class_name": "FixFutureImports", "function_description": "Creates a new import statement for Python 2 compatibility, adding future features like absolute_import, division, and print_function. This supports code modernization by enabling future Python 3 behaviors in older code."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_future_imports.py", "function": "transform", "line_number": 31, "body": "def transform(self, node, results):\n        self.found_future_import = True\n        return self.new_future_import(node)", "is_method": true, "class_name": "FixFutureImports", "function_description": "Core method of the FixFutureImports class that marks detection of a future import statement and transforms it into a standardized future import node representation."}, {"file": "./dataset/RepoExec/test-apps/tornado/maint/scripts/custom_fixers/fix_future_imports.py", "function": "finish_tree", "line_number": 35, "body": "def finish_tree(self, tree, filename):\n        if self.found_future_import:\n            return\n        if not isinstance(tree, pytree.Node):\n            # Empty files (usually __init__.py) show up as a single Leaf\n            # instead of a Node, so leave them alone\n            return\n        first_stmt = tree.children[0]\n        if is_docstring(first_stmt):\n            # Skip a line and add the import after the docstring\n            tree.insert_child(1, Newline())\n            pos = 2\n        elif first_stmt.prefix:\n            # No docstring, but an initial comment (perhaps a #! line).\n            # Transfer the initial comment to a new blank line.\n            newline = Newline()\n            newline.prefix = first_stmt.prefix\n            first_stmt.prefix = \"\"\n            tree.insert_child(0, newline)\n            pos = 1\n        else:\n            # No comments or docstring, just insert at the start\n            pos = 0\n        tree.insert_child(pos, self.new_future_import(None))\n        tree.insert_child(pos + 1, Newline())", "is_method": true, "class_name": "FixFutureImports", "function_description": "Adds a future import statement to a Python syntax tree if none exists, ensuring compatibility or feature enabling, while preserving existing docstrings or initial comments in the source code."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/facebook/facebook.py", "function": "main", "line_number": 112, "body": "def main():\n    tornado.options.parse_command_line()\n    if not (options.facebook_api_key and options.facebook_secret):\n        print(\"--facebook_api_key and --facebook_secret must be set\")\n        return\n    http_server = tornado.httpserver.HTTPServer(Application())\n    http_server.listen(options.port)\n    tornado.ioloop.IOLoop.current().start()", "is_method": false, "function_description": "Starts a Tornado web server application after validating required Facebook API credentials, enabling the app to listen on a specified port and handle incoming requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/facebook/facebook.py", "function": "get_current_user", "line_number": 55, "body": "def get_current_user(self):\n        user_json = self.get_secure_cookie(\"fbdemo_user\")\n        if not user_json:\n            return None\n        return tornado.escape.json_decode(user_json)", "is_method": true, "class_name": "BaseHandler", "function_description": "Method of the BaseHandler class that retrieves and decodes the current user's information from a secure cookie, facilitating user session management in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/facebook/facebook.py", "function": "get", "line_number": 102, "body": "def get(self):\n        self.clear_cookie(\"fbdemo_user\")\n        self.redirect(self.get_argument(\"next\", \"/\"))", "is_method": true, "class_name": "AuthLogoutHandler", "function_description": "Clears the user authentication cookie and redirects the user to a specified or default page, effectively logging them out. This method supports session termination in web authentication flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/facebook/facebook.py", "function": "render", "line_number": 108, "body": "def render(self, post):\n        return self.render_string(\"modules/post.html\", post=post)", "is_method": true, "class_name": "PostModule", "function_description": "Utility method in PostModule that renders a post using a predefined HTML template, facilitating consistent post presentation in the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "get", "line_number": 48, "body": "def get(self):\n        self.render(\"index.html\", messages=ChatSocketHandler.cache)", "is_method": true, "class_name": "MainHandler", "function_description": "Renders the index.html page, providing it with cached chat messages for display. This enables serving a chat interface populated with current conversation history."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "get_compression_options", "line_number": 57, "body": "def get_compression_options(self):\n        # Non-None enables compression with default options.\n        return {}", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Returns compression settings for the chat socket, enabling message compression with default options if set. It provides configuration support for optimizing data transmission in real-time chat communications."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "open", "line_number": 61, "body": "def open(self):\n        ChatSocketHandler.waiters.add(self)", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Adds the current chat socket connection to the list of active waiters, enabling it to receive real-time updates or messages. This function is essential for managing active WebSocket connections in a chat application."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "on_close", "line_number": 64, "body": "def on_close(self):\n        ChatSocketHandler.waiters.remove(self)", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Removes the current socket connection from the set of active clients when the connection closes, helping manage and track active websocket sessions."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "update_cache", "line_number": 68, "body": "def update_cache(cls, chat):\n        cls.cache.append(chat)\n        if len(cls.cache) > cls.cache_size:\n            cls.cache = cls.cache[-cls.cache_size :]", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Utility method of ChatSocketHandler that maintains a fixed-size cache of chat objects by appending new entries and trimming excess to preserve cache size limits."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "send_updates", "line_number": 74, "body": "def send_updates(cls, chat):\n        logging.info(\"sending message to %d waiters\", len(cls.waiters))\n        for waiter in cls.waiters:\n            try:\n                waiter.write_message(chat)\n            except:\n                logging.error(\"Error sending message\", exc_info=True)", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Service method of ChatSocketHandler that broadcasts chat updates to all connected waiters, ensuring real-time message delivery with error handling for each recipient."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/websocket/chatdemo.py", "function": "on_message", "line_number": 82, "body": "def on_message(self, message):\n        logging.info(\"got message %r\", message)\n        parsed = tornado.escape.json_decode(message)\n        chat = {\"id\": str(uuid.uuid4()), \"body\": parsed[\"body\"]}\n        chat[\"html\"] = tornado.escape.to_basestring(\n            self.render_string(\"message.html\", message=chat)\n        )\n\n        ChatSocketHandler.update_cache(chat)\n        ChatSocketHandler.send_updates(chat)", "is_method": true, "class_name": "ChatSocketHandler", "function_description": "Handles incoming chat messages by parsing, formatting, caching, and broadcasting them to update connected clients in real-time chat sessions."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/helloworld/helloworld.py", "function": "main", "line_number": 32, "body": "def main():\n    tornado.options.parse_command_line()\n    application = tornado.web.Application([(r\"/\", MainHandler)])\n    http_server = tornado.httpserver.HTTPServer(application)\n    http_server.listen(options.port)\n    tornado.ioloop.IOLoop.current().start()", "is_method": false, "function_description": "Starts a Tornado web server configured to listen on a specified port and handle incoming HTTP requests using a main request handler. It provides a simple entry point to run the web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/helloworld/helloworld.py", "function": "get", "line_number": 28, "body": "def get(self):\n        self.write(\"Hello, world\")", "is_method": true, "class_name": "MainHandler", "function_description": "Simple web request handler method sending a plain text greeting response, typically used as a basic test or placeholder endpoint in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_uploader.py", "function": "multipart_producer", "line_number": 31, "body": "def multipart_producer(boundary, filenames, write):\n    boundary_bytes = boundary.encode()\n\n    for filename in filenames:\n        filename_bytes = filename.encode()\n        mtype = mimetypes.guess_type(filename)[0] or \"application/octet-stream\"\n        buf = (\n            (b\"--%s\\r\\n\" % boundary_bytes)\n            + (\n                b'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"\\r\\n'\n                % (filename_bytes, filename_bytes)\n            )\n            + (b\"Content-Type: %s\\r\\n\" % mtype.encode())\n            + b\"\\r\\n\"\n        )\n        yield write(buf)\n        with open(filename, \"rb\") as f:\n            while True:\n                # 16k at a time.\n                chunk = f.read(16 * 1024)\n                if not chunk:\n                    break\n                yield write(chunk)\n\n        yield write(b\"\\r\\n\")\n\n    yield write(b\"--%s--\\r\\n\" % (boundary_bytes,))", "is_method": false, "function_description": "Generates multipart/form-data body parts for given files, writing each file's content with proper headers in chunks to support file uploads over HTTP. Useful for constructing HTTP requests with multiple file payloads."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_uploader.py", "function": "post", "line_number": 63, "body": "def post(filenames):\n    client = httpclient.AsyncHTTPClient()\n    boundary = uuid4().hex\n    headers = {\"Content-Type\": \"multipart/form-data; boundary=%s\" % boundary}\n    producer = partial(multipart_producer, boundary, filenames)\n    response = yield client.fetch(\n        \"http://localhost:8888/post\",\n        method=\"POST\",\n        headers=headers,\n        body_producer=producer,\n    )\n\n    print(response)", "is_method": false, "function_description": "This function asynchronously sends files using a multipart/form-data POST request to a local server endpoint and prints the server's response. It is useful for uploading multiple files in an asynchronous application."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_uploader.py", "function": "raw_producer", "line_number": 79, "body": "def raw_producer(filename, write):\n    with open(filename, \"rb\") as f:\n        while True:\n            # 16K at a time.\n            chunk = f.read(16 * 1024)\n            if not chunk:\n                # Complete.\n                break\n\n            yield write(chunk)", "is_method": false, "function_description": "Function that reads a file in 16KB chunks and applies a given write function to each chunk, yielding the results. Useful for processing large files incrementally without loading them entirely in memory."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_uploader.py", "function": "put", "line_number": 92, "body": "def put(filenames):\n    client = httpclient.AsyncHTTPClient()\n    for filename in filenames:\n        mtype = mimetypes.guess_type(filename)[0] or \"application/octet-stream\"\n        headers = {\"Content-Type\": mtype}\n        producer = partial(raw_producer, filename)\n        url_path = quote(os.path.basename(filename))\n        response = yield client.fetch(\n            \"http://localhost:8888/%s\" % url_path,\n            method=\"PUT\",\n            headers=headers,\n            body_producer=producer,\n        )\n        print(response)", "is_method": false, "function_description": "Function that uploads multiple files asynchronously to a local HTTP server using PUT requests, automatically setting content types based on file extensions. Useful for batch uploading or syncing files to a web service."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_receiver.py", "function": "make_app", "line_number": 52, "body": "def make_app():\n    return tornado.web.Application([(r\"/post\", POSTHandler), (r\"/(.*)\", PUTHandler)])", "is_method": false, "function_description": "Constructs and returns a Tornado web application configured with routing for POST and PUT request handlers. This function serves as the entry point for setting up the application's request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_receiver.py", "function": "post", "line_number": 25, "body": "def post(self):\n        for field_name, files in self.request.files.items():\n            for info in files:\n                filename, content_type = info[\"filename\"], info[\"content_type\"]\n                body = info[\"body\"]\n                logging.info(\n                    'POST \"%s\" \"%s\" %d bytes', filename, content_type, len(body)\n                )\n\n        self.write(\"OK\")", "is_method": true, "class_name": "POSTHandler", "function_description": "Handles incoming POST requests by logging details of each uploaded file and responding with a simple confirmation message. It supports file uploads by processing all files included in the request."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_receiver.py", "function": "initialize", "line_number": 39, "body": "def initialize(self):\n        self.bytes_read = 0", "is_method": true, "class_name": "PUTHandler", "function_description": "Resets the byte counter for tracking data received during a PUT request, preparing the handler to measure incoming data size from the start."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_receiver.py", "function": "data_received", "line_number": 42, "body": "def data_received(self, chunk):\n        self.bytes_read += len(chunk)", "is_method": true, "class_name": "PUTHandler", "function_description": "In the context of the PUTHandler class, this method tracks the amount of data received by incrementally updating the byte count as new data chunks arrive. It provides a way to monitor data transfer progress during PUT operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/file_upload/file_receiver.py", "function": "put", "line_number": 45, "body": "def put(self, filename):\n        filename = unquote(filename)\n        mtype = self.request.headers.get(\"Content-Type\")\n        logging.info('PUT \"%s\" \"%s\" %d bytes', filename, mtype, self.bytes_read)\n        self.write(\"OK\")", "is_method": true, "class_name": "PUTHandler", "function_description": "Handles HTTP PUT requests by logging the filename, content type, and bytes received, then responds with a confirmation message. Used to process and acknowledge file upload attempts."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "start", "line_number": 57, "body": "def start(port, root_directory, bucket_depth):\n    \"\"\"Starts the mock S3 server on the given port at the given path.\"\"\"\n    application = S3Application(root_directory, bucket_depth)\n    http_server = httpserver.HTTPServer(application)\n    http_server.listen(port)\n    ioloop.IOLoop.current().start()", "is_method": false, "function_description": "Starts and runs a mock S3 server on the specified port using a given root directory and bucket depth, enabling local S3-compatible storage and testing environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "render_xml", "line_number": 91, "body": "def render_xml(self, value):\n        assert isinstance(value, dict) and len(value) == 1\n        self.set_header(\"Content-Type\", \"application/xml; charset=UTF-8\")\n        name = list(value.keys())[0]\n        parts = []\n        parts.append(\"<\" + name + ' xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">')\n        self._render_parts(value[name], parts)\n        parts.append(\"</\" + name + \">\")\n        self.finish('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' + \"\".join(parts))", "is_method": true, "class_name": "BaseRequestHandler", "function_description": "Provides XML response rendering by converting a single-root dictionary into a namespaced XML string, setting appropriate headers, and finalizing the HTTP response with the XML content."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "_render_parts", "line_number": 101, "body": "def _render_parts(self, value, parts=[]):\n        if isinstance(value, (unicode_type, bytes)):\n            parts.append(escape.xhtml_escape(value))\n        elif isinstance(value, (int, long)):\n            parts.append(str(value))\n        elif isinstance(value, datetime.datetime):\n            parts.append(value.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"))\n        elif isinstance(value, dict):\n            for name, subvalue in value.items():\n                if not isinstance(subvalue, list):\n                    subvalue = [subvalue]\n                for subsubvalue in subvalue:\n                    parts.append(\"<\" + name + \">\")\n                    self._render_parts(subsubvalue, parts)\n                    parts.append(\"</\" + name + \">\")\n        else:\n            raise Exception(\"Unknown S3 value type %r\", value)", "is_method": true, "class_name": "BaseRequestHandler", "function_description": "Utility method in BaseRequestHandler that converts various Python data types into escaped XML string parts, supporting nested dictionaries for structured XML serialization."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "_object_path", "line_number": 119, "body": "def _object_path(self, bucket, object_name):\n        if self.application.bucket_depth < 1:\n            return os.path.abspath(\n                os.path.join(self.application.directory, bucket, object_name)\n            )\n        hash = hashlib.md5(object_name).hexdigest()\n        path = os.path.abspath(os.path.join(self.application.directory, bucket))\n        for i in range(self.application.bucket_depth):\n            path = os.path.join(path, hash[: 2 * (i + 1)])\n        return os.path.join(path, object_name)", "is_method": true, "class_name": "BaseRequestHandler", "function_description": "Generates a filesystem path for an object within a bucket, optionally organizing it into nested subdirectories based on a hash of the object's name. This enables efficient and scalable storage management with fixed-depth directory structures."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "get", "line_number": 132, "body": "def get(self):\n        names = os.listdir(self.application.directory)\n        buckets = []\n        for name in names:\n            path = os.path.join(self.application.directory, name)\n            info = os.stat(path)\n            buckets.append(\n                {\n                    \"Name\": name,\n                    \"CreationDate\": datetime.datetime.utcfromtimestamp(info.st_ctime),\n                }\n            )\n        self.render_xml({\"ListAllMyBucketsResult\": {\"Buckets\": {\"Bucket\": buckets}}})", "is_method": true, "class_name": "RootHandler", "function_description": "Provides a listing of all buckets in the application's directory with their creation dates, rendering the result in XML format. It supports clients needing an overview of available storage buckets and their metadata."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "get", "line_number": 148, "body": "def get(self, bucket_name):\n        prefix = self.get_argument(\"prefix\", u\"\")\n        marker = self.get_argument(\"marker\", u\"\")\n        max_keys = int(self.get_argument(\"max-keys\", 50000))\n        path = os.path.abspath(os.path.join(self.application.directory, bucket_name))\n        terse = int(self.get_argument(\"terse\", 0))\n        if not path.startswith(self.application.directory) or not os.path.isdir(path):\n            raise web.HTTPError(404)\n        object_names = []\n        for root, dirs, files in os.walk(path):\n            for file_name in files:\n                object_names.append(os.path.join(root, file_name))\n        skip = len(path) + 1\n        for i in range(self.application.bucket_depth):\n            skip += 2 * (i + 1) + 1\n        object_names = [n[skip:] for n in object_names]\n        object_names.sort()\n        contents = []\n\n        start_pos = 0\n        if marker:\n            start_pos = bisect.bisect_right(object_names, marker, start_pos)\n        if prefix:\n            start_pos = bisect.bisect_left(object_names, prefix, start_pos)\n\n        truncated = False\n        for object_name in object_names[start_pos:]:\n            if not object_name.startswith(prefix):\n                break\n            if len(contents) >= max_keys:\n                truncated = True\n                break\n            object_path = self._object_path(bucket_name, object_name)\n            c = {\"Key\": object_name}\n            if not terse:\n                info = os.stat(object_path)\n                c.update(\n                    {\n                        \"LastModified\": datetime.datetime.utcfromtimestamp(\n                            info.st_mtime\n                        ),\n                        \"Size\": info.st_size,\n                    }\n                )\n            contents.append(c)\n            marker = object_name\n        self.render_xml(\n            {\n                \"ListBucketResult\": {\n                    \"Name\": bucket_name,\n                    \"Prefix\": prefix,\n                    \"Marker\": marker,\n                    \"MaxKeys\": max_keys,\n                    \"IsTruncated\": truncated,\n                    \"Contents\": contents,\n                }\n            }\n        )", "is_method": true, "class_name": "BucketHandler", "function_description": "Handles listing and retrieving objects within a specified storage bucket, supporting filtering by prefix and marker, pagination via max-keys, and optional terse metadata output for efficient bucket content browsing."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "put", "line_number": 207, "body": "def put(self, bucket_name):\n        path = os.path.abspath(os.path.join(self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or os.path.exists(path):\n            raise web.HTTPError(403)\n        os.makedirs(path)\n        self.finish()", "is_method": true, "class_name": "BucketHandler", "function_description": "Creates a new directory with the given bucket name within the application\u2019s directory, ensuring no overwriting or unauthorized access. Provides controlled bucket creation for managing application storage."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "delete", "line_number": 214, "body": "def delete(self, bucket_name):\n        path = os.path.abspath(os.path.join(self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or not os.path.isdir(path):\n            raise web.HTTPError(404)\n        if len(os.listdir(path)) > 0:\n            raise web.HTTPError(403)\n        os.rmdir(path)\n        self.set_status(204)\n        self.finish()", "is_method": true, "class_name": "BucketHandler", "function_description": "Utility method of BucketHandler that deletes an empty directory named after the bucket within the application directory, enforcing existence and emptiness checks before removal to ensure safe bucket deletion."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "get", "line_number": 226, "body": "def get(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or not os.path.isfile(path):\n            raise web.HTTPError(404)\n        info = os.stat(path)\n        self.set_header(\"Content-Type\", \"application/unknown\")\n        self.set_header(\n            \"Last-Modified\", datetime.datetime.utcfromtimestamp(info.st_mtime)\n        )\n        with open(path, \"rb\") as object_file:\n            self.finish(object_file.read())", "is_method": true, "class_name": "ObjectHandler", "function_description": "Handles HTTP GET requests to retrieve an object file from a specified bucket, verifies its existence and path, sets appropriate headers, and returns the file's binary content for client delivery."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "put", "line_number": 239, "body": "def put(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        bucket_dir = os.path.abspath(os.path.join(self.application.directory, bucket))\n        if not bucket_dir.startswith(self.application.directory) or not os.path.isdir(\n            bucket_dir\n        ):\n            raise web.HTTPError(404)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(bucket_dir) or os.path.isdir(path):\n            raise web.HTTPError(403)\n        directory = os.path.dirname(path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        with open(path, \"w\") as object_file:\n            object_file.write(self.request.body)\n        self.finish()", "is_method": true, "class_name": "ObjectHandler", "function_description": "Method of ObjectHandler that stores the request body as a file named object_name inside a specified bucket directory, ensuring directory safety and creating necessary folders. It facilitates secure file uploads within the application\u2019s storage structure."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/s3server/s3server.py", "function": "delete", "line_number": 256, "body": "def delete(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or not os.path.isfile(path):\n            raise web.HTTPError(404)\n        os.unlink(path)\n        self.set_status(204)\n        self.finish()", "is_method": true, "class_name": "ObjectHandler", "function_description": "Method of ObjectHandler that deletes a specified object file from a given bucket after validating its path, providing a way to remove stored files within a controlled directory."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/blog/blog.py", "function": "row_to_obj", "line_number": 84, "body": "def row_to_obj(self, row, cur):\n        \"\"\"Convert a SQL row to an object supporting dict and attribute access.\"\"\"\n        obj = tornado.util.ObjectDict()\n        for val, desc in zip(row, cur.description):\n            obj[desc.name] = val\n        return obj", "is_method": true, "class_name": "BaseHandler", "function_description": "Core method of BaseHandler that converts a SQL query result row into an object supporting both dictionary-style and attribute-style access for easier data manipulation and readability."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/blog/blog.py", "function": "get", "line_number": 230, "body": "def get(self):\n        self.render(\"create_author.html\")", "is_method": true, "class_name": "AuthCreateHandler", "function_description": "Renders and displays the \"create_author.html\" page, typically serving as the interface for creating a new author entry."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/blog/blog.py", "function": "get", "line_number": 283, "body": "def get(self):\n        self.clear_cookie(\"blogdemo_user\")\n        self.redirect(self.get_argument(\"next\", \"/\"))", "is_method": true, "class_name": "AuthLogoutHandler", "function_description": "Handles user logout by clearing the authentication cookie and redirecting to a specified or default page. This function enables session termination in web authentication workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/blog/blog.py", "function": "render", "line_number": 289, "body": "def render(self, entry):\n        return self.render_string(\"modules/entry.html\", entry=entry)", "is_method": true, "class_name": "EntryModule", "function_description": "Render method of EntryModule that generates the HTML representation of an entry using a predefined template. It provides a convenient way to convert entry data into a formatted webpage segment."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "main", "line_number": 110, "body": "def main():\n    parse_command_line()\n    app = tornado.web.Application(\n        [\n            (r\"/\", MainHandler),\n            (r\"/a/message/new\", MessageNewHandler),\n            (r\"/a/message/updates\", MessageUpdatesHandler),\n        ],\n        cookie_secret=\"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\",\n        template_path=os.path.join(os.path.dirname(__file__), \"templates\"),\n        static_path=os.path.join(os.path.dirname(__file__), \"static\"),\n        xsrf_cookies=True,\n        debug=options.debug,\n    )\n    app.listen(options.port)\n    tornado.ioloop.IOLoop.current().start()", "is_method": false, "function_description": "Entry-point function that configures and starts a Tornado web server with specified routes, security settings, and resource paths to handle web requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "get_messages_since", "line_number": 38, "body": "def get_messages_since(self, cursor):\n        \"\"\"Returns a list of messages newer than the given cursor.\n\n        ``cursor`` should be the ``id`` of the last message received.\n        \"\"\"\n        results = []\n        for msg in reversed(self.cache):\n            if msg[\"id\"] == cursor:\n                break\n            results.append(msg)\n        results.reverse()\n        return results", "is_method": true, "class_name": "MessageBuffer", "function_description": "Retrieves all messages added after a specific message ID from the MessageBuffer, enabling incremental access to new messages since a given point in the conversation history."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "add_message", "line_number": 51, "body": "def add_message(self, message):\n        self.cache.append(message)\n        if len(self.cache) > self.cache_size:\n            self.cache = self.cache[-self.cache_size :]\n        self.cond.notify_all()", "is_method": true, "class_name": "MessageBuffer", "function_description": "Utility method of MessageBuffer that adds a message to the buffer while enforcing a maximum cache size, and notifies any waiting processes of the new message availability."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "get", "line_number": 63, "body": "def get(self):\n        self.render(\"index.html\", messages=global_message_buffer.cache)", "is_method": true, "class_name": "MainHandler", "function_description": "Handles HTTP GET requests by rendering the main page with a cache of global messages, supporting web interface updates with current message data."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "post", "line_number": 70, "body": "def post(self):\n        message = {\"id\": str(uuid.uuid4()), \"body\": self.get_argument(\"body\")}\n        # render_string() returns a byte string, which is not supported\n        # in json, so we must convert it to a character string.\n        message[\"html\"] = tornado.escape.to_unicode(\n            self.render_string(\"message.html\", message=message)\n        )\n        if self.get_argument(\"next\", None):\n            self.redirect(self.get_argument(\"next\"))\n        else:\n            self.write(message)\n        global_message_buffer.add_message(message)", "is_method": true, "class_name": "MessageNewHandler", "function_description": "Handles posting a new message by creating, rendering, and storing it, then optionally redirecting or returning the message data. It facilitates message submission and buffering in a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/chat/chatdemo.py", "function": "on_connection_close", "line_number": 106, "body": "def on_connection_close(self):\n        self.wait_future.cancel()", "is_method": true, "class_name": "MessageUpdatesHandler", "function_description": "Cancels any pending wait operations when a connection is closed, ensuring proper cleanup of resources in connection management."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/twitter/twitterdemo.py", "function": "get_current_user", "line_number": 55, "body": "def get_current_user(self):\n        user_json = self.get_secure_cookie(self.COOKIE_NAME)\n        if not user_json:\n            return None\n        return json_decode(user_json)", "is_method": true, "class_name": "BaseHandler", "function_description": "Provides the current authenticated user's information by retrieving and decoding a secure cookie. This method is essential for user session management and access control within the BaseHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/twitter/twitterdemo.py", "function": "get", "line_number": 65, "body": "def get(self):\n        timeline = yield self.twitter_request(\n            \"/statuses/home_timeline\", access_token=self.current_user[\"access_token\"]\n        )\n        self.render(\"home.html\", timeline=timeline)", "is_method": true, "class_name": "MainHandler", "function_description": "Handles GET requests by fetching the user's Twitter home timeline and rendering it on the homepage. It enables displaying real-time tweets from the authenticated user's feed."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/twitter/twitterdemo.py", "function": "get", "line_number": 74, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            user = yield self.get_authenticated_user()\n            del user[\"description\"]\n            self.set_secure_cookie(self.COOKIE_NAME, json_encode(user))\n            self.redirect(self.get_argument(\"next\", \"/\"))\n        else:\n            yield self.authorize_redirect(callback_uri=self.request.full_url())", "is_method": true, "class_name": "LoginHandler", "function_description": "Handles OAuth login by retrieving user info with a token, setting a secure cookie, and redirecting; if no token is provided, it initiates the OAuth authorization flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/twitter/twitterdemo.py", "function": "get", "line_number": 85, "body": "def get(self):\n        self.clear_cookie(self.COOKIE_NAME)", "is_method": true, "class_name": "LogoutHandler", "function_description": "Method of the LogoutHandler class that clears the authentication cookie to log a user out. It provides a straightforward way to terminate user sessions by removing their login token."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/webspider/webspider.py", "function": "remove_fragment", "line_number": 29, "body": "def remove_fragment(url):\n    pure_url, frag = urldefrag(url)\n    return pure_url", "is_method": false, "function_description": "Function that removes the fragment component from a URL, returning the base URL without any anchor tags. Useful for standardizing URLs by excluding fragment identifiers."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/webspider/webspider.py", "function": "get_links", "line_number": 34, "body": "def get_links(html):\n    class URLSeeker(HTMLParser):\n        def __init__(self):\n            HTMLParser.__init__(self)\n            self.urls = []\n\n        def handle_starttag(self, tag, attrs):\n            href = dict(attrs).get(\"href\")\n            if href and tag == \"a\":\n                self.urls.append(href)\n\n    url_seeker = URLSeeker()\n    url_seeker.feed(html)\n    return url_seeker.urls", "is_method": false, "function_description": "Function that extracts and returns all hyperlink URLs from a given HTML string, supporting use cases like web scraping and link analysis."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/webspider/webspider.py", "function": "handle_starttag", "line_number": 40, "body": "def handle_starttag(self, tag, attrs):\n            href = dict(attrs).get(\"href\")\n            if href and tag == \"a\":\n                self.urls.append(href)", "is_method": true, "class_name": "URLSeeker", "function_description": "Extracts and collects all URLs from anchor (<a>) tags encountered during HTML parsing, enabling subsequent processing or analysis of linked web resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/demos/tcpecho/server.py", "function": "handle_stream", "line_number": 16, "body": "def handle_stream(self, stream, address):\n        while True:\n            try:\n                data = yield stream.read_until(b\"\\n\")\n                logger.info(\"Received bytes: %s\", data)\n                if not data.endswith(b\"\\n\"):\n                    data = data + b\"\\n\"\n                yield stream.write(data)\n            except StreamClosedError:\n                logger.warning(\"Lost client at host %s\", address[0])\n                break\n            except Exception as e:\n                print(e)", "is_method": true, "class_name": "EchoServer", "function_description": "Handles a persistent stream by reading incoming data until newline, then echoes it back to the sender. It manages connection interruptions gracefully, supporting real-time data exchange in an echo server context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "_unquote_or_none", "line_number": 708, "body": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "is_method": false, "function_description": "Helper function that safely decodes a URL-encoded byte string or returns None if the input is None, ensuring correct handling of optional unmatched groups during decoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "start_request", "line_number": 207, "body": "def start_request(\n        self, server_conn: object, request_conn: httputil.HTTPConnection\n    ) -> httputil.HTTPMessageDelegate:\n        return _RoutingDelegate(self, server_conn, request_conn)", "is_method": true, "class_name": "Router", "function_description": "Returns a delegate that manages routing for an incoming HTTP request, linking server and request connections to handle request processing within the Router class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "headers_received", "line_number": 238, "body": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        assert isinstance(start_line, httputil.RequestStartLine)\n        request = httputil.HTTPServerRequest(\n            connection=self.request_conn,\n            server_connection=self.server_conn,\n            start_line=start_line,\n            headers=headers,\n        )\n\n        self.delegate = self.router.find_handler(request)\n        if self.delegate is None:\n            app_log.debug(\n                \"Delegate for %s %s request not found\",\n                start_line.method,\n                start_line.path,\n            )\n            self.delegate = _DefaultMessageDelegate(self.request_conn)\n\n        return self.delegate.headers_received(start_line, headers)", "is_method": true, "class_name": "_RoutingDelegate", "function_description": "Handles incoming HTTP request headers by selecting or creating an appropriate delegate to process the request, enabling dynamic routing based on the request details."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "data_received", "line_number": 262, "body": "def data_received(self, chunk: bytes) -> Optional[Awaitable[None]]:\n        assert self.delegate is not None\n        return self.delegate.data_received(chunk)", "is_method": true, "class_name": "_RoutingDelegate", "function_description": "This method forwards received data chunks to a delegate for processing, enabling flexible handling of incoming byte streams in a network routing context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "finish", "line_number": 266, "body": "def finish(self) -> None:\n        assert self.delegate is not None\n        self.delegate.finish()", "is_method": true, "class_name": "_RoutingDelegate", "function_description": "Calls the finish method of its assigned delegate to complete any ongoing operations, acting as a pass-through to finalize delegated tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "on_connection_close", "line_number": 270, "body": "def on_connection_close(self) -> None:\n        assert self.delegate is not None\n        self.delegate.on_connection_close()", "is_method": true, "class_name": "_RoutingDelegate", "function_description": "Calls the delegate's on_connection_close method to handle connection closure events. It enables forwarding connection close notifications within a routing delegation context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "finish", "line_number": 279, "body": "def finish(self) -> None:\n        self.connection.write_headers(\n            httputil.ResponseStartLine(\"HTTP/1.1\", 404, \"Not Found\"),\n            httputil.HTTPHeaders(),\n        )\n        self.connection.finish()", "is_method": true, "class_name": "_DefaultMessageDelegate", "function_description": "Finishes the connection by sending a 404 Not Found HTTP response and closing the connection. This method signals that the requested resource was not found and terminates the communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "add_rules", "line_number": 334, "body": "def add_rules(self, rules: _RuleList) -> None:\n        \"\"\"Appends new rules to the router.\n\n        :arg rules: a list of Rule instances (or tuples of arguments, which are\n            passed to Rule constructor).\n        \"\"\"\n        for rule in rules:\n            if isinstance(rule, (tuple, list)):\n                assert len(rule) in (2, 3, 4)\n                if isinstance(rule[0], basestring_type):\n                    rule = Rule(PathMatches(rule[0]), *rule[1:])\n                else:\n                    rule = Rule(*rule)\n\n            self.rules.append(self.process_rule(rule))", "is_method": true, "class_name": "RuleRouter", "function_description": "Adds new matching rules to the RuleRouter, allowing flexible rule definition via Rule instances or argument tuples to extend routing logic. This enables dynamic configuration of routing behavior based on customizable criteria."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "process_rule", "line_number": 350, "body": "def process_rule(self, rule: \"Rule\") -> \"Rule\":\n        \"\"\"Override this method for additional preprocessing of each rule.\n\n        :arg Rule rule: a rule to be processed.\n        :returns: the same or modified Rule instance.\n        \"\"\"\n        return rule", "is_method": true, "class_name": "RuleRouter", "function_description": "Method in RuleRouter allowing customization of rule preprocessing by returning the original or a modified rule instance before further processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "find_handler", "line_number": 358, "body": "def find_handler(\n        self, request: httputil.HTTPServerRequest, **kwargs: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        for rule in self.rules:\n            target_params = rule.matcher.match(request)\n            if target_params is not None:\n                if rule.target_kwargs:\n                    target_params[\"target_kwargs\"] = rule.target_kwargs\n\n                delegate = self.get_target_delegate(\n                    rule.target, request, **target_params\n                )\n\n                if delegate is not None:\n                    return delegate\n\n        return None", "is_method": true, "class_name": "RuleRouter", "function_description": "Provides the ability to identify and return the appropriate handler for an HTTP request by matching it against routing rules, facilitating dynamic request delegation in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "get_target_delegate", "line_number": 376, "body": "def get_target_delegate(\n        self, target: Any, request: httputil.HTTPServerRequest, **target_params: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        \"\"\"Returns an instance of `~.httputil.HTTPMessageDelegate` for a\n        Rule's target. This method is called by `~.find_handler` and can be\n        extended to provide additional target types.\n\n        :arg target: a Rule's target.\n        :arg httputil.HTTPServerRequest request: current request.\n        :arg target_params: additional parameters that can be useful\n            for `~.httputil.HTTPMessageDelegate` creation.\n        \"\"\"\n        if isinstance(target, Router):\n            return target.find_handler(request, **target_params)\n\n        elif isinstance(target, httputil.HTTPServerConnectionDelegate):\n            assert request.connection is not None\n            return target.start_request(request.server_connection, request.connection)\n\n        elif callable(target):\n            assert request.connection is not None\n            return _CallableAdapter(\n                partial(target, **target_params), request.connection\n            )\n\n        return None", "is_method": true, "class_name": "RuleRouter", "function_description": "Core method of the RuleRouter class that determines and returns the appropriate HTTP message delegate for a given target based on its type, enabling flexible request handling and routing logic."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "process_rule", "line_number": 416, "body": "def process_rule(self, rule: \"Rule\") -> \"Rule\":\n        rule = super().process_rule(rule)\n\n        if rule.name:\n            if rule.name in self.named_rules:\n                app_log.warning(\n                    \"Multiple handlers named %s; replacing previous value\", rule.name\n                )\n            self.named_rules[rule.name] = rule\n\n        return rule", "is_method": true, "class_name": "ReversibleRuleRouter", "function_description": "Service method of ReversibleRuleRouter that processes a rule and registers it by name, replacing any existing rule with the same name to maintain a unique named-rule mapping."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "reverse_url", "line_number": 428, "body": "def reverse_url(self, name: str, *args: Any) -> Optional[str]:\n        if name in self.named_rules:\n            return self.named_rules[name].matcher.reverse(*args)\n\n        for rule in self.rules:\n            if isinstance(rule.target, ReversibleRouter):\n                reversed_url = rule.target.reverse_url(name, *args)\n                if reversed_url is not None:\n                    return reversed_url\n\n        return None", "is_method": true, "class_name": "ReversibleRuleRouter", "function_description": "Utility method in ReversibleRuleRouter that generates a URL string by reversing a named routing rule, supporting nested routers for flexible URL resolution in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "reverse", "line_number": 477, "body": "def reverse(self, *args: Any) -> Optional[str]:\n        return self.matcher.reverse(*args)", "is_method": true, "class_name": "Rule", "function_description": "This method in the Rule class delegates to its matcher to produce a reversed representation based on given arguments, potentially useful for generating or reconstructing patterns in reverse."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "__repr__", "line_number": 480, "body": "def __repr__(self) -> str:\n        return \"%s(%r, %s, kwargs=%r, name=%r)\" % (\n            self.__class__.__name__,\n            self.matcher,\n            self.target,\n            self.target_kwargs,\n            self.name,\n        )", "is_method": true, "class_name": "Rule", "function_description": "Provides a readable string representation of a Rule instance, displaying its matcher, target, target arguments, and name for easier debugging and logging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "match", "line_number": 513, "body": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        return {}", "is_method": true, "class_name": "AnyMatches", "function_description": "Returns an empty dictionary regardless of the input request, likely serving as a placeholder or default match response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "match", "line_number": 528, "body": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        if self.host_pattern.match(request.host_name):\n            return {}\n\n        return None", "is_method": true, "class_name": "HostMatches", "function_description": "Matches an HTTP request's host name against a predefined pattern, indicating whether the request matches specified host criteria. Useful for routing or filtering requests based on host names."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "match", "line_number": 544, "body": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        # Look for default host if not behind load balancer (for debugging)\n        if \"X-Real-Ip\" not in request.headers:\n            if self.host_pattern.match(self.application.default_host):\n                return {}\n        return None", "is_method": true, "class_name": "DefaultHostMatches", "function_description": "Checks if an incoming HTTP request matches the default host configuration when not behind a load balancer, typically used for debugging purposes. It provides a way to confirm default host handling in the DefaultHostMatches class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "match", "line_number": 570, "body": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        match = self.regex.match(request.path)\n        if match is None:\n            return None\n        if not self.regex.groups:\n            return {}\n\n        path_args = []  # type: List[bytes]\n        path_kwargs = {}  # type: Dict[str, bytes]\n\n        # Pass matched groups to the handler.  Since\n        # match.groups() includes both named and\n        # unnamed groups, we want to use either groups\n        # or groupdict but not both.\n        if self.regex.groupindex:\n            path_kwargs = dict(\n                (str(k), _unquote_or_none(v)) for (k, v) in match.groupdict().items()\n            )\n        else:\n            path_args = [_unquote_or_none(s) for s in match.groups()]\n\n        return dict(path_args=path_args, path_kwargs=path_kwargs)", "is_method": true, "class_name": "PathMatches", "function_description": "Returns extracted URL path parameters from an HTTP request if the path matches a predefined regex pattern, supporting both named and positional groups for flexible route handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "reverse", "line_number": 593, "body": "def reverse(self, *args: Any) -> Optional[str]:\n        if self._path is None:\n            raise ValueError(\"Cannot reverse url regex \" + self.regex.pattern)\n        assert len(args) == self._group_count, (\n            \"required number of arguments \" \"not found\"\n        )\n        if not len(args):\n            return self._path\n        converted_args = []\n        for a in args:\n            if not isinstance(a, (unicode_type, bytes)):\n                a = str(a)\n            converted_args.append(url_escape(utf8(a), plus=False))\n        return self._path % tuple(converted_args)", "is_method": true, "class_name": "PathMatches", "function_description": "Provides a way to reconstruct a URL path by substituting given arguments into predefined URL patterns, supporting URL reversing with argument escaping and validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "_find_groups", "line_number": 608, "body": "def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n        \"\"\"Returns a tuple (reverse string, group count) for a url.\n\n        For example: Given the url pattern /([0-9]{4})/([a-z-]+)/, this method\n        would return ('/%s/%s/', 2).\n        \"\"\"\n        pattern = self.regex.pattern\n        if pattern.startswith(\"^\"):\n            pattern = pattern[1:]\n        if pattern.endswith(\"$\"):\n            pattern = pattern[:-1]\n\n        if self.regex.groups != pattern.count(\"(\"):\n            # The pattern is too complicated for our simplistic matching,\n            # so we can't support reversing it.\n            return None, None\n\n        pieces = []\n        for fragment in pattern.split(\"(\"):\n            if \")\" in fragment:\n                paren_loc = fragment.index(\")\")\n                if paren_loc >= 0:\n                    try:\n                        unescaped_fragment = re_unescape(fragment[paren_loc + 1 :])\n                    except ValueError:\n                        # If we can't unescape part of it, we can't\n                        # reverse this url.\n                        return (None, None)\n                    pieces.append(\"%s\" + unescaped_fragment)\n            else:\n                try:\n                    unescaped_fragment = re_unescape(fragment)\n                except ValueError:\n                    # If we can't unescape part of it, we can't\n                    # reverse this url.\n                    return (None, None)\n                pieces.append(unescaped_fragment)\n\n        return \"\".join(pieces), self.regex.groups", "is_method": true, "class_name": "PathMatches", "function_description": "Utility method of PathMatches that extracts a simplified, reversible string pattern and counts matching regex groups from a URL regex. This supports reversing URL patterns for use cases like URL generation or matching group extraction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/routing.py", "function": "__repr__", "line_number": 688, "body": "def __repr__(self) -> str:\n        return \"%s(%r, %s, kwargs=%r, name=%r)\" % (\n            self.__class__.__name__,\n            self.regex.pattern,\n            self.handler_class,\n            self.kwargs,\n            self.name,\n        )", "is_method": true, "class_name": "URLSpec", "function_description": "Provides a string representation of the URLSpec instance showing its pattern, handler, arguments, and name for debugging or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "xhtml_escape", "line_number": 43, "body": "def xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n       Added the single quote to the list of escaped characters.\n    \"\"\"\n    return _XHTML_ESCAPE_RE.sub(\n        lambda match: _XHTML_ESCAPE_DICT[match.group(0)], to_basestring(value)\n    )", "is_method": false, "function_description": "Function that converts special characters in a string or bytes into their corresponding XHTML-safe escape sequences, ensuring the text can be safely embedded within HTML or XML content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "xhtml_unescape", "line_number": 59, "body": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n    return re.sub(r\"&(#?)(\\w+?);\", _convert_entity, _unicode(value))", "is_method": false, "function_description": "Function that converts XML-escaped characters in a string back to their original form, enabling processing of properly unescaped text from XHTML or XML sources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "json_encode", "line_number": 67, "body": "def json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\"\"\"\n    # JSON permits but does not require forward slashes to be escaped.\n    # This is useful when json data is emitted in a <script> tag\n    # in HTML, as it prevents </script> tags from prematurely terminating\n    # the JavaScript.  Some json libraries do this escaping by default,\n    # although python's standard library does not, so we do it here.\n    # http://stackoverflow.com/questions/1580647/json-why-are-forward-slashes-escaped\n    return json.dumps(value).replace(\"</\", \"<\\\\/\")", "is_method": false, "function_description": "Function that serializes a Python object into a JSON-formatted string while escaping forward slashes to safely embed the JSON within HTML script tags. It ensures JSON output prevents premature script termination in web contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "json_decode", "line_number": 78, "body": "def json_decode(value: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n    return json.loads(to_basestring(value))", "is_method": false, "function_description": "Utility function that converts a JSON-formatted string or bytes input into its corresponding Python object representation, supporting flexible input types for JSON decoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "squeeze", "line_number": 86, "body": "def squeeze(value: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n    return re.sub(r\"[\\x00-\\x20]+\", \" \", value).strip()", "is_method": false, "function_description": "Function that normalizes any input string by replacing all whitespace sequences with a single space and trimming leading and trailing spaces, improving text consistency for further processing or comparison."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "url_escape", "line_number": 91, "body": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n        The ``plus`` argument\n    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))", "is_method": false, "function_description": "Utility function that returns a URL-encoded string from input, optionally encoding spaces as plus signs for query strings or as %20 for URL paths. It supports both string and byte inputs for flexible URL encoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "url_unescape", "line_number": 118, "body": "def url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)", "is_method": false, "function_description": "Function that decodes URL-encoded strings or bytes, optionally interpreting plus signs as spaces, returning either a decoded unicode or byte string based on the specified encoding. Useful for parsing URL query parameters or form data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "parse_qs_bytes", "line_number": 147, "body": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n    # This is gross, but python3 doesn't give us another way.\n    # Latin1 is the universal donor of character encodings.\n    if isinstance(qs, bytes):\n        qs = qs.decode(\"latin1\")\n    result = urllib.parse.parse_qs(\n        qs, keep_blank_values, strict_parsing, encoding=\"latin1\", errors=\"strict\"\n    )\n    encoded = {}\n    for k, v in result.items():\n        encoded[k] = [i.encode(\"latin1\") for i in v]\n    return encoded", "is_method": false, "function_description": "Function that parses a byte-based query string into a dictionary mapping keys (as strings) to lists of byte string values, preserving the original byte representation of the parameters for accurate low-level processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "utf8", "line_number": 188, "body": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.encode(\"utf-8\")", "is_method": false, "function_description": "Utility function that converts a unicode string to UTF-8 encoded bytes, returning byte strings or None unchanged. It ensures consistent byte string output for text inputs in UTF-8 encoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "to_unicode", "line_number": 219, "body": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:  # noqa: F811\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.decode(\"utf-8\")", "is_method": false, "function_description": "Utility function that converts input values to a UTF-8 decoded Unicode string, returning strings and None unchanged while decoding byte strings for consistent text handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "recursive_unicode", "line_number": 242, "body": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, dict):\n        return dict(\n            (recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.items()\n        )\n    elif isinstance(obj, list):\n        return list(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, bytes):\n        return to_unicode(obj)\n    else:\n        return obj", "is_method": false, "function_description": "Function that recursively converts all byte strings within nested lists, tuples, or dictionaries into unicode strings, ensuring uniform string representation in complex data structures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "linkify", "line_number": 275, "body": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n      taking the link as an argument and returning the extra text\n      e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n      or::\n\n          def extra_params_cb(url):\n              if url.startswith(\"http://example.com\"):\n                  return 'class=\"internal\"'\n              else:\n                  return 'class=\"external\" rel=\"nofollow\"'\n          linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n      this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n      linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n      \"mailto\"])``. It is very unsafe to include protocols such as\n      ``javascript``.\n    \"\"\"\n    if extra_params and not callable(extra_params):\n        extra_params = \" \" + extra_params.strip()\n\n    def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)\n\n    # First HTML-escape so that our strings are all safe.\n    # The regex is modified to avoid character entites other than &amp; so\n    # that we won't pick up &quot;, etc.\n    text = _unicode(xhtml_escape(text))\n    return _URL_RE.sub(make_link, text)", "is_method": false, "function_description": "Function that transforms URLs in plain text into safe HTML hyperlinks, optionally shortening link text and adding customizable attributes. It supports protocol filtering and enforcing protocol presence to control which URLs become clickable links."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "_convert_entity", "line_number": 380, "body": "def _convert_entity(m: typing.Match) -> str:\n    if m.group(1) == \"#\":\n        try:\n            if m.group(2)[:1].lower() == \"x\":\n                return chr(int(m.group(2)[1:], 16))\n            else:\n                return chr(int(m.group(2)))\n        except ValueError:\n            return \"&#%s;\" % m.group(2)\n    try:\n        return _HTML_UNICODE_MAP[m.group(2)]\n    except KeyError:\n        return \"&%s;\" % m.group(2)", "is_method": false, "function_description": "Converts HTML or numeric character references in text to their corresponding Unicode characters, handling both named and numeric entities robustly. Useful for decoding HTML-encoded strings into readable text."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "_build_unicode_map", "line_number": 395, "body": "def _build_unicode_map() -> Dict[str, str]:\n    unicode_map = {}\n    for name, value in html.entities.name2codepoint.items():\n        unicode_map[name] = chr(value)\n    return unicode_map", "is_method": false, "function_description": "Constructs and returns a dictionary mapping HTML entity names to their corresponding Unicode characters, useful for decoding or converting HTML entities into readable text."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/escape.py", "function": "make_link", "line_number": 314, "body": "def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)", "is_method": false, "function_description": "This function converts matched URL text into an HTML hyperlink, applying protocol validation, optional URL shortening, and additional parameters for customized link attributes. It is useful for safely transforming URLs in text into clickable links with controlled formatting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "_garbage_collect", "line_number": 45, "body": "def _garbage_collect(self) -> None:\n        # Occasionally clear timed-out waiters.\n        self._timeouts += 1\n        if self._timeouts > 100:\n            self._timeouts = 0\n            self._waiters = collections.deque(w for w in self._waiters if not w.done())", "is_method": true, "class_name": "_TimeoutGarbageCollector", "function_description": "Internal method of _TimeoutGarbageCollector that periodically removes completed or timed-out waiters from its queue to manage resource cleanup and prevent stale references."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__repr__", "line_number": 117, "body": "def __repr__(self) -> str:\n        result = \"<%s\" % (self.__class__.__name__,)\n        if self._waiters:\n            result += \" waiters[%s]\" % len(self._waiters)\n        return result + \">\"", "is_method": true, "class_name": "Condition", "function_description": "Special method that provides a concise string representation of a Condition instance, including the count of waiting threads if any, useful for debugging and logging synchronization states."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "wait", "line_number": 123, "body": "def wait(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[bool]:\n        \"\"\"Wait for `.notify`.\n\n        Returns a `.Future` that resolves ``True`` if the condition is notified,\n        or ``False`` after a timeout.\n        \"\"\"\n        waiter = Future()  # type: Future[bool]\n        self._waiters.append(waiter)\n        if timeout:\n\n            def on_timeout() -> None:\n                if not waiter.done():\n                    future_set_result_unless_cancelled(waiter, False)\n                self._garbage_collect()\n\n            io_loop = ioloop.IOLoop.current()\n            timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n            waiter.add_done_callback(lambda _: io_loop.remove_timeout(timeout_handle))\n        return waiter", "is_method": true, "class_name": "Condition", "function_description": "Core method of the Condition class that asynchronously waits until a notification occurs or an optional timeout expires, returning a Future that indicates whether the wait was successful or timed out."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "notify", "line_number": 145, "body": "def notify(self, n: int = 1) -> None:\n        \"\"\"Wake ``n`` waiters.\"\"\"\n        waiters = []  # Waiters we plan to run right now.\n        while n and self._waiters:\n            waiter = self._waiters.popleft()\n            if not waiter.done():  # Might have timed out.\n                n -= 1\n                waiters.append(waiter)\n\n        for waiter in waiters:\n            future_set_result_unless_cancelled(waiter, True)", "is_method": true, "class_name": "Condition", "function_description": "Service method of the Condition class that wakes up to n waiting tasks or threads, allowing them to proceed after a condition is met. It is useful for signaling and coordinating concurrent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "notify_all", "line_number": 157, "body": "def notify_all(self) -> None:\n        \"\"\"Wake all waiters.\"\"\"\n        self.notify(len(self._waiters))", "is_method": true, "class_name": "Condition", "function_description": "Core method of the Condition class that wakes all threads waiting on the condition, ensuring all waiters are notified simultaneously."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__repr__", "line_number": 206, "body": "def __repr__(self) -> str:\n        return \"<%s %s>\" % (\n            self.__class__.__name__,\n            \"set\" if self.is_set() else \"clear\",\n        )", "is_method": true, "class_name": "Event", "function_description": "Provides a string representation of the Event object, indicating its class name and whether the event is currently set or clear. This aids in debugging and logging by summarizing the event's state succinctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "is_set", "line_number": 212, "body": "def is_set(self) -> bool:\n        \"\"\"Return ``True`` if the internal flag is true.\"\"\"\n        return self._value", "is_method": true, "class_name": "Event", "function_description": "This method checks and returns whether the internal event flag is currently set, providing a simple way to query the event's state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "set", "line_number": 216, "body": "def set(self) -> None:\n        \"\"\"Set the internal flag to ``True``. All waiters are awakened.\n\n        Calling `.wait` once the flag is set will not block.\n        \"\"\"\n        if not self._value:\n            self._value = True\n\n            for fut in self._waiters:\n                if not fut.done():\n                    fut.set_result(None)", "is_method": true, "class_name": "Event", "function_description": "Allows setting the Event's internal flag to True, releasing all waiting coroutines and ensuring subsequent calls to wait do not block. It facilitates synchronization by signaling the occurrence of an event."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "clear", "line_number": 228, "body": "def clear(self) -> None:\n        \"\"\"Reset the internal flag to ``False``.\n\n        Calls to `.wait` will block until `.set` is called.\n        \"\"\"\n        self._value = False", "is_method": true, "class_name": "Event", "function_description": "Clears the event's internal flag, causing any wait calls to block until the event is set again. This method resets the event's state to unsignaled in concurrency control."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "wait", "line_number": 235, "body": "def wait(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[None]:\n        \"\"\"Block until the internal flag is true.\n\n        Returns an awaitable, which raises `tornado.util.TimeoutError` after a\n        timeout.\n        \"\"\"\n        fut = Future()  # type: Future[None]\n        if self._value:\n            fut.set_result(None)\n            return fut\n        self._waiters.add(fut)\n        fut.add_done_callback(lambda fut: self._waiters.remove(fut))\n        if timeout is None:\n            return fut\n        else:\n            timeout_fut = gen.with_timeout(timeout, fut)\n            # This is a slightly clumsy workaround for the fact that\n            # gen.with_timeout doesn't cancel its futures. Cancelling\n            # fut will remove it from the waiters list.\n            timeout_fut.add_done_callback(\n                lambda tf: fut.cancel() if not fut.done() else None\n            )\n            return timeout_fut", "is_method": true, "class_name": "Event", "function_description": "Provides an awaitable that pauses execution until the event's internal flag is set or a timeout occurs, enabling asynchronous coordination with optional timeout handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__exit__", "line_number": 277, "body": "def __exit__(\n        self,\n        exc_type: \"Optional[Type[BaseException]]\",\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[types.TracebackType],\n    ) -> None:\n        self._obj.release()", "is_method": true, "class_name": "_ReleasingContextManager", "function_description": "Handles exit from a context by releasing a resource or object, ensuring proper cleanup when the context ends. It supports resource management within a with-statement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__repr__", "line_number": 389, "body": "def __repr__(self) -> str:\n        res = super().__repr__()\n        extra = (\n            \"locked\" if self._value == 0 else \"unlocked,value:{0}\".format(self._value)\n        )\n        if self._waiters:\n            extra = \"{0},waiters:{1}\".format(extra, len(self._waiters))\n        return \"<{0} [{1}]>\".format(res[1:-1], extra)", "is_method": true, "class_name": "Semaphore", "function_description": "Provides a string representation of the Semaphore showing its current lock state, available permits, and number of waiting threads, aiding in debugging and status inspection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "release", "line_number": 398, "body": "def release(self) -> None:\n        \"\"\"Increment the counter and wake one waiter.\"\"\"\n        self._value += 1\n        while self._waiters:\n            waiter = self._waiters.popleft()\n            if not waiter.done():\n                self._value -= 1\n\n                # If the waiter is a coroutine paused at\n                #\n                #     with (yield semaphore.acquire()):\n                #\n                # then the context manager's __exit__ calls release() at the end\n                # of the \"with\" block.\n                waiter.set_result(_ReleasingContextManager(self))\n                break", "is_method": true, "class_name": "Semaphore", "function_description": "Releases a semaphore slot by incrementing its count and resumes one waiting coroutine to allow it to proceed. This method manages concurrency by controlling access to a shared resource."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "acquire", "line_number": 415, "body": "def acquire(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_ReleasingContextManager]:\n        \"\"\"Decrement the counter. Returns an awaitable.\n\n        Block if the counter is zero and wait for a `.release`. The awaitable\n        raises `.TimeoutError` after the deadline.\n        \"\"\"\n        waiter = Future()  # type: Future[_ReleasingContextManager]\n        if self._value > 0:\n            self._value -= 1\n            waiter.set_result(_ReleasingContextManager(self))\n        else:\n            self._waiters.append(waiter)\n            if timeout:\n\n                def on_timeout() -> None:\n                    if not waiter.done():\n                        waiter.set_exception(gen.TimeoutError())\n                    self._garbage_collect()\n\n                io_loop = ioloop.IOLoop.current()\n                timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n                waiter.add_done_callback(\n                    lambda _: io_loop.remove_timeout(timeout_handle)\n                )\n        return waiter", "is_method": true, "class_name": "Semaphore", "function_description": "Provides an asynchronous mechanism to decrement a semaphore counter, blocking and waiting with an optional timeout if the counter is zero, thus controlling concurrent access to a shared resource."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__enter__", "line_number": 443, "body": "def __enter__(self) -> None:\n        raise RuntimeError(\"Use 'async with' instead of 'with' for Semaphore\")", "is_method": true, "class_name": "Semaphore", "function_description": "This method prevents misuse of the Semaphore class by raising an error if used with a synchronous context manager, enforcing asynchronous context usage instead. It ensures correct Semaphore handling in asynchronous programming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "release", "line_number": 479, "body": "def release(self) -> None:\n        \"\"\"Increment the counter and wake one waiter.\"\"\"\n        if self._value >= self._initial_value:\n            raise ValueError(\"Semaphore released too many times\")\n        super().release()", "is_method": true, "class_name": "BoundedSemaphore", "function_description": "Releases a semaphore, incrementing its counter and notifying one waiting thread while preventing the counter from exceeding its initial limit. It manages access control in concurrent programming by bounding resource availability."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__repr__", "line_number": 526, "body": "def __repr__(self) -> str:\n        return \"<%s _block=%s>\" % (self.__class__.__name__, self._block)", "is_method": true, "class_name": "Lock", "function_description": "Representation method of the Lock class that returns a string showing the class name and its current blocking status, useful for debugging or logging lock state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "acquire", "line_number": 529, "body": "def acquire(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_ReleasingContextManager]:\n        \"\"\"Attempt to lock. Returns an awaitable.\n\n        Returns an awaitable, which raises `tornado.util.TimeoutError` after a\n        timeout.\n        \"\"\"\n        return self._block.acquire(timeout)", "is_method": true, "class_name": "Lock", "function_description": "Provides an asynchronous mechanism to attempt acquiring the lock, supporting an optional timeout. It returns an awaitable that completes when the lock is acquired or raises a timeout error if unable to do so in time."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "release", "line_number": 539, "body": "def release(self) -> None:\n        \"\"\"Unlock.\n\n        The first coroutine in line waiting for `acquire` gets the lock.\n\n        If not locked, raise a `RuntimeError`.\n        \"\"\"\n        try:\n            self._block.release()\n        except ValueError:\n            raise RuntimeError(\"release unlocked lock\")", "is_method": true, "class_name": "Lock", "function_description": "Releases the lock held by the current owner, allowing the next waiting coroutine to acquire it. Raises an error if the lock is not currently held."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "__enter__", "line_number": 551, "body": "def __enter__(self) -> None:\n        raise RuntimeError(\"Use `async with` instead of `with` for Lock\")", "is_method": true, "class_name": "Lock", "function_description": "This method enforces usage of the Lock class exclusively with asynchronous context managers by raising an error when used in a synchronous 'with' statement. It ensures correct async locking semantics are followed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "on_timeout", "line_number": 135, "body": "def on_timeout() -> None:\n                if not waiter.done():\n                    future_set_result_unless_cancelled(waiter, False)\n                self._garbage_collect()", "is_method": true, "class_name": "Condition", "function_description": "Core method of the Condition class that handles timeout events by signaling waiting tasks of the timeout and performing cleanup operations. It ensures proper state update and resource management when a wait condition times out."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locks.py", "function": "on_timeout", "line_number": 431, "body": "def on_timeout() -> None:\n                    if not waiter.done():\n                        waiter.set_exception(gen.TimeoutError())\n                    self._garbage_collect()", "is_method": true, "class_name": "Semaphore", "function_description": "Core method of the Semaphore class that handles timeout events by signaling a timeout error to waiting operations and performs cleanup to maintain system integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "initialize", "line_number": 152, "body": "def initialize(\n        self,\n        request_callback: Union[\n            httputil.HTTPServerConnectionDelegate,\n            Callable[[httputil.HTTPServerRequest], None],\n        ],\n        no_keep_alive: bool = False,\n        xheaders: bool = False,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        protocol: Optional[str] = None,\n        decompress_request: bool = False,\n        chunk_size: Optional[int] = None,\n        max_header_size: Optional[int] = None,\n        idle_connection_timeout: Optional[float] = None,\n        body_timeout: Optional[float] = None,\n        max_body_size: Optional[int] = None,\n        max_buffer_size: Optional[int] = None,\n        trusted_downstream: Optional[List[str]] = None,\n    ) -> None:\n        # This method's signature is not extracted with autodoc\n        # because we want its arguments to appear on the class\n        # constructor. When changing this signature, also update the\n        # copy in httpserver.rst.\n        self.request_callback = request_callback\n        self.xheaders = xheaders\n        self.protocol = protocol\n        self.conn_params = HTTP1ConnectionParameters(\n            decompress=decompress_request,\n            chunk_size=chunk_size,\n            max_header_size=max_header_size,\n            header_timeout=idle_connection_timeout or 3600,\n            max_body_size=max_body_size,\n            body_timeout=body_timeout,\n            no_keep_alive=no_keep_alive,\n        )\n        TCPServer.__init__(\n            self,\n            ssl_options=ssl_options,\n            max_buffer_size=max_buffer_size,\n            read_chunk_size=chunk_size,\n        )\n        self._connections = set()  # type: Set[HTTP1ServerConnection]\n        self.trusted_downstream = trusted_downstream", "is_method": true, "class_name": "HTTPServer", "function_description": "Initialization method of HTTPServer that configures request handling, connection behavior, SSL options, timeouts, and buffer sizes to prepare the server for processing HTTP requests with optional customizations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "configurable_base", "line_number": 197, "body": "def configurable_base(cls) -> Type[Configurable]:\n        return HTTPServer", "is_method": true, "class_name": "HTTPServer", "function_description": "Returns the HTTPServer class as the configurable base type for configuration management or inheritance purposes within related systems."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "configurable_default", "line_number": 201, "body": "def configurable_default(cls) -> Type[Configurable]:\n        return HTTPServer", "is_method": true, "class_name": "HTTPServer", "function_description": "Returns the HTTPServer class as the default configurable type. This method provides a way to specify or retrieve the default configuration class within HTTPServer context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "handle_stream", "line_number": 223, "body": "def handle_stream(self, stream: iostream.IOStream, address: Tuple) -> None:\n        context = _HTTPRequestContext(\n            stream, address, self.protocol, self.trusted_downstream\n        )\n        conn = HTTP1ServerConnection(stream, self.conn_params, context)\n        self._connections.add(conn)\n        conn.start_serving(self)", "is_method": true, "class_name": "HTTPServer", "function_description": "Handles an incoming HTTP stream by establishing a connection context and beginning request processing. It serves as the entry point for processing HTTP requests within the HTTPServer class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "start_request", "line_number": 231, "body": "def start_request(\n        self, server_conn: object, request_conn: httputil.HTTPConnection\n    ) -> httputil.HTTPMessageDelegate:\n        if isinstance(self.request_callback, httputil.HTTPServerConnectionDelegate):\n            delegate = self.request_callback.start_request(server_conn, request_conn)\n        else:\n            delegate = _CallableAdapter(self.request_callback, request_conn)\n\n        if self.xheaders:\n            delegate = _ProxyAdapter(delegate, request_conn)\n\n        return delegate", "is_method": true, "class_name": "HTTPServer", "function_description": "Core method of the HTTPServer class that initiates handling of an incoming HTTP request by creating and returning an appropriate delegate to process the request, optionally wrapping it for header support."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "on_close", "line_number": 244, "body": "def on_close(self, server_conn: object) -> None:\n        self._connections.remove(typing.cast(HTTP1ServerConnection, server_conn))", "is_method": true, "class_name": "HTTPServer", "function_description": "Removes a server connection from the active connections list upon closure, helping manage and track current client connections in the HTTPServer class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "headers_received", "line_number": 260, "body": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        self.request = httputil.HTTPServerRequest(\n            connection=self.connection,\n            start_line=typing.cast(httputil.RequestStartLine, start_line),\n            headers=headers,\n        )\n        return None", "is_method": true, "class_name": "_CallableAdapter", "function_description": "The method initializes an HTTP request object from start line and headers, integrating it into the connection context. It provides a standardized way to capture incoming HTTP request details within the _CallableAdapter class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "data_received", "line_number": 272, "body": "def data_received(self, chunk: bytes) -> Optional[Awaitable[None]]:\n        self._chunks.append(chunk)\n        return None", "is_method": true, "class_name": "_CallableAdapter", "function_description": "Utility method of the _CallableAdapter class that appends incoming byte chunks to an internal collection, facilitating incremental data handling or buffering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "finish", "line_number": 276, "body": "def finish(self) -> None:\n        assert self.request is not None\n        self.request.body = b\"\".join(self._chunks)\n        self.request._parse_body()\n        self.request_callback(self.request)", "is_method": true, "class_name": "_CallableAdapter", "function_description": "Finalizes the request body by assembling received data chunks and triggers the associated callback for further processing. It ensures the request is complete and ready for handling by downstream functions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "on_connection_close", "line_number": 282, "body": "def on_connection_close(self) -> None:\n        del self._chunks", "is_method": true, "class_name": "_CallableAdapter", "function_description": "Method in _CallableAdapter that clears stored data chunks upon connection closure to free resources and maintain clean state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "__str__", "line_number": 321, "body": "def __str__(self) -> str:\n        if self.address_family in (socket.AF_INET, socket.AF_INET6):\n            return self.remote_ip\n        elif isinstance(self.address, bytes):\n            # Python 3 with the -bb option warns about str(bytes),\n            # so convert it explicitly.\n            # Unix socket addresses are str on mac but bytes on linux.\n            return native_str(self.address)\n        else:\n            return str(self.address)", "is_method": true, "class_name": "_HTTPRequestContext", "function_description": "String representation method for _HTTPRequestContext that returns the remote IP for internet sockets or a suitable string version of the address for other socket types. It enables clear, human-readable identification of the request source."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "_apply_xheaders", "line_number": 332, "body": "def _apply_xheaders(self, headers: httputil.HTTPHeaders) -> None:\n        \"\"\"Rewrite the ``remote_ip`` and ``protocol`` fields.\"\"\"\n        # Squid uses X-Forwarded-For, others use X-Real-Ip\n        ip = headers.get(\"X-Forwarded-For\", self.remote_ip)\n        # Skip trusted downstream hosts in X-Forwarded-For list\n        for ip in (cand.strip() for cand in reversed(ip.split(\",\"))):\n            if ip not in self.trusted_downstream:\n                break\n        ip = headers.get(\"X-Real-Ip\", ip)\n        if netutil.is_valid_ip(ip):\n            self.remote_ip = ip\n        # AWS uses X-Forwarded-Proto\n        proto_header = headers.get(\n            \"X-Scheme\", headers.get(\"X-Forwarded-Proto\", self.protocol)\n        )\n        if proto_header:\n            # use only the last proto entry if there is more than one\n            # TODO: support trusting multiple layers of proxied protocol\n            proto_header = proto_header.split(\",\")[-1].strip()\n        if proto_header in (\"http\", \"https\"):\n            self.protocol = proto_header", "is_method": true, "class_name": "_HTTPRequestContext", "function_description": "Adjusts the request's remote IP and protocol fields based on specific HTTP headers to accurately reflect client information behind proxies. Useful for handling forwarded requests and ensuring correct client identity and protocol detection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "_unapply_xheaders", "line_number": 354, "body": "def _unapply_xheaders(self) -> None:\n        \"\"\"Undo changes from `_apply_xheaders`.\n\n        Xheaders are per-request so they should not leak to the next\n        request on the same connection.\n        \"\"\"\n        self.remote_ip = self._orig_remote_ip\n        self.protocol = self._orig_protocol", "is_method": true, "class_name": "_HTTPRequestContext", "function_description": "Resets request-specific headers like remote IP and protocol to their original values to prevent cross-request contamination in persistent connections within the _HTTPRequestContext class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "headers_received", "line_number": 373, "body": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        # TODO: either make context an official part of the\n        # HTTPConnection interface or figure out some other way to do this.\n        self.connection.context._apply_xheaders(headers)  # type: ignore\n        return self.delegate.headers_received(start_line, headers)", "is_method": true, "class_name": "_ProxyAdapter", "function_description": "Handles incoming HTTP header lines by applying contextual headers and delegating further processing, facilitating header management within a proxy connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "data_received", "line_number": 383, "body": "def data_received(self, chunk: bytes) -> Optional[Awaitable[None]]:\n        return self.delegate.data_received(chunk)", "is_method": true, "class_name": "_ProxyAdapter", "function_description": "This method forwards incoming byte data to a delegate handler for processing. It enables transparent data reception delegation within the _ProxyAdapter class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "finish", "line_number": 386, "body": "def finish(self) -> None:\n        self.delegate.finish()\n        self._cleanup()", "is_method": true, "class_name": "_ProxyAdapter", "function_description": "Utility method in the _ProxyAdapter class that finalizes processing by delegating cleanup tasks and performing internal resource cleanup. It ensures proper completion and release of associated resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "on_connection_close", "line_number": 390, "body": "def on_connection_close(self) -> None:\n        self.delegate.on_connection_close()\n        self._cleanup()", "is_method": true, "class_name": "_ProxyAdapter", "function_description": "Handles the closing of a connection by delegating the event and performing necessary cleanup operations within the proxy adapter context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpserver.py", "function": "_cleanup", "line_number": 394, "body": "def _cleanup(self) -> None:\n        self.connection.context._unapply_xheaders()", "is_method": true, "class_name": "_ProxyAdapter", "function_description": "Utility method in the _ProxyAdapter class that cleans up the connection context by removing any previously applied headers, ensuring a reset state for subsequent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "listen", "line_number": 143, "body": "def listen(self, port: int, address: str = \"\") -> None:\n        \"\"\"Starts accepting connections on the given port.\n\n        This method may be called more than once to listen on multiple ports.\n        `listen` takes effect immediately; it is not necessary to call\n        `TCPServer.start` afterwards.  It is, however, necessary to start\n        the `.IOLoop`.\n        \"\"\"\n        sockets = bind_sockets(port, address=address)\n        self.add_sockets(sockets)", "is_method": true, "class_name": "TCPServer", "function_description": "Starts accepting incoming TCP connections on the specified port and address, allowing the server to listen on multiple ports concurrently. This method enables immediate readiness to handle client connections without additional startup calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "add_sockets", "line_number": 154, "body": "def add_sockets(self, sockets: Iterable[socket.socket]) -> None:\n        \"\"\"Makes this server start accepting connections on the given sockets.\n\n        The ``sockets`` parameter is a list of socket objects such as\n        those returned by `~tornado.netutil.bind_sockets`.\n        `add_sockets` is typically used in combination with that\n        method and `tornado.process.fork_processes` to provide greater\n        control over the initialization of a multi-process server.\n        \"\"\"\n        for sock in sockets:\n            self._sockets[sock.fileno()] = sock\n            self._handlers[sock.fileno()] = add_accept_handler(\n                sock, self._handle_connection\n            )", "is_method": true, "class_name": "TCPServer", "function_description": "Adds multiple socket objects to the TCPServer to begin accepting incoming connections on them. This enables multi-socket and multi-process server setups for flexible network initialization and connection handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "add_socket", "line_number": 169, "body": "def add_socket(self, socket: socket.socket) -> None:\n        \"\"\"Singular version of `add_sockets`.  Takes a single socket object.\"\"\"\n        self.add_sockets([socket])", "is_method": true, "class_name": "TCPServer", "function_description": "Utility method of TCPServer that adds a single socket to the server by internally calling the method handling multiple sockets. It simplifies socket management by providing a convenient single-socket addition interface."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "bind", "line_number": 173, "body": "def bind(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = 128,\n        reuse_port: bool = False,\n    ) -> None:\n        \"\"\"Binds this server to the given port on the given address.\n\n        To start the server, call `start`. If you want to run this server\n        in a single process, you can call `listen` as a shortcut to the\n        sequence of `bind` and `start` calls.\n\n        Address may be either an IP address or hostname.  If it's a hostname,\n        the server will listen on all IP addresses associated with the\n        name.  Address may be an empty string or None to listen on all\n        available interfaces.  Family may be set to either `socket.AF_INET`\n        or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n        both will be used if available.\n\n        The ``backlog`` argument has the same meaning as for\n        `socket.listen <socket.socket.listen>`. The ``reuse_port`` argument\n        has the same meaning as for `.bind_sockets`.\n\n        This method may be called multiple times prior to `start` to listen\n        on multiple ports or interfaces.\n\n        .. versionchanged:: 4.4\n           Added the ``reuse_port`` argument.\n        \"\"\"\n        sockets = bind_sockets(\n            port, address=address, family=family, backlog=backlog, reuse_port=reuse_port\n        )\n        if self._started:\n            self.add_sockets(sockets)\n        else:\n            self._pending_sockets.extend(sockets)", "is_method": true, "class_name": "TCPServer", "function_description": "Sets up the server to listen for incoming connections on specified ports and addresses, supporting multiple interfaces and configurable socket options before starting the server."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "start", "line_number": 212, "body": "def start(\n        self, num_processes: Optional[int] = 1, max_restarts: Optional[int] = None\n    ) -> None:\n        \"\"\"Starts this server in the `.IOLoop`.\n\n        By default, we run the server in this process and do not fork any\n        additional child process.\n\n        If num_processes is ``None`` or <= 0, we detect the number of cores\n        available on this machine and fork that number of child\n        processes. If num_processes is given and > 1, we fork that\n        specific number of sub-processes.\n\n        Since we use processes and not threads, there is no shared memory\n        between any server code.\n\n        Note that multiple processes are not compatible with the autoreload\n        module (or the ``autoreload=True`` option to `tornado.web.Application`\n        which defaults to True when ``debug=True``).\n        When using multiple processes, no IOLoops can be created or\n        referenced until after the call to ``TCPServer.start(n)``.\n\n        Values of ``num_processes`` other than 1 are not supported on Windows.\n\n        The ``max_restarts`` argument is passed to `.fork_processes`.\n\n        .. versionchanged:: 6.0\n\n           Added ``max_restarts`` argument.\n        \"\"\"\n        assert not self._started\n        self._started = True\n        if num_processes != 1:\n            process.fork_processes(num_processes, max_restarts)\n        sockets = self._pending_sockets\n        self._pending_sockets = []\n        self.add_sockets(sockets)", "is_method": true, "class_name": "TCPServer", "function_description": "Starts the TCP server with optional multiprocessing, allowing it to run across multiple processes for improved performance. It manages process forking based on CPU cores or a specified number, enabling scalable server deployment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "stop", "line_number": 250, "body": "def stop(self) -> None:\n        \"\"\"Stops listening for new connections.\n\n        Requests currently in progress may still continue after the\n        server is stopped.\n        \"\"\"\n        if self._stopped:\n            return\n        self._stopped = True\n        for fd, sock in self._sockets.items():\n            assert sock.fileno() == fd\n            # Unregister socket from IOLoop\n            self._handlers.pop(fd)()\n            sock.close()", "is_method": true, "class_name": "TCPServer", "function_description": "Stops the TCP server from accepting new connections while allowing ongoing requests to complete. This method enables controlled shutdown of the server's listening behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpserver.py", "function": "_handle_connection", "line_number": 284, "body": "def _handle_connection(self, connection: socket.socket, address: Any) -> None:\n        if self.ssl_options is not None:\n            assert ssl, \"Python 2.6+ and OpenSSL required for SSL\"\n            try:\n                connection = ssl_wrap_socket(\n                    connection,\n                    self.ssl_options,\n                    server_side=True,\n                    do_handshake_on_connect=False,\n                )\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_EOF:\n                    return connection.close()\n                else:\n                    raise\n            except socket.error as err:\n                # If the connection is closed immediately after it is created\n                # (as in a port scan), we can get one of several errors.\n                # wrap_socket makes an internal call to getpeername,\n                # which may return either EINVAL (Mac OS X) or ENOTCONN\n                # (Linux).  If it returns ENOTCONN, this error is\n                # silently swallowed by the ssl module, so we need to\n                # catch another error later on (AttributeError in\n                # SSLIOStream._do_ssl_handshake).\n                # To test this behavior, try nmap with the -sT flag.\n                # https://github.com/tornadoweb/tornado/pull/750\n                if errno_from_exception(err) in (errno.ECONNABORTED, errno.EINVAL):\n                    return connection.close()\n                else:\n                    raise\n        try:\n            if self.ssl_options is not None:\n                stream = SSLIOStream(\n                    connection,\n                    max_buffer_size=self.max_buffer_size,\n                    read_chunk_size=self.read_chunk_size,\n                )  # type: IOStream\n            else:\n                stream = IOStream(\n                    connection,\n                    max_buffer_size=self.max_buffer_size,\n                    read_chunk_size=self.read_chunk_size,\n                )\n\n            future = self.handle_stream(stream, address)\n            if future is not None:\n                IOLoop.current().add_future(\n                    gen.convert_yielded(future), lambda f: f.result()\n                )\n        except Exception:\n            app_log.error(\"Error in connection callback\", exc_info=True)", "is_method": true, "class_name": "TCPServer", "function_description": "Handles a new TCP connection by optionally wrapping it with SSL and passing its I/O stream to the server's handler, enabling secure and asynchronous processing of incoming client connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "filter_whitespace", "line_number": 227, "body": "def filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n      character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n      character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == \"all\":\n        return text\n    elif mode == \"single\":\n        text = re.sub(r\"([\\t ]+)\", \" \", text)\n        text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n        return text\n    elif mode == \"oneline\":\n        return re.sub(r\"(\\s+)\", \" \", text)\n    else:\n        raise Exception(\"invalid whitespace mode %s\" % mode)", "is_method": false, "function_description": "Utility function that modifies whitespace in a text string based on a specified mode, supporting preservation, collapsing, or removal of newlines for flexible whitespace normalization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_format_code", "line_number": 842, "body": "def _format_code(code: str) -> str:\n    lines = code.splitlines()\n    format = \"%%%dd  %%s\\n\" % len(repr(len(lines) + 1))\n    return \"\".join([format % (i + 1, line) for (i, line) in enumerate(lines)])", "is_method": false, "function_description": "Utility function that formats source code by prefixing each line with its line number, enhancing code readability and reference in contexts such as debugging or code display."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_parse", "line_number": 848, "body": "def _parse(\n    reader: _TemplateReader,\n    template: Template,\n    in_block: Optional[str] = None,\n    in_loop: Optional[str] = None,\n) -> _ChunkList:\n    body = _ChunkList([])\n    while True:\n        # Find next template directive\n        curly = 0\n        while True:\n            curly = reader.find(\"{\", curly)\n            if curly == -1 or curly + 1 == reader.remaining():\n                # EOF\n                if in_block:\n                    reader.raise_parse_error(\n                        \"Missing {%% end %%} block for %s\" % in_block\n                    )\n                body.chunks.append(\n                    _Text(reader.consume(), reader.line, reader.whitespace)\n                )\n                return body\n            # If the first curly brace is not the start of a special token,\n            # start searching from the character after it\n            if reader[curly + 1] not in (\"{\", \"%\", \"#\"):\n                curly += 1\n                continue\n            # When there are more than 2 curlies in a row, use the\n            # innermost ones.  This is useful when generating languages\n            # like latex where curlies are also meaningful\n            if (\n                curly + 2 < reader.remaining()\n                and reader[curly + 1] == \"{\"\n                and reader[curly + 2] == \"{\"\n            ):\n                curly += 1\n                continue\n            break\n\n        # Append any text before the special token\n        if curly > 0:\n            cons = reader.consume(curly)\n            body.chunks.append(_Text(cons, reader.line, reader.whitespace))\n\n        start_brace = reader.consume(2)\n        line = reader.line\n\n        # Template directives may be escaped as \"{{!\" or \"{%!\".\n        # In this case output the braces and consume the \"!\".\n        # This is especially useful in conjunction with jquery templates,\n        # which also use double braces.\n        if reader.remaining() and reader[0] == \"!\":\n            reader.consume(1)\n            body.chunks.append(_Text(start_brace, line, reader.whitespace))\n            continue\n\n        # Comment\n        if start_brace == \"{#\":\n            end = reader.find(\"#}\")\n            if end == -1:\n                reader.raise_parse_error(\"Missing end comment #}\")\n            contents = reader.consume(end).strip()\n            reader.consume(2)\n            continue\n\n        # Expression\n        if start_brace == \"{{\":\n            end = reader.find(\"}}\")\n            if end == -1:\n                reader.raise_parse_error(\"Missing end expression }}\")\n            contents = reader.consume(end).strip()\n            reader.consume(2)\n            if not contents:\n                reader.raise_parse_error(\"Empty expression\")\n            body.chunks.append(_Expression(contents, line))\n            continue\n\n        # Block\n        assert start_brace == \"{%\", start_brace\n        end = reader.find(\"%}\")\n        if end == -1:\n            reader.raise_parse_error(\"Missing end block %}\")\n        contents = reader.consume(end).strip()\n        reader.consume(2)\n        if not contents:\n            reader.raise_parse_error(\"Empty block tag ({% %})\")\n\n        operator, space, suffix = contents.partition(\" \")\n        suffix = suffix.strip()\n\n        # Intermediate (\"else\", \"elif\", etc) blocks\n        intermediate_blocks = {\n            \"else\": set([\"if\", \"for\", \"while\", \"try\"]),\n            \"elif\": set([\"if\"]),\n            \"except\": set([\"try\"]),\n            \"finally\": set([\"try\"]),\n        }\n        allowed_parents = intermediate_blocks.get(operator)\n        if allowed_parents is not None:\n            if not in_block:\n                reader.raise_parse_error(\n                    \"%s outside %s block\" % (operator, allowed_parents)\n                )\n            if in_block not in allowed_parents:\n                reader.raise_parse_error(\n                    \"%s block cannot be attached to %s block\" % (operator, in_block)\n                )\n            body.chunks.append(_IntermediateControlBlock(contents, line))\n            continue\n\n        # End tag\n        elif operator == \"end\":\n            if not in_block:\n                reader.raise_parse_error(\"Extra {% end %} block\")\n            return body\n\n        elif operator in (\n            \"extends\",\n            \"include\",\n            \"set\",\n            \"import\",\n            \"from\",\n            \"comment\",\n            \"autoescape\",\n            \"whitespace\",\n            \"raw\",\n            \"module\",\n        ):\n            if operator == \"comment\":\n                continue\n            if operator == \"extends\":\n                suffix = suffix.strip('\"').strip(\"'\")\n                if not suffix:\n                    reader.raise_parse_error(\"extends missing file path\")\n                block = _ExtendsBlock(suffix)  # type: _Node\n            elif operator in (\"import\", \"from\"):\n                if not suffix:\n                    reader.raise_parse_error(\"import missing statement\")\n                block = _Statement(contents, line)\n            elif operator == \"include\":\n                suffix = suffix.strip('\"').strip(\"'\")\n                if not suffix:\n                    reader.raise_parse_error(\"include missing file path\")\n                block = _IncludeBlock(suffix, reader, line)\n            elif operator == \"set\":\n                if not suffix:\n                    reader.raise_parse_error(\"set missing statement\")\n                block = _Statement(suffix, line)\n            elif operator == \"autoescape\":\n                fn = suffix.strip()  # type: Optional[str]\n                if fn == \"None\":\n                    fn = None\n                template.autoescape = fn\n                continue\n            elif operator == \"whitespace\":\n                mode = suffix.strip()\n                # Validate the selected mode\n                filter_whitespace(mode, \"\")\n                reader.whitespace = mode\n                continue\n            elif operator == \"raw\":\n                block = _Expression(suffix, line, raw=True)\n            elif operator == \"module\":\n                block = _Module(suffix, line)\n            body.chunks.append(block)\n            continue\n\n        elif operator in (\"apply\", \"block\", \"try\", \"if\", \"for\", \"while\"):\n            # parse inner body recursively\n            if operator in (\"for\", \"while\"):\n                block_body = _parse(reader, template, operator, operator)\n            elif operator == \"apply\":\n                # apply creates a nested function so syntactically it's not\n                # in the loop.\n                block_body = _parse(reader, template, operator, None)\n            else:\n                block_body = _parse(reader, template, operator, in_loop)\n\n            if operator == \"apply\":\n                if not suffix:\n                    reader.raise_parse_error(\"apply missing method name\")\n                block = _ApplyBlock(suffix, line, block_body)\n            elif operator == \"block\":\n                if not suffix:\n                    reader.raise_parse_error(\"block missing name\")\n                block = _NamedBlock(suffix, block_body, template, line)\n            else:\n                block = _ControlBlock(contents, line, block_body)\n            body.chunks.append(block)\n            continue\n\n        elif operator in (\"break\", \"continue\"):\n            if not in_loop:\n                reader.raise_parse_error(\n                    \"%s outside %s block\" % (operator, set([\"for\", \"while\"]))\n                )\n            body.chunks.append(_Statement(contents, line))\n            continue\n\n        else:\n            reader.raise_parse_error(\"unknown operator: %r\" % operator)", "is_method": false, "function_description": "Internal parsing function of a template engine that processes template text into a structured list of chunks representing text, expressions, blocks, and statements, enabling template interpretation and rendering with nested control structures and error checking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 337, "body": "def generate(self, **kwargs: Any) -> bytes:\n        \"\"\"Generate this template with the given arguments.\"\"\"\n        namespace = {\n            \"escape\": escape.xhtml_escape,\n            \"xhtml_escape\": escape.xhtml_escape,\n            \"url_escape\": escape.url_escape,\n            \"json_encode\": escape.json_encode,\n            \"squeeze\": escape.squeeze,\n            \"linkify\": escape.linkify,\n            \"datetime\": datetime,\n            \"_tt_utf8\": escape.utf8,  # for internal use\n            \"_tt_string_types\": (unicode_type, bytes),\n            # __name__ and __loader__ allow the traceback mechanism to find\n            # the generated source code.\n            \"__name__\": self.name.replace(\".\", \"_\"),\n            \"__loader__\": ObjectDict(get_source=lambda name: self.code),\n        }\n        namespace.update(self.namespace)\n        namespace.update(kwargs)\n        exec_in(self.compiled, namespace)\n        execute = typing.cast(Callable[[], bytes], namespace[\"_tt_execute\"])\n        # Clear the traceback module's cache of source data now that\n        # we've generated a new template (mainly for this module's\n        # unittests, where different tests reuse the same name).\n        linecache.clearcache()\n        return execute()", "is_method": true, "class_name": "Template", "function_description": "Provides a service that executes a precompiled template with given arguments and returns the generated content as bytes. This enables dynamic content generation within the Template class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_generate_python", "line_number": 364, "body": "def _generate_python(self, loader: Optional[\"BaseLoader\"]) -> str:\n        buffer = StringIO()\n        try:\n            # named_blocks maps from names to _NamedBlock objects\n            named_blocks = {}  # type: Dict[str, _NamedBlock]\n            ancestors = self._get_ancestors(loader)\n            ancestors.reverse()\n            for ancestor in ancestors:\n                ancestor.find_named_blocks(loader, named_blocks)\n            writer = _CodeWriter(buffer, named_blocks, loader, ancestors[0].template)\n            ancestors[0].generate(writer)\n            return buffer.getvalue()\n        finally:\n            buffer.close()", "is_method": true, "class_name": "Template", "function_description": "Generates the complete Python source code for a template by aggregating and processing named blocks from ancestor templates. It supports template inheritance to produce the final executable code string."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_get_ancestors", "line_number": 379, "body": "def _get_ancestors(self, loader: Optional[\"BaseLoader\"]) -> List[\"_File\"]:\n        ancestors = [self.file]\n        for chunk in self.file.body.chunks:\n            if isinstance(chunk, _ExtendsBlock):\n                if not loader:\n                    raise ParseError(\n                        \"{% extends %} block found, but no \" \"template loader\"\n                    )\n                template = loader.load(chunk.name, self.name)\n                ancestors.extend(template._get_ancestors(loader))\n        return ancestors", "is_method": true, "class_name": "Template", "function_description": "Internal method of the Template class that recursively gathers all ancestor templates referenced via extends blocks, supporting hierarchical template inheritance resolution during loading."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "reset", "line_number": 432, "body": "def reset(self) -> None:\n        \"\"\"Resets the cache of compiled templates.\"\"\"\n        with self.lock:\n            self.templates = {}", "is_method": true, "class_name": "BaseLoader", "function_description": "Core method of the BaseLoader class that clears the cache of compiled templates, ensuring a fresh state for subsequent template loading or compilation operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "load", "line_number": 441, "body": "def load(self, name: str, parent_path: Optional[str] = None) -> Template:\n        \"\"\"Loads a template.\"\"\"\n        name = self.resolve_path(name, parent_path=parent_path)\n        with self.lock:\n            if name not in self.templates:\n                self.templates[name] = self._create_template(name)\n            return self.templates[name]", "is_method": true, "class_name": "BaseLoader", "function_description": "Loads and returns a template by name, creating and caching it if not already available, ensuring thread-safe access within the BaseLoader."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "resolve_path", "line_number": 461, "body": "def resolve_path(self, name: str, parent_path: Optional[str] = None) -> str:\n        if (\n            parent_path\n            and not parent_path.startswith(\"<\")\n            and not parent_path.startswith(\"/\")\n            and not name.startswith(\"/\")\n        ):\n            current_path = os.path.join(self.root, parent_path)\n            file_dir = os.path.dirname(os.path.abspath(current_path))\n            relative_path = os.path.abspath(os.path.join(file_dir, name))\n            if relative_path.startswith(self.root):\n                name = relative_path[len(self.root) + 1 :]\n        return name", "is_method": true, "class_name": "Loader", "function_description": "Service function of the Loader class that resolves a file path relative to a given parent path, ensuring the resulting path stays within the loader's root directory. It helps manage and normalize resource locations safely."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_create_template", "line_number": 475, "body": "def _create_template(self, name: str) -> Template:\n        path = os.path.join(self.root, name)\n        with open(path, \"rb\") as f:\n            template = Template(f.read(), name=name, loader=self)\n            return template", "is_method": true, "class_name": "Loader", "function_description": "Private method of the Loader class that loads and returns a Template object from a file by name, facilitating template retrieval from the loader's root directory."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "resolve_path", "line_number": 489, "body": "def resolve_path(self, name: str, parent_path: Optional[str] = None) -> str:\n        if (\n            parent_path\n            and not parent_path.startswith(\"<\")\n            and not parent_path.startswith(\"/\")\n            and not name.startswith(\"/\")\n        ):\n            file_dir = posixpath.dirname(parent_path)\n            name = posixpath.normpath(posixpath.join(file_dir, name))\n        return name", "is_method": true, "class_name": "DictLoader", "function_description": "Resolves a file path by combining a relative name with a parent path, producing a normalized absolute or relative path. Useful for managing and locating files within hierarchical dictionary-based loading contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "_create_template", "line_number": 500, "body": "def _create_template(self, name: str) -> Template:\n        return Template(self.dict[name], name=name, loader=self)", "is_method": true, "class_name": "DictLoader", "function_description": "Private method of DictLoader that creates a Template object from a dictionary entry by name, facilitating template retrieval within the loader's context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 505, "body": "def each_child(self) -> Iterable[\"_Node\"]:\n        return ()", "is_method": true, "class_name": "_Node", "function_description": "This method provides an iterable over the children of a node but currently returns no children. It serves as a placeholder for subclasses to implement child node iteration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "find_named_blocks", "line_number": 511, "body": "def find_named_blocks(\n        self, loader: Optional[BaseLoader], named_blocks: Dict[str, \"_NamedBlock\"]\n    ) -> None:\n        for child in self.each_child():\n            child.find_named_blocks(loader, named_blocks)", "is_method": true, "class_name": "_Node", "function_description": "Recursively traverses child nodes to collect or identify named blocks within a node hierarchy, supporting hierarchical data processing or parsing tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 524, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        writer.write_line(\"def _tt_execute():\", self.line)\n        with writer.indent():\n            writer.write_line(\"_tt_buffer = []\", self.line)\n            writer.write_line(\"_tt_append = _tt_buffer.append\", self.line)\n            self.body.generate(writer)\n            writer.write_line(\"return _tt_utf8('').join(_tt_buffer)\", self.line)", "is_method": true, "class_name": "_File", "function_description": "Generates Python code defining a function that accumulates output into a buffer and returns it as a UTF-8 string. This supports dynamic code generation with buffered string assembly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 532, "body": "def each_child(self) -> Iterable[\"_Node\"]:\n        return (self.body,)", "is_method": true, "class_name": "_File", "function_description": "Returns an iterable containing the single child node of the _File instance, facilitating traversal of its body element."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 540, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        for chunk in self.chunks:\n            chunk.generate(writer)", "is_method": true, "class_name": "_ChunkList", "function_description": "Method of the _ChunkList class that sequentially invokes the generate method on each chunk, facilitating collective code generation through a shared writer object."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 544, "body": "def each_child(self) -> Iterable[\"_Node\"]:\n        return self.chunks", "is_method": true, "class_name": "_ChunkList", "function_description": "Returns an iterable of all child nodes (chunks) contained within the _ChunkList instance, enabling iteration over its components."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 555, "body": "def each_child(self) -> Iterable[\"_Node\"]:\n        return (self.body,)", "is_method": true, "class_name": "_NamedBlock", "function_description": "Returns an iterable containing the sole child node of this _NamedBlock instance, facilitating traversal or processing of its single body element."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 558, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        block = writer.named_blocks[self.name]\n        with writer.include(block.template, self.line):\n            block.body.generate(writer)", "is_method": true, "class_name": "_NamedBlock", "function_description": "Generates code for a named block by locating its template and delegating body generation within the appropriate context. It supports structured code output using named templates in the _NamedBlock class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "find_named_blocks", "line_number": 563, "body": "def find_named_blocks(\n        self, loader: Optional[BaseLoader], named_blocks: Dict[str, \"_NamedBlock\"]\n    ) -> None:\n        named_blocks[self.name] = self\n        _Node.find_named_blocks(self, loader, named_blocks)", "is_method": true, "class_name": "_NamedBlock", "function_description": "Registers the current named block by its name into a collection and delegates further named block discovery to its superclass. This function helps aggregate named blocks for organized access or processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "find_named_blocks", "line_number": 581, "body": "def find_named_blocks(\n        self, loader: Optional[BaseLoader], named_blocks: Dict[str, _NamedBlock]\n    ) -> None:\n        assert loader is not None\n        included = loader.load(self.name, self.template_name)\n        included.file.find_named_blocks(loader, named_blocks)", "is_method": true, "class_name": "_IncludeBlock", "function_description": "Method of the _IncludeBlock class that identifies and aggregates named blocks from an included template using a loader, facilitating template composition and reuse through nested block retrieval."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 588, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        assert writer.loader is not None\n        included = writer.loader.load(self.name, self.template_name)\n        with writer.include(included, self.line):\n            included.file.body.generate(writer)", "is_method": true, "class_name": "_IncludeBlock", "function_description": "Generates content from an included template block by loading and embedding it into the current output stream. This enables modular template composition within the _IncludeBlock context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 601, "body": "def each_child(self) -> Iterable[\"_Node\"]:\n        return (self.body,)", "is_method": true, "class_name": "_ApplyBlock", "function_description": "Returns an iterable containing the child nodes of the current block, facilitating traversal or processing of its contained elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 604, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        method_name = \"_tt_apply%d\" % writer.apply_counter\n        writer.apply_counter += 1\n        writer.write_line(\"def %s():\" % method_name, self.line)\n        with writer.indent():\n            writer.write_line(\"_tt_buffer = []\", self.line)\n            writer.write_line(\"_tt_append = _tt_buffer.append\", self.line)\n            self.body.generate(writer)\n            writer.write_line(\"return _tt_utf8('').join(_tt_buffer)\", self.line)\n        writer.write_line(\n            \"_tt_append(_tt_utf8(%s(%s())))\" % (self.method, method_name), self.line\n        )", "is_method": true, "class_name": "_ApplyBlock", "function_description": "Generates a uniquely named helper function that accumulates output by executing the block's body and appends its processed result using a specified method, facilitating code generation with output buffering in the _ApplyBlock context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "each_child", "line_number": 624, "body": "def each_child(self) -> Iterable[_Node]:\n        return (self.body,)", "is_method": true, "class_name": "_ControlBlock", "function_description": "Returns an iterable containing the single child node of the control block, facilitating traversal or processing of its child elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 627, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        writer.write_line(\"%s:\" % self.statement, self.line)\n        with writer.indent():\n            self.body.generate(writer)\n            # Just in case the body was empty\n            writer.write_line(\"pass\", self.line)", "is_method": true, "class_name": "_ControlBlock", "function_description": "Generates code for a control block statement by writing its header and indented body, ensuring valid syntax even if the body is empty. This supports structured code generation within a code-writing utility."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 640, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        # In case the previous block was empty\n        writer.write_line(\"pass\", self.line)\n        writer.write_line(\"%s:\" % self.statement, self.line, writer.indent_size() - 1)", "is_method": true, "class_name": "_IntermediateControlBlock", "function_description": "Generates code lines for an intermediate control block, ensuring a placeholder if the previous block is empty and writing the control statement with correct indentation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 651, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        writer.write_line(self.statement, self.line)", "is_method": true, "class_name": "_Statement", "function_description": "Utility method of the _Statement class that outputs the stored statement string to a code writer object at a specified line, facilitating code generation or representation tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 661, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        writer.write_line(\"_tt_tmp = %s\" % self.expression, self.line)\n        writer.write_line(\n            \"if isinstance(_tt_tmp, _tt_string_types):\" \" _tt_tmp = _tt_utf8(_tt_tmp)\",\n            self.line,\n        )\n        writer.write_line(\"else: _tt_tmp = _tt_utf8(str(_tt_tmp))\", self.line)\n        if not self.raw and writer.current_template.autoescape is not None:\n            # In python3 functions like xhtml_escape return unicode,\n            # so we have to convert to utf8 again.\n            writer.write_line(\n                \"_tt_tmp = _tt_utf8(%s(_tt_tmp))\" % writer.current_template.autoescape,\n                self.line,\n            )\n        writer.write_line(\"_tt_append(_tt_tmp)\", self.line)", "is_method": true, "class_name": "_Expression", "function_description": "Produces code to safely convert and escape an expression's value for insertion into a template output, ensuring correct string encoding and optional autoescaping for HTML or similar contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "generate", "line_number": 689, "body": "def generate(self, writer: \"_CodeWriter\") -> None:\n        value = self.value\n\n        # Compress whitespace if requested, with a crude heuristic to avoid\n        # altering preformatted whitespace.\n        if \"<pre>\" not in value:\n            value = filter_whitespace(self.whitespace, value)\n\n        if value:\n            writer.write_line(\"_tt_append(%r)\" % escape.utf8(value), self.line)", "is_method": true, "class_name": "_Text", "function_description": "Generates and writes processed text content, optionally compressing whitespace while preserving preformatted sections, to a code writer. This supports text output with controlled formatting in code generation contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__str__", "line_number": 720, "body": "def __str__(self) -> str:\n        return \"%s at %s:%d\" % (self.message, self.filename, self.lineno)", "is_method": true, "class_name": "ParseError", "function_description": "Returns a formatted string representing the parse error with its message, filename, and line number, facilitating clear and concise error reporting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "indent_size", "line_number": 740, "body": "def indent_size(self) -> int:\n        return self._indent", "is_method": true, "class_name": "_CodeWriter", "function_description": "Returns the current indentation size used by the _CodeWriter instance for formatting code output. This value helps maintain consistent code indentation across generated code blocks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "indent", "line_number": 743, "body": "def indent(self) -> \"ContextManager\":\n        class Indenter(object):\n            def __enter__(_) -> \"_CodeWriter\":\n                self._indent += 1\n                return self\n\n            def __exit__(_, *args: Any) -> None:\n                assert self._indent > 0\n                self._indent -= 1\n\n        return Indenter()", "is_method": true, "class_name": "_CodeWriter", "function_description": "Provides a context manager to increase and decrease the indentation level within the _CodeWriter class, facilitating structured code generation with automatic indentation handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "include", "line_number": 755, "body": "def include(self, template: Template, line: int) -> \"ContextManager\":\n        self.include_stack.append((self.current_template, line))\n        self.current_template = template\n\n        class IncludeTemplate(object):\n            def __enter__(_) -> \"_CodeWriter\":\n                return self\n\n            def __exit__(_, *args: Any) -> None:\n                self.current_template = self.include_stack.pop()[0]\n\n        return IncludeTemplate()", "is_method": true, "class_name": "_CodeWriter", "function_description": "Manages the temporary inclusion of another template within the current context, allowing nested template processing and ensuring the original template is restored afterward. Useful for handling hierarchical or embedded templates safely."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "write_line", "line_number": 768, "body": "def write_line(\n        self, line: str, line_number: int, indent: Optional[int] = None\n    ) -> None:\n        if indent is None:\n            indent = self._indent\n        line_comment = \"  # %s:%d\" % (self.current_template.name, line_number)\n        if self.include_stack:\n            ancestors = [\n                \"%s:%d\" % (tmpl.name, lineno) for (tmpl, lineno) in self.include_stack\n            ]\n            line_comment += \" (via %s)\" % \", \".join(reversed(ancestors))\n        print(\"    \" * indent + line + line_comment, file=self.file)", "is_method": true, "class_name": "_CodeWriter", "function_description": "Utility method of the _CodeWriter class that writes a code line to a file with optional indentation and appends a comment indicating the original template name and line number, including the include stack trace if enabled."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "find", "line_number": 790, "body": "def find(self, needle: str, start: int = 0, end: Optional[int] = None) -> int:\n        assert start >= 0, start\n        pos = self.pos\n        start += pos\n        if end is None:\n            index = self.text.find(needle, start)\n        else:\n            end += pos\n            assert end >= start\n            index = self.text.find(needle, start, end)\n        if index != -1:\n            index -= pos\n        return index", "is_method": true, "class_name": "_TemplateReader", "function_description": "Method of _TemplateReader that locates a substring within the reader's text relative to its current position, returning the substring's offset or -1 if not found. It supports optional search range specification for targeted substring detection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "consume", "line_number": 804, "body": "def consume(self, count: Optional[int] = None) -> str:\n        if count is None:\n            count = len(self.text) - self.pos\n        newpos = self.pos + count\n        self.line += self.text.count(\"\\n\", self.pos, newpos)\n        s = self.text[self.pos : newpos]\n        self.pos = newpos\n        return s", "is_method": true, "class_name": "_TemplateReader", "function_description": "Core method of _TemplateReader that returns the next specified number of characters from the current position in the text, updating position and line counters. It supports sequential consumption of template text for parsing or processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "remaining", "line_number": 813, "body": "def remaining(self) -> int:\n        return len(self.text) - self.pos", "is_method": true, "class_name": "_TemplateReader", "function_description": "Returns the number of characters left to read in the template, indicating how much text remains for processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__len__", "line_number": 816, "body": "def __len__(self) -> int:\n        return self.remaining()", "is_method": true, "class_name": "_TemplateReader", "function_description": "Returns the number of remaining elements or items available for reading in the _TemplateReader, providing a concise way to check how much data is left to process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__getitem__", "line_number": 819, "body": "def __getitem__(self, key: Union[int, slice]) -> str:\n        if isinstance(key, slice):\n            size = len(self)\n            start, stop, step = key.indices(size)\n            if start is None:\n                start = self.pos\n            else:\n                start += self.pos\n            if stop is not None:\n                stop += self.pos\n            return self.text[slice(start, stop, step)]\n        elif key < 0:\n            return self.text[key]\n        else:\n            return self.text[self.pos + key]", "is_method": true, "class_name": "_TemplateReader", "function_description": "Provides indexed access to a text segment relative to the current position, supporting both integer indexing and slicing with automatic position adjustment within the _TemplateReader context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__str__", "line_number": 835, "body": "def __str__(self) -> str:\n        return self.text[self.pos :]", "is_method": true, "class_name": "_TemplateReader", "function_description": "Returns the remaining unread portion of the template text from the current reading position as a string."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "raise_parse_error", "line_number": 838, "body": "def raise_parse_error(self, msg: str) -> None:\n        raise ParseError(msg, self.name, self.line)", "is_method": true, "class_name": "_TemplateReader", "function_description": "Utility method of the _TemplateReader class that raises a parsing error with a detailed message including the template name and line number for precise error reporting during template processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__enter__", "line_number": 745, "body": "def __enter__(_) -> \"_CodeWriter\":\n                self._indent += 1\n                return self", "is_method": true, "class_name": "Indenter", "function_description": "Context manager method that increments the indentation level upon entering a code block, facilitating automatic indentation management during code generation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__exit__", "line_number": 749, "body": "def __exit__(_, *args: Any) -> None:\n                assert self._indent > 0\n                self._indent -= 1", "is_method": true, "class_name": "Indenter", "function_description": "Method of the Indenter class that decreases the indentation level upon exiting a context, ensuring proper indentation tracking during scoped code blocks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__enter__", "line_number": 760, "body": "def __enter__(_) -> \"_CodeWriter\":\n                return self", "is_method": true, "class_name": "IncludeTemplate", "function_description": "Returns the instance to support usage as a context manager, enabling the with-statement protocol within the IncludeTemplate class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/template.py", "function": "__exit__", "line_number": 763, "body": "def __exit__(_, *args: Any) -> None:\n                self.current_template = self.include_stack.pop()[0]", "is_method": true, "class_name": "IncludeTemplate", "function_description": "Special method in IncludeTemplate that restores the previous template context when exiting a with-block, managing the template inclusion stack."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_normalize_header", "line_number": 67, "body": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")\n    'Content-Type'\n    \"\"\"\n    return \"-\".join([w.capitalize() for w in name.split(\"-\")])", "is_method": false, "function_description": "Utility function that converts HTTP header names to standard Http-Header-Case format, ensuring consistent capitalization across headers for HTTP communication and processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "url_concat", "line_number": 610, "body": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n    if args is None:\n        return url\n    parsed_url = urlparse(url)\n    if isinstance(args, dict):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args.items())\n    elif isinstance(args, list) or isinstance(args, tuple):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args)\n    else:\n        err = \"'args' parameter should be dict, list or tuple. Not {0}\".format(\n            type(args)\n        )\n        raise TypeError(err)\n    final_query = urlencode(parsed_query)\n    url = urlunparse(\n        (\n            parsed_url[0],\n            parsed_url[1],\n            parsed_url[2],\n            parsed_url[3],\n            final_query,\n            parsed_url[5],\n        )\n    )\n    return url", "is_method": false, "function_description": "Function that appends query parameters to a given URL, properly handling existing parameters and allowing multiple values per key. Useful for dynamically building URLs with flexible argument formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_parse_request_range", "line_number": 671, "body": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n    unit, _, value = range_header.partition(\"=\")\n    unit, value = unit.strip(), value.strip()\n    if unit != \"bytes\":\n        return None\n    start_b, _, end_b = value.partition(\"-\")\n    try:\n        start = _int_or_none(start_b)\n        end = _int_or_none(end_b)\n    except ValueError:\n        return None\n    if end is not None:\n        if start is None:\n            if end != 0:\n                start = -end\n                end = None\n        else:\n            end += 1\n    return (start, end)", "is_method": false, "function_description": "Parses an HTTP Range header to extract byte positions as slice indexes, supporting single-range requests. Useful for handling partial content delivery in HTTP servers or clients."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_get_content_range", "line_number": 722, "body": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)", "is_method": false, "function_description": "Function that generates a valid HTTP Content-Range header string based on given start, end, and total byte positions, useful for indicating partial content delivery in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_int_or_none", "line_number": 737, "body": "def _int_or_none(val: str) -> Optional[int]:\n    val = val.strip()\n    if val == \"\":\n        return None\n    return int(val)", "is_method": false, "function_description": "Utility function that converts a string to an integer or returns None if the string is empty, facilitating safe parsing of optional integer values from strings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_body_arguments", "line_number": 744, "body": "def parse_body_arguments(\n    content_type: str,\n    body: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n    headers: Optional[HTTPHeaders] = None,\n) -> None:\n    \"\"\"Parses a form request body.\n\n    Supports ``application/x-www-form-urlencoded`` and\n    ``multipart/form-data``.  The ``content_type`` parameter should be\n    a string and ``body`` should be a byte string.  The ``arguments``\n    and ``files`` parameters are dictionaries that will be updated\n    with the parsed contents.\n    \"\"\"\n    if content_type.startswith(\"application/x-www-form-urlencoded\"):\n        if headers and \"Content-Encoding\" in headers:\n            gen_log.warning(\n                \"Unsupported Content-Encoding: %s\", headers[\"Content-Encoding\"]\n            )\n            return\n        try:\n            # real charset decoding will happen in RequestHandler.decode_argument()\n            uri_arguments = parse_qs_bytes(body, keep_blank_values=True)\n        except Exception as e:\n            gen_log.warning(\"Invalid x-www-form-urlencoded body: %s\", e)\n            uri_arguments = {}\n        for name, values in uri_arguments.items():\n            if values:\n                arguments.setdefault(name, []).extend(values)\n    elif content_type.startswith(\"multipart/form-data\"):\n        if headers and \"Content-Encoding\" in headers:\n            gen_log.warning(\n                \"Unsupported Content-Encoding: %s\", headers[\"Content-Encoding\"]\n            )\n            return\n        try:\n            fields = content_type.split(\";\")\n            for field in fields:\n                k, sep, v = field.strip().partition(\"=\")\n                if k == \"boundary\" and v:\n                    parse_multipart_form_data(utf8(v), body, arguments, files)\n                    break\n            else:\n                raise ValueError(\"multipart boundary not found\")\n        except Exception as e:\n            gen_log.warning(\"Invalid multipart/form-data: %s\", e)", "is_method": false, "function_description": "Parses HTTP form request bodies of type `application/x-www-form-urlencoded` or `multipart/form-data`, extracting and organizing form fields and file uploads into given dictionaries for downstream processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_multipart_form_data", "line_number": 793, "body": "def parse_multipart_form_data(\n    boundary: bytes,\n    data: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n) -> None:\n    \"\"\"Parses a ``multipart/form-data`` body.\n\n    The ``boundary`` and ``data`` parameters are both byte strings.\n    The dictionaries given in the arguments and files parameters\n    will be updated with the contents of the body.\n\n    .. versionchanged:: 5.1\n\n       Now recognizes non-ASCII filenames in RFC 2231/5987\n       (``filename*=``) format.\n    \"\"\"\n    # The standard allows for the boundary to be quoted in the header,\n    # although it's rare (it happens at least for google app engine\n    # xmpp).  I think we're also supposed to handle backslash-escapes\n    # here but I'll save that until we see a client that uses them\n    # in the wild.\n    if boundary.startswith(b'\"') and boundary.endswith(b'\"'):\n        boundary = boundary[1:-1]\n    final_boundary_index = data.rfind(b\"--\" + boundary + b\"--\")\n    if final_boundary_index == -1:\n        gen_log.warning(\"Invalid multipart/form-data: no final boundary\")\n        return\n    parts = data[:final_boundary_index].split(b\"--\" + boundary + b\"\\r\\n\")\n    for part in parts:\n        if not part:\n            continue\n        eoh = part.find(b\"\\r\\n\\r\\n\")\n        if eoh == -1:\n            gen_log.warning(\"multipart/form-data missing headers\")\n            continue\n        headers = HTTPHeaders.parse(part[:eoh].decode(\"utf-8\"))\n        disp_header = headers.get(\"Content-Disposition\", \"\")\n        disposition, disp_params = _parse_header(disp_header)\n        if disposition != \"form-data\" or not part.endswith(b\"\\r\\n\"):\n            gen_log.warning(\"Invalid multipart/form-data\")\n            continue\n        value = part[eoh + 4 : -2]\n        if not disp_params.get(\"name\"):\n            gen_log.warning(\"multipart/form-data value missing name\")\n            continue\n        name = disp_params[\"name\"]\n        if disp_params.get(\"filename\"):\n            ctype = headers.get(\"Content-Type\", \"application/unknown\")\n            files.setdefault(name, []).append(\n                HTTPFile(\n                    filename=disp_params[\"filename\"], body=value, content_type=ctype\n                )\n            )\n        else:\n            arguments.setdefault(name, []).append(value)", "is_method": false, "function_description": "Function that parses raw multipart/form-data byte content, extracting form field values and uploaded files into provided dictionaries by interpreting MIME boundaries and headers. Useful for processing HTTP form submissions involving file uploads and text fields."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "format_timestamp", "line_number": 851, "body": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n    if isinstance(ts, (int, float)):\n        time_num = ts\n    elif isinstance(ts, (tuple, time.struct_time)):\n        time_num = calendar.timegm(ts)\n    elif isinstance(ts, datetime.datetime):\n        time_num = calendar.timegm(ts.utctimetuple())\n    else:\n        raise TypeError(\"unknown timestamp type: %r\" % ts)\n    return email.utils.formatdate(time_num, usegmt=True)", "is_method": false, "function_description": "Utility function that converts various timestamp formats into a standardized HTTP-date string, facilitating consistent date representations in HTTP headers or protocols."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_request_start_line", "line_number": 882, "body": "def parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n    try:\n        method, path, version = line.split(\" \")\n    except ValueError:\n        # https://tools.ietf.org/html/rfc7230#section-3.1.1\n        # invalid request-line SHOULD respond with a 400 (Bad Request)\n        raise HTTPInputError(\"Malformed HTTP request line\")\n    if not _http_version_re.match(version):\n        raise HTTPInputError(\n            \"Malformed HTTP version in HTTP Request-Line: %r\" % version\n        )\n    return RequestStartLine(method, path, version)", "is_method": false, "function_description": "Parses an HTTP/1.x request line into its components: method, path, and version, validating its format and raising errors for malformed inputs. This enables downstream processing of HTTP requests by extracting core request details."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_response_start_line", "line_number": 911, "body": "def parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n    line = native_str(line)\n    match = _http_response_line_re.match(line)\n    if not match:\n        raise HTTPInputError(\"Error parsing response start line\")\n    return ResponseStartLine(match.group(1), int(match.group(2)), match.group(3))", "is_method": false, "function_description": "Utility function that parses an HTTP 1.x response start line into its version, status code, and reason phrase components for easier HTTP response handling and analysis."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_parseparam", "line_number": 934, "body": "def _parseparam(s: str) -> Generator[str, None, None]:\n    while s[:1] == \";\":\n        s = s[1:]\n        end = s.find(\";\")\n        while end > 0 and (s.count('\"', 0, end) - s.count('\\\\\"', 0, end)) % 2:\n            end = s.find(\";\", end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]", "is_method": false, "function_description": "Utility function that parses and yields individual parameters from a semicolon-separated string, correctly handling quoted sections to ensure proper extraction of each parameter."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_parse_header", "line_number": 947, "body": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n    parts = _parseparam(\";\" + line)\n    key = next(parts)\n    # decode_params treats first argument special, but we already stripped key\n    params = [(\"Dummy\", \"value\")]\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i + 1 :].strip()\n            params.append((name, native_str(value)))\n    decoded_params = email.utils.decode_params(params)\n    decoded_params.pop(0)  # get rid of the dummy again\n    pdict = {}\n    for name, decoded_value in decoded_params:\n        value = email.utils.collapse_rfc2231_value(decoded_value)\n        if len(value) >= 2 and value[0] == '\"' and value[-1] == '\"':\n            value = value[1:-1]\n        pdict[name] = value\n    return key, pdict", "is_method": false, "function_description": "Parses a Content-Type header string into its main type and option dictionary, decoding parameters per RFC 2231 for accurate metadata extraction. Useful for interpreting HTTP or MIME content headers in network or email processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_encode_header", "line_number": 982, "body": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n    if not pdict:\n        return key\n    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(\"%s=%s\" % (k, v))\n    return \"; \".join(out)", "is_method": false, "function_description": "Utility function that converts a header key and its parameters dictionary into a single formatted header string, supporting serialization of WebSocket extension headers or similar parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "encode_username_password", "line_number": 1002, "body": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)", "is_method": false, "function_description": "Provides a utility to encode a username and password into a single byte string formatted as \"username:password\" for use in HTTP authentication schemes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "doctests", "line_number": 1018, "body": "def doctests():\n    # type: () -> unittest.TestSuite\n    import doctest\n\n    return doctest.DocTestSuite()", "is_method": false, "function_description": "Returns a unittest TestSuite containing all doctests found in the current module, enabling automated testing of embedded documentation examples."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "split_host_and_port", "line_number": 1028, "body": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)", "is_method": false, "function_description": "This function parses a network location string into its host and optional port components, returning them as a tuple. It enables other functions to easily access and utilize the host and port information from network addresses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "qs_to_qsl", "line_number": 1045, "body": "def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():\n        for v in vs:\n            yield (k, v)", "is_method": false, "function_description": "Function that converts a dictionary of query parameters (each mapped to multiple values) into an iterable of individual name-value pairs, facilitating processing of URL query strings in a flat structure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_unquote_cookie", "line_number": 1060, "body": "def _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if s is None or len(s) < 2:\n        return s\n    if s[0] != '\"' or s[-1] != '\"':\n        return s\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    s = s[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    i = 0\n    n = len(s)\n    res = []\n    while 0 <= i < n:\n        o_match = _OctalPatt.search(s, i)\n        q_match = _QuotePatt.search(s, i)\n        if not o_match and not q_match:  # Neither matched\n            res.append(s[i:])\n            break\n        # else:\n        j = k = -1\n        if o_match:\n            j = o_match.start(0)\n        if q_match:\n            k = q_match.start(0)\n        if q_match and (not o_match or k < j):  # QuotePatt matched\n            res.append(s[i:k])\n            res.append(s[k + 1])\n            i = k + 2\n        else:  # OctalPatt matched\n            res.append(s[i:j])\n            res.append(chr(int(s[j + 1 : j + 4], 8)))\n            i = j + 4\n    return _nulljoin(res)", "is_method": false, "function_description": "Utility function that decodes and cleans a quoted HTTP cookie value by handling escaped characters and octal sequences, ensuring proper extraction of the original cookie string."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_cookie", "line_number": 1110, "body": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n    cookiedict = {}\n    for chunk in cookie.split(str(\";\")):\n        if str(\"=\") in chunk:\n            key, val = chunk.split(str(\"=\"), 1)\n        else:\n            # Assume an empty name per\n            # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n            key, val = str(\"\"), chunk\n        key, val = key.strip(), val.strip()\n        if key or val:\n            # unquote using Python's algorithm.\n            cookiedict[key] = _unquote_cookie(val)\n    return cookiedict", "is_method": false, "function_description": "Function that converts an HTTP Cookie header string into a dictionary of cookie name-value pairs, mimicking typical browser parsing behavior for use in web request handling and cookie management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "add", "line_number": 135, "body": "def add(self, name: str, value: str) -> None:\n        \"\"\"Adds a new value for the given key.\"\"\"\n        norm_name = _normalize_header(name)\n        self._last_key = norm_name\n        if norm_name in self:\n            self._dict[norm_name] = (\n                native_str(self[norm_name]) + \",\" + native_str(value)\n            )\n            self._as_list[norm_name].append(value)\n        else:\n            self[norm_name] = value", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Provides a way to add or append header values under a given name in the HTTPHeaders collection, supporting multiple values for the same header key in HTTP communications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "get_list", "line_number": 147, "body": "def get_list(self, name: str) -> List[str]:\n        \"\"\"Returns all values for the given header as a list.\"\"\"\n        norm_name = _normalize_header(name)\n        return self._as_list.get(norm_name, [])", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Utility method of the HTTPHeaders class that retrieves all values associated with a specific header name, returning them as a list for convenient access to multiple header values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "get_all", "line_number": 152, "body": "def get_all(self) -> Iterable[Tuple[str, str]]:\n        \"\"\"Returns an iterable of all (name, value) pairs.\n\n        If a header has multiple values, multiple pairs will be\n        returned with the same name.\n        \"\"\"\n        for name, values in self._as_list.items():\n            for value in values:\n                yield (name, value)", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Utility method in HTTPHeaders that provides an iterable over all header name-value pairs, including multiple entries for headers with several values. It enables easy access to the complete set of HTTP headers stored."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse_line", "line_number": 162, "body": "def parse_line(self, line: str) -> None:\n        \"\"\"Updates the dictionary with a single header line.\n\n        >>> h = HTTPHeaders()\n        >>> h.parse_line(\"Content-Type: text/html\")\n        >>> h.get('content-type')\n        'text/html'\n        \"\"\"\n        if line[0].isspace():\n            # continuation of a multi-line header\n            if self._last_key is None:\n                raise HTTPInputError(\"first header line cannot start with whitespace\")\n            new_part = \" \" + line.lstrip()\n            self._as_list[self._last_key][-1] += new_part\n            self._dict[self._last_key] += new_part\n        else:\n            try:\n                name, value = line.split(\":\", 1)\n            except ValueError:\n                raise HTTPInputError(\"no colon in header line\")\n            self.add(name, value.strip())", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Parses and adds a single HTTP header line to the HTTPHeaders collection, handling multi-line header continuations and ensuring proper header formatting for later retrieval."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "parse", "line_number": 185, "body": "def parse(cls, headers: str) -> \"HTTPHeaders\":\n        \"\"\"Returns a dictionary from HTTP header text.\n\n        >>> h = HTTPHeaders.parse(\"Content-Type: text/html\\\\r\\\\nContent-Length: 42\\\\r\\\\n\")\n        >>> sorted(h.items())\n        [('Content-Length', '42'), ('Content-Type', 'text/html')]\n\n        .. versionchanged:: 5.1\n\n           Raises `HTTPInputError` on malformed headers instead of a\n           mix of `KeyError`, and `ValueError`.\n\n        \"\"\"\n        h = cls()\n        # RFC 7230 section 3.5: a recipient MAY recognize a single LF as a line\n        # terminator and ignore any preceding CR.\n        for line in headers.split(\"\\n\"):\n            if line.endswith(\"\\r\"):\n                line = line[:-1]\n            if line:\n                h.parse_line(line)\n        return h", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Parses raw HTTP header text into an HTTPHeaders object representing header fields as a dictionary, enabling easy access and manipulation of HTTP headers from their string representation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__setitem__", "line_number": 210, "body": "def __setitem__(self, name: str, value: str) -> None:\n        norm_name = _normalize_header(name)\n        self._dict[norm_name] = value\n        self._as_list[norm_name] = [value]", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Sets or updates an HTTP header\u2019s value, normalizing the header name and storing it in both dictionary and list formats for consistent header management. This method enables easy assignment of header fields within HTTPHeaders."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__getitem__", "line_number": 215, "body": "def __getitem__(self, name: str) -> str:\n        return self._dict[_normalize_header(name)]", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Provides dictionary-like access to HTTP header values by normalized header names, enabling retrieval of specific headers from an HTTPHeaders instance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__delitem__", "line_number": 218, "body": "def __delitem__(self, name: str) -> None:\n        norm_name = _normalize_header(name)\n        del self._dict[norm_name]\n        del self._as_list[norm_name]", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Core method of the HTTPHeaders class that removes a header and its associated values by name, ensuring the header is deleted from all internal storage representations for consistent state management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__len__", "line_number": 223, "body": "def __len__(self) -> int:\n        return len(self._dict)", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Returns the number of HTTP header entries stored in the HTTPHeaders instance. This allows users to quickly determine how many headers are present in the collection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__iter__", "line_number": 226, "body": "def __iter__(self) -> Iterator[typing.Any]:\n        return iter(self._dict)", "is_method": true, "class_name": "HTTPHeaders", "function_description": "This method enables iteration over the HTTPHeaders object's keys, allowing users to traverse header names stored internally. It provides standard iterable behavior for the HTTPHeaders class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "copy", "line_number": 229, "body": "def copy(self) -> \"HTTPHeaders\":\n        # defined in dict but not in MutableMapping.\n        return HTTPHeaders(self)", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Creates and returns a shallow copy of the HTTPHeaders instance, allowing manipulation without altering the original header collection. This is useful for safely modifying headers in HTTP request/response workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__str__", "line_number": 238, "body": "def __str__(self) -> str:\n        lines = []\n        for name, value in self.get_all():\n            lines.append(\"%s: %s\\n\" % (name, value))\n        return \"\".join(lines)", "is_method": true, "class_name": "HTTPHeaders", "function_description": "Converts all HTTP header fields and their values into a formatted string, suitable for display or transmission as HTTP header lines. This method provides a readable representation of headers in the HTTPHeaders class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "cookies", "line_number": 387, "body": "def cookies(self) -> Dict[str, http.cookies.Morsel]:\n        \"\"\"A dictionary of ``http.cookies.Morsel`` objects.\"\"\"\n        if not hasattr(self, \"_cookies\"):\n            self._cookies = (\n                http.cookies.SimpleCookie()\n            )  # type: http.cookies.SimpleCookie\n            if \"Cookie\" in self.headers:\n                try:\n                    parsed = parse_cookie(self.headers[\"Cookie\"])\n                except Exception:\n                    pass\n                else:\n                    for k, v in parsed.items():\n                        try:\n                            self._cookies[k] = v\n                        except Exception:\n                            # SimpleCookie imposes some restrictions on keys;\n                            # parse_cookie does not. Discard any cookies\n                            # with disallowed keys.\n                            pass\n        return self._cookies", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Method of HTTPServerRequest that parses and returns HTTP cookies from the request headers as a dictionary of cookie objects, facilitating easy access to cookie data in server-side request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "full_url", "line_number": 409, "body": "def full_url(self) -> str:\n        \"\"\"Reconstructs the full URL for this request.\"\"\"\n        return self.protocol + \"://\" + self.host + self.uri", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Returns the complete URL of the HTTP request by combining its protocol, host, and URI. This method helps other components easily access the full request address."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "request_time", "line_number": 413, "body": "def request_time(self) -> float:\n        \"\"\"Returns the amount of time it took for this request to execute.\"\"\"\n        if self._finish_time is None:\n            return time.time() - self._start_time\n        else:\n            return self._finish_time - self._start_time", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Provides the execution duration of an HTTP request from start to finish, useful for measuring response times and performance monitoring in server applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "get_ssl_certificate", "line_number": 420, "body": "def get_ssl_certificate(\n        self, binary_form: bool = False\n    ) -> Union[None, Dict, bytes]:\n        \"\"\"Returns the client's SSL certificate, if any.\n\n        To use client certificates, the HTTPServer's\n        `ssl.SSLContext.verify_mode` field must be set, e.g.::\n\n            ssl_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            ssl_ctx.load_cert_chain(\"foo.crt\", \"foo.key\")\n            ssl_ctx.load_verify_locations(\"cacerts.pem\")\n            ssl_ctx.verify_mode = ssl.CERT_REQUIRED\n            server = HTTPServer(app, ssl_options=ssl_ctx)\n\n        By default, the return value is a dictionary (or None, if no\n        client certificate is present).  If ``binary_form`` is true, a\n        DER-encoded form of the certificate is returned instead.  See\n        SSLSocket.getpeercert() in the standard library for more\n        details.\n        http://docs.python.org/library/ssl.html#sslsocket-objects\n        \"\"\"\n        try:\n            if self.connection is None:\n                return None\n            # TODO: add a method to HTTPConnection for this so it can work with HTTP/2\n            return self.connection.stream.socket.getpeercert(  # type: ignore\n                binary_form=binary_form\n            )\n        except SSLError:\n            return None", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Provides access to the client's SSL certificate from an HTTP request, returning it as a dictionary or DER-encoded bytes. Useful for verifying client identities when mutual TLS authentication is enabled on the server."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "_parse_body", "line_number": 451, "body": "def _parse_body(self) -> None:\n        parse_body_arguments(\n            self.headers.get(\"Content-Type\", \"\"),\n            self.body,\n            self.body_arguments,\n            self.files,\n            self.headers,\n        )\n\n        for k, v in self.body_arguments.items():\n            self.arguments.setdefault(k, []).extend(v)", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Internal method of HTTPServerRequest that parses the request body based on its content type, extracting parameters and files, and integrates these into the request's arguments for further processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "__repr__", "line_number": 463, "body": "def __repr__(self) -> str:\n        attrs = (\"protocol\", \"host\", \"method\", \"uri\", \"version\", \"remote_ip\")\n        args = \", \".join([\"%s=%r\" % (n, getattr(self, n)) for n in attrs])\n        return \"%s(%s)\" % (self.__class__.__name__, args)", "is_method": true, "class_name": "HTTPServerRequest", "function_description": "Provides a string representation of an HTTPServerRequest instance, summarizing key request attributes for debugging or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httputil.py", "function": "headers_received", "line_number": 524, "body": "def headers_received(\n        self,\n        start_line: Union[\"RequestStartLine\", \"ResponseStartLine\"],\n        headers: HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        \"\"\"Called when the HTTP headers have been received and parsed.\n\n        :arg start_line: a `.RequestStartLine` or `.ResponseStartLine`\n            depending on whether this is a client or server message.\n        :arg headers: a `.HTTPHeaders` instance.\n\n        Some `.HTTPConnection` methods can only be called during\n        ``headers_received``.\n\n        May return a `.Future`; if it does the body will not be read\n        until it is done.\n        \"\"\"\n        pass", "is_method": true, "class_name": "HTTPMessageDelegate", "function_description": "Notification hook in HTTPMessageDelegate triggered upon receiving and parsing HTTP headers, allowing asynchronous processing before the message body is read."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "__exit__", "line_number": 59, "body": "def __exit__(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: types.TracebackType,\n    ) -> None:\n        if value is not None:\n            assert typ is not None\n            self.logger.error(\"Uncaught exception\", exc_info=(typ, value, tb))\n            raise _QuietException", "is_method": true, "class_name": "_ExceptionLoggingContext", "function_description": "This method logs any uncaught exception with detailed traceback information upon exiting a context and then suppresses it by raising a sentinel exception, supporting robust error handling within the _ExceptionLoggingContext."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "read_response", "line_number": 165, "body": "def read_response(self, delegate: httputil.HTTPMessageDelegate) -> Awaitable[bool]:\n        \"\"\"Read a single HTTP response.\n\n        Typical client-mode usage is to write a request using `write_headers`,\n        `write`, and `finish`, and then call ``read_response``.\n\n        :arg delegate: a `.HTTPMessageDelegate`\n\n        Returns a `.Future` that resolves to a bool after the full response has\n        been read. The result is true if the stream is still open.\n        \"\"\"\n        if self.params.decompress:\n            delegate = _GzipMessageDelegate(delegate, self.params.chunk_size)\n        return self._read_message(delegate)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Provides an asynchronous method to read and process a single HTTP response using a delegate, optionally handling decompression. It returns a future indicating if the connection remains open after the response is fully read."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_clear_callbacks", "line_number": 302, "body": "def _clear_callbacks(self) -> None:\n        \"\"\"Clears the callback attributes.\n\n        This allows the request handler to be garbage collected more\n        quickly in CPython by breaking up reference cycles.\n        \"\"\"\n        self._write_callback = None\n        self._write_future = None  # type: Optional[Future[None]]\n        self._close_callback = None  # type: Optional[Callable[[], None]]\n        if self.stream is not None:\n            self.stream.set_close_callback(None)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Clears internal callback references to break reference cycles, aiding timely garbage collection of the request handler in HTTP1Connection instances."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "set_close_callback", "line_number": 314, "body": "def set_close_callback(self, callback: Optional[Callable[[], None]]) -> None:\n        \"\"\"Sets a callback that will be run when the connection is closed.\n\n        Note that this callback is slightly different from\n        `.HTTPMessageDelegate.on_connection_close`: The\n        `.HTTPMessageDelegate` method is called when the connection is\n        closed while receiving a message. This callback is used when\n        there is not an active delegate (for example, on the server\n        side this callback is used if the client closes the connection\n        after sending its request but before receiving all the\n        response.\n        \"\"\"\n        self._close_callback = callback", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Provides a way to specify a function that runs when an HTTP/1 connection closes without an active message delegate, enabling custom cleanup or handling for premature or unusual connection terminations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_on_connection_close", "line_number": 328, "body": "def _on_connection_close(self) -> None:\n        # Note that this callback is only registered on the IOStream\n        # when we have finished reading the request and are waiting for\n        # the application to produce its response.\n        if self._close_callback is not None:\n            callback = self._close_callback\n            self._close_callback = None\n            callback()\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)\n        self._clear_callbacks()", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Handles connection closure by triggering any registered close callbacks, ensuring the finish future is resolved, and cleaning up internal callbacks to properly finalize the HTTP connection state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "close", "line_number": 340, "body": "def close(self) -> None:\n        if self.stream is not None:\n            self.stream.close()\n        self._clear_callbacks()\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Method of HTTP1Connection that gracefully closes the underlying stream, clears related callbacks, and marks the connection's finishing process as complete to ensure proper cleanup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "detach", "line_number": 347, "body": "def detach(self) -> iostream.IOStream:\n        \"\"\"Take control of the underlying stream.\n\n        Returns the underlying `.IOStream` object and stops all further\n        HTTP processing.  May only be called during\n        `.HTTPMessageDelegate.headers_received`.  Intended for implementing\n        protocols like websockets that tunnel over an HTTP handshake.\n        \"\"\"\n        self._clear_callbacks()\n        stream = self.stream\n        self.stream = None  # type: ignore\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)\n        return stream", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Provides access to the raw underlying stream by detaching it from HTTP processing, enabling protocols like WebSockets to take direct control during the HTTP handshake phase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "set_body_timeout", "line_number": 362, "body": "def set_body_timeout(self, timeout: float) -> None:\n        \"\"\"Sets the body timeout for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._body_timeout = timeout", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Sets a custom timeout duration for the body of an HTTP request, overriding the default parameter to control how long the connection waits during request body transmission."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "set_max_body_size", "line_number": 369, "body": "def set_max_body_size(self, max_body_size: int) -> None:\n        \"\"\"Sets the body size limit for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._max_body_size = max_body_size", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Sets the maximum allowed size for the body of a single HTTP request, overriding the default limit. This enables control over request payload size for managing resource usage or security within HTTP1Connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "write_headers", "line_number": 376, "body": "def write_headers(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n        chunk: Optional[bytes] = None,\n    ) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n        lines = []\n        if self.is_client:\n            assert isinstance(start_line, httputil.RequestStartLine)\n            self._request_start_line = start_line\n            lines.append(utf8(\"%s %s HTTP/1.1\" % (start_line[0], start_line[1])))\n            # Client requests with a non-empty body must have either a\n            # Content-Length or a Transfer-Encoding.\n            self._chunking_output = (\n                start_line.method in (\"POST\", \"PUT\", \"PATCH\")\n                and \"Content-Length\" not in headers\n                and (\n                    \"Transfer-Encoding\" not in headers\n                    or headers[\"Transfer-Encoding\"] == \"chunked\"\n                )\n            )\n        else:\n            assert isinstance(start_line, httputil.ResponseStartLine)\n            assert self._request_start_line is not None\n            assert self._request_headers is not None\n            self._response_start_line = start_line\n            lines.append(utf8(\"HTTP/1.1 %d %s\" % (start_line[1], start_line[2])))\n            self._chunking_output = (\n                # TODO: should this use\n                # self._request_start_line.version or\n                # start_line.version?\n                self._request_start_line.version == \"HTTP/1.1\"\n                # Omit payload header field for HEAD request.\n                and self._request_start_line.method != \"HEAD\"\n                # 1xx, 204 and 304 responses have no body (not even a zero-length\n                # body), and so should not have either Content-Length or\n                # Transfer-Encoding headers.\n                and start_line.code not in (204, 304)\n                and (start_line.code < 100 or start_line.code >= 200)\n                # No need to chunk the output if a Content-Length is specified.\n                and \"Content-Length\" not in headers\n                # Applications are discouraged from touching Transfer-Encoding,\n                # but if they do, leave it alone.\n                and \"Transfer-Encoding\" not in headers\n            )\n            # If connection to a 1.1 client will be closed, inform client\n            if (\n                self._request_start_line.version == \"HTTP/1.1\"\n                and self._disconnect_on_finish\n            ):\n                headers[\"Connection\"] = \"close\"\n            # If a 1.0 client asked for keep-alive, add the header.\n            if (\n                self._request_start_line.version == \"HTTP/1.0\"\n                and self._request_headers.get(\"Connection\", \"\").lower() == \"keep-alive\"\n            ):\n                headers[\"Connection\"] = \"Keep-Alive\"\n        if self._chunking_output:\n            headers[\"Transfer-Encoding\"] = \"chunked\"\n        if not self.is_client and (\n            self._request_start_line.method == \"HEAD\"\n            or cast(httputil.ResponseStartLine, start_line).code == 304\n        ):\n            self._expected_content_remaining = 0\n        elif \"Content-Length\" in headers:\n            self._expected_content_remaining = int(headers[\"Content-Length\"])\n        else:\n            self._expected_content_remaining = None\n        # TODO: headers are supposed to be of type str, but we still have some\n        # cases that let bytes slip through. Remove these native_str calls when those\n        # are fixed.\n        header_lines = (\n            native_str(n) + \": \" + native_str(v) for n, v in headers.get_all()\n        )\n        lines.extend(line.encode(\"latin1\") for line in header_lines)\n        for line in lines:\n            if b\"\\n\" in line:\n                raise ValueError(\"Newline in header: \" + repr(line))\n        future = None\n        if self.stream.closed():\n            future = self._write_future = Future()\n            future.set_exception(iostream.StreamClosedError())\n            future.exception()\n        else:\n            future = self._write_future = Future()\n            data = b\"\\r\\n\".join(lines) + b\"\\r\\n\\r\\n\"\n            if chunk:\n                data += self._format_chunk(chunk)\n            self._pending_write = self.stream.write(data)\n            future_add_done_callback(self._pending_write, self._on_write_complete)\n        return future", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Handles formatting and sending HTTP/1.1 start line and headers for requests or responses, managing chunked transfer encoding and connection persistence. It prepares header data for transmission and returns a Future representing the write operation's completion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_format_chunk", "line_number": 469, "body": "def _format_chunk(self, chunk: bytes) -> bytes:\n        if self._expected_content_remaining is not None:\n            self._expected_content_remaining -= len(chunk)\n            if self._expected_content_remaining < 0:\n                # Close the stream now to stop further framing errors.\n                self.stream.close()\n                raise httputil.HTTPOutputError(\n                    \"Tried to write more data than Content-Length\"\n                )\n        if self._chunking_output and chunk:\n            # Don't write out empty chunks because that means END-OF-STREAM\n            # with chunked encoding\n            return utf8(\"%x\" % len(chunk)) + b\"\\r\\n\" + chunk + b\"\\r\\n\"\n        else:\n            return chunk", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Formats a data chunk for HTTP/1 output, applying chunked transfer encoding if enabled and ensuring content length limits are respected to prevent protocol errors. Useful for managing HTTP response body streaming with or without chunked encoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "write", "line_number": 485, "body": "def write(self, chunk: bytes) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write`.\n\n        For backwards compatibility it is allowed but deprecated to\n        skip `write_headers` and instead call `write()` with a\n        pre-encoded header block.\n        \"\"\"\n        future = None\n        if self.stream.closed():\n            future = self._write_future = Future()\n            self._write_future.set_exception(iostream.StreamClosedError())\n            self._write_future.exception()\n        else:\n            future = self._write_future = Future()\n            self._pending_write = self.stream.write(self._format_chunk(chunk))\n            future_add_done_callback(self._pending_write, self._on_write_complete)\n        return future", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Provides asynchronous writing of byte chunks to an HTTP/1 connection stream, handling stream closure and supporting deprecated pre-encoded header writes for backward compatibility."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "finish", "line_number": 503, "body": "def finish(self) -> None:\n        \"\"\"Implements `.HTTPConnection.finish`.\"\"\"\n        if (\n            self._expected_content_remaining is not None\n            and self._expected_content_remaining != 0\n            and not self.stream.closed()\n        ):\n            self.stream.close()\n            raise httputil.HTTPOutputError(\n                \"Tried to write %d bytes less than Content-Length\"\n                % self._expected_content_remaining\n            )\n        if self._chunking_output:\n            if not self.stream.closed():\n                self._pending_write = self.stream.write(b\"0\\r\\n\\r\\n\")\n                self._pending_write.add_done_callback(self._on_write_complete)\n        self._write_finished = True\n        # If the app finished the request while we're still reading,\n        # divert any remaining data away from the delegate and\n        # close the connection when we're done sending our response.\n        # Closing the connection is the only way to avoid reading the\n        # whole input body.\n        if not self._read_finished:\n            self._disconnect_on_finish = True\n        # No more data is coming, so instruct TCP to send any remaining\n        # data immediately instead of waiting for a full packet or ack.\n        self.stream.set_nodelay(True)\n        if self._pending_write is None:\n            self._finish_request(None)\n        else:\n            future_add_done_callback(self._pending_write, self._finish_request)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Finalizes an HTTP/1 connection by ensuring all expected data is sent, properly closing streams, handling chunked transfer completion, and preparing the connection for closure or reuse. It guarantees protocol compliance and resource cleanup after a request completes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_on_write_complete", "line_number": 535, "body": "def _on_write_complete(self, future: \"Future[None]\") -> None:\n        exc = future.exception()\n        if exc is not None and not isinstance(exc, iostream.StreamClosedError):\n            future.result()\n        if self._write_callback is not None:\n            callback = self._write_callback\n            self._write_callback = None\n            self.stream.io_loop.add_callback(callback)\n        if self._write_future is not None:\n            future = self._write_future\n            self._write_future = None\n            future_set_result_unless_cancelled(future, None)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Handles the completion of a write operation by processing errors, invoking a write callback, and resolving an associated future to signal the write's end within the HTTP1Connection context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_can_keep_alive", "line_number": 548, "body": "def _can_keep_alive(\n        self, start_line: httputil.RequestStartLine, headers: httputil.HTTPHeaders\n    ) -> bool:\n        if self.params.no_keep_alive:\n            return False\n        connection_header = headers.get(\"Connection\")\n        if connection_header is not None:\n            connection_header = connection_header.lower()\n        if start_line.version == \"HTTP/1.1\":\n            return connection_header != \"close\"\n        elif (\n            \"Content-Length\" in headers\n            or headers.get(\"Transfer-Encoding\", \"\").lower() == \"chunked\"\n            or getattr(start_line, \"method\", None) in (\"HEAD\", \"GET\")\n        ):\n            # start_line may be a request or response start line; only\n            # the former has a method attribute.\n            return connection_header == \"keep-alive\"\n        return False", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Determines if an HTTP/1 connection should be kept alive based on request/response start line and headers, enabling efficient connection reuse and persistent HTTP sessions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_finish_request", "line_number": 568, "body": "def _finish_request(self, future: \"Optional[Future[None]]\") -> None:\n        self._clear_callbacks()\n        if not self.is_client and self._disconnect_on_finish:\n            self.close()\n            return\n        # Turn Nagle's algorithm back on, leaving the stream in its\n        # default state for the next request.\n        self.stream.set_nodelay(False)\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Internal method of HTTP1Connection handling post-request cleanup, managing connection closure, and resetting stream settings to prepare for the next request or terminate the connection appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_parse_headers", "line_number": 579, "body": "def _parse_headers(self, data: bytes) -> Tuple[str, httputil.HTTPHeaders]:\n        # The lstrip removes newlines that some implementations sometimes\n        # insert between messages of a reused connection.  Per RFC 7230,\n        # we SHOULD ignore at least one empty line before the request.\n        # http://tools.ietf.org/html/rfc7230#section-3.5\n        data_str = native_str(data.decode(\"latin1\")).lstrip(\"\\r\\n\")\n        # RFC 7230 section allows for both CRLF and bare LF.\n        eol = data_str.find(\"\\n\")\n        start_line = data_str[:eol].rstrip(\"\\r\")\n        headers = httputil.HTTPHeaders.parse(data_str[eol:])\n        return start_line, headers", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Parses raw HTTP header bytes into a start line and a structured HTTPHeaders object, facilitating compliant HTTP/1 message header extraction for connection handling and request/response processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "_read_body", "line_number": 591, "body": "def _read_body(\n        self,\n        code: int,\n        headers: httputil.HTTPHeaders,\n        delegate: httputil.HTTPMessageDelegate,\n    ) -> Optional[Awaitable[None]]:\n        if \"Content-Length\" in headers:\n            if \"Transfer-Encoding\" in headers:\n                # Response cannot contain both Content-Length and\n                # Transfer-Encoding headers.\n                # http://tools.ietf.org/html/rfc7230#section-3.3.3\n                raise httputil.HTTPInputError(\n                    \"Response with both Transfer-Encoding and Content-Length\"\n                )\n            if \",\" in headers[\"Content-Length\"]:\n                # Proxies sometimes cause Content-Length headers to get\n                # duplicated.  If all the values are identical then we can\n                # use them but if they differ it's an error.\n                pieces = re.split(r\",\\s*\", headers[\"Content-Length\"])\n                if any(i != pieces[0] for i in pieces):\n                    raise httputil.HTTPInputError(\n                        \"Multiple unequal Content-Lengths: %r\"\n                        % headers[\"Content-Length\"]\n                    )\n                headers[\"Content-Length\"] = pieces[0]\n\n            try:\n                content_length = int(headers[\"Content-Length\"])  # type: Optional[int]\n            except ValueError:\n                # Handles non-integer Content-Length value.\n                raise httputil.HTTPInputError(\n                    \"Only integer Content-Length is allowed: %s\"\n                    % headers[\"Content-Length\"]\n                )\n\n            if cast(int, content_length) > self._max_body_size:\n                raise httputil.HTTPInputError(\"Content-Length too long\")\n        else:\n            content_length = None\n\n        if code == 204:\n            # This response code is not allowed to have a non-empty body,\n            # and has an implicit length of zero instead of read-until-close.\n            # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.3\n            if \"Transfer-Encoding\" in headers or content_length not in (None, 0):\n                raise httputil.HTTPInputError(\n                    \"Response with code %d should not have body\" % code\n                )\n            content_length = 0\n\n        if content_length is not None:\n            return self._read_fixed_body(content_length, delegate)\n        if headers.get(\"Transfer-Encoding\", \"\").lower() == \"chunked\":\n            return self._read_chunked_body(delegate)\n        if self.is_client:\n            return self._read_body_until_close(delegate)\n        return None", "is_method": true, "class_name": "HTTP1Connection", "function_description": "Handles reading an HTTP/1 response body by validating and interpreting headers like Content-Length and Transfer-Encoding, then returns the appropriate coroutine to read the body accordingly. It ensures protocol compliance and error handling for edge cases like status 204 or invalid headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "headers_received", "line_number": 714, "body": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        if headers.get(\"Content-Encoding\") == \"gzip\":\n            self._decompressor = GzipDecompressor()\n            # Downstream delegates will only see uncompressed data,\n            # so rename the content-encoding header.\n            # (but note that curl_httpclient doesn't do this).\n            headers.add(\"X-Consumed-Content-Encoding\", headers[\"Content-Encoding\"])\n            del headers[\"Content-Encoding\"]\n        return self._delegate.headers_received(start_line, headers)", "is_method": true, "class_name": "_GzipMessageDelegate", "function_description": "Handles HTTP headers to detect gzip encoding, initializes decompression, and modifies headers to present uncompressed data to downstream handlers. Enables transparent processing of gzipped HTTP responses within the _GzipMessageDelegate."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "finish", "line_number": 749, "body": "def finish(self) -> None:\n        if self._decompressor is not None:\n            tail = self._decompressor.flush()\n            if tail:\n                # The tail should always be empty: decompress returned\n                # all that it can in data_received and the only\n                # purpose of the flush call is to detect errors such\n                # as truncated input. If we did legitimately get a new\n                # chunk at this point we'd need to change the\n                # interface to make finish() a coroutine.\n                raise ValueError(\n                    \"decompressor.flush returned data; possible truncated input\"\n                )\n        return self._delegate.finish()", "is_method": true, "class_name": "_GzipMessageDelegate", "function_description": "Finalizes decompression by checking for errors like truncated input, then delegates finishing operations to the underlying handler. It ensures data integrity after processing a gzip-compressed message."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "on_connection_close", "line_number": 764, "body": "def on_connection_close(self) -> None:\n        return self._delegate.on_connection_close()", "is_method": true, "class_name": "_GzipMessageDelegate", "function_description": "This method delegates the connection close event handling to an internal handler, enabling seamless connection lifecycle management within the _GzipMessageDelegate context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/http1connection.py", "function": "start_serving", "line_number": 804, "body": "def start_serving(self, delegate: httputil.HTTPServerConnectionDelegate) -> None:\n        \"\"\"Starts serving requests on this connection.\n\n        :arg delegate: a `.HTTPServerConnectionDelegate`\n        \"\"\"\n        assert isinstance(delegate, httputil.HTTPServerConnectionDelegate)\n        fut = gen.convert_yielded(self._server_request_loop(delegate))\n        self._serving_future = fut\n        # Register the future on the IOLoop so its errors get logged.\n        self.stream.io_loop.add_future(fut, lambda f: f.result())", "is_method": true, "class_name": "HTTP1ServerConnection", "function_description": "Starts processing incoming HTTP requests on the connection using the provided delegate to handle request events, enabling asynchronous request serving within the HTTP1ServerConnection context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "is_future", "line_number": 52, "body": "def is_future(x: Any) -> bool:\n    return isinstance(x, FUTURES)", "is_method": false, "function_description": "Function checks whether the given input is classified as a future object, enabling other code to distinguish and handle asynchronous or delayed computation entities appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "run_on_executor", "line_number": 74, "body": "def run_on_executor(*args: Any, **kwargs: Any) -> Callable:\n    \"\"\"Decorator to run a synchronous method asynchronously on an executor.\n\n    Returns a future.\n\n    The executor to be used is determined by the ``executor``\n    attributes of ``self``. To use a different attribute name, pass a\n    keyword argument to the decorator::\n\n        @run_on_executor(executor='_thread_pool')\n        def foo(self):\n            pass\n\n    This decorator should not be confused with the similarly-named\n    `.IOLoop.run_in_executor`. In general, using ``run_in_executor``\n    when *calling* a blocking method is recommended instead of using\n    this decorator when *defining* a method. If compatibility with older\n    versions of Tornado is required, consider defining an executor\n    and using ``executor.submit()`` at the call site.\n\n    .. versionchanged:: 4.2\n       Added keyword arguments to use alternative attributes.\n\n    .. versionchanged:: 5.0\n       Always uses the current IOLoop instead of ``self.io_loop``.\n\n    .. versionchanged:: 5.1\n       Returns a `.Future` compatible with ``await`` instead of a\n       `concurrent.futures.Future`.\n\n    .. deprecated:: 5.1\n\n       The ``callback`` argument is deprecated and will be removed in\n       6.0. The decorator itself is discouraged in new code but will\n       not be removed in 6.0.\n\n    .. versionchanged:: 6.0\n\n       The ``callback`` argument was removed.\n    \"\"\"\n    # Fully type-checking decorators is tricky, and this one is\n    # discouraged anyway so it doesn't have all the generic magic.\n    def run_on_executor_decorator(fn: Callable) -> Callable[..., Future]:\n        executor = kwargs.get(\"executor\", \"executor\")\n\n        @functools.wraps(fn)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -> Future:\n            async_future = Future()  # type: Future\n            conc_future = getattr(self, executor).submit(fn, self, *args, **kwargs)\n            chain_future(conc_future, async_future)\n            return async_future\n\n        return wrapper\n\n    if args and kwargs:\n        raise ValueError(\"cannot combine positional and keyword args\")\n    if len(args) == 1:\n        return run_on_executor_decorator(args[0])\n    elif len(args) != 0:\n        raise ValueError(\"expected 1 argument, got %d\", len(args))\n    return run_on_executor_decorator", "is_method": false, "function_description": "Decorator that converts a synchronous method into an asynchronous one by running it on a specified executor, returning a future for asynchronous execution and integration with async workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "chain_future", "line_number": 140, "body": "def chain_future(a: \"Future[_T]\", b: \"Future[_T]\") -> None:\n    \"\"\"Chain two futures together so that when one completes, so does the other.\n\n    The result (success or failure) of ``a`` will be copied to ``b``, unless\n    ``b`` has already been completed or cancelled by the time ``a`` finishes.\n\n    .. versionchanged:: 5.0\n\n       Now accepts both Tornado/asyncio `Future` objects and\n       `concurrent.futures.Future`.\n\n    \"\"\"\n\n    def copy(future: \"Future[_T]\") -> None:\n        assert future is a\n        if b.done():\n            return\n        if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n            future_set_exc_info(b, a.exc_info())  # type: ignore\n        elif a.exception() is not None:\n            b.set_exception(a.exception())\n        else:\n            b.set_result(a.result())\n\n    if isinstance(a, Future):\n        future_add_done_callback(a, copy)\n    else:\n        # concurrent.futures.Future\n        from tornado.ioloop import IOLoop\n\n        IOLoop.current().add_future(a, copy)", "is_method": false, "function_description": "Utility function that links two Future objects so that completion (result or exception) of the first automatically completes the second, enabling coordinated asynchronous task management across different Future implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "future_set_result_unless_cancelled", "line_number": 173, "body": "def future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)", "is_method": false, "function_description": "Utility function that sets a given value as the result of a Future only if it has not been cancelled, preventing errors from setting results on cancelled asynchronous tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "future_set_exception_unless_cancelled", "line_number": 187, "body": "def future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.\n\n    If the Future is already canceled, logs the exception instead. If\n    this logging is not desired, the caller should explicitly check\n    the state of the Future and call ``Future.set_exception`` instead of\n    this wrapper.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_exception()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 6.0\n\n    \"\"\"\n    if not future.cancelled():\n        future.set_exception(exc)\n    else:\n        app_log.error(\"Exception after Future was cancelled\", exc_info=exc)", "is_method": false, "function_description": "Utility function to safely set an exception on a Future unless it is cancelled, preventing errors and optionally logging exceptions for cancelled Futures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "future_set_exc_info", "line_number": 209, "body": "def future_set_exc_info(\n    future: \"Union[futures.Future[_T], Future[_T]]\",\n    exc_info: Tuple[\n        Optional[type], Optional[BaseException], Optional[types.TracebackType]\n    ],\n) -> None:\n    \"\"\"Set the given ``exc_info`` as the `Future`'s exception.\n\n    Understands both `asyncio.Future` and the extensions in older\n    versions of Tornado to enable better tracebacks on Python 2.\n\n    .. versionadded:: 5.0\n\n    .. versionchanged:: 6.0\n\n       If the future is already cancelled, this function is a no-op.\n       (previously ``asyncio.InvalidStateError`` would be raised)\n\n    \"\"\"\n    if exc_info[1] is None:\n        raise Exception(\"future_set_exc_info called with no exception\")\n    future_set_exception_unless_cancelled(future, exc_info[1])", "is_method": false, "function_description": "Sets an exception on a Future object using the provided exception info, supporting enhanced traceback handling for different Future implementations while safely ignoring cancelled futures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "future_add_done_callback", "line_number": 247, "body": "def future_add_done_callback(  # noqa: F811\n    future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n) -> None:\n    \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n\n    ``callback`` is invoked with one argument, the ``future``.\n\n    If ``future`` is already done, ``callback`` is invoked immediately.\n    This may differ from the behavior of ``Future.add_done_callback``,\n    which makes no such guarantee.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if future.done():\n        callback(future)\n    else:\n        future.add_done_callback(callback)", "is_method": false, "function_description": "Function that ensures a callback is invoked immediately if a future is already complete, otherwise it schedules the callback to run upon the future's completion. This guarantees prompt callback execution for asynchronous task handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "submit", "line_number": 57, "body": "def submit(\n        self, fn: Callable[..., _T], *args: Any, **kwargs: Any\n    ) -> \"futures.Future[_T]\":\n        future = futures.Future()  # type: futures.Future[_T]\n        try:\n            future_set_result_unless_cancelled(future, fn(*args, **kwargs))\n        except Exception:\n            future_set_exc_info(future, sys.exc_info())\n        return future", "is_method": true, "class_name": "DummyExecutor", "function_description": "Provides synchronous execution of a callable wrapped in a Future, immediately setting its result or exception without running asynchronously. Useful for uniform interfaces expecting Future objects without actual concurrency."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/concurrent.py", "function": "run_on_executor_decorator", "line_number": 116, "body": "def run_on_executor_decorator(fn: Callable) -> Callable[..., Future]:\n        executor = kwargs.get(\"executor\", \"executor\")\n\n        @functools.wraps(fn)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -> Future:\n            async_future = Future()  # type: Future\n            conc_future = getattr(self, executor).submit(fn, self, *args, **kwargs)\n            chain_future(conc_future, async_future)\n            return async_future\n\n        return wrapper", "is_method": false, "function_description": "Provides a decorator that runs the decorated method asynchronously on a specified executor, returning a Future for concurrent execution and integration with async workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "import_object", "line_number": 131, "body": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)\n\n    parts = name.split(\".\")\n    obj = __import__(\".\".join(parts[:-1]), fromlist=[parts[-1]])\n    try:\n        return getattr(obj, parts[-1])\n    except AttributeError:\n        raise ImportError(\"No module named %s\" % parts[-1])", "is_method": false, "function_description": "Utility function that dynamically imports a module or an attribute by its fully qualified name, enabling flexible access to Python objects based on string names during runtime."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "exec_in", "line_number": 160, "body": "def exec_in(\n    code: Any, glob: Dict[str, Any], loc: Optional[Optional[Mapping[str, Any]]] = None\n) -> None:\n    if isinstance(code, str):\n        # exec(string) inherits the caller's future imports; compile\n        # the string first to prevent that.\n        code = compile(code, \"<string>\", \"exec\", dont_inherit=True)\n    exec(code, glob, loc)", "is_method": false, "function_description": "Utility function that executes given code within specified global and local namespaces, ensuring string code is compiled to avoid inheriting caller's future imports. Useful for controlled dynamic code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "raise_exc_info", "line_number": 170, "body": "def raise_exc_info(\n    exc_info,  # type: Tuple[Optional[type], Optional[BaseException], Optional[TracebackType]]\n):\n    # type: (...) -> typing.NoReturn\n    #\n    # This function's type annotation must use comments instead of\n    # real annotations because typing.NoReturn does not exist in\n    # python 3.5's typing module. The formatting is funky because this\n    # is apparently what flake8 wants.\n    try:\n        if exc_info[1] is not None:\n            raise exc_info[1].with_traceback(exc_info[2])\n        else:\n            raise TypeError(\"raise_exc_info called with no exception\")\n    finally:\n        # Clear the traceback reference from our stack frame to\n        # minimize circular references that slow down GC.\n        exc_info = (None, None, None)", "is_method": false, "function_description": "Function that re-raises an exception from an exc_info tuple, preserving its original traceback while preventing reference cycles to aid garbage collection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "errno_from_exception", "line_number": 190, "body": "def errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n\n    if hasattr(e, \"errno\"):\n        return e.errno  # type: ignore\n    elif e.args:\n        return e.args[0]\n    else:\n        return None", "is_method": false, "function_description": "Function that extracts the errno value from an exception object in a safe and consistent way, abstracting different exception structures for easier error code retrieval. It supports error handling by providing a unified method to obtain error numbers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_re_unescape_replacement", "line_number": 211, "body": "def _re_unescape_replacement(match: Match[str]) -> str:\n    group = match.group(1)\n    if group[0] in _alphanum:\n        raise ValueError(\"cannot unescape '\\\\\\\\%s'\" % group[0])\n    return group", "is_method": false, "function_description": "Internal helper function that processes regex replacement strings by validating and unescaping certain escape sequences, raising errors for invalid alphanumeric escapes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "re_unescape", "line_number": 221, "body": "def re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n    return _re_unescape_pattern.sub(_re_unescape_replacement, s)", "is_method": false, "function_description": "Function that reverses the escaping applied by `re.escape`, restoring the original string from an escaped regular expression pattern. It is useful for processing or displaying regex patterns in their unescaped form."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "timedelta_to_seconds", "line_number": 435, "body": "def timedelta_to_seconds(td):\n    # type: (datetime.timedelta) -> float\n    \"\"\"Equivalent to ``td.total_seconds()`` (introduced in Python 2.7).\"\"\"\n    return td.total_seconds()", "is_method": false, "function_description": "Utility function converting a timedelta duration to its total seconds as a float, providing compatibility with Python versions earlier than 2.7."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_websocket_mask_python", "line_number": 441, "body": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n    mask_arr = array.array(\"B\", mask)\n    unmasked_arr = array.array(\"B\", data)\n    for i in range(len(data)):\n        unmasked_arr[i] = unmasked_arr[i] ^ mask_arr[i % 4]\n    return unmasked_arr.tobytes()", "is_method": false, "function_description": "Function providing a pure-Python implementation of the WebSocket data masking process, applying a 4-byte mask to arbitrary-length byte data as defined in RFC 6455. It enables compliant encoding or decoding of WebSocket frames during communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "doctests", "line_number": 470, "body": "def doctests():\n    # type: () -> unittest.TestSuite\n    import doctest\n\n    return doctest.DocTestSuite()", "is_method": false, "function_description": "Returns a test suite containing all doctests found in the current module, facilitating automatic testing based on embedded documentation examples."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "__getattr__", "line_number": 80, "body": "def __getattr__(self, name: str) -> Any:\n        try:\n            return self[name]\n        except KeyError:\n            raise AttributeError(name)", "is_method": true, "class_name": "ObjectDict", "function_description": "Provides attribute-style access to dictionary items in ObjectDict, allowing retrieval by key as if accessing an object\u2019s attribute. Raises an AttributeError if the key does not exist."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "__setattr__", "line_number": 86, "body": "def __setattr__(self, name: str, value: Any) -> None:\n        self[name] = value", "is_method": true, "class_name": "ObjectDict", "function_description": "Overrides attribute assignment to store values as dictionary entries, allowing attribute-style access for setting items in ObjectDict instances."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "decompress", "line_number": 103, "body": "def decompress(self, value: bytes, max_length: int = 0) -> bytes:\n        \"\"\"Decompress a chunk, returning newly-available data.\n\n        Some data may be buffered for later processing; `flush` must\n        be called when there is no more input data to ensure that\n        all data was processed.\n\n        If ``max_length`` is given, some input data may be left over\n        in ``unconsumed_tail``; you must retrieve this value and pass\n        it back to a future call to `decompress` if it is not empty.\n        \"\"\"\n        return self.decompressobj.decompress(value, max_length)", "is_method": true, "class_name": "GzipDecompressor", "function_description": "Utility method of the GzipDecompressor class that decompresses byte data chunks, optionally limiting output size, while managing buffered and leftover data for incremental decompression workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "unconsumed_tail", "line_number": 117, "body": "def unconsumed_tail(self) -> bytes:\n        \"\"\"Returns the unconsumed portion left over\n        \"\"\"\n        return self.decompressobj.unconsumed_tail", "is_method": true, "class_name": "GzipDecompressor", "function_description": "Provides access to any remaining compressed data not yet processed during decompression, allowing other functions to handle or reprocess leftover input as needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "flush", "line_number": 122, "body": "def flush(self) -> bytes:\n        \"\"\"Return any remaining buffered data not yet returned by decompress.\n\n        Also checks for errors such as truncated input.\n        No other methods may be called on this object after `flush`.\n        \"\"\"\n        return self.decompressobj.flush()", "is_method": true, "class_name": "GzipDecompressor", "function_description": "Provides remaining decompressed data buffered internally and verifies input completeness; finalizes the decompression stream disallowing further decompression calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "__new__", "line_number": 271, "body": "def __new__(cls, *args: Any, **kwargs: Any) -> Any:\n        base = cls.configurable_base()\n        init_kwargs = {}  # type: Dict[str, Any]\n        if cls is base:\n            impl = cls.configured_class()\n            if base.__impl_kwargs:\n                init_kwargs.update(base.__impl_kwargs)\n        else:\n            impl = cls\n        init_kwargs.update(kwargs)\n        if impl.configurable_base() is not base:\n            # The impl class is itself configurable, so recurse.\n            return impl(*args, **init_kwargs)\n        instance = super(Configurable, cls).__new__(impl)\n        # initialize vs __init__ chosen for compatibility with AsyncHTTPClient\n        # singleton magic.  If we get rid of that we can switch to __init__\n        # here too.\n        instance.initialize(*args, **init_kwargs)\n        return instance", "is_method": true, "class_name": "Configurable", "function_description": "Core method of the Configurable class that creates and initializes an instance of the appropriate subclass, supporting recursive configuration and dynamic class selection based on class-level settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "configurable_base", "line_number": 292, "body": "def configurable_base(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the base class of a configurable hierarchy.\n\n        This will normally return the class in which it is defined.\n        (which is *not* necessarily the same as the ``cls`` classmethod\n        parameter).\n\n        \"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "Configurable", "function_description": "Returns the base class of a configurable class hierarchy, typically the class where this method is defined. Useful for identifying the root configuration class in inheritance structures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "configurable_default", "line_number": 304, "body": "def configurable_default(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the implementation class to be used if none is configured.\"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "Configurable", "function_description": "Returns the default implementation class for use when no specific configuration is provided. It defines a required interface for subclasses to specify their fallback class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "configure", "line_number": 322, "body": "def configure(cls, impl, **kwargs):\n        # type: (Union[None, str, Type[Configurable]], Any) -> None\n        \"\"\"Sets the class to use when the base class is instantiated.\n\n        Keyword arguments will be saved and added to the arguments passed\n        to the constructor.  This can be used to set global defaults for\n        some parameters.\n        \"\"\"\n        base = cls.configurable_base()\n        if isinstance(impl, str):\n            impl = typing.cast(Type[Configurable], import_object(impl))\n        if impl is not None and not issubclass(impl, cls):\n            raise ValueError(\"Invalid subclass of %s\" % cls)\n        base.__impl_class = impl\n        base.__impl_kwargs = kwargs", "is_method": true, "class_name": "Configurable", "function_description": "Provides a way to globally specify and customize which subclass the Configurable base class should instantiate, along with default keyword arguments for its constructor. This enables flexible configuration and dynamic subclass selection system-wide."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "configured_class", "line_number": 339, "body": "def configured_class(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the currently configured class.\"\"\"\n        base = cls.configurable_base()\n        # Manually mangle the private name to see whether this base\n        # has been configured (and not another base higher in the\n        # hierarchy).\n        if base.__dict__.get(\"_Configurable__impl_class\") is None:\n            base.__impl_class = cls.configurable_default()\n        if base.__impl_class is not None:\n            return base.__impl_class\n        else:\n            # Should be impossible, but mypy wants an explicit check.\n            raise ValueError(\"configured class not found\")", "is_method": true, "class_name": "Configurable", "function_description": "Utility method in Configurable that returns the currently active configured subclass, ensuring the correct implementation class is determined for the configuration hierarchy."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_save_configuration", "line_number": 355, "body": "def _save_configuration(cls):\n        # type: () -> Tuple[Optional[Type[Configurable]], Dict[str, Any]]\n        base = cls.configurable_base()\n        return (base.__impl_class, base.__impl_kwargs)", "is_method": true, "class_name": "Configurable", "function_description": "Returns the implementation class and its configuration parameters from the base configurable class, enabling access to stored configuration details within the Configurable hierarchy."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_restore_configuration", "line_number": 361, "body": "def _restore_configuration(cls, saved):\n        # type: (Tuple[Optional[Type[Configurable]], Dict[str, Any]]) -> None\n        base = cls.configurable_base()\n        base.__impl_class = saved[0]\n        base.__impl_kwargs = saved[1]", "is_method": true, "class_name": "Configurable", "function_description": "Sets the base configurable class and its parameters from a saved state to restore a previous configuration. This supports reinitializing configuration settings within the Configurable class hierarchy."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_getargnames", "line_number": 384, "body": "def _getargnames(self, func: Callable) -> List[str]:\n        try:\n            return getfullargspec(func).args\n        except TypeError:\n            if hasattr(func, \"func_code\"):\n                # Cython-generated code has all the attributes needed\n                # by inspect.getfullargspec, but the inspect module only\n                # works with ordinary functions. Inline the portion of\n                # getfullargspec that we need here. Note that for static\n                # functions the @cython.binding(True) decorator must\n                # be used (for methods it works out of the box).\n                code = func.func_code  # type: ignore\n                return code.co_varnames[: code.co_argcount]\n            raise", "is_method": true, "class_name": "ArgReplacer", "function_description": "Utility method in ArgReplacer that extracts the argument names of a given function, supporting both standard and Cython-generated functions for flexible introspection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "get_old_value", "line_number": 399, "body": "def get_old_value(\n        self, args: Sequence[Any], kwargs: Dict[str, Any], default: Any = None\n    ) -> Any:\n        \"\"\"Returns the old value of the named argument without replacing it.\n\n        Returns ``default`` if the argument is not present.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            return args[self.arg_pos]\n        else:\n            return kwargs.get(self.name, default)", "is_method": true, "class_name": "ArgReplacer", "function_description": "Utility method of ArgReplacer that retrieves the current value of a specific argument by position or name without modifying it, returning a default if the argument is absent."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "replace", "line_number": 411, "body": "def replace(\n        self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n    ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n        \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n\n        Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n        ``kwargs`` objects may not be the same as the input objects, or\n        the input objects may be mutated.\n\n        If the named argument was not found, ``new_value`` will be added\n        to ``kwargs`` and None will be returned as ``old_value``.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            # The arg to replace is passed positionally\n            old_value = args[self.arg_pos]\n            args = list(args)  # *args is normally a tuple\n            args[self.arg_pos] = new_value\n        else:\n            # The arg to replace is either omitted or passed by keyword.\n            old_value = kwargs.get(self.name)\n            kwargs[self.name] = new_value\n        return old_value, args, kwargs", "is_method": true, "class_name": "ArgReplacer", "function_description": "Utility method of the ArgReplacer class that updates a specified argument in given positional and keyword argument collections with a new value, returning the original value alongside the updated argument containers. It handles both positional and keyword cases transparently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/util.py", "function": "_get_emulated_is_finalizing", "line_number": 53, "body": "def _get_emulated_is_finalizing() -> Callable[[], bool]:\n        L = []  # type: List[None]\n        atexit.register(lambda: L.append(None))\n\n        def is_finalizing() -> bool:\n            # Not referencing any globals here\n            return L != []\n\n        return is_finalizing", "is_method": false, "function_description": "Utility function that provides a callable to detect if the program is in its shutdown phase by checking if the registered exit handler has been triggered. This enables safe handling of operations during interpreter finalization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "main", "line_number": 757, "body": "def main() -> None:\n    from tornado.options import define, options, parse_command_line\n\n    define(\"print_headers\", type=bool, default=False)\n    define(\"print_body\", type=bool, default=True)\n    define(\"follow_redirects\", type=bool, default=True)\n    define(\"validate_cert\", type=bool, default=True)\n    define(\"proxy_host\", type=str)\n    define(\"proxy_port\", type=int)\n    args = parse_command_line()\n    client = HTTPClient()\n    for arg in args:\n        try:\n            response = client.fetch(\n                arg,\n                follow_redirects=options.follow_redirects,\n                validate_cert=options.validate_cert,\n                proxy_host=options.proxy_host,\n                proxy_port=options.proxy_port,\n            )\n        except HTTPError as e:\n            if e.response is not None:\n                response = e.response\n            else:\n                raise\n        if options.print_headers:\n            print(response.headers)\n        if options.print_body:\n            print(native_str(response.body))\n    client.close()", "is_method": false, "function_description": "This function processes command-line URLs and fetches their HTTP responses with configurable options for redirects, certificate validation, and proxy settings. It supports printing response headers and bodies, enabling flexible HTTP request handling from the command line."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "__del__", "line_number": 112, "body": "def __del__(self) -> None:\n        self.close()", "is_method": true, "class_name": "HTTPClient", "function_description": "Destructor method of the HTTPClient class that ensures the connection is properly closed when the instance is deleted, helping to manage resources and prevent leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "close", "line_number": 115, "body": "def close(self) -> None:\n        \"\"\"Closes the HTTPClient, freeing any resources used.\"\"\"\n        if not self._closed:\n            self._async_client.close()\n            self._io_loop.close()\n            self._closed = True", "is_method": true, "class_name": "HTTPClient", "function_description": "Utility method of HTTPClient that closes the client and releases associated resources to prevent resource leaks and finalize connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "fetch", "line_number": 122, "body": "def fetch(\n        self, request: Union[\"HTTPRequest\", str], **kwargs: Any\n    ) -> \"HTTPResponse\":\n        \"\"\"Executes a request, returning an `HTTPResponse`.\n\n        The request may be either a string URL or an `HTTPRequest` object.\n        If it is a string, we construct an `HTTPRequest` using any additional\n        kwargs: ``HTTPRequest(request, **kwargs)``\n\n        If an error occurs during the fetch, we raise an `HTTPError` unless\n        the ``raise_error`` keyword argument is set to False.\n        \"\"\"\n        response = self._io_loop.run_sync(\n            functools.partial(self._async_client.fetch, request, **kwargs)\n        )\n        return response", "is_method": true, "class_name": "HTTPClient", "function_description": "Core method of HTTPClient that synchronously executes an HTTP request from a URL string or request object, returning the response. It optionally raises errors based on caller preference."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "configurable_base", "line_number": 182, "body": "def configurable_base(cls) -> Type[Configurable]:\n        return AsyncHTTPClient", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Returns the AsyncHTTPClient class as the configurable base type. This method provides a standard way to identify the base configuration class for customization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "configurable_default", "line_number": 186, "body": "def configurable_default(cls) -> Type[Configurable]:\n        from tornado.simple_httpclient import SimpleAsyncHTTPClient\n\n        return SimpleAsyncHTTPClient", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Returns the default configurable HTTP client class used for asynchronous HTTP requests, enabling customization of the underlying HTTP client implementation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "_async_clients", "line_number": 192, "body": "def _async_clients(cls) -> Dict[IOLoop, \"AsyncHTTPClient\"]:\n        attr_name = \"_async_client_dict_\" + cls.__name__\n        if not hasattr(cls, attr_name):\n            setattr(cls, attr_name, weakref.WeakKeyDictionary())\n        return getattr(cls, attr_name)", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Internal utility method of AsyncHTTPClient that manages and returns a class-level dictionary mapping IOLoop instances to async HTTP client instances, ensuring unique clients per event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "__new__", "line_number": 198, "body": "def __new__(cls, force_instance: bool = False, **kwargs: Any) -> \"AsyncHTTPClient\":\n        io_loop = IOLoop.current()\n        if force_instance:\n            instance_cache = None\n        else:\n            instance_cache = cls._async_clients()\n        if instance_cache is not None and io_loop in instance_cache:\n            return instance_cache[io_loop]\n        instance = super(AsyncHTTPClient, cls).__new__(cls, **kwargs)  # type: ignore\n        # Make sure the instance knows which cache to remove itself from.\n        # It can't simply call _async_clients() because we may be in\n        # __new__(AsyncHTTPClient) but instance.__class__ may be\n        # SimpleAsyncHTTPClient.\n        instance._instance_cache = instance_cache\n        if instance_cache is not None:\n            instance_cache[instance.io_loop] = instance\n        return instance", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Overrides instance creation to enforce a singleton AsyncHTTPClient per IOLoop unless forced, ensuring efficient reuse of HTTP client instances tied to asynchronous event loops. This supports managing HTTP clients in async applications with optimal resource sharing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "initialize", "line_number": 216, "body": "def initialize(self, defaults: Optional[Dict[str, Any]] = None) -> None:\n        self.io_loop = IOLoop.current()\n        self.defaults = dict(HTTPRequest._DEFAULTS)\n        if defaults is not None:\n            self.defaults.update(defaults)\n        self._closed = False", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Initializes the AsyncHTTPClient by setting up its event loop and default request parameters, allowing configuration of HTTP request settings before use."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "close", "line_number": 223, "body": "def close(self) -> None:\n        \"\"\"Destroys this HTTP client, freeing any file descriptors used.\n\n        This method is **not needed in normal use** due to the way\n        that `AsyncHTTPClient` objects are transparently reused.\n        ``close()`` is generally only necessary when either the\n        `.IOLoop` is also being closed, or the ``force_instance=True``\n        argument was used when creating the `AsyncHTTPClient`.\n\n        No other methods may be called on the `AsyncHTTPClient` after\n        ``close()``.\n\n        \"\"\"\n        if self._closed:\n            return\n        self._closed = True\n        if self._instance_cache is not None:\n            cached_val = self._instance_cache.pop(self.io_loop, None)\n            # If there's an object other than self in the instance\n            # cache for our IOLoop, something has gotten mixed up. A\n            # value of None appears to be possible when this is called\n            # from a destructor (HTTPClient.__del__) as the weakref\n            # gets cleared before the destructor runs.\n            if cached_val is not None and cached_val is not self:\n                raise RuntimeError(\"inconsistent AsyncHTTPClient cache\")", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Method of AsyncHTTPClient that releases resources by closing the client instance, preventing further use and ensuring proper cleanup, primarily needed when the associated IOLoop or forced instances require manual shutdown."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "fetch", "line_number": 249, "body": "def fetch(\n        self,\n        request: Union[str, \"HTTPRequest\"],\n        raise_error: bool = True,\n        **kwargs: Any\n    ) -> \"Future[HTTPResponse]\":\n        \"\"\"Executes a request, asynchronously returning an `HTTPResponse`.\n\n        The request may be either a string URL or an `HTTPRequest` object.\n        If it is a string, we construct an `HTTPRequest` using any additional\n        kwargs: ``HTTPRequest(request, **kwargs)``\n\n        This method returns a `.Future` whose result is an\n        `HTTPResponse`. By default, the ``Future`` will raise an\n        `HTTPError` if the request returned a non-200 response code\n        (other errors may also be raised if the server could not be\n        contacted). Instead, if ``raise_error`` is set to False, the\n        response will always be returned regardless of the response\n        code.\n\n        If a ``callback`` is given, it will be invoked with the `HTTPResponse`.\n        In the callback interface, `HTTPError` is not automatically raised.\n        Instead, you must check the response's ``error`` attribute or\n        call its `~HTTPResponse.rethrow` method.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n           The ``raise_error=False`` argument only affects the\n           `HTTPError` raised when a non-200 response code is used,\n           instead of suppressing all errors.\n        \"\"\"\n        if self._closed:\n            raise RuntimeError(\"fetch() called on closed AsyncHTTPClient\")\n        if not isinstance(request, HTTPRequest):\n            request = HTTPRequest(url=request, **kwargs)\n        else:\n            if kwargs:\n                raise ValueError(\n                    \"kwargs can't be used if request is an HTTPRequest object\"\n                )\n        # We may modify this (to add Host, Accept-Encoding, etc),\n        # so make sure we don't modify the caller's object.  This is also\n        # where normal dicts get converted to HTTPHeaders objects.\n        request.headers = httputil.HTTPHeaders(request.headers)\n        request_proxy = _RequestProxy(request, self.defaults)\n        future = Future()  # type: Future[HTTPResponse]\n\n        def handle_response(response: \"HTTPResponse\") -> None:\n            if response.error:\n                if raise_error or not response._error_is_response_code:\n                    future_set_exception_unless_cancelled(future, response.error)\n                    return\n            future_set_result_unless_cancelled(future, response)\n\n        self.fetch_impl(cast(HTTPRequest, request_proxy), handle_response)\n        return future", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Provides an asynchronous HTTP request execution, returning a future that resolves to an HTTPResponse. It supports flexible input, error handling control, and enables non-blocking network operations in asynchronous applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "configure", "line_number": 315, "body": "def configure(\n        cls, impl: \"Union[None, str, Type[Configurable]]\", **kwargs: Any\n    ) -> None:\n        \"\"\"Configures the `AsyncHTTPClient` subclass to use.\n\n        ``AsyncHTTPClient()`` actually creates an instance of a subclass.\n        This method may be called with either a class object or the\n        fully-qualified name of such a class (or ``None`` to use the default,\n        ``SimpleAsyncHTTPClient``)\n\n        If additional keyword arguments are given, they will be passed\n        to the constructor of each subclass instance created.  The\n        keyword argument ``max_clients`` determines the maximum number\n        of simultaneous `~AsyncHTTPClient.fetch()` operations that can\n        execute in parallel on each `.IOLoop`.  Additional arguments\n        may be supported depending on the implementation class in use.\n\n        Example::\n\n           AsyncHTTPClient.configure(\"tornado.curl_httpclient.CurlAsyncHTTPClient\")\n        \"\"\"\n        super(AsyncHTTPClient, cls).configure(impl, **kwargs)", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Class method for AsyncHTTPClient that sets which subclass to instantiate for HTTP operations, allowing customization of the client implementation and its initialization parameters like maximum parallel fetches."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "headers", "line_number": 552, "body": "def headers(self) -> httputil.HTTPHeaders:\n        # TODO: headers may actually be a plain dict until fairly late in\n        # the process (AsyncHTTPClient.fetch), but practically speaking,\n        # whenever the property is used they're already HTTPHeaders.\n        return self._headers", "is_method": true, "class_name": "HTTPRequest", "function_description": "Returns the HTTP headers associated with the request, providing access to metadata like content type and authentication details for further processing or inspection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "headers", "line_number": 559, "body": "def headers(self, value: Union[Dict[str, str], httputil.HTTPHeaders]) -> None:\n        if value is None:\n            self._headers = httputil.HTTPHeaders()\n        else:\n            self._headers = value", "is_method": true, "class_name": "HTTPRequest", "function_description": "Setter method in the HTTPRequest class that assigns or resets the HTTP headers for the request, accepting either a dictionary or HTTPHeaders object as input."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "body", "line_number": 566, "body": "def body(self) -> bytes:\n        return self._body", "is_method": true, "class_name": "HTTPRequest", "function_description": "Returns the raw byte content of the HTTP request body. This method provides direct access to the request payload for further processing or parsing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "body", "line_number": 570, "body": "def body(self, value: Union[bytes, str]) -> None:\n        self._body = utf8(value)", "is_method": true, "class_name": "HTTPRequest", "function_description": "Sets the HTTP request body content by encoding the given input as UTF-8 bytes. It enables consistent body data assignment for HTTP requests regardless of input type."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "body", "line_number": 672, "body": "def body(self) -> bytes:\n        if self.buffer is None:\n            return b\"\"\n        elif self._body is None:\n            self._body = self.buffer.getvalue()\n\n        return self._body", "is_method": true, "class_name": "HTTPResponse", "function_description": "Returns the complete response body as bytes, caching it for repeated access. It enables efficient retrieval of HTTP response content for processing or inspection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "rethrow", "line_number": 680, "body": "def rethrow(self) -> None:\n        \"\"\"If there was an error on the request, raise an `HTTPError`.\"\"\"\n        if self.error:\n            raise self.error", "is_method": true, "class_name": "HTTPResponse", "function_description": "This method in the HTTPResponse class raises an HTTPError if the HTTP request resulted in an error. It provides a way to propagate request errors for handling by calling code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "__repr__", "line_number": 685, "body": "def __repr__(self) -> str:\n        args = \",\".join(\"%s=%r\" % i for i in sorted(self.__dict__.items()))\n        return \"%s(%s)\" % (self.__class__.__name__, args)", "is_method": true, "class_name": "HTTPResponse", "function_description": "Provides a string representation of the HTTPResponse instance showing its class name and sorted attributes, useful for debugging or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "__str__", "line_number": 722, "body": "def __str__(self) -> str:\n        return \"HTTP %d: %s\" % (self.code, self.message)", "is_method": true, "class_name": "HTTPClientError", "function_description": "Provides a readable string representation of the HTTPClientError, summarizing the HTTP status code and message for clearer error reporting and logging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "__getattr__", "line_number": 747, "body": "def __getattr__(self, name: str) -> Any:\n        request_attr = getattr(self.request, name)\n        if request_attr is not None:\n            return request_attr\n        elif self.defaults is not None:\n            return self.defaults.get(name, None)\n        else:\n            return None", "is_method": true, "class_name": "_RequestProxy", "function_description": "Utility method in _RequestProxy that accesses attributes from the wrapped request object or falls back to default values, providing a seamless attribute retrieval interface with prioritized sources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/httpclient.py", "function": "handle_response", "line_number": 299, "body": "def handle_response(response: \"HTTPResponse\") -> None:\n            if response.error:\n                if raise_error or not response._error_is_response_code:\n                    future_set_exception_unless_cancelled(future, response.error)\n                    return\n            future_set_result_unless_cancelled(future, response)", "is_method": true, "class_name": "AsyncHTTPClient", "function_description": "Handles an HTTP response by setting the result or an error on an associated future, facilitating asynchronous response processing within the AsyncHTTPClient. It manages error propagation and successful response delivery for awaiting tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "__str__", "line_number": 56, "body": "def __str__(self) -> str:\n        return self.message or \"Timeout\"", "is_method": true, "class_name": "HTTPTimeoutError", "function_description": "Overrides the string representation to return the error message or a default \"Timeout\" text, aiding clear communication of HTTP timeout errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "__str__", "line_number": 75, "body": "def __str__(self) -> str:\n        return self.message or \"Stream closed\"", "is_method": true, "class_name": "HTTPStreamClosedError", "function_description": "Returns the error message for an HTTP stream closure, defaulting to \"Stream closed\" if no specific message is provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "initialize", "line_number": 89, "body": "def initialize(  # type: ignore\n        self,\n        max_clients: int = 10,\n        hostname_mapping: Optional[Dict[str, str]] = None,\n        max_buffer_size: int = 104857600,\n        resolver: Optional[Resolver] = None,\n        defaults: Optional[Dict[str, Any]] = None,\n        max_header_size: Optional[int] = None,\n        max_body_size: Optional[int] = None,\n    ) -> None:\n        \"\"\"Creates a AsyncHTTPClient.\n\n        Only a single AsyncHTTPClient instance exists per IOLoop\n        in order to provide limitations on the number of pending connections.\n        ``force_instance=True`` may be used to suppress this behavior.\n\n        Note that because of this implicit reuse, unless ``force_instance``\n        is used, only the first call to the constructor actually uses\n        its arguments. It is recommended to use the ``configure`` method\n        instead of the constructor to ensure that arguments take effect.\n\n        ``max_clients`` is the number of concurrent requests that can be\n        in progress; when this limit is reached additional requests will be\n        queued. Note that time spent waiting in this queue still counts\n        against the ``request_timeout``.\n\n        ``hostname_mapping`` is a dictionary mapping hostnames to IP addresses.\n        It can be used to make local DNS changes when modifying system-wide\n        settings like ``/etc/hosts`` is not possible or desirable (e.g. in\n        unittests).\n\n        ``max_buffer_size`` (default 100MB) is the number of bytes\n        that can be read into memory at once. ``max_body_size``\n        (defaults to ``max_buffer_size``) is the largest response body\n        that the client will accept.  Without a\n        ``streaming_callback``, the smaller of these two limits\n        applies; with a ``streaming_callback`` only ``max_body_size``\n        does.\n\n        .. versionchanged:: 4.2\n           Added the ``max_body_size`` argument.\n        \"\"\"\n        super().initialize(defaults=defaults)\n        self.max_clients = max_clients\n        self.queue = (\n            collections.deque()\n        )  # type: Deque[Tuple[object, HTTPRequest, Callable[[HTTPResponse], None]]]\n        self.active = (\n            {}\n        )  # type: Dict[object, Tuple[HTTPRequest, Callable[[HTTPResponse], None]]]\n        self.waiting = (\n            {}\n        )  # type: Dict[object, Tuple[HTTPRequest, Callable[[HTTPResponse], None], object]]\n        self.max_buffer_size = max_buffer_size\n        self.max_header_size = max_header_size\n        self.max_body_size = max_body_size\n        # TCPClient could create a Resolver for us, but we have to do it\n        # ourselves to support hostname_mapping.\n        if resolver:\n            self.resolver = resolver\n            self.own_resolver = False\n        else:\n            self.resolver = Resolver()\n            self.own_resolver = True\n        if hostname_mapping is not None:\n            self.resolver = OverrideResolver(\n                resolver=self.resolver, mapping=hostname_mapping\n            )\n        self.tcp_client = TCPClient(resolver=self.resolver)", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Initialization method of SimpleAsyncHTTPClient that sets up connection limits, hostname resolution, and buffer sizes to manage concurrent asynchronous HTTP requests efficiently with optional DNS overrides and resource constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "close", "line_number": 159, "body": "def close(self) -> None:\n        super().close()\n        if self.own_resolver:\n            self.resolver.close()\n        self.tcp_client.close()", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Method of SimpleAsyncHTTPClient that closes network connections and associated resources, ensuring proper cleanup of the HTTP client's internal components."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "fetch_impl", "line_number": 165, "body": "def fetch_impl(\n        self, request: HTTPRequest, callback: Callable[[HTTPResponse], None]\n    ) -> None:\n        key = object()\n        self.queue.append((key, request, callback))\n        assert request.connect_timeout is not None\n        assert request.request_timeout is not None\n        timeout_handle = None\n        if len(self.active) >= self.max_clients:\n            timeout = (\n                min(request.connect_timeout, request.request_timeout)\n                or request.connect_timeout\n                or request.request_timeout\n            )  # min but skip zero\n            if timeout:\n                timeout_handle = self.io_loop.add_timeout(\n                    self.io_loop.time() + timeout,\n                    functools.partial(self._on_timeout, key, \"in request queue\"),\n                )\n        self.waiting[key] = (request, callback, timeout_handle)\n        self._process_queue()\n        if self.queue:\n            gen_log.debug(\n                \"max_clients limit reached, request queued. \"\n                \"%d active, %d queued requests.\" % (len(self.active), len(self.queue))\n            )", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Schedules and manages an HTTP request asynchronously, queuing it if client limits are reached and invoking a callback upon response. Enables controlled concurrent HTTP operations with timeout handling in SimpleAsyncHTTPClient."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_process_queue", "line_number": 192, "body": "def _process_queue(self) -> None:\n        while self.queue and len(self.active) < self.max_clients:\n            key, request, callback = self.queue.popleft()\n            if key not in self.waiting:\n                continue\n            self._remove_timeout(key)\n            self.active[key] = (request, callback)\n            release_callback = functools.partial(self._release_fetch, key)\n            self._handle_request(request, release_callback, callback)", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Internal method of SimpleAsyncHTTPClient managing queued HTTP requests by activating them up to a concurrency limit, ensuring orderly processing and proper timeout handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_connection_class", "line_number": 202, "body": "def _connection_class(self) -> type:\n        return _HTTPConnection", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Returns the specific HTTP connection class used internally by SimpleAsyncHTTPClient for managing HTTP connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_handle_request", "line_number": 205, "body": "def _handle_request(\n        self,\n        request: HTTPRequest,\n        release_callback: Callable[[], None],\n        final_callback: Callable[[HTTPResponse], None],\n    ) -> None:\n        self._connection_class()(\n            self,\n            request,\n            release_callback,\n            final_callback,\n            self.max_buffer_size,\n            self.tcp_client,\n            self.max_header_size,\n            self.max_body_size,\n        )", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Internal method of SimpleAsyncHTTPClient that initiates an HTTP request handling process by creating a connection instance, forwarding callbacks, size limits, and client configurations. It facilitates asynchronous HTTP communication management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_release_fetch", "line_number": 222, "body": "def _release_fetch(self, key: object) -> None:\n        del self.active[key]\n        self._process_queue()", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Private method in SimpleAsyncHTTPClient that releases a completed fetch request and triggers processing of pending requests in the queue."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_remove_timeout", "line_number": 226, "body": "def _remove_timeout(self, key: object) -> None:\n        if key in self.waiting:\n            request, callback, timeout_handle = self.waiting[key]\n            if timeout_handle is not None:\n                self.io_loop.remove_timeout(timeout_handle)\n            del self.waiting[key]", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Internal method of SimpleAsyncHTTPClient that cancels and removes a pending request's timeout, cleaning up its tracking entry to prevent timeout callbacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_on_timeout", "line_number": 233, "body": "def _on_timeout(self, key: object, info: Optional[str] = None) -> None:\n        \"\"\"Timeout callback of request.\n\n        Construct a timeout HTTPResponse when a timeout occurs.\n\n        :arg object key: A simple object to mark the request.\n        :info string key: More detailed timeout information.\n        \"\"\"\n        request, callback, timeout_handle = self.waiting[key]\n        self.queue.remove((key, request, callback))\n\n        error_message = \"Timeout {0}\".format(info) if info else \"Timeout\"\n        timeout_response = HTTPResponse(\n            request,\n            599,\n            error=HTTPTimeoutError(error_message),\n            request_time=self.io_loop.time() - request.start_time,\n        )\n        self.io_loop.add_callback(callback, timeout_response)\n        del self.waiting[key]", "is_method": true, "class_name": "SimpleAsyncHTTPClient", "function_description": "Handles request timeouts by generating a timeout HTTP response and invoking the associated callback with timeout error details, ensuring proper cleanup of the pending request state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_get_ssl_options", "line_number": 449, "body": "def _get_ssl_options(\n        self, scheme: str\n    ) -> Union[None, Dict[str, Any], ssl.SSLContext]:\n        if scheme == \"https\":\n            if self.request.ssl_options is not None:\n                return self.request.ssl_options\n            # If we are using the defaults, don't construct a\n            # new SSLContext.\n            if (\n                self.request.validate_cert\n                and self.request.ca_certs is None\n                and self.request.client_cert is None\n                and self.request.client_key is None\n            ):\n                return _client_ssl_defaults\n            ssl_ctx = ssl.create_default_context(\n                ssl.Purpose.SERVER_AUTH, cafile=self.request.ca_certs\n            )\n            if not self.request.validate_cert:\n                ssl_ctx.check_hostname = False\n                ssl_ctx.verify_mode = ssl.CERT_NONE\n            if self.request.client_cert is not None:\n                ssl_ctx.load_cert_chain(\n                    self.request.client_cert, self.request.client_key\n                )\n            if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n                # See netutil.ssl_options_to_context\n                ssl_ctx.options |= ssl.OP_NO_COMPRESSION\n            return ssl_ctx\n        return None", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Provides appropriate SSL configuration options for HTTPS connections based on request settings, including certificate validation and client certificates; returns None for non-HTTPS schemes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_on_timeout", "line_number": 480, "body": "def _on_timeout(self, info: Optional[str] = None) -> None:\n        \"\"\"Timeout callback of _HTTPConnection instance.\n\n        Raise a `HTTPTimeoutError` when a timeout occurs.\n\n        :info string key: More detailed timeout information.\n        \"\"\"\n        self._timeout = None\n        error_message = \"Timeout {0}\".format(info) if info else \"Timeout\"\n        if self.final_callback is not None:\n            self._handle_exception(\n                HTTPTimeoutError, HTTPTimeoutError(error_message), None\n            )", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Private method in _HTTPConnection that handles timeout events by raising an HTTPTimeoutError with optional detailed information, facilitating error management during HTTP operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_remove_timeout", "line_number": 494, "body": "def _remove_timeout(self) -> None:\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Core utility method of the _HTTPConnection class that cancels any active timeout associated with the connection, ensuring no pending timeout callbacks remain in the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_create_connection", "line_number": 499, "body": "def _create_connection(self, stream: IOStream) -> HTTP1Connection:\n        stream.set_nodelay(True)\n        connection = HTTP1Connection(\n            stream,\n            True,\n            HTTP1ConnectionParameters(\n                no_keep_alive=True,\n                max_header_size=self.max_header_size,\n                max_body_size=self.max_body_size,\n                decompress=bool(self.request.decompress_response),\n            ),\n            self._sockaddr,\n        )\n        return connection", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Creates and configures an HTTP/1 connection using a given stream with specific parameters like header and body size limits, decompression, and no keep-alive support. This method facilitates connection setup for HTTP request handling within the _HTTPConnection context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_release", "line_number": 529, "body": "def _release(self) -> None:\n        if self.release_callback is not None:\n            release_callback = self.release_callback\n            self.release_callback = None  # type: ignore\n            release_callback()", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Utility method in _HTTPConnection that triggers and clears a release callback, managing connection cleanup or resource release when invoked."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_run_callback", "line_number": 535, "body": "def _run_callback(self, response: HTTPResponse) -> None:\n        self._release()\n        if self.final_callback is not None:\n            final_callback = self.final_callback\n            self.final_callback = None  # type: ignore\n            self.io_loop.add_callback(final_callback, response)", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Handles completion of an HTTP request by releasing resources and scheduling a final callback with the response, facilitating asynchronous processing within the connection lifecycle."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_handle_exception", "line_number": 542, "body": "def _handle_exception(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> bool:\n        if self.final_callback:\n            self._remove_timeout()\n            if isinstance(value, StreamClosedError):\n                if value.real_error is None:\n                    value = HTTPStreamClosedError(\"Stream closed\")\n                else:\n                    value = value.real_error\n            self._run_callback(\n                HTTPResponse(\n                    self.request,\n                    599,\n                    error=value,\n                    request_time=self.io_loop.time() - self.start_time,\n                    start_time=self.start_wall_time,\n                )\n            )\n\n            if hasattr(self, \"stream\"):\n                # TODO: this may cause a StreamClosedError to be raised\n                # by the connection's Future.  Should we cancel the\n                # connection more gracefully?\n                self.stream.close()\n            return True\n        else:\n            # If our callback has already been called, we are probably\n            # catching an exception that is not caused by us but rather\n            # some child of our callback. Rather than drop it on the floor,\n            # pass it along, unless it's just the stream being closed.\n            return isinstance(value, StreamClosedError)", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Handles exceptions during an HTTP connection by invoking a final callback with an error response and cleaning up resources; it determines whether an exception has been managed or should be propagated further."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "on_connection_close", "line_number": 578, "body": "def on_connection_close(self) -> None:\n        if self.final_callback is not None:\n            message = \"Connection closed\"\n            if self.stream.error:\n                raise self.stream.error\n            try:\n                raise HTTPStreamClosedError(message)\n            except HTTPStreamClosedError:\n                self._handle_exception(*sys.exc_info())", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Handles the closing of an HTTP connection by triggering a final callback and managing any stream errors or exceptions that arise during closure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_should_follow_redirect", "line_number": 611, "body": "def _should_follow_redirect(self) -> bool:\n        if self.request.follow_redirects:\n            assert self.request.max_redirects is not None\n            return (\n                self.code in (301, 302, 303, 307, 308)\n                and self.request.max_redirects > 0\n                and self.headers is not None\n                and self.headers.get(\"Location\") is not None\n            )\n        return False", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Determines if an HTTP request should automatically follow a redirect based on response status, headers, and configured redirect limits. It enables controlled handling of HTTP redirection in connection management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "finish", "line_number": 622, "body": "def finish(self) -> None:\n        assert self.code is not None\n        data = b\"\".join(self.chunks)\n        self._remove_timeout()\n        original_request = getattr(self.request, \"original_request\", self.request)\n        if self._should_follow_redirect():\n            assert isinstance(self.request, _RequestProxy)\n            new_request = copy.copy(self.request.request)\n            new_request.url = urllib.parse.urljoin(\n                self.request.url, self.headers[\"Location\"]\n            )\n            new_request.max_redirects = self.request.max_redirects - 1\n            del new_request.headers[\"Host\"]\n            # https://tools.ietf.org/html/rfc7231#section-6.4\n            #\n            # The original HTTP spec said that after a 301 or 302\n            # redirect, the request method should be preserved.\n            # However, browsers implemented this by changing the\n            # method to GET, and the behavior stuck. 303 redirects\n            # always specified this POST-to-GET behavior, arguably\n            # for *all* methods, but libcurl < 7.70 only does this\n            # for POST, while libcurl >= 7.70 does it for other methods.\n            if (self.code == 303 and self.request.method != \"HEAD\") or (\n                self.code in (301, 302) and self.request.method == \"POST\"\n            ):\n                new_request.method = \"GET\"\n                new_request.body = None\n                for h in [\n                    \"Content-Length\",\n                    \"Content-Type\",\n                    \"Content-Encoding\",\n                    \"Transfer-Encoding\",\n                ]:\n                    try:\n                        del self.request.headers[h]\n                    except KeyError:\n                        pass\n            new_request.original_request = original_request\n            final_callback = self.final_callback\n            self.final_callback = None\n            self._release()\n            fut = self.client.fetch(new_request, raise_error=False)\n            fut.add_done_callback(lambda f: final_callback(f.result()))\n            self._on_end_request()\n            return\n        if self.request.streaming_callback:\n            buffer = BytesIO()\n        else:\n            buffer = BytesIO(data)  # TODO: don't require one big string?\n        response = HTTPResponse(\n            original_request,\n            self.code,\n            reason=getattr(self, \"reason\", None),\n            headers=self.headers,\n            request_time=self.io_loop.time() - self.start_time,\n            start_time=self.start_wall_time,\n            buffer=buffer,\n            effective_url=self.request.url,\n        )\n        self._run_callback(response)\n        self._on_end_request()", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Core method of the _HTTPConnection class that finalizes an HTTP response, handling redirects if needed, buffering response data, and invoking callbacks to complete the request lifecycle."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "_on_end_request", "line_number": 684, "body": "def _on_end_request(self) -> None:\n        self.stream.close()", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Internal method of the _HTTPConnection class that closes the current network stream when an HTTP request ends, ensuring proper resource cleanup after communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/simple_httpclient.py", "function": "data_received", "line_number": 687, "body": "def data_received(self, chunk: bytes) -> None:\n        if self._should_follow_redirect():\n            # We're going to follow a redirect so just discard the body.\n            return\n        if self.request.streaming_callback is not None:\n            self.request.streaming_callback(chunk)\n        else:\n            self.chunks.append(chunk)", "is_method": true, "class_name": "_HTTPConnection", "function_description": "Processes incoming data chunks by either passing them to a streaming callback or buffering them, handling redirection scenarios appropriately. It supports incremental data consumption during HTTP connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "split", "line_number": 76, "body": "def split(\n        addrinfo: List[Tuple],\n    ) -> Tuple[\n        List[Tuple[socket.AddressFamily, Tuple]],\n        List[Tuple[socket.AddressFamily, Tuple]],\n    ]:\n        \"\"\"Partition the ``addrinfo`` list by address family.\n\n        Returns two lists.  The first list contains the first entry from\n        ``addrinfo`` and all others with the same family, and the\n        second list contains all other addresses (normally one list will\n        be AF_INET and the other AF_INET6, although non-standard resolvers\n        may return additional families).\n        \"\"\"\n        primary = []\n        secondary = []\n        primary_af = addrinfo[0][0]\n        for af, addr in addrinfo:\n            if af == primary_af:\n                primary.append((af, addr))\n            else:\n                secondary.append((af, addr))\n        return primary, secondary", "is_method": true, "class_name": "_Connector", "function_description": "Utility method in the _Connector class that separates a list of address info tuples into two lists based on address family, grouping the primary family addresses separately from others. This assists in managing mixed IPv4/IPv6 or multi-family network address data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "start", "line_number": 100, "body": "def start(\n        self,\n        timeout: float = _INITIAL_CONNECT_TIMEOUT,\n        connect_timeout: Optional[Union[float, datetime.timedelta]] = None,\n    ) -> \"Future[Tuple[socket.AddressFamily, Any, IOStream]]\":\n        self.try_connect(iter(self.primary_addrs))\n        self.set_timeout(timeout)\n        if connect_timeout is not None:\n            self.set_connect_timeout(connect_timeout)\n        return self.future", "is_method": true, "class_name": "_Connector", "function_description": "Starts an asynchronous connection attempt to primary addresses with configurable timeouts, returning a future representing the connection result. This enables non-blocking network connection establishment with timeout management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "try_connect", "line_number": 111, "body": "def try_connect(self, addrs: Iterator[Tuple[socket.AddressFamily, Tuple]]) -> None:\n        try:\n            af, addr = next(addrs)\n        except StopIteration:\n            # We've reached the end of our queue, but the other queue\n            # might still be working.  Send a final error on the future\n            # only when both queues are finished.\n            if self.remaining == 0 and not self.future.done():\n                self.future.set_exception(\n                    self.last_error or IOError(\"connection failed\")\n                )\n            return\n        stream, future = self.connect(af, addr)\n        self.streams.add(stream)\n        future_add_done_callback(\n            future, functools.partial(self.on_connect_done, addrs, af, addr)\n        )", "is_method": true, "class_name": "_Connector", "function_description": "Handles iterative connection attempts to multiple addresses, managing connection streams and signaling failure only after all options are exhausted; enables robust, asynchronous connection establishment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "on_connect_done", "line_number": 129, "body": "def on_connect_done(\n        self,\n        addrs: Iterator[Tuple[socket.AddressFamily, Tuple]],\n        af: socket.AddressFamily,\n        addr: Tuple,\n        future: \"Future[IOStream]\",\n    ) -> None:\n        self.remaining -= 1\n        try:\n            stream = future.result()\n        except Exception as e:\n            if self.future.done():\n                return\n            # Error: try again (but remember what happened so we have an\n            # error to raise in the end)\n            self.last_error = e\n            self.try_connect(addrs)\n            if self.timeout is not None:\n                # If the first attempt failed, don't wait for the\n                # timeout to try an address from the secondary queue.\n                self.io_loop.remove_timeout(self.timeout)\n                self.on_timeout()\n            return\n        self.clear_timeouts()\n        if self.future.done():\n            # This is a late arrival; just drop it.\n            stream.close()\n        else:\n            self.streams.discard(stream)\n            self.future.set_result((af, addr, stream))\n            self.close_streams()", "is_method": true, "class_name": "_Connector", "function_description": "Handles the completion of an asynchronous connection attempt, managing success and failure by setting results, retrying connections, and cleaning up resources accordingly. It ensures reliable connection establishment with timeout and error management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "set_timeout", "line_number": 161, "body": "def set_timeout(self, timeout: float) -> None:\n        self.timeout = self.io_loop.add_timeout(\n            self.io_loop.time() + timeout, self.on_timeout\n        )", "is_method": true, "class_name": "_Connector", "function_description": "Sets a timeout event that triggers a handler after a specified duration, enabling asynchronous operations to handle timeouts within the connector's I/O loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "on_timeout", "line_number": 166, "body": "def on_timeout(self) -> None:\n        self.timeout = None\n        if not self.future.done():\n            self.try_connect(iter(self.secondary_addrs))", "is_method": true, "class_name": "_Connector", "function_description": "Handles connection timeout by attempting to reconnect using secondary addresses if the current connection attempt hasn't completed. It ensures retry logic for establishing a network connection after a timeout."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "clear_timeout", "line_number": 171, "body": "def clear_timeout(self) -> None:\n        if self.timeout is not None:\n            self.io_loop.remove_timeout(self.timeout)", "is_method": true, "class_name": "_Connector", "function_description": "Utility method of the _Connector class that cancels a previously set timeout to prevent its execution. It helps manage asynchronous operations by clearing scheduled timeout events."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "set_connect_timeout", "line_number": 175, "body": "def set_connect_timeout(\n        self, connect_timeout: Union[float, datetime.timedelta]\n    ) -> None:\n        self.connect_timeout = self.io_loop.add_timeout(\n            connect_timeout, self.on_connect_timeout\n        )", "is_method": true, "class_name": "_Connector", "function_description": "Sets a connection timeout that triggers a handler after the specified duration, managing connection attempts within the _Connector's asynchronous I/O loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "on_connect_timeout", "line_number": 182, "body": "def on_connect_timeout(self) -> None:\n        if not self.future.done():\n            self.future.set_exception(TimeoutError())\n        self.close_streams()", "is_method": true, "class_name": "_Connector", "function_description": "Handles connection timeouts by signaling a TimeoutError and closing associated streams, ensuring proper cleanup during connection attempts in the _Connector class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "clear_timeouts", "line_number": 187, "body": "def clear_timeouts(self) -> None:\n        if self.timeout is not None:\n            self.io_loop.remove_timeout(self.timeout)\n        if self.connect_timeout is not None:\n            self.io_loop.remove_timeout(self.connect_timeout)", "is_method": true, "class_name": "_Connector", "function_description": "Method of the _Connector class that cancels any scheduled I/O timeouts, ensuring no pending timeout callbacks remain active during connection handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "close_streams", "line_number": 193, "body": "def close_streams(self) -> None:\n        for stream in self.streams:\n            stream.close()", "is_method": true, "class_name": "_Connector", "function_description": "Closes all active streams managed by the _Connector instance, ensuring proper resource cleanup and preventing potential resource leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "close", "line_number": 213, "body": "def close(self) -> None:\n        if self._own_resolver:\n            self.resolver.close()", "is_method": true, "class_name": "TCPClient", "function_description": "Closes the resolver resource owned by the TCPClient, ensuring proper cleanup and release of associated network or DNS resolution resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/tcpclient.py", "function": "_create_stream", "line_number": 293, "body": "def _create_stream(\n        self,\n        max_buffer_size: int,\n        af: socket.AddressFamily,\n        addr: Tuple,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n    ) -> Tuple[IOStream, \"Future[IOStream]\"]:\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        source_port_bind = source_port if isinstance(source_port, int) else 0\n        source_ip_bind = source_ip\n        if source_port_bind and not source_ip:\n            # User required a specific port, but did not specify\n            # a certain source IP, will bind to the default loopback.\n            source_ip_bind = \"::1\" if af == socket.AF_INET6 else \"127.0.0.1\"\n            # Trying to use the same address family as the requested af socket:\n            # - 127.0.0.1 for IPv4\n            # - ::1 for IPv6\n        socket_obj = socket.socket(af)\n        if source_port_bind or source_ip_bind:\n            # If the user requires binding also to a specific IP/port.\n            try:\n                socket_obj.bind((source_ip_bind, source_port_bind))\n            except socket.error:\n                socket_obj.close()\n                # Fail loudly if unable to use the IP/port.\n                raise\n        try:\n            stream = IOStream(socket_obj, max_buffer_size=max_buffer_size)\n        except socket.error as e:\n            fu = Future()  # type: Future[IOStream]\n            fu.set_exception(e)\n            return stream, fu\n        else:\n            return stream, stream.connect(addr)", "is_method": true, "class_name": "TCPClient", "function_description": "Creates and returns a non-SSL IOStream connected to a specified address, optionally binding to a given source IP and port. It initiates connection asynchronously, providing both the stream and its connection future for TCP client operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "_value_from_stopiteration", "line_number": 131, "body": "def _value_from_stopiteration(e: Union[StopIteration, \"Return\"]) -> Any:\n    try:\n        # StopIteration has a value attribute beginning in py33.\n        # So does our Return class.\n        return e.value\n    except AttributeError:\n        pass\n    try:\n        # Cython backports coroutine functionality by putting the value in\n        # e.args[0].\n        return e.args[0]\n    except (AttributeError, IndexError):\n        return None", "is_method": false, "function_description": "Internal helper function that extracts the return value from StopIteration or custom Return exceptions, supporting compatibility with various Python and Cython coroutine implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "_create_future", "line_number": 146, "body": "def _create_future() -> Future:\n    future = Future()  # type: Future\n    # Fixup asyncio debug info by removing extraneous stack entries\n    source_traceback = getattr(future, \"_source_traceback\", ())\n    while source_traceback:\n        # Each traceback entry is equivalent to a\n        # (filename, self.lineno, self.name, self.line) tuple\n        filename = source_traceback[-1][0]\n        if filename == __file__:\n            del source_traceback[-1]\n        else:\n            break\n    return future", "is_method": false, "function_description": "Creates and returns a Future object with cleaned-up debug stack trace entries for improved asyncio debugging clarity. This function helps manage asynchronous task results while removing internal stack noise."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "_fake_ctx_run", "line_number": 161, "body": "def _fake_ctx_run(f: Callable[..., _T], *args: Any, **kw: Any) -> _T:\n    return f(*args, **kw)", "is_method": false, "function_description": "Utility function that synchronously executes a given callable with provided arguments and returns its result."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "coroutine", "line_number": 166, "body": "def coroutine(\n    func: Callable[..., \"Generator[Any, Any, _T]\"]\n) -> Callable[..., \"Future[_T]\"]:\n    ...", "is_method": false, "function_description": "Decorator function that transforms a generator-based coroutine into an awaitable Future, enabling asynchronous execution of generator functions in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "coroutine", "line_number": 177, "body": "def coroutine(\n    func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]]\n) -> Callable[..., \"Future[_T]\"]:\n    \"\"\"Decorator for asynchronous generators.\n\n    For compatibility with older versions of Python, coroutines may\n    also \"return\" by raising the special exception `Return(value)\n    <Return>`.\n\n    Functions with this decorator return a `.Future`.\n\n    .. warning::\n\n       When exceptions occur inside a coroutine, the exception\n       information will be stored in the `.Future` object. You must\n       examine the result of the `.Future` object, or the exception\n       may go unnoticed by your code. This means yielding the function\n       if called from another coroutine, using something like\n       `.IOLoop.run_sync` for top-level calls, or passing the `.Future`\n       to `.IOLoop.add_future`.\n\n    .. versionchanged:: 6.0\n\n       The ``callback`` argument was removed. Use the returned\n       awaitable object instead.\n\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # type: (*Any, **Any) -> Future[_T]\n        # This function is type-annotated with a comment to work around\n        # https://bitbucket.org/pypy/pypy/issues/2868/segfault-with-args-type-annotation-in\n        future = _create_future()\n        if contextvars is not None:\n            ctx_run = contextvars.copy_context().run  # type: Callable\n        else:\n            ctx_run = _fake_ctx_run\n        try:\n            result = ctx_run(func, *args, **kwargs)\n        except (Return, StopIteration) as e:\n            result = _value_from_stopiteration(e)\n        except Exception:\n            future_set_exc_info(future, sys.exc_info())\n            try:\n                return future\n            finally:\n                # Avoid circular references\n                future = None  # type: ignore\n        else:\n            if isinstance(result, Generator):\n                # Inline the first iteration of Runner.run.  This lets us\n                # avoid the cost of creating a Runner when the coroutine\n                # never actually yields, which in turn allows us to\n                # use \"optional\" coroutines in critical path code without\n                # performance penalty for the synchronous case.\n                try:\n                    yielded = ctx_run(next, result)\n                except (StopIteration, Return) as e:\n                    future_set_result_unless_cancelled(\n                        future, _value_from_stopiteration(e)\n                    )\n                except Exception:\n                    future_set_exc_info(future, sys.exc_info())\n                else:\n                    # Provide strong references to Runner objects as long\n                    # as their result future objects also have strong\n                    # references (typically from the parent coroutine's\n                    # Runner). This keeps the coroutine's Runner alive.\n                    # We do this by exploiting the public API\n                    # add_done_callback() instead of putting a private\n                    # attribute on the Future.\n                    # (GitHub issues #1769, #2229).\n                    runner = Runner(ctx_run, result, future, yielded)\n                    future.add_done_callback(lambda _: runner)\n                yielded = None\n                try:\n                    return future\n                finally:\n                    # Subtle memory optimization: if next() raised an exception,\n                    # the future's exc_info contains a traceback which\n                    # includes this stack frame.  This creates a cycle,\n                    # which will be collected at the next full GC but has\n                    # been shown to greatly increase memory usage of\n                    # benchmarks (relative to the refcount-based scheme\n                    # used in the absence of cycles).  We can avoid the\n                    # cycle by clearing the local variable after we return it.\n                    future = None  # type: ignore\n        future_set_result_unless_cancelled(future, result)\n        return future\n\n    wrapper.__wrapped__ = func  # type: ignore\n    wrapper.__tornado_coroutine__ = True  # type: ignore\n    return wrapper", "is_method": false, "function_description": "Decorator function that converts generator-based or regular functions into asynchronous coroutines returning a Future, enabling asynchronous execution and compatibility with older Python coroutine patterns. It facilitates managing asynchronous workflows without explicit async/await syntax."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "is_coroutine_function", "line_number": 273, "body": "def is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n    return getattr(func, \"__tornado_coroutine__\", False)", "is_method": false, "function_description": "Utility function that checks if a given function is a coroutine wrapped with Tornado's coroutine decorator, enabling detection of asynchronous functions in Tornado-based applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "multi", "line_number": 434, "body": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n        results = []\n        for future in list_of_futures:\n            results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n       If multiple yieldables fail, any exceptions after the first\n       (which is raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n       Replaced the class ``Multi`` and the function ``multi_future``\n       with a unified function ``multi``. Added support for yieldables\n       other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n    return multi_future(children, quiet_exceptions=quiet_exceptions)", "is_method": false, "function_description": "Utility function that concurrently runs multiple asynchronous operations, returning a structured result matching the input type (list or dict). It simplifies parallel execution while managing exceptions and optionally suppressing specific error logs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "multi_future", "line_number": 488, "body": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n       If multiple ``Futures`` fail, any exceptions after the first (which is\n       raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n       Use `multi` instead.\n    \"\"\"\n    if isinstance(children, dict):\n        keys = list(children.keys())  # type: Optional[List]\n        children_seq = children.values()  # type: Iterable\n    else:\n        keys = None\n        children_seq = children\n    children_futs = list(map(convert_yielded, children_seq))\n    assert all(is_future(i) or isinstance(i, _NullFuture) for i in children_futs)\n    unfinished_children = set(children_futs)\n\n    future = _create_future()\n    if not children_futs:\n        future_set_result_unless_cancelled(future, {} if keys is not None else [])\n\n    def callback(fut: Future) -> None:\n        unfinished_children.remove(fut)\n        if not unfinished_children:\n            result_list = []\n            for f in children_futs:\n                try:\n                    result_list.append(f.result())\n                except Exception as e:\n                    if future.done():\n                        if not isinstance(e, quiet_exceptions):\n                            app_log.error(\n                                \"Multiple exceptions in yield list\", exc_info=True\n                            )\n                    else:\n                        future_set_exc_info(future, sys.exc_info())\n            if not future.done():\n                if keys is not None:\n                    future_set_result_unless_cancelled(\n                        future, dict(zip(keys, result_list))\n                    )\n                else:\n                    future_set_result_unless_cancelled(future, result_list)\n\n    listening = set()  # type: Set[Future]\n    for f in children_futs:\n        if f not in listening:\n            listening.add(f)\n            future_add_done_callback(f, callback)\n    return future", "is_method": false, "function_description": "Utility function that waits for multiple asynchronous futures concurrently and returns their results as a list or dictionary. It aggregates outcomes, handles exceptions with optional quiet logging, and supports backward compatibility within Tornado's async ecosystem."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "maybe_future", "line_number": 551, "body": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n       This function only handles ``Futures``, not other yieldable objects.\n       Instead of `maybe_future`, check for the non-future result types\n       you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n    if is_future(x):\n        return x\n    else:\n        fut = _create_future()\n        fut.set_result(x)\n        return fut", "is_method": false, "function_description": "Utility function that ensures any input is returned as a Future, wrapping non-Future values transparently to support asynchronous code expecting Futures. Useful when the return type may or may not already be a Future."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "with_timeout", "line_number": 572, "body": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n       Added the ``quiet_exceptions`` argument and the logging of unhandled\n       exceptions.\n\n    .. versionchanged:: 4.4\n       Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n       ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n    # It's tempting to optimize this by cancelling the input future on timeout\n    # instead of creating a new one, but A) we can't know if we are the only\n    # one waiting on the input future, so cancelling it might disrupt other\n    # callers and B) concurrent futures can only be cancelled while they are\n    # in the queue, so cancellation cannot reliably bound our waiting time.\n    future_converted = convert_yielded(future)\n    result = _create_future()\n    chain_future(future_converted, result)\n    io_loop = IOLoop.current()\n\n    def error_callback(future: Future) -> None:\n        try:\n            future.result()\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                app_log.error(\n                    \"Exception in Future %r after timeout\", future, exc_info=True\n                )\n\n    def timeout_callback() -> None:\n        if not result.done():\n            result.set_exception(TimeoutError(\"Timeout\"))\n        # In case the wrapped future goes on to fail, log it.\n        future_add_done_callback(future_converted, error_callback)\n\n    timeout_handle = io_loop.add_timeout(timeout, timeout_callback)\n    if isinstance(future_converted, Future):\n        # We know this future will resolve on the IOLoop, so we don't\n        # need the extra thread-safety of IOLoop.add_future (and we also\n        # don't care about StackContext here.\n        future_add_done_callback(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    else:\n        # concurrent.futures.Futures may resolve on any thread, so we\n        # need to route them back to the IOLoop.\n        io_loop.add_future(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    return result", "is_method": false, "function_description": "Function that wraps an asynchronous operation with a timeout, raising an error if it doesn't complete in time. It allows handling or suppressing exceptions after timeout without canceling the original operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "sleep", "line_number": 650, "body": "def sleep(duration: float) -> \"Future[None]\":\n    \"\"\"Return a `.Future` that resolves after the given number of seconds.\n\n    When used with ``yield`` in a coroutine, this is a non-blocking\n    analogue to `time.sleep` (which should not be used in coroutines\n    because it is blocking)::\n\n        yield gen.sleep(0.5)\n\n    Note that calling this function on its own does nothing; you must\n    wait on the `.Future` it returns (usually by yielding it).\n\n    .. versionadded:: 4.1\n    \"\"\"\n    f = _create_future()\n    IOLoop.current().call_later(\n        duration, lambda: future_set_result_unless_cancelled(f, None)\n    )\n    return f", "is_method": false, "function_description": "Provides a non-blocking sleep operation that returns a Future resolving after a specified delay, enabling asynchronous coroutines to pause without blocking the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "convert_yielded", "line_number": 841, "body": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n        @convert_yielded.register(asyncio.Future)\n        def _(asyncio_future):\n            return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n    if yielded is None or yielded is moment:\n        return moment\n    elif yielded is _null_future:\n        return _null_future\n    elif isinstance(yielded, (list, dict)):\n        return multi(yielded)  # type: ignore\n    elif is_future(yielded):\n        return typing.cast(Future, yielded)\n    elif isawaitable(yielded):\n        return _wrap_awaitable(yielded)  # type: ignore\n    else:\n        raise BadYieldError(\"yielded unknown object %r\" % (yielded,))", "is_method": false, "function_description": "Utility function that converts various yielded objects\u2014including lists, dictionaries, coroutines, and futures\u2014into a unified Future object to standardize asynchronous handling and ensure coroutine execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "wrapper", "line_number": 206, "body": "def wrapper(*args, **kwargs):\n        # type: (*Any, **Any) -> Future[_T]\n        # This function is type-annotated with a comment to work around\n        # https://bitbucket.org/pypy/pypy/issues/2868/segfault-with-args-type-annotation-in\n        future = _create_future()\n        if contextvars is not None:\n            ctx_run = contextvars.copy_context().run  # type: Callable\n        else:\n            ctx_run = _fake_ctx_run\n        try:\n            result = ctx_run(func, *args, **kwargs)\n        except (Return, StopIteration) as e:\n            result = _value_from_stopiteration(e)\n        except Exception:\n            future_set_exc_info(future, sys.exc_info())\n            try:\n                return future\n            finally:\n                # Avoid circular references\n                future = None  # type: ignore\n        else:\n            if isinstance(result, Generator):\n                # Inline the first iteration of Runner.run.  This lets us\n                # avoid the cost of creating a Runner when the coroutine\n                # never actually yields, which in turn allows us to\n                # use \"optional\" coroutines in critical path code without\n                # performance penalty for the synchronous case.\n                try:\n                    yielded = ctx_run(next, result)\n                except (StopIteration, Return) as e:\n                    future_set_result_unless_cancelled(\n                        future, _value_from_stopiteration(e)\n                    )\n                except Exception:\n                    future_set_exc_info(future, sys.exc_info())\n                else:\n                    # Provide strong references to Runner objects as long\n                    # as their result future objects also have strong\n                    # references (typically from the parent coroutine's\n                    # Runner). This keeps the coroutine's Runner alive.\n                    # We do this by exploiting the public API\n                    # add_done_callback() instead of putting a private\n                    # attribute on the Future.\n                    # (GitHub issues #1769, #2229).\n                    runner = Runner(ctx_run, result, future, yielded)\n                    future.add_done_callback(lambda _: runner)\n                yielded = None\n                try:\n                    return future\n                finally:\n                    # Subtle memory optimization: if next() raised an exception,\n                    # the future's exc_info contains a traceback which\n                    # includes this stack frame.  This creates a cycle,\n                    # which will be collected at the next full GC but has\n                    # been shown to greatly increase memory usage of\n                    # benchmarks (relative to the refcount-based scheme\n                    # used in the absence of cycles).  We can avoid the\n                    # cycle by clearing the local variable after we return it.\n                    future = None  # type: ignore\n        future_set_result_unless_cancelled(future, result)\n        return future", "is_method": false, "function_description": "Wrapper function that executes a given callable within an optional context, handling coroutine or generator results asynchronously by returning a Future representing the eventual completion or failure of the execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "done", "line_number": 386, "body": "def done(self) -> bool:\n        \"\"\"Returns True if this iterator has no more results.\"\"\"\n        if self._finished or self._unfinished:\n            return False\n        # Clear the 'current' values when iteration is done.\n        self.current_index = self.current_future = None\n        return True", "is_method": true, "class_name": "WaitIterator", "function_description": "Method of the WaitIterator class that indicates whether the iteration is complete, returning True only when no further results remain and internal iteration state is fully finished."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "next", "line_number": 394, "body": "def next(self) -> Future:\n        \"\"\"Returns a `.Future` that will yield the next available result.\n\n        Note that this `.Future` will not be the same object as any of\n        the inputs.\n        \"\"\"\n        self._running_future = Future()\n\n        if self._finished:\n            self._return_result(self._finished.popleft())\n\n        return self._running_future", "is_method": true, "class_name": "WaitIterator", "function_description": "Provides a Future that delivers the next available result from the iterator, enabling asynchronous retrieval of items as they become ready. It manages the state to ensure each Future is distinct and reflects current iteration progress."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "_done_callback", "line_number": 407, "body": "def _done_callback(self, done: Future) -> None:\n        if self._running_future and not self._running_future.done():\n            self._return_result(done)\n        else:\n            self._finished.append(done)", "is_method": true, "class_name": "WaitIterator", "function_description": "Internal callback method of WaitIterator that processes a completed Future by either returning its result if a tracked task is active or storing it for later handling once active tasks finish."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "_return_result", "line_number": 413, "body": "def _return_result(self, done: Future) -> None:\n        \"\"\"Called set the returned future's state that of the future\n        we yielded, and set the current future for the iterator.\n        \"\"\"\n        if self._running_future is None:\n            raise Exception(\"no future is running\")\n        chain_future(done, self._running_future)\n\n        self.current_future = done\n        self.current_index = self._unfinished.pop(done)", "is_method": true, "class_name": "WaitIterator", "function_description": "Internal method of WaitIterator that updates the iterator\u2019s current state by linking a completed future's result and tracking its position, enabling iterative management of asynchronous task completions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "__aiter__", "line_number": 424, "body": "def __aiter__(self) -> typing.AsyncIterator:\n        return self", "is_method": true, "class_name": "WaitIterator", "function_description": "Enables asynchronous iteration over the WaitIterator instance, allowing it to be used in async for loops for asynchronous processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "__anext__", "line_number": 427, "body": "def __anext__(self) -> Future:\n        if self.done():\n            # Lookup by name to silence pyflakes on older versions.\n            raise getattr(builtins, \"StopAsyncIteration\")()\n        return self.next()", "is_method": true, "class_name": "WaitIterator", "function_description": "Core asynchronous iterator method of WaitIterator that returns the next future unless the iteration is complete, in which case it signals iteration termination."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "error_callback", "line_number": 616, "body": "def error_callback(future: Future) -> None:\n        try:\n            future.result()\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                app_log.error(\n                    \"Exception in Future %r after timeout\", future, exc_info=True\n                )", "is_method": false, "function_description": "Utility function that logs exceptions from asynchronous Future objects unless they are cancelled or belong to specified quiet exceptions, aiding in error handling and debugging in async workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "result", "line_number": 684, "body": "def result(self) -> None:\n        return None", "is_method": true, "class_name": "_NullFuture", "function_description": "This method returns None as a placeholder result, indicating no meaningful value is produced or expected from the future-like object in the _NullFuture class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "done", "line_number": 687, "body": "def done(self) -> bool:\n        return True", "is_method": true, "class_name": "_NullFuture", "function_description": "Simple method indicating that the future computation is already complete. It serves as a status check always confirming completion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "run", "line_number": 743, "body": "def run(self) -> None:\n        \"\"\"Starts or resumes the generator, running until it reaches a\n        yield point that is not ready.\n        \"\"\"\n        if self.running or self.finished:\n            return\n        try:\n            self.running = True\n            while True:\n                future = self.future\n                if future is None:\n                    raise Exception(\"No pending future\")\n                if not future.done():\n                    return\n                self.future = None\n                try:\n                    exc_info = None\n\n                    try:\n                        value = future.result()\n                    except Exception:\n                        exc_info = sys.exc_info()\n                    future = None\n\n                    if exc_info is not None:\n                        try:\n                            yielded = self.gen.throw(*exc_info)  # type: ignore\n                        finally:\n                            # Break up a reference to itself\n                            # for faster GC on CPython.\n                            exc_info = None\n                    else:\n                        yielded = self.gen.send(value)\n\n                except (StopIteration, Return) as e:\n                    self.finished = True\n                    self.future = _null_future\n                    future_set_result_unless_cancelled(\n                        self.result_future, _value_from_stopiteration(e)\n                    )\n                    self.result_future = None  # type: ignore\n                    return\n                except Exception:\n                    self.finished = True\n                    self.future = _null_future\n                    future_set_exc_info(self.result_future, sys.exc_info())\n                    self.result_future = None  # type: ignore\n                    return\n                if not self.handle_yield(yielded):\n                    return\n                yielded = None\n        finally:\n            self.running = False", "is_method": true, "class_name": "Runner", "function_description": "Core method of the Runner class that manages execution of a generator, advancing it until it encounters a not-ready yield point, handling results, exceptions, and completion signals for asynchronous control flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "handle_yield", "line_number": 797, "body": "def handle_yield(self, yielded: _Yieldable) -> bool:\n        try:\n            self.future = convert_yielded(yielded)\n        except BadYieldError:\n            self.future = Future()\n            future_set_exc_info(self.future, sys.exc_info())\n\n        if self.future is moment:\n            self.io_loop.add_callback(self.ctx_run, self.run)\n            return False\n        elif self.future is None:\n            raise Exception(\"no pending future\")\n        elif not self.future.done():\n\n            def inner(f: Any) -> None:\n                # Break a reference cycle to speed GC.\n                f = None  # noqa: F841\n                self.ctx_run(self.run)\n\n            self.io_loop.add_future(self.future, inner)\n            return False\n        return True", "is_method": true, "class_name": "Runner", "function_description": "Handles and manages yielded values by converting them into futures and scheduling their execution within an I/O loop, coordinating asynchronous control flow in the Runner class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "handle_exception", "line_number": 820, "body": "def handle_exception(\n        self, typ: Type[Exception], value: Exception, tb: types.TracebackType\n    ) -> bool:\n        if not self.running and not self.finished:\n            self.future = Future()\n            future_set_exc_info(self.future, (typ, value, tb))\n            self.ctx_run(self.run)\n            return True\n        else:\n            return False", "is_method": true, "class_name": "Runner", "function_description": "Handles an exception by initializing and scheduling a future task if the runner hasn't started or finished, enabling controlled execution after an error occurs. This supports error management within asynchronous or controlled run workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/gen.py", "function": "inner", "line_number": 811, "body": "def inner(f: Any) -> None:\n                # Break a reference cycle to speed GC.\n                f = None  # noqa: F841\n                self.ctx_run(self.run)", "is_method": true, "class_name": "Runner", "function_description": "Terminates a given function reference to facilitate garbage collection, then triggers the Runner's context-specific run operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "cpu_count", "line_number": 48, "body": "def cpu_count() -> int:\n    \"\"\"Returns the number of processors on this machine.\"\"\"\n    if multiprocessing is None:\n        return 1\n    try:\n        return multiprocessing.cpu_count()\n    except NotImplementedError:\n        pass\n    try:\n        return os.sysconf(\"SC_NPROCESSORS_CONF\")  # type: ignore\n    except (AttributeError, ValueError):\n        pass\n    gen_log.error(\"Could not detect number of processors; assuming 1\")\n    return 1", "is_method": false, "function_description": "Function that determines the number of CPU processors available on the machine, providing system information useful for optimizing parallel or concurrent processing tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "_reseed_random", "line_number": 64, "body": "def _reseed_random() -> None:\n    if \"random\" not in sys.modules:\n        return\n    import random\n\n    # If os.urandom is available, this method does the same thing as\n    # random.seed (at least as of python 2.6).  If os.urandom is not\n    # available, we mix in the pid in addition to a timestamp.\n    try:\n        seed = int(hexlify(os.urandom(16)), 16)\n    except NotImplementedError:\n        seed = int(time.time() * 1000) ^ os.getpid()\n    random.seed(seed)", "is_method": false, "function_description": "Reinitializes Python\u2019s random number generator with a high-entropy seed for improved randomness, using system sources when available or falling back to time and process ID. This ensures unpredictable random sequences for applications requiring secure or varied randomness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "fork_processes", "line_number": 82, "body": "def fork_processes(\n    num_processes: Optional[int], max_restarts: Optional[int] = None\n) -> int:\n    \"\"\"Starts multiple worker processes.\n\n    If ``num_processes`` is None or <= 0, we detect the number of cores\n    available on this machine and fork that number of child\n    processes. If ``num_processes`` is given and > 0, we fork that\n    specific number of sub-processes.\n\n    Since we use processes and not threads, there is no shared memory\n    between any server code.\n\n    Note that multiple processes are not compatible with the autoreload\n    module (or the ``autoreload=True`` option to `tornado.web.Application`\n    which defaults to True when ``debug=True``).\n    When using multiple processes, no IOLoops can be created or\n    referenced until after the call to ``fork_processes``.\n\n    In each child process, ``fork_processes`` returns its *task id*, a\n    number between 0 and ``num_processes``.  Processes that exit\n    abnormally (due to a signal or non-zero exit status) are restarted\n    with the same id (up to ``max_restarts`` times).  In the parent\n    process, ``fork_processes`` calls ``sys.exit(0)`` after all child\n    processes have exited normally.\n\n    max_restarts defaults to 100.\n\n    Availability: Unix\n    \"\"\"\n    if sys.platform == \"win32\":\n        # The exact form of this condition matters to mypy; it understands\n        # if but not assert in this context.\n        raise Exception(\"fork not available on windows\")\n    if max_restarts is None:\n        max_restarts = 100\n\n    global _task_id\n    assert _task_id is None\n    if num_processes is None or num_processes <= 0:\n        num_processes = cpu_count()\n    gen_log.info(\"Starting %d processes\", num_processes)\n    children = {}\n\n    def start_child(i: int) -> Optional[int]:\n        pid = os.fork()\n        if pid == 0:\n            # child process\n            _reseed_random()\n            global _task_id\n            _task_id = i\n            return i\n        else:\n            children[pid] = i\n            return None\n\n    for i in range(num_processes):\n        id = start_child(i)\n        if id is not None:\n            return id\n    num_restarts = 0\n    while children:\n        pid, status = os.wait()\n        if pid not in children:\n            continue\n        id = children.pop(pid)\n        if os.WIFSIGNALED(status):\n            gen_log.warning(\n                \"child %d (pid %d) killed by signal %d, restarting\",\n                id,\n                pid,\n                os.WTERMSIG(status),\n            )\n        elif os.WEXITSTATUS(status) != 0:\n            gen_log.warning(\n                \"child %d (pid %d) exited with status %d, restarting\",\n                id,\n                pid,\n                os.WEXITSTATUS(status),\n            )\n        else:\n            gen_log.info(\"child %d (pid %d) exited normally\", id, pid)\n            continue\n        num_restarts += 1\n        if num_restarts > max_restarts:\n            raise RuntimeError(\"Too many child restarts, giving up\")\n        new_id = start_child(id)\n        if new_id is not None:\n            return new_id\n    # All child processes exited cleanly, so exit the master process\n    # instead of just returning to right after the call to\n    # fork_processes (which will probably just start up another IOLoop\n    # unless the caller checks the return value).\n    sys.exit(0)", "is_method": false, "function_description": "Function that initializes multiple child processes based on the specified or available CPU cores, assigning each a unique task ID and ensuring automatic restarts on abnormal exits up to a limit. It facilitates concurrent process management on Unix systems for scalable workloads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "task_id", "line_number": 178, "body": "def task_id() -> Optional[int]:\n    \"\"\"Returns the current task id, if any.\n\n    Returns None if this process was not created by `fork_processes`.\n    \"\"\"\n    global _task_id\n    return _task_id", "is_method": false, "function_description": "Function that returns the current task identifier if the process was spawned via forking; otherwise, it returns None. Useful for distinguishing or managing parallel tasks in multi-process execution environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "start_child", "line_number": 126, "body": "def start_child(i: int) -> Optional[int]:\n        pid = os.fork()\n        if pid == 0:\n            # child process\n            _reseed_random()\n            global _task_id\n            _task_id = i\n            return i\n        else:\n            children[pid] = i\n            return None", "is_method": false, "function_description": "Function to spawn a child process with a specific task identifier, allowing the child to initialize and return its task ID while the parent tracks child processes. Useful for managing parallel task execution in multiprocessing workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "set_exit_callback", "line_number": 254, "body": "def set_exit_callback(self, callback: Callable[[int], None]) -> None:\n        \"\"\"Runs ``callback`` when this process exits.\n\n        The callback takes one argument, the return code of the process.\n\n        This method uses a ``SIGCHLD`` handler, which is a global setting\n        and may conflict if you have other libraries trying to handle the\n        same signal.  If you are using more than one ``IOLoop`` it may\n        be necessary to call `Subprocess.initialize` first to designate\n        one ``IOLoop`` to run the signal handlers.\n\n        In many cases a close callback on the stdout or stderr streams\n        can be used as an alternative to an exit callback if the\n        signal handler is causing a problem.\n\n        Availability: Unix\n        \"\"\"\n        self._exit_callback = callback\n        Subprocess.initialize()\n        Subprocess._waiting[self.pid] = self\n        Subprocess._try_cleanup_process(self.pid)", "is_method": true, "class_name": "Subprocess", "function_description": "Provides a way to register a callback that executes upon process termination, receiving its exit code. This enables asynchronous handling of subprocess completion on Unix systems using signal-based notifications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "wait_for_exit", "line_number": 276, "body": "def wait_for_exit(self, raise_error: bool = True) -> \"Future[int]\":\n        \"\"\"Returns a `.Future` which resolves when the process exits.\n\n        Usage::\n\n            ret = yield proc.wait_for_exit()\n\n        This is a coroutine-friendly alternative to `set_exit_callback`\n        (and a replacement for the blocking `subprocess.Popen.wait`).\n\n        By default, raises `subprocess.CalledProcessError` if the process\n        has a non-zero exit status. Use ``wait_for_exit(raise_error=False)``\n        to suppress this behavior and return the exit status without raising.\n\n        .. versionadded:: 4.2\n\n        Availability: Unix\n        \"\"\"\n        future = Future()  # type: Future[int]\n\n        def callback(ret: int) -> None:\n            if ret != 0 and raise_error:\n                # Unfortunately we don't have the original args any more.\n                future_set_exception_unless_cancelled(\n                    future, CalledProcessError(ret, \"unknown\")\n                )\n            else:\n                future_set_result_unless_cancelled(future, ret)\n\n        self.set_exit_callback(callback)\n        return future", "is_method": true, "class_name": "Subprocess", "function_description": "Provides a coroutine-compatible Future that resolves upon process exit, optionally raising an error on non-zero exit codes. It enables asynchronous waiting for process completion without blocking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "initialize", "line_number": 309, "body": "def initialize(cls) -> None:\n        \"\"\"Initializes the ``SIGCHLD`` handler.\n\n        The signal handler is run on an `.IOLoop` to avoid locking issues.\n        Note that the `.IOLoop` used for signal handling need not be the\n        same one used by individual Subprocess objects (as long as the\n        ``IOLoops`` are each running in separate threads).\n\n        .. versionchanged:: 5.0\n           The ``io_loop`` argument (deprecated since version 4.1) has been\n           removed.\n\n        Availability: Unix\n        \"\"\"\n        if cls._initialized:\n            return\n        io_loop = ioloop.IOLoop.current()\n        cls._old_sigchld = signal.signal(\n            signal.SIGCHLD,\n            lambda sig, frame: io_loop.add_callback_from_signal(cls._cleanup),\n        )\n        cls._initialized = True", "is_method": true, "class_name": "Subprocess", "function_description": "Initializes a Unix-specific SIGCHLD signal handler to manage subprocess termination without locking, ensuring cleanup callbacks run within an asynchronous IOLoop context. This prepares the environment for safe subprocess lifecycle handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "uninitialize", "line_number": 333, "body": "def uninitialize(cls) -> None:\n        \"\"\"Removes the ``SIGCHLD`` handler.\"\"\"\n        if not cls._initialized:\n            return\n        signal.signal(signal.SIGCHLD, cls._old_sigchld)\n        cls._initialized = False", "is_method": true, "class_name": "Subprocess", "function_description": "Provides a cleanup utility for the Subprocess class by removing the SIGCHLD signal handler and resetting its initialization state. This ensures proper teardown of subprocess signal management when no longer needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "_cleanup", "line_number": 341, "body": "def _cleanup(cls) -> None:\n        for pid in list(cls._waiting.keys()):  # make a copy\n            cls._try_cleanup_process(pid)", "is_method": true, "class_name": "Subprocess", "function_description": "Internal class method that attempts to clean up and finalize all tracked subprocesses to free related resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "_try_cleanup_process", "line_number": 346, "body": "def _try_cleanup_process(cls, pid: int) -> None:\n        try:\n            ret_pid, status = os.waitpid(pid, os.WNOHANG)  # type: ignore\n        except ChildProcessError:\n            return\n        if ret_pid == 0:\n            return\n        assert ret_pid == pid\n        subproc = cls._waiting.pop(pid)\n        subproc.io_loop.add_callback_from_signal(subproc._set_returncode, status)", "is_method": true, "class_name": "Subprocess", "function_description": "Internal method of the Subprocess class that attempts to clean up a finished child process by reaping its exit status and triggering related callbacks. It ensures proper resource management for asynchronous subprocess handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "_set_returncode", "line_number": 357, "body": "def _set_returncode(self, status: int) -> None:\n        if sys.platform == \"win32\":\n            self.returncode = -1\n        else:\n            if os.WIFSIGNALED(status):\n                self.returncode = -os.WTERMSIG(status)\n            else:\n                assert os.WIFEXITED(status)\n                self.returncode = os.WEXITSTATUS(status)\n        # We've taken over wait() duty from the subprocess.Popen\n        # object. If we don't inform it of the process's return code,\n        # it will log a warning at destruction in python 3.6+.\n        self.proc.returncode = self.returncode\n        if self._exit_callback:\n            callback = self._exit_callback\n            self._exit_callback = None\n            callback(self.returncode)", "is_method": true, "class_name": "Subprocess", "function_description": "Sets the subprocess return code based on the process status and triggers any registered exit callback. It ensures proper return code handling across platforms and prevents warnings from the underlying subprocess."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/process.py", "function": "callback", "line_number": 296, "body": "def callback(ret: int) -> None:\n            if ret != 0 and raise_error:\n                # Unfortunately we don't have the original args any more.\n                future_set_exception_unless_cancelled(\n                    future, CalledProcessError(ret, \"unknown\")\n                )\n            else:\n                future_set_result_unless_cancelled(future, ret)", "is_method": true, "class_name": "Subprocess", "function_description": "Handles subprocess completion by setting the result or raising an error in the associated future based on the return code and error configuration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/log.py", "function": "_stderr_supports_color", "line_number": 55, "body": "def _stderr_supports_color() -> bool:\n    try:\n        if hasattr(sys.stderr, \"isatty\") and sys.stderr.isatty():\n            if curses:\n                curses.setupterm()\n                if curses.tigetnum(\"colors\") > 0:\n                    return True\n            elif colorama:\n                if sys.stderr is getattr(\n                    colorama.initialise, \"wrapped_stderr\", object()\n                ):\n                    return True\n    except Exception:\n        # Very broad exception handling because it's always better to\n        # fall back to non-colored logs than to break at startup.\n        pass\n    return False", "is_method": false, "function_description": "Determines if the standard error stream supports colored output by checking terminal capabilities and initialization of color libraries. Useful for conditionally enabling colored logging or terminal messages."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/log.py", "function": "_safe_unicode", "line_number": 74, "body": "def _safe_unicode(s: Any) -> str:\n    try:\n        return _unicode(s)\n    except UnicodeDecodeError:\n        return repr(s)", "is_method": false, "function_description": "Internal utility function that safely converts any input to a Unicode string, returning a fallback string representation if decoding fails due to Unicode errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/log.py", "function": "enable_pretty_logging", "line_number": 211, "body": "def enable_pretty_logging(\n    options: Any = None, logger: Optional[logging.Logger] = None\n) -> None:\n    \"\"\"Turns on formatted logging output as configured.\n\n    This is called automatically by `tornado.options.parse_command_line`\n    and `tornado.options.parse_config_file`.\n    \"\"\"\n    if options is None:\n        import tornado.options\n\n        options = tornado.options.options\n    if options.logging is None or options.logging.lower() == \"none\":\n        return\n    if logger is None:\n        logger = logging.getLogger()\n    logger.setLevel(getattr(logging, options.logging.upper()))\n    if options.log_file_prefix:\n        rotate_mode = options.log_rotate_mode\n        if rotate_mode == \"size\":\n            channel = logging.handlers.RotatingFileHandler(\n                filename=options.log_file_prefix,\n                maxBytes=options.log_file_max_size,\n                backupCount=options.log_file_num_backups,\n                encoding=\"utf-8\",\n            )  # type: logging.Handler\n        elif rotate_mode == \"time\":\n            channel = logging.handlers.TimedRotatingFileHandler(\n                filename=options.log_file_prefix,\n                when=options.log_rotate_when,\n                interval=options.log_rotate_interval,\n                backupCount=options.log_file_num_backups,\n                encoding=\"utf-8\",\n            )\n        else:\n            error_message = (\n                \"The value of log_rotate_mode option should be \"\n                + '\"size\" or \"time\", not \"%s\".' % rotate_mode\n            )\n            raise ValueError(error_message)\n        channel.setFormatter(LogFormatter(color=False))\n        logger.addHandler(channel)\n\n    if options.log_to_stderr or (options.log_to_stderr is None and not logger.handlers):\n        # Set up color if we are in a tty and curses is installed\n        channel = logging.StreamHandler()\n        channel.setFormatter(LogFormatter())\n        logger.addHandler(channel)", "is_method": false, "function_description": "Sets up and enables configurable, formatted logging output with support for log rotation and optional color formatting, integrating Tornado options. It provides flexible logging configuration for applications using Tornado\u2019s logging settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/log.py", "function": "define_logging_options", "line_number": 261, "body": "def define_logging_options(options: Any = None) -> None:\n    \"\"\"Add logging-related flags to ``options``.\n\n    These options are present automatically on the default options instance;\n    this method is only necessary if you have created your own `.OptionParser`.\n\n    .. versionadded:: 4.2\n        This function existed in prior versions but was broken and undocumented until 4.2.\n    \"\"\"\n    if options is None:\n        # late import to prevent cycle\n        import tornado.options\n\n        options = tornado.options.options\n    options.define(\n        \"logging\",\n        default=\"info\",\n        help=(\n            \"Set the Python log level. If 'none', tornado won't touch the \"\n            \"logging configuration.\"\n        ),\n        metavar=\"debug|info|warning|error|none\",\n    )\n    options.define(\n        \"log_to_stderr\",\n        type=bool,\n        default=None,\n        help=(\n            \"Send log output to stderr (colorized if possible). \"\n            \"By default use stderr if --log_file_prefix is not set and \"\n            \"no other logging is configured.\"\n        ),\n    )\n    options.define(\n        \"log_file_prefix\",\n        type=str,\n        default=None,\n        metavar=\"PATH\",\n        help=(\n            \"Path prefix for log files. \"\n            \"Note that if you are running multiple tornado processes, \"\n            \"log_file_prefix must be different for each of them (e.g. \"\n            \"include the port number)\"\n        ),\n    )\n    options.define(\n        \"log_file_max_size\",\n        type=int,\n        default=100 * 1000 * 1000,\n        help=\"max size of log files before rollover\",\n    )\n    options.define(\n        \"log_file_num_backups\", type=int, default=10, help=\"number of log files to keep\"\n    )\n\n    options.define(\n        \"log_rotate_when\",\n        type=str,\n        default=\"midnight\",\n        help=(\n            \"specify the type of TimedRotatingFileHandler interval \"\n            \"other options:('S', 'M', 'H', 'D', 'W0'-'W6')\"\n        ),\n    )\n    options.define(\n        \"log_rotate_interval\",\n        type=int,\n        default=1,\n        help=\"The interval value of timed rotating\",\n    )\n\n    options.define(\n        \"log_rotate_mode\",\n        type=str,\n        default=\"size\",\n        help=\"The mode of rotating files(time or size)\",\n    )\n\n    options.add_parse_callback(lambda: enable_pretty_logging(options))", "is_method": false, "function_description": "Function that adds a comprehensive set of configurable logging options to a given options parser, enabling customization of logging behavior such as log level, output destination, file rotation, and formatting. This is useful for applications needing flexible and standardized logging setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/log.py", "function": "format", "line_number": 164, "body": "def format(self, record: Any) -> str:\n        try:\n            message = record.getMessage()\n            assert isinstance(message, basestring_type)  # guaranteed by logging\n            # Encoding notes:  The logging module prefers to work with character\n            # strings, but only enforces that log messages are instances of\n            # basestring.  In python 2, non-ascii bytestrings will make\n            # their way through the logging framework until they blow up with\n            # an unhelpful decoding error (with this formatter it happens\n            # when we attach the prefix, but there are other opportunities for\n            # exceptions further along in the framework).\n            #\n            # If a byte string makes it this far, convert it to unicode to\n            # ensure it will make it out to the logs.  Use repr() as a fallback\n            # to ensure that all byte strings can be converted successfully,\n            # but don't do it by default so we don't add extra quotes to ascii\n            # bytestrings.  This is a bit of a hacky place to do this, but\n            # it's worth it since the encoding errors that would otherwise\n            # result are so useless (and tornado is fond of using utf8-encoded\n            # byte strings wherever possible).\n            record.message = _safe_unicode(message)\n        except Exception as e:\n            record.message = \"Bad message (%r): %r\" % (e, record.__dict__)\n\n        record.asctime = self.formatTime(record, cast(str, self.datefmt))\n\n        if record.levelno in self._colors:\n            record.color = self._colors[record.levelno]\n            record.end_color = self._normal\n        else:\n            record.color = record.end_color = \"\"\n\n        formatted = self._fmt % record.__dict__\n\n        if record.exc_info:\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            # exc_text contains multiple lines.  We need to _safe_unicode\n            # each line separately so that non-utf8 bytes don't cause\n            # all the newlines to turn into '\\n'.\n            lines = [formatted.rstrip()]\n            lines.extend(_safe_unicode(ln) for ln in record.exc_text.split(\"\\n\"))\n            formatted = \"\\n\".join(lines)\n        return formatted.replace(\"\\n\", \"\\n    \")", "is_method": true, "class_name": "LogFormatter", "function_description": "Formats a log record into a color-coded, timestamped string with safe handling of Unicode and exception information, ensuring readable and consistent log output for enhanced debugging and monitoring."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "doctests", "line_number": 1657, "body": "def doctests() -> Any:\n    import doctest\n\n    return doctest.DocTestSuite()", "is_method": false, "function_description": "Returns a collection of doctest test cases for automated testing of embedded documentation examples. It facilitates verification of code correctness by running examples included in docstrings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "__len__", "line_number": 133, "body": "def __len__(self) -> int:\n        return self._size", "is_method": true, "class_name": "_StreamBuffer", "function_description": "Returns the current number of bytes stored in the stream buffer, providing a quick way to check its size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "append", "line_number": 140, "body": "def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n        \"\"\"\n        Append the given piece of data (should be a buffer-compatible object).\n        \"\"\"\n        size = len(data)\n        if size > self._large_buf_threshold:\n            if not isinstance(data, memoryview):\n                data = memoryview(data)\n            self._buffers.append((True, data))\n        elif size > 0:\n            if self._buffers:\n                is_memview, b = self._buffers[-1]\n                new_buf = is_memview or len(b) >= self._large_buf_threshold\n            else:\n                new_buf = True\n            if new_buf:\n                self._buffers.append((False, bytearray(data)))\n            else:\n                b += data  # type: ignore\n\n        self._size += size", "is_method": true, "class_name": "_StreamBuffer", "function_description": "Method of the _StreamBuffer class that appends buffer-compatible data efficiently by managing internal storage based on data size, supporting incremental accumulation of byte streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "peek", "line_number": 162, "body": "def peek(self, size: int) -> memoryview:\n        \"\"\"\n        Get a view over at most ``size`` bytes (possibly fewer) at the\n        current buffer position.\n        \"\"\"\n        assert size > 0\n        try:\n            is_memview, b = self._buffers[0]\n        except IndexError:\n            return memoryview(b\"\")\n\n        pos = self._first_pos\n        if is_memview:\n            return typing.cast(memoryview, b[pos : pos + size])\n        else:\n            return memoryview(b)[pos : pos + size]", "is_method": true, "class_name": "_StreamBuffer", "function_description": "The peek method of _StreamBuffer provides a memory-efficient view of up to a specified number of bytes from the current buffer position without advancing the read cursor. It enables inspecting buffered data non-destructively for streaming or parsing tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "advance", "line_number": 179, "body": "def advance(self, size: int) -> None:\n        \"\"\"\n        Advance the current buffer position by ``size`` bytes.\n        \"\"\"\n        assert 0 < size <= self._size\n        self._size -= size\n        pos = self._first_pos\n\n        buffers = self._buffers\n        while buffers and size > 0:\n            is_large, b = buffers[0]\n            b_remain = len(b) - size - pos\n            if b_remain <= 0:\n                buffers.popleft()\n                size -= len(b) - pos\n                pos = 0\n            elif is_large:\n                pos += size\n                size = 0\n            else:\n                # Amortized O(1) shrink for Python 2\n                pos += size\n                if len(b) <= 2 * pos:\n                    del typing.cast(bytearray, b)[:pos]\n                    pos = 0\n                size = 0\n\n        assert size == 0\n        self._first_pos = pos", "is_method": true, "class_name": "_StreamBuffer", "function_description": "Advances the current position within the stream buffer by a specified byte size, effectively consuming data from the buffer. This enables incremental reading or processing of streamed byte data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "fileno", "line_number": 286, "body": "def fileno(self) -> Union[int, ioloop._Selectable]:\n        \"\"\"Returns the file descriptor for this stream.\"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "BaseIOStream", "function_description": "Returns the file descriptor associated with the stream, enabling low-level I/O operations. This method must be implemented by subclasses to provide the stream's underlying file descriptor."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "get_fd_error", "line_number": 320, "body": "def get_fd_error(self) -> Optional[Exception]:\n        \"\"\"Returns information about any error on the underlying file.\n\n        This method is called after the `.IOLoop` has signaled an error on the\n        file descriptor, and should return an Exception (such as `socket.error`\n        with additional information, or None if no such information is\n        available.\n        \"\"\"\n        return None", "is_method": true, "class_name": "BaseIOStream", "function_description": "Returns detailed error information about the underlying file descriptor after an I/O error is detected, or None if no details are available."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_until_regex", "line_number": 330, "body": "def read_until_regex(\n        self, regex: bytes, max_bytes: Optional[int] = None\n    ) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read until we have matched the given regex.\n\n        The result includes the data that matches the regex and anything\n        that came before it.\n\n        If ``max_bytes`` is not None, the connection will be closed\n        if more than ``max_bytes`` bytes have been read and the regex is\n        not satisfied.\n\n        .. versionchanged:: 4.0\n            Added the ``max_bytes`` argument.  The ``callback`` argument is\n            now optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        future = self._start_read()\n        self._read_regex = re.compile(regex)\n        self._read_max_bytes = max_bytes\n        try:\n            self._try_inline_read()\n        except UnsatisfiableReadError as e:\n            # Handle this the same way as in _handle_events.\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n            return future\n        except:\n            # Ensure that the future doesn't log an error because its\n            # failure was never examined.\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously reads data from a stream until a specified regex pattern is matched or an optional byte limit is exceeded, supporting controlled, pattern-driven data retrieval in async I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_until", "line_number": 369, "body": "def read_until(\n        self, delimiter: bytes, max_bytes: Optional[int] = None\n    ) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read until we have found the given delimiter.\n\n        The result includes all the data read including the delimiter.\n\n        If ``max_bytes`` is not None, the connection will be closed\n        if more than ``max_bytes`` bytes have been read and the delimiter\n        is not found.\n\n        .. versionchanged:: 4.0\n            Added the ``max_bytes`` argument.  The ``callback`` argument is\n            now optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n        \"\"\"\n        future = self._start_read()\n        self._read_delimiter = delimiter\n        self._read_max_bytes = max_bytes\n        try:\n            self._try_inline_read()\n        except UnsatisfiableReadError as e:\n            # Handle this the same way as in _handle_events.\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n            return future\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously reads data from the stream up to and including a specified delimiter, optionally enforcing a maximum byte limit to prevent excessive reads. It enables other functions to await delimiter-terminated data efficiently in asynchronous I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_bytes", "line_number": 404, "body": "def read_bytes(self, num_bytes: int, partial: bool = False) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        If ``partial`` is true, data is returned as soon as we have\n        any bytes to return (but never more than ``num_bytes``)\n\n        .. versionchanged:: 4.0\n            Added the ``partial`` argument.  The callback argument is now\n            optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` and ``streaming_callback`` arguments have\n           been removed. Use the returned `.Future` (and\n           ``partial=True`` for ``streaming_callback``) instead.\n\n        \"\"\"\n        future = self._start_read()\n        assert isinstance(num_bytes, numbers.Integral)\n        self._read_bytes = num_bytes\n        self._read_partial = partial\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously reads up to a specified number of bytes from a stream, optionally returning data as soon as any bytes are available. This enables efficient non-blocking byte retrieval for I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_into", "line_number": 432, "body": "def read_into(self, buf: bytearray, partial: bool = False) -> Awaitable[int]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        ``buf`` must be a writable buffer into which data will be read.\n\n        If ``partial`` is true, the callback is run as soon as any bytes\n        have been read.  Otherwise, it is run when the ``buf`` has been\n        entirely filled with read data.\n\n        .. versionadded:: 5.0\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        future = self._start_read()\n\n        # First copy data already in read buffer\n        available_bytes = self._read_buffer_size\n        n = len(buf)\n        if available_bytes >= n:\n            end = self._read_buffer_pos + n\n            buf[:] = memoryview(self._read_buffer)[self._read_buffer_pos : end]\n            del self._read_buffer[:end]\n            self._after_user_read_buffer = self._read_buffer\n        elif available_bytes > 0:\n            buf[:available_bytes] = memoryview(self._read_buffer)[\n                self._read_buffer_pos :\n            ]\n\n        # Set up the supplied buffer as our temporary read buffer.\n        # The original (if it had any data remaining) has been\n        # saved for later.\n        self._user_read_buffer = True\n        self._read_buffer = buf\n        self._read_buffer_pos = 0\n        self._read_buffer_size = available_bytes\n        self._read_bytes = n\n        self._read_partial = partial\n\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously reads bytes into a given writable buffer, returning a Future that completes when the buffer is fully or partially filled based on the partial flag. This enables coroutine-friendly, incremental data reading from a stream."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_until_close", "line_number": 481, "body": "def read_until_close(self) -> Awaitable[bytes]:\n        \"\"\"Asynchronously reads all data from the socket until it is closed.\n\n        This will buffer all available data until ``max_buffer_size``\n        is reached. If flow control or cancellation are desired, use a\n        loop with `read_bytes(partial=True) <.read_bytes>` instead.\n\n        .. versionchanged:: 4.0\n            The callback argument is now optional and a `.Future` will\n            be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` and ``streaming_callback`` arguments have\n           been removed. Use the returned `.Future` (and `read_bytes`\n           with ``partial=True`` for ``streaming_callback``) instead.\n\n        \"\"\"\n        future = self._start_read()\n        if self.closed():\n            self._finish_read(self._read_buffer_size, False)\n            return future\n        self._read_until_close = True\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously reads and buffers all data from a socket until the connection closes, returning a future representing the complete byte stream. Useful for receiving entire data transmissions without manual flow control."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "write", "line_number": 511, "body": "def write(self, data: Union[bytes, memoryview]) -> \"Future[None]\":\n        \"\"\"Asynchronously write the given data to this stream.\n\n        This method returns a `.Future` that resolves (with a result\n        of ``None``) when the write has been completed.\n\n        The ``data`` argument may be of type `bytes` or `memoryview`.\n\n        .. versionchanged:: 4.0\n            Now returns a `.Future` if no callback is given.\n\n        .. versionchanged:: 4.5\n            Added support for `memoryview` arguments.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        self._check_closed()\n        if data:\n            if (\n                self.max_write_buffer_size is not None\n                and len(self._write_buffer) + len(data) > self.max_write_buffer_size\n            ):\n                raise StreamBufferFullError(\"Reached maximum write buffer size\")\n            self._write_buffer.append(data)\n            self._total_write_index += len(data)\n        future = Future()  # type: Future[None]\n        future.add_done_callback(lambda f: f.exception())\n        self._write_futures.append((self._total_write_index, future))\n        if not self._connecting:\n            self._handle_write()\n            if self._write_buffer:\n                self._add_io_state(self.io_loop.WRITE)\n            self._maybe_add_error_listener()\n        return future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Asynchronously writes bytes or memoryview data to the stream, returning a Future that completes when writing is done. This enables non-blocking, buffered output operations with backpressure handling in I/O stream workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "set_close_callback", "line_number": 550, "body": "def set_close_callback(self, callback: Optional[Callable[[], None]]) -> None:\n        \"\"\"Call the given callback when the stream is closed.\n\n        This mostly is not necessary for applications that use the\n        `.Future` interface; all outstanding ``Futures`` will resolve\n        with a `StreamClosedError` when the stream is closed. However,\n        it is still useful as a way to signal that the stream has been\n        closed while no other read or write is in progress.\n\n        Unlike other callback-based interfaces, ``set_close_callback``\n        was not removed in Tornado 6.0.\n        \"\"\"\n        self._close_callback = callback\n        self._maybe_add_error_listener()", "is_method": true, "class_name": "BaseIOStream", "function_description": "Utility method of the BaseIOStream class that registers a callback to be invoked when the stream closes, allowing clients to handle stream closure events outside of ongoing read or write operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "close", "line_number": 565, "body": "def close(\n        self,\n        exc_info: Union[\n            None,\n            bool,\n            BaseException,\n            Tuple[\n                \"Optional[Type[BaseException]]\",\n                Optional[BaseException],\n                Optional[TracebackType],\n            ],\n        ] = False,\n    ) -> None:\n        \"\"\"Close this stream.\n\n        If ``exc_info`` is true, set the ``error`` attribute to the current\n        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n        use that instead of `sys.exc_info`).\n        \"\"\"\n        if not self.closed():\n            if exc_info:\n                if isinstance(exc_info, tuple):\n                    self.error = exc_info[1]\n                elif isinstance(exc_info, BaseException):\n                    self.error = exc_info\n                else:\n                    exc_info = sys.exc_info()\n                    if any(exc_info):\n                        self.error = exc_info[1]\n            if self._read_until_close:\n                self._read_until_close = False\n                self._finish_read(self._read_buffer_size, False)\n            elif self._read_future is not None:\n                # resolve reads that are pending and ready to complete\n                try:\n                    pos = self._find_read_pos()\n                except UnsatisfiableReadError:\n                    pass\n                else:\n                    if pos is not None:\n                        self._read_from_buffer(pos)\n            if self._state is not None:\n                self.io_loop.remove_handler(self.fileno())\n                self._state = None\n            self.close_fd()\n            self._closed = True\n        self._signal_closed()", "is_method": true, "class_name": "BaseIOStream", "function_description": "Service method of BaseIOStream that closes the stream, handles any associated exceptions, resolves pending reads, and cleans up resources to properly finalize the stream\u2019s lifecycle."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_signal_closed", "line_number": 613, "body": "def _signal_closed(self) -> None:\n        futures = []  # type: List[Future]\n        if self._read_future is not None:\n            futures.append(self._read_future)\n            self._read_future = None\n        futures += [future for _, future in self._write_futures]\n        self._write_futures.clear()\n        if self._connect_future is not None:\n            futures.append(self._connect_future)\n            self._connect_future = None\n        for future in futures:\n            if not future.done():\n                future.set_exception(StreamClosedError(real_error=self.error))\n            # Reference the exception to silence warnings. Annoyingly,\n            # this raises if the future was cancelled, but just\n            # returns any other error.\n            try:\n                future.exception()\n            except asyncio.CancelledError:\n                pass\n        if self._ssl_connect_future is not None:\n            # _ssl_connect_future expects to see the real exception (typically\n            # an ssl.SSLError), not just StreamClosedError.\n            if not self._ssl_connect_future.done():\n                if self.error is not None:\n                    self._ssl_connect_future.set_exception(self.error)\n                else:\n                    self._ssl_connect_future.set_exception(StreamClosedError())\n            self._ssl_connect_future.exception()\n            self._ssl_connect_future = None\n        if self._close_callback is not None:\n            cb = self._close_callback\n            self._close_callback = None\n            self.io_loop.add_callback(cb)\n        # Clear the buffers so they can be cleared immediately even\n        # if the IOStream object is kept alive by a reference cycle.\n        # TODO: Clear the read buffer too; it currently breaks some tests.\n        self._write_buffer = None", "is_method": true, "class_name": "BaseIOStream", "function_description": "Internal method of BaseIOStream that signals closure by setting exceptions on pending future operations and invoking any registered close callbacks to properly release resources and notify listeners of the stream closure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "reading", "line_number": 652, "body": "def reading(self) -> bool:\n        \"\"\"Returns ``True`` if we are currently reading from the stream.\"\"\"\n        return self._read_future is not None", "is_method": true, "class_name": "BaseIOStream", "function_description": "Indicates whether the BaseIOStream is currently engaged in a read operation by returning True if a read process is active. Useful for monitoring the stream's reading state in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "writing", "line_number": 656, "body": "def writing(self) -> bool:\n        \"\"\"Returns ``True`` if we are currently writing to the stream.\"\"\"\n        return bool(self._write_buffer)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Indicates whether the BaseIOStream is currently in a writing state by checking if there is data in the write buffer. Useful for managing or monitoring stream output activity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "closed", "line_number": 660, "body": "def closed(self) -> bool:\n        \"\"\"Returns ``True`` if the stream has been closed.\"\"\"\n        return self._closed", "is_method": true, "class_name": "BaseIOStream", "function_description": "Returns whether the BaseIOStream instance is closed, indicating if no further I/O operations can be performed on it."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_events", "line_number": 682, "body": "def _handle_events(self, fd: Union[int, ioloop._Selectable], events: int) -> None:\n        if self.closed():\n            gen_log.warning(\"Got events for closed stream %s\", fd)\n            return\n        try:\n            if self._connecting:\n                # Most IOLoops will report a write failed connect\n                # with the WRITE event, but SelectIOLoop reports a\n                # READ as well so we must check for connecting before\n                # either.\n                self._handle_connect()\n            if self.closed():\n                return\n            if events & self.io_loop.READ:\n                self._handle_read()\n            if self.closed():\n                return\n            if events & self.io_loop.WRITE:\n                self._handle_write()\n            if self.closed():\n                return\n            if events & self.io_loop.ERROR:\n                self.error = self.get_fd_error()\n                # We may have queued up a user callback in _handle_read or\n                # _handle_write, so don't close the IOStream until those\n                # callbacks have had a chance to run.\n                self.io_loop.add_callback(self.close)\n                return\n            state = self.io_loop.ERROR\n            if self.reading():\n                state |= self.io_loop.READ\n            if self.writing():\n                state |= self.io_loop.WRITE\n            if state == self.io_loop.ERROR and self._read_buffer_size == 0:\n                # If the connection is idle, listen for reads too so\n                # we can tell if the connection is closed.  If there is\n                # data in the read buffer we won't run the close callback\n                # yet anyway, so we don't need to listen in this case.\n                state |= self.io_loop.READ\n            if state != self._state:\n                assert (\n                    self._state is not None\n                ), \"shouldn't happen: _handle_events without self._state\"\n                self._state = state\n                self.io_loop.update_handler(self.fileno(), self._state)\n        except UnsatisfiableReadError as e:\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n        except Exception as e:\n            gen_log.error(\"Uncaught exception, closing connection.\", exc_info=True)\n            self.close(exc_info=e)\n            raise", "is_method": true, "class_name": "BaseIOStream", "function_description": "Handles and dispatches I/O events on the stream's file descriptor, managing connection state, reading, writing, errors, and closing the stream as needed to maintain asynchronous communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_read_to_buffer_loop", "line_number": 735, "body": "def _read_to_buffer_loop(self) -> Optional[int]:\n        # This method is called from _handle_read and _try_inline_read.\n        if self._read_bytes is not None:\n            target_bytes = self._read_bytes  # type: Optional[int]\n        elif self._read_max_bytes is not None:\n            target_bytes = self._read_max_bytes\n        elif self.reading():\n            # For read_until without max_bytes, or\n            # read_until_close, read as much as we can before\n            # scanning for the delimiter.\n            target_bytes = None\n        else:\n            target_bytes = 0\n        next_find_pos = 0\n        while not self.closed():\n            # Read from the socket until we get EWOULDBLOCK or equivalent.\n            # SSL sockets do some internal buffering, and if the data is\n            # sitting in the SSL object's buffer select() and friends\n            # can't see it; the only way to find out if it's there is to\n            # try to read it.\n            if self._read_to_buffer() == 0:\n                break\n\n            # If we've read all the bytes we can use, break out of\n            # this loop.\n\n            # If we've reached target_bytes, we know we're done.\n            if target_bytes is not None and self._read_buffer_size >= target_bytes:\n                break\n\n            # Otherwise, we need to call the more expensive find_read_pos.\n            # It's inefficient to do this on every read, so instead\n            # do it on the first read and whenever the read buffer\n            # size has doubled.\n            if self._read_buffer_size >= next_find_pos:\n                pos = self._find_read_pos()\n                if pos is not None:\n                    return pos\n                next_find_pos = self._read_buffer_size * 2\n        return self._find_read_pos()", "is_method": true, "class_name": "BaseIOStream", "function_description": "Provides a controlled loop for reading data into a buffer from a stream until a specified byte limit, delimiter, or stream closure is reached. It manages buffered reads efficiently, supporting reading constraints and delimiter-based stopping."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_read", "line_number": 776, "body": "def _handle_read(self) -> None:\n        try:\n            pos = self._read_to_buffer_loop()\n        except UnsatisfiableReadError:\n            raise\n        except asyncio.CancelledError:\n            raise\n        except Exception as e:\n            gen_log.warning(\"error on read: %s\" % e)\n            self.close(exc_info=e)\n            return\n        if pos is not None:\n            self._read_from_buffer(pos)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Handles data reading operations in the BaseIOStream class, managing buffer reads and error conditions to ensure reliable asynchronous data input processing. It provides robust handling and cleanup on read errors or cancellations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_start_read", "line_number": 790, "body": "def _start_read(self) -> Future:\n        if self._read_future is not None:\n            # It is an error to start a read while a prior read is unresolved.\n            # However, if the prior read is unresolved because the stream was\n            # closed without satisfying it, it's better to raise\n            # StreamClosedError instead of AssertionError. In particular, this\n            # situation occurs in harmless situations in http1connection.py and\n            # an AssertionError would be logged noisily.\n            #\n            # On the other hand, it is legal to start a new read while the\n            # stream is closed, in case the read can be satisfied from the\n            # read buffer. So we only want to check the closed status of the\n            # stream if we need to decide what kind of error to raise for\n            # \"already reading\".\n            #\n            # These conditions have proven difficult to test; we have no\n            # unittests that reliably verify this behavior so be careful\n            # when making changes here. See #2651 and #2719.\n            self._check_closed()\n            assert self._read_future is None, \"Already reading\"\n        self._read_future = Future()\n        return self._read_future", "is_method": true, "class_name": "BaseIOStream", "function_description": "Utility method in BaseIOStream that initiates a new asynchronous read operation, enforcing single-read concurrency and handling stream closure errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_finish_read", "line_number": 813, "body": "def _finish_read(self, size: int, streaming: bool) -> None:\n        if self._user_read_buffer:\n            self._read_buffer = self._after_user_read_buffer or bytearray()\n            self._after_user_read_buffer = None\n            self._read_buffer_pos = 0\n            self._read_buffer_size = len(self._read_buffer)\n            self._user_read_buffer = False\n            result = size  # type: Union[int, bytes]\n        else:\n            result = self._consume(size)\n        if self._read_future is not None:\n            future = self._read_future\n            self._read_future = None\n            future_set_result_unless_cancelled(future, result)\n        self._maybe_add_error_listener()", "is_method": true, "class_name": "BaseIOStream", "function_description": "Internal method of BaseIOStream that completes a read operation by updating buffers and setting the read result future, supporting both streaming and non-streaming read scenarios. It ensures proper state management and callback notification after a read finishes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_try_inline_read", "line_number": 829, "body": "def _try_inline_read(self) -> None:\n        \"\"\"Attempt to complete the current read operation from buffered data.\n\n        If the read can be completed without blocking, schedules the\n        read callback on the next IOLoop iteration; otherwise starts\n        listening for reads on the socket.\n        \"\"\"\n        # See if we've already got the data from a previous read\n        pos = self._find_read_pos()\n        if pos is not None:\n            self._read_from_buffer(pos)\n            return\n        self._check_closed()\n        pos = self._read_to_buffer_loop()\n        if pos is not None:\n            self._read_from_buffer(pos)\n            return\n        # We couldn't satisfy the read inline, so make sure we're\n        # listening for new data unless the stream is closed.\n        if not self.closed():\n            self._add_io_state(ioloop.IOLoop.READ)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Utility method of BaseIOStream that tries to complete a read operation immediately from existing buffered data, scheduling a callback if successful or preparing to listen for new input if more data is needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_read_to_buffer", "line_number": 851, "body": "def _read_to_buffer(self) -> Optional[int]:\n        \"\"\"Reads from the socket and appends the result to the read buffer.\n\n        Returns the number of bytes read.  Returns 0 if there is nothing\n        to read (i.e. the read returns EWOULDBLOCK or equivalent).  On\n        error closes the socket and raises an exception.\n        \"\"\"\n        try:\n            while True:\n                try:\n                    if self._user_read_buffer:\n                        buf = memoryview(self._read_buffer)[\n                            self._read_buffer_size :\n                        ]  # type: Union[memoryview, bytearray]\n                    else:\n                        buf = bytearray(self.read_chunk_size)\n                    bytes_read = self.read_from_fd(buf)\n                except (socket.error, IOError, OSError) as e:\n                    # ssl.SSLError is a subclass of socket.error\n                    if self._is_connreset(e):\n                        # Treat ECONNRESET as a connection close rather than\n                        # an error to minimize log spam  (the exception will\n                        # be available on self.error for apps that care).\n                        self.close(exc_info=e)\n                        return None\n                    self.close(exc_info=e)\n                    raise\n                break\n            if bytes_read is None:\n                return 0\n            elif bytes_read == 0:\n                self.close()\n                return 0\n            if not self._user_read_buffer:\n                self._read_buffer += memoryview(buf)[:bytes_read]\n            self._read_buffer_size += bytes_read\n        finally:\n            # Break the reference to buf so we don't waste a chunk's worth of\n            # memory in case an exception hangs on to our stack frame.\n            del buf\n        if self._read_buffer_size > self.max_buffer_size:\n            gen_log.error(\"Reached maximum read buffer size\")\n            self.close()\n            raise StreamBufferFullError(\"Reached maximum read buffer size\")\n        return bytes_read", "is_method": true, "class_name": "BaseIOStream", "function_description": "Core method of BaseIOStream that reads data from a socket into an internal buffer, handling partial reads, errors, and connection resets, while enforcing buffer size limits. It supports stream management by providing raw byte intake with error and overflow control."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_read_from_buffer", "line_number": 897, "body": "def _read_from_buffer(self, pos: int) -> None:\n        \"\"\"Attempts to complete the currently-pending read from the buffer.\n\n        The argument is either a position in the read buffer or None,\n        as returned by _find_read_pos.\n        \"\"\"\n        self._read_bytes = self._read_delimiter = self._read_regex = None\n        self._read_partial = False\n        self._finish_read(pos, False)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Internal method of the BaseIOStream class that finalizes a pending read operation from the buffer at a specified position, managing read state and completion without returning data directly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_find_read_pos", "line_number": 907, "body": "def _find_read_pos(self) -> Optional[int]:\n        \"\"\"Attempts to find a position in the read buffer that satisfies\n        the currently-pending read.\n\n        Returns a position in the buffer if the current read can be satisfied,\n        or None if it cannot.\n        \"\"\"\n        if self._read_bytes is not None and (\n            self._read_buffer_size >= self._read_bytes\n            or (self._read_partial and self._read_buffer_size > 0)\n        ):\n            num_bytes = min(self._read_bytes, self._read_buffer_size)\n            return num_bytes\n        elif self._read_delimiter is not None:\n            # Multi-byte delimiters (e.g. '\\r\\n') may straddle two\n            # chunks in the read buffer, so we can't easily find them\n            # without collapsing the buffer.  However, since protocols\n            # using delimited reads (as opposed to reads of a known\n            # length) tend to be \"line\" oriented, the delimiter is likely\n            # to be in the first few chunks.  Merge the buffer gradually\n            # since large merges are relatively expensive and get undone in\n            # _consume().\n            if self._read_buffer:\n                loc = self._read_buffer.find(\n                    self._read_delimiter, self._read_buffer_pos\n                )\n                if loc != -1:\n                    loc -= self._read_buffer_pos\n                    delimiter_len = len(self._read_delimiter)\n                    self._check_max_bytes(self._read_delimiter, loc + delimiter_len)\n                    return loc + delimiter_len\n                self._check_max_bytes(self._read_delimiter, self._read_buffer_size)\n        elif self._read_regex is not None:\n            if self._read_buffer:\n                m = self._read_regex.search(self._read_buffer, self._read_buffer_pos)\n                if m is not None:\n                    loc = m.end() - self._read_buffer_pos\n                    self._check_max_bytes(self._read_regex, loc)\n                    return loc\n                self._check_max_bytes(self._read_regex, self._read_buffer_size)\n        return None", "is_method": true, "class_name": "BaseIOStream", "function_description": "Core utility method of BaseIOStream that determines if the current read request can be fulfilled from the buffer by locating a satisfying position based on fixed byte count, delimiter, or regex. It supports managing buffered data reads flexibly for different read protocols."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_check_max_bytes", "line_number": 949, "body": "def _check_max_bytes(self, delimiter: Union[bytes, Pattern], size: int) -> None:\n        if self._read_max_bytes is not None and size > self._read_max_bytes:\n            raise UnsatisfiableReadError(\n                \"delimiter %r not found within %d bytes\"\n                % (delimiter, self._read_max_bytes)\n            )", "is_method": true, "class_name": "BaseIOStream", "function_description": "Utility method in BaseIOStream that enforces a maximum byte read limit, raising an error if a specified delimiter is not found within that byte range. It helps prevent excessive data reads during stream processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_write", "line_number": 956, "body": "def _handle_write(self) -> None:\n        while True:\n            size = len(self._write_buffer)\n            if not size:\n                break\n            assert size > 0\n            try:\n                if _WINDOWS:\n                    # On windows, socket.send blows up if given a\n                    # write buffer that's too large, instead of just\n                    # returning the number of bytes it was able to\n                    # process.  Therefore we must not call socket.send\n                    # with more than 128KB at a time.\n                    size = 128 * 1024\n\n                num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n                if num_bytes == 0:\n                    break\n                self._write_buffer.advance(num_bytes)\n                self._total_write_done_index += num_bytes\n            except BlockingIOError:\n                break\n            except (socket.error, IOError, OSError) as e:\n                if not self._is_connreset(e):\n                    # Broken pipe errors are usually caused by connection\n                    # reset, and its better to not log EPIPE errors to\n                    # minimize log spam\n                    gen_log.warning(\"Write error on %s: %s\", self.fileno(), e)\n                self.close(exc_info=e)\n                return\n\n        while self._write_futures:\n            index, future = self._write_futures[0]\n            if index > self._total_write_done_index:\n                break\n            self._write_futures.popleft()\n            future_set_result_unless_cancelled(future, None)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Handles writing buffered data to a file descriptor or socket, managing partial writes, errors, and write completion notifications to ensure reliable asynchronous output streaming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_consume", "line_number": 994, "body": "def _consume(self, loc: int) -> bytes:\n        # Consume loc bytes from the read buffer and return them\n        if loc == 0:\n            return b\"\"\n        assert loc <= self._read_buffer_size\n        # Slice the bytearray buffer into bytes, without intermediate copying\n        b = (\n            memoryview(self._read_buffer)[\n                self._read_buffer_pos : self._read_buffer_pos + loc\n            ]\n        ).tobytes()\n        self._read_buffer_pos += loc\n        self._read_buffer_size -= loc\n        # Amortized O(1) shrink\n        # (this heuristic is implemented natively in Python 3.4+\n        #  but is replicated here for Python 2)\n        if self._read_buffer_pos > self._read_buffer_size:\n            del self._read_buffer[: self._read_buffer_pos]\n            self._read_buffer_pos = 0\n        return b", "is_method": true, "class_name": "BaseIOStream", "function_description": "Core internal method of BaseIOStream that extracts and removes a specified number of bytes from its read buffer, providing efficient sequential consumption of buffered data for downstream processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_check_closed", "line_number": 1015, "body": "def _check_closed(self) -> None:\n        if self.closed():\n            raise StreamClosedError(real_error=self.error)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Internal check in BaseIOStream that raises an error if the stream is closed, ensuring operations are performed only on open streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_maybe_add_error_listener", "line_number": 1019, "body": "def _maybe_add_error_listener(self) -> None:\n        # This method is part of an optimization: to detect a connection that\n        # is closed when we're not actively reading or writing, we must listen\n        # for read events.  However, it is inefficient to do this when the\n        # connection is first established because we are going to read or write\n        # immediately anyway.  Instead, we insert checks at various times to\n        # see if the connection is idle and add the read listener then.\n        if self._state is None or self._state == ioloop.IOLoop.ERROR:\n            if (\n                not self.closed()\n                and self._read_buffer_size == 0\n                and self._close_callback is not None\n            ):\n                self._add_io_state(ioloop.IOLoop.READ)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Adds a read event listener to detect closed connections only when the stream is idle, optimizing resource use by delaying the listener until needed for error detection during inactivity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_add_io_state", "line_number": 1034, "body": "def _add_io_state(self, state: int) -> None:\n        \"\"\"Adds `state` (IOLoop.{READ,WRITE} flags) to our event handler.\n\n        Implementation notes: Reads and writes have a fast path and a\n        slow path.  The fast path reads synchronously from socket\n        buffers, while the slow path uses `_add_io_state` to schedule\n        an IOLoop callback.\n\n        To detect closed connections, we must have called\n        `_add_io_state` at some point, but we want to delay this as\n        much as possible so we don't have to set an `IOLoop.ERROR`\n        listener that will be overwritten by the next slow-path\n        operation. If a sequence of fast-path ops do not end in a\n        slow-path op, (e.g. for an @asynchronous long-poll request),\n        we must add the error handler.\n\n        TODO: reevaluate this now that callbacks are gone.\n\n        \"\"\"\n        if self.closed():\n            # connection has been closed, so there can be no future events\n            return\n        if self._state is None:\n            self._state = ioloop.IOLoop.ERROR | state\n            self.io_loop.add_handler(self.fileno(), self._handle_events, self._state)\n        elif not self._state & state:\n            self._state = self._state | state\n            self.io_loop.update_handler(self.fileno(), self._state)", "is_method": true, "class_name": "BaseIOStream", "function_description": "Core method of BaseIOStream that registers or updates I/O event flags to monitor read/write readiness and errors on the stream\u2019s file descriptor, enabling asynchronous event handling in an I/O loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_is_connreset", "line_number": 1063, "body": "def _is_connreset(self, exc: BaseException) -> bool:\n        \"\"\"Return ``True`` if exc is ECONNRESET or equivalent.\n\n        May be overridden in subclasses.\n        \"\"\"\n        return (\n            isinstance(exc, (socket.error, IOError))\n            and errno_from_exception(exc) in _ERRNO_CONNRESET\n        )", "is_method": true, "class_name": "BaseIOStream", "function_description": "Checks if a given exception corresponds to a connection reset error, allowing subclasses to identify and handle such network interruptions consistently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "fileno", "line_number": 1127, "body": "def fileno(self) -> Union[int, ioloop._Selectable]:\n        return self.socket", "is_method": true, "class_name": "IOStream", "function_description": "Returns the underlying file descriptor or selectable socket associated with the IOStream for direct low-level I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "close_fd", "line_number": 1130, "body": "def close_fd(self) -> None:\n        self.socket.close()\n        self.socket = None", "is_method": true, "class_name": "IOStream", "function_description": "Closes the underlying socket connection and releases the associated resource in the IOStream class. It ensures the stream is properly terminated and no longer usable."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "get_fd_error", "line_number": 1134, "body": "def get_fd_error(self) -> Optional[Exception]:\n        errno = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        return socket.error(errno, os.strerror(errno))", "is_method": true, "class_name": "IOStream", "function_description": "Method of IOStream that retrieves the current socket error as an exception object, facilitating error handling for socket operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_from_fd", "line_number": 1138, "body": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            return self.socket.recv_into(buf, len(buf))\n        except BlockingIOError:\n            return None\n        finally:\n            del buf", "is_method": true, "class_name": "IOStream", "function_description": "Method of IOStream that attempts to read bytes directly from a socket into a buffer, returning the number of bytes read or None if the operation would block. It enables non-blocking, low-level input operations using file descriptors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "write_to_fd", "line_number": 1146, "body": "def write_to_fd(self, data: memoryview) -> int:\n        try:\n            return self.socket.send(data)  # type: ignore\n        finally:\n            # Avoid keeping to data, which can be a memoryview.\n            # See https://github.com/tornadoweb/tornado/pull/2008\n            del data", "is_method": true, "class_name": "IOStream", "function_description": "Writes data from a memoryview to the socket associated with the IOStream instance and returns the number of bytes sent. This method manages data transfer while ensuring memory is promptly released after sending."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "connect", "line_number": 1154, "body": "def connect(\n        self: _IOStreamType, address: Any, server_hostname: Optional[str] = None\n    ) -> \"Future[_IOStreamType]\":\n        \"\"\"Connects the socket to a remote address without blocking.\n\n        May only be called if the socket passed to the constructor was\n        not previously connected.  The address parameter is in the\n        same format as for `socket.connect <socket.socket.connect>` for\n        the type of socket passed to the IOStream constructor,\n        e.g. an ``(ip, port)`` tuple.  Hostnames are accepted here,\n        but will be resolved synchronously and block the IOLoop.\n        If you have a hostname instead of an IP address, the `.TCPClient`\n        class is recommended instead of calling this method directly.\n        `.TCPClient` will do asynchronous DNS resolution and handle\n        both IPv4 and IPv6.\n\n        If ``callback`` is specified, it will be called with no\n        arguments when the connection is completed; if not this method\n        returns a `.Future` (whose result after a successful\n        connection will be the stream itself).\n\n        In SSL mode, the ``server_hostname`` parameter will be used\n        for certificate validation (unless disabled in the\n        ``ssl_options``) and SNI (if supported; requires Python\n        2.7.9+).\n\n        Note that it is safe to call `IOStream.write\n        <BaseIOStream.write>` while the connection is pending, in\n        which case the data will be written as soon as the connection\n        is ready.  Calling `IOStream` read methods before the socket is\n        connected works on some platforms but is non-portable.\n\n        .. versionchanged:: 4.0\n            If no callback is given, returns a `.Future`.\n\n        .. versionchanged:: 4.2\n           SSL certificates are validated by default; pass\n           ``ssl_options=dict(cert_reqs=ssl.CERT_NONE)`` or a\n           suitably-configured `ssl.SSLContext` to the\n           `SSLIOStream` constructor to disable.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        self._connecting = True\n        future = Future()  # type: Future[_IOStreamType]\n        self._connect_future = typing.cast(\"Future[IOStream]\", future)\n        try:\n            self.socket.connect(address)\n        except BlockingIOError:\n            # In non-blocking mode we expect connect() to raise an\n            # exception with EINPROGRESS or EWOULDBLOCK.\n            pass\n        except socket.error as e:\n            # On freebsd, other errors such as ECONNREFUSED may be\n            # returned immediately when attempting to connect to\n            # localhost, so handle them the same way as an error\n            # reported later in _handle_connect.\n            if future is None:\n                gen_log.warning(\"Connect error on fd %s: %s\", self.socket.fileno(), e)\n            self.close(exc_info=e)\n            return future\n        self._add_io_state(self.io_loop.WRITE)\n        return future", "is_method": true, "class_name": "IOStream", "function_description": "Connects the IOStream socket to a remote address asynchronously, returning a future that resolves when the connection is established. It supports SSL hostname validation and allows non-blocking writes during the connection process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "start_tls", "line_number": 1222, "body": "def start_tls(\n        self,\n        server_side: bool,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        server_hostname: Optional[str] = None,\n    ) -> Awaitable[\"SSLIOStream\"]:\n        \"\"\"Convert this `IOStream` to an `SSLIOStream`.\n\n        This enables protocols that begin in clear-text mode and\n        switch to SSL after some initial negotiation (such as the\n        ``STARTTLS`` extension to SMTP and IMAP).\n\n        This method cannot be used if there are outstanding reads\n        or writes on the stream, or if there is any data in the\n        IOStream's buffer (data in the operating system's socket\n        buffer is allowed).  This means it must generally be used\n        immediately after reading or writing the last clear-text\n        data.  It can also be used immediately after connecting,\n        before any reads or writes.\n\n        The ``ssl_options`` argument may be either an `ssl.SSLContext`\n        object or a dictionary of keyword arguments for the\n        `ssl.wrap_socket` function.  The ``server_hostname`` argument\n        will be used for certificate validation unless disabled\n        in the ``ssl_options``.\n\n        This method returns a `.Future` whose result is the new\n        `SSLIOStream`.  After this method has been called,\n        any other operation on the original stream is undefined.\n\n        If a close callback is defined on this stream, it will be\n        transferred to the new stream.\n\n        .. versionadded:: 4.0\n\n        .. versionchanged:: 4.2\n           SSL certificates are validated by default; pass\n           ``ssl_options=dict(cert_reqs=ssl.CERT_NONE)`` or a\n           suitably-configured `ssl.SSLContext` to disable.\n        \"\"\"\n        if (\n            self._read_future\n            or self._write_futures\n            or self._connect_future\n            or self._closed\n            or self._read_buffer\n            or self._write_buffer\n        ):\n            raise ValueError(\"IOStream is not idle; cannot convert to SSL\")\n        if ssl_options is None:\n            if server_side:\n                ssl_options = _server_ssl_defaults\n            else:\n                ssl_options = _client_ssl_defaults\n\n        socket = self.socket\n        self.io_loop.remove_handler(socket)\n        self.socket = None  # type: ignore\n        socket = ssl_wrap_socket(\n            socket,\n            ssl_options,\n            server_hostname=server_hostname,\n            server_side=server_side,\n            do_handshake_on_connect=False,\n        )\n        orig_close_callback = self._close_callback\n        self._close_callback = None\n\n        future = Future()  # type: Future[SSLIOStream]\n        ssl_stream = SSLIOStream(socket, ssl_options=ssl_options)\n        ssl_stream.set_close_callback(orig_close_callback)\n        ssl_stream._ssl_connect_future = future\n        ssl_stream.max_buffer_size = self.max_buffer_size\n        ssl_stream.read_chunk_size = self.read_chunk_size\n        return future", "is_method": true, "class_name": "IOStream", "function_description": "Method of IOStream that initiates upgrading a clear-text connection to SSL/TLS asynchronously, enabling secure communication after initial negotiation like STARTTLS in email protocols. It returns a future resolving to an SSLIOStream representing the secured connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_connect", "line_number": 1298, "body": "def _handle_connect(self) -> None:\n        try:\n            err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        except socket.error as e:\n            # Hurd doesn't allow SO_ERROR for loopback sockets because all\n            # errors for such sockets are reported synchronously.\n            if errno_from_exception(e) == errno.ENOPROTOOPT:\n                err = 0\n        if err != 0:\n            self.error = socket.error(err, os.strerror(err))\n            # IOLoop implementations may vary: some of them return\n            # an error state before the socket becomes writable, so\n            # in that case a connection failure would be handled by the\n            # error path in _handle_events instead of here.\n            if self._connect_future is None:\n                gen_log.warning(\n                    \"Connect error on fd %s: %s\",\n                    self.socket.fileno(),\n                    errno.errorcode[err],\n                )\n            self.close()\n            return\n        if self._connect_future is not None:\n            future = self._connect_future\n            self._connect_future = None\n            future_set_result_unless_cancelled(future, self)\n        self._connecting = False", "is_method": true, "class_name": "IOStream", "function_description": "Handles the completion of a socket connection attempt, managing errors and notifying any awaiting futures. It ensures proper connection state updates and cleanup in asynchronous I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "set_nodelay", "line_number": 1326, "body": "def set_nodelay(self, value: bool) -> None:\n        if self.socket is not None and self.socket.family in (\n            socket.AF_INET,\n            socket.AF_INET6,\n        ):\n            try:\n                self.socket.setsockopt(\n                    socket.IPPROTO_TCP, socket.TCP_NODELAY, 1 if value else 0\n                )\n            except socket.error as e:\n                # Sometimes setsockopt will fail if the socket is closed\n                # at the wrong time.  This can happen with HTTPServer\n                # resetting the value to ``False`` between requests.\n                if e.errno != errno.EINVAL and not self._is_connreset(e):\n                    raise", "is_method": true, "class_name": "IOStream", "function_description": "Method of IOStream that enables or disables the TCP_NODELAY option on an IPv4 or IPv6 socket to control Nagle's algorithm, optimizing data transmission latency for network communications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "reading", "line_number": 1380, "body": "def reading(self) -> bool:\n        return self._handshake_reading or super().reading()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Indicates whether the SSLIOStream is currently in a reading state, including during an SSL handshake or regular reading operation. This helps manage input readiness during secure communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "writing", "line_number": 1383, "body": "def writing(self) -> bool:\n        return self._handshake_writing or super().writing()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Indicates whether the SSLIOStream is currently in a writing state, including during SSL handshake or regular write operations. This helps manage stream status accurately during secure data transmission."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_do_ssl_handshake", "line_number": 1386, "body": "def _do_ssl_handshake(self) -> None:\n        # Based on code from test_ssl.py in the python stdlib\n        try:\n            self._handshake_reading = False\n            self._handshake_writing = False\n            self.socket.do_handshake()\n        except ssl.SSLError as err:\n            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                self._handshake_reading = True\n                return\n            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                self._handshake_writing = True\n                return\n            elif err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN):\n                return self.close(exc_info=err)\n            elif err.args[0] == ssl.SSL_ERROR_SSL:\n                try:\n                    peer = self.socket.getpeername()\n                except Exception:\n                    peer = \"(not connected)\"\n                gen_log.warning(\n                    \"SSL Error on %s %s: %s\", self.socket.fileno(), peer, err\n                )\n                return self.close(exc_info=err)\n            raise\n        except ssl.CertificateError as err:\n            # CertificateError can happen during handshake (hostname\n            # verification) and should be passed to user. Starting\n            # in Python 3.7, this error is a subclass of SSLError\n            # and will be handled by the previous block instead.\n            return self.close(exc_info=err)\n        except socket.error as err:\n            # Some port scans (e.g. nmap in -sT mode) have been known\n            # to cause do_handshake to raise EBADF and ENOTCONN, so make\n            # those errors quiet as well.\n            # https://groups.google.com/forum/?fromgroups#!topic/python-tornado/ApucKJat1_0\n            # Errno 0 is also possible in some cases (nc -z).\n            # https://github.com/tornadoweb/tornado/issues/2504\n            if self._is_connreset(err) or err.args[0] in (\n                0,\n                errno.EBADF,\n                errno.ENOTCONN,\n            ):\n                return self.close(exc_info=err)\n            raise\n        except AttributeError as err:\n            # On Linux, if the connection was reset before the call to\n            # wrap_socket, do_handshake will fail with an\n            # AttributeError.\n            return self.close(exc_info=err)\n        else:\n            self._ssl_accepting = False\n            if not self._verify_cert(self.socket.getpeercert()):\n                self.close()\n                return\n            self._finish_ssl_connect()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Handles the SSL handshake process for the SSLIOStream, managing various SSL and socket errors to establish a secure connection or close it on failure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_finish_ssl_connect", "line_number": 1443, "body": "def _finish_ssl_connect(self) -> None:\n        if self._ssl_connect_future is not None:\n            future = self._ssl_connect_future\n            self._ssl_connect_future = None\n            future_set_result_unless_cancelled(future, self)", "is_method": true, "class_name": "SSLIOStream", "function_description": "Core internal method of SSLIOStream that completes the SSL connection process by resolving the associated connection future, enabling asynchronous SSL handshake completion management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_verify_cert", "line_number": 1449, "body": "def _verify_cert(self, peercert: Any) -> bool:\n        \"\"\"Returns ``True`` if peercert is valid according to the configured\n        validation mode and hostname.\n\n        The ssl handshake already tested the certificate for a valid\n        CA signature; the only thing that remains is to check\n        the hostname.\n        \"\"\"\n        if isinstance(self._ssl_options, dict):\n            verify_mode = self._ssl_options.get(\"cert_reqs\", ssl.CERT_NONE)\n        elif isinstance(self._ssl_options, ssl.SSLContext):\n            verify_mode = self._ssl_options.verify_mode\n        assert verify_mode in (ssl.CERT_NONE, ssl.CERT_REQUIRED, ssl.CERT_OPTIONAL)\n        if verify_mode == ssl.CERT_NONE or self._server_hostname is None:\n            return True\n        cert = self.socket.getpeercert()\n        if cert is None and verify_mode == ssl.CERT_REQUIRED:\n            gen_log.warning(\"No SSL certificate given\")\n            return False\n        try:\n            ssl.match_hostname(peercert, self._server_hostname)\n        except ssl.CertificateError as e:\n            gen_log.warning(\"Invalid SSL certificate: %s\" % e)\n            return False\n        else:\n            return True", "is_method": true, "class_name": "SSLIOStream", "function_description": "Private method in SSLIOStream that verifies the peer SSL certificate's hostname matches the expected server hostname based on the configured validation mode, ensuring secure SSL connection integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_read", "line_number": 1476, "body": "def _handle_read(self) -> None:\n        if self._ssl_accepting:\n            self._do_ssl_handshake()\n            return\n        super()._handle_read()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Core internal method of SSLIOStream that manages read events by performing an SSL handshake if in acceptance phase, otherwise delegating to the standard read handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_write", "line_number": 1482, "body": "def _handle_write(self) -> None:\n        if self._ssl_accepting:\n            self._do_ssl_handshake()\n            return\n        super()._handle_write()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Internal method of SSLIOStream that manages write operations, performing the SSL handshake if required before proceeding with normal write handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "connect", "line_number": 1488, "body": "def connect(\n        self, address: Tuple, server_hostname: Optional[str] = None\n    ) -> \"Future[SSLIOStream]\":\n        self._server_hostname = server_hostname\n        # Ignore the result of connect(). If it fails,\n        # wait_for_handshake will raise an error too. This is\n        # necessary for the old semantics of the connect callback\n        # (which takes no arguments). In 6.0 this can be refactored to\n        # be a regular coroutine.\n        # TODO: This is trickier than it looks, since if write()\n        # is called with a connect() pending, we want the connect\n        # to resolve before the write. Or do we care about this?\n        # (There's a test for it, but I think in practice users\n        # either wait for the connect before performing a write or\n        # they don't care about the connect Future at all)\n        fut = super().connect(address)\n        fut.add_done_callback(lambda f: f.exception())\n        return self.wait_for_handshake()", "is_method": true, "class_name": "SSLIOStream", "function_description": "Method of SSLIOStream that initiates a connection to a specified address and returns a Future that resolves once the SSL handshake completes, enabling asynchronous SSL connection setup with optional server hostname verification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_handle_connect", "line_number": 1507, "body": "def _handle_connect(self) -> None:\n        # Call the superclass method to check for errors.\n        super()._handle_connect()\n        if self.closed():\n            return\n        # When the connection is complete, wrap the socket for SSL\n        # traffic.  Note that we do this by overriding _handle_connect\n        # instead of by passing a callback to super().connect because\n        # user callbacks are enqueued asynchronously on the IOLoop,\n        # but since _handle_events calls _handle_connect immediately\n        # followed by _handle_write we need this to be synchronous.\n        #\n        # The IOLoop will get confused if we swap out self.socket while the\n        # fd is registered, so remove it now and re-register after\n        # wrap_socket().\n        self.io_loop.remove_handler(self.socket)\n        old_state = self._state\n        assert old_state is not None\n        self._state = None\n        self.socket = ssl_wrap_socket(\n            self.socket,\n            self._ssl_options,\n            server_hostname=self._server_hostname,\n            do_handshake_on_connect=False,\n        )\n        self._add_io_state(old_state)", "is_method": true, "class_name": "SSLIOStream", "function_description": "Handles the completion of a connection by synchronously wrapping the socket with SSL, ensuring secure communication within the IOLoop while managing socket registration states correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "wait_for_handshake", "line_number": 1534, "body": "def wait_for_handshake(self) -> \"Future[SSLIOStream]\":\n        \"\"\"Wait for the initial SSL handshake to complete.\n\n        If a ``callback`` is given, it will be called with no\n        arguments once the handshake is complete; otherwise this\n        method returns a `.Future` which will resolve to the\n        stream itself after the handshake is complete.\n\n        Once the handshake is complete, information such as\n        the peer's certificate and NPN/ALPN selections may be\n        accessed on ``self.socket``.\n\n        This method is intended for use on server-side streams\n        or after using `IOStream.start_tls`; it should not be used\n        with `IOStream.connect` (which already waits for the\n        handshake to complete). It may only be called once per stream.\n\n        .. versionadded:: 4.2\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        if self._ssl_connect_future is not None:\n            raise RuntimeError(\"Already waiting\")\n        future = self._ssl_connect_future = Future()\n        if not self._ssl_accepting:\n            self._finish_ssl_connect()\n        return future", "is_method": true, "class_name": "SSLIOStream", "function_description": "Core method of SSLIOStream that asynchronously waits for the completion of the initial SSL handshake, returning a Future that resolves when the secure connection is established."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "write_to_fd", "line_number": 1566, "body": "def write_to_fd(self, data: memoryview) -> int:\n        try:\n            return self.socket.send(data)  # type: ignore\n        except ssl.SSLError as e:\n            if e.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                # In Python 3.5+, SSLSocket.send raises a WANT_WRITE error if\n                # the socket is not writeable; we need to transform this into\n                # an EWOULDBLOCK socket.error or a zero return value,\n                # either of which will be recognized by the caller of this\n                # method. Prior to Python 3.5, an unwriteable socket would\n                # simply return 0 bytes written.\n                return 0\n            raise\n        finally:\n            # Avoid keeping to data, which can be a memoryview.\n            # See https://github.com/tornadoweb/tornado/pull/2008\n            del data", "is_method": true, "class_name": "SSLIOStream", "function_description": "Core method of SSLIOStream that attempts to write byte data to a socket while handling SSL-specific non-blocking write conditions, returning the number of bytes sent or zero if the socket is temporarily unwriteable."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_from_fd", "line_number": 1584, "body": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            if self._ssl_accepting:\n                # If the handshake hasn't finished yet, there can't be anything\n                # to read (attempting to read may or may not raise an exception\n                # depending on the SSL version)\n                return None\n            try:\n                return self.socket.recv_into(buf, len(buf))\n            except ssl.SSLError as e:\n                # SSLError is a subclass of socket.error, so this except\n                # block must come first.\n                if e.args[0] == ssl.SSL_ERROR_WANT_READ:\n                    return None\n                else:\n                    raise\n            except BlockingIOError:\n                return None\n        finally:\n            del buf", "is_method": true, "class_name": "SSLIOStream", "function_description": "Provides a non-blocking read operation on an SSL socket, returning the number of bytes read or None if the read cannot proceed (e.g., during handshake or would block). Useful for SSL stream data retrieval without stalling the program."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "_is_connreset", "line_number": 1605, "body": "def _is_connreset(self, e: BaseException) -> bool:\n        if isinstance(e, ssl.SSLError) and e.args[0] == ssl.SSL_ERROR_EOF:\n            return True\n        return super()._is_connreset(e)", "is_method": true, "class_name": "SSLIOStream", "function_description": "Utility method in SSLIOStream that detects if an SSL error corresponds to a connection reset due to EOF, enhancing error handling for SSL socket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "fileno", "line_number": 1628, "body": "def fileno(self) -> int:\n        return self.fd", "is_method": true, "class_name": "PipeIOStream", "function_description": "Returns the file descriptor associated with the PipeIOStream, allowing other functions to access the underlying OS-level file handle for IO operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "close_fd", "line_number": 1631, "body": "def close_fd(self) -> None:\n        self._fio.close()", "is_method": true, "class_name": "PipeIOStream", "function_description": "Closes the internal file-like resource managed by the PipeIOStream instance, ensuring proper release of system resources. This is essential for cleanup in stream handling or inter-process communication contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "write_to_fd", "line_number": 1634, "body": "def write_to_fd(self, data: memoryview) -> int:\n        try:\n            return os.write(self.fd, data)  # type: ignore\n        finally:\n            # Avoid keeping to data, which can be a memoryview.\n            # See https://github.com/tornadoweb/tornado/pull/2008\n            del data", "is_method": true, "class_name": "PipeIOStream", "function_description": "Core method in PipeIOStream that writes bytes data directly to a file descriptor, ensuring efficient transmission while managing memory references for resource optimization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/iostream.py", "function": "read_from_fd", "line_number": 1642, "body": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            return self._fio.readinto(buf)  # type: ignore\n        except (IOError, OSError) as e:\n            if errno_from_exception(e) == errno.EBADF:\n                # If the writing half of a pipe is closed, select will\n                # report it as readable but reads will fail with EBADF.\n                self.close(exc_info=e)\n                return None\n            else:\n                raise\n        finally:\n            del buf", "is_method": true, "class_name": "PipeIOStream", "function_description": "Method in PipeIOStream that reads data into a buffer from a file descriptor, handling closed pipe errors gracefully by closing the stream and signaling end-of-input."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/speedups.py", "function": "websocket_mask", "line_number": 1, "body": "def websocket_mask(mask: bytes, data: bytes) -> bytes: ...", "is_method": false, "function_description": "Utility function that applies a WebSocket masking key to data bytes, enabling proper encoding or decoding of WebSocket frames per the protocol specification. It is useful for WebSocket communication handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "get", "line_number": 61, "body": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n    return Locale.get_closest(*locale_codes)", "is_method": false, "function_description": "Utility function that returns the best matching locale for given locale codes, defaulting to \"en_US\" if none match. Useful for selecting appropriate language settings in localization contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "set_default_locale", "line_number": 75, "body": "def set_default_locale(code: str) -> None:\n    \"\"\"Sets the default locale.\n\n    The default locale is assumed to be the language used for all strings\n    in the system. The translations loaded from disk are mappings from\n    the default locale to the destination locale. Consequently, you don't\n    need to create a translation file for the default locale.\n    \"\"\"\n    global _default_locale\n    global _supported_locales\n    _default_locale = code\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])", "is_method": false, "function_description": "Sets the system's default language locale, establishing the base language for string translations and updating supported locales accordingly. This function helps manage internationalization by defining the source locale for translation mappings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "load_translations", "line_number": 89, "body": "def load_translations(directory: str, encoding: Optional[str] = None) -> None:\n    \"\"\"Loads translations from CSV files in a directory.\n\n    Translations are strings with optional Python-style named placeholders\n    (e.g., ``My name is %(name)s``) and their associated translations.\n\n    The directory should have translation files of the form ``LOCALE.csv``,\n    e.g. ``es_GT.csv``. The CSV files should have two or three columns: string,\n    translation, and an optional plural indicator. Plural indicators should\n    be one of \"plural\" or \"singular\". A given string can have both singular\n    and plural forms. For example ``%(name)s liked this`` may have a\n    different verb conjugation depending on whether %(name)s is one\n    name or a list of names. There should be two rows in the CSV file for\n    that string, one with plural indicator \"singular\", and one \"plural\".\n    For strings with no verbs that would change on translation, simply\n    use \"unknown\" or the empty string (or don't include the column at all).\n\n    The file is read using the `csv` module in the default \"excel\" dialect.\n    In this format there should not be spaces after the commas.\n\n    If no ``encoding`` parameter is given, the encoding will be\n    detected automatically (among UTF-8 and UTF-16) if the file\n    contains a byte-order marker (BOM), defaulting to UTF-8 if no BOM\n    is present.\n\n    Example translation ``es_LA.csv``::\n\n        \"I love you\",\"Te amo\"\n        \"%(name)s liked this\",\"A %(name)s les gust\u00f3 esto\",\"plural\"\n        \"%(name)s liked this\",\"A %(name)s le gust\u00f3 esto\",\"singular\"\n\n    .. versionchanged:: 4.3\n       Added ``encoding`` parameter. Added support for BOM-based encoding\n       detection, UTF-16, and UTF-8-with-BOM.\n    \"\"\"\n    global _translations\n    global _supported_locales\n    _translations = {}\n    for path in os.listdir(directory):\n        if not path.endswith(\".csv\"):\n            continue\n        locale, extension = path.split(\".\")\n        if not re.match(\"[a-z]+(_[A-Z]+)?$\", locale):\n            gen_log.error(\n                \"Unrecognized locale %r (path: %s)\",\n                locale,\n                os.path.join(directory, path),\n            )\n            continue\n        full_path = os.path.join(directory, path)\n        if encoding is None:\n            # Try to autodetect encoding based on the BOM.\n            with open(full_path, \"rb\") as bf:\n                data = bf.read(len(codecs.BOM_UTF16_LE))\n            if data in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n                encoding = \"utf-16\"\n            else:\n                # utf-8-sig is \"utf-8 with optional BOM\". It's discouraged\n                # in most cases but is common with CSV files because Excel\n                # cannot read utf-8 files without a BOM.\n                encoding = \"utf-8-sig\"\n        # python 3: csv.reader requires a file open in text mode.\n        # Specify an encoding to avoid dependence on $LANG environment variable.\n        with open(full_path, encoding=encoding) as f:\n            _translations[locale] = {}\n            for i, row in enumerate(csv.reader(f)):\n                if not row or len(row) < 2:\n                    continue\n                row = [escape.to_unicode(c).strip() for c in row]\n                english, translation = row[:2]\n                if len(row) > 2:\n                    plural = row[2] or \"unknown\"\n                else:\n                    plural = \"unknown\"\n                if plural not in (\"plural\", \"singular\", \"unknown\"):\n                    gen_log.error(\n                        \"Unrecognized plural indicator %r in %s line %d\",\n                        plural,\n                        path,\n                        i + 1,\n                    )\n                    continue\n                _translations[locale].setdefault(plural, {})[english] = translation\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])\n    gen_log.debug(\"Supported locales: %s\", sorted(_supported_locales))", "is_method": false, "function_description": "Function that loads and organizes translated strings with optional plural forms from locale-specific CSV files within a directory, supporting automatic encoding detection. It enables applications to manage multilingual text resources with pluralization support for localization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "load_gettext_translations", "line_number": 176, "body": "def load_gettext_translations(directory: str, domain: str) -> None:\n    \"\"\"Loads translations from `gettext`'s locale tree\n\n    Locale tree is similar to system's ``/usr/share/locale``, like::\n\n        {directory}/{lang}/LC_MESSAGES/{domain}.mo\n\n    Three steps are required to have your app translated:\n\n    1. Generate POT translation file::\n\n        xgettext --language=Python --keyword=_:1,2 -d mydomain file1.py file2.html etc\n\n    2. Merge against existing POT file::\n\n        msgmerge old.po mydomain.po > new.po\n\n    3. Compile::\n\n        msgfmt mydomain.po -o {directory}/pt_BR/LC_MESSAGES/mydomain.mo\n    \"\"\"\n    global _translations\n    global _supported_locales\n    global _use_gettext\n    _translations = {}\n    for lang in os.listdir(directory):\n        if lang.startswith(\".\"):\n            continue  # skip .svn, etc\n        if os.path.isfile(os.path.join(directory, lang)):\n            continue\n        try:\n            os.stat(os.path.join(directory, lang, \"LC_MESSAGES\", domain + \".mo\"))\n            _translations[lang] = gettext.translation(\n                domain, directory, languages=[lang]\n            )\n        except Exception as e:\n            gen_log.error(\"Cannot load translation for '%s': %s\", lang, str(e))\n            continue\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])\n    _use_gettext = True\n    gen_log.debug(\"Supported locales: %s\", sorted(_supported_locales))", "is_method": false, "function_description": "Loads and registers gettext translations from a locale directory for a specified domain, enabling support for multiple languages in the application based on available compiled translation files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "get_supported_locales", "line_number": 219, "body": "def get_supported_locales() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n    return _supported_locales", "is_method": false, "function_description": "Function that provides all supported locale codes, enabling other components to know which locales are available for localization or internationalization purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "get_closest", "line_number": 234, "body": "def get_closest(cls, *locale_codes: str) -> \"Locale\":\n        \"\"\"Returns the closest match for the given locale code.\"\"\"\n        for code in locale_codes:\n            if not code:\n                continue\n            code = code.replace(\"-\", \"_\")\n            parts = code.split(\"_\")\n            if len(parts) > 2:\n                continue\n            elif len(parts) == 2:\n                code = parts[0].lower() + \"_\" + parts[1].upper()\n            if code in _supported_locales:\n                return cls.get(code)\n            if parts[0].lower() in _supported_locales:\n                return cls.get(parts[0].lower())\n        return cls.get(_default_locale)", "is_method": true, "class_name": "Locale", "function_description": "Method of the Locale class that returns the best matching supported locale for given locale codes, defaulting when no exact or partial match is found. It helps normalize and resolve locale preferences reliably."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "get", "line_number": 252, "body": "def get(cls, code: str) -> \"Locale\":\n        \"\"\"Returns the Locale for the given locale code.\n\n        If it is not supported, we raise an exception.\n        \"\"\"\n        if code not in cls._cache:\n            assert code in _supported_locales\n            translations = _translations.get(code, None)\n            if translations is None:\n                locale = CSVLocale(code, {})  # type: Locale\n            elif _use_gettext:\n                locale = GettextLocale(code, translations)\n            else:\n                locale = CSVLocale(code, translations)\n            cls._cache[code] = locale\n        return cls._cache[code]", "is_method": true, "class_name": "Locale", "function_description": "Provides a Locale instance for a given locale code, ensuring only supported locales are returned and caching them for efficient reuse in localization tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "format_date", "line_number": 328, "body": "def format_date(\n        self,\n        date: Union[int, float, datetime.datetime],\n        gmt_offset: int = 0,\n        relative: bool = True,\n        shorter: bool = False,\n        full_format: bool = False,\n    ) -> str:\n        \"\"\"Formats the given date (which should be GMT).\n\n        By default, we return a relative time (e.g., \"2 minutes ago\"). You\n        can return an absolute date string with ``relative=False``.\n\n        You can force a full format date (\"July 10, 1980\") with\n        ``full_format=True``.\n\n        This method is primarily intended for dates in the past.\n        For dates in the future, we fall back to full format.\n        \"\"\"\n        if isinstance(date, (int, float)):\n            date = datetime.datetime.utcfromtimestamp(date)\n        now = datetime.datetime.utcnow()\n        if date > now:\n            if relative and (date - now).seconds < 60:\n                # Due to click skew, things are some things slightly\n                # in the future. Round timestamps in the immediate\n                # future down to now in relative mode.\n                date = now\n            else:\n                # Otherwise, future dates always use the full format.\n                full_format = True\n        local_date = date - datetime.timedelta(minutes=gmt_offset)\n        local_now = now - datetime.timedelta(minutes=gmt_offset)\n        local_yesterday = local_now - datetime.timedelta(hours=24)\n        difference = now - date\n        seconds = difference.seconds\n        days = difference.days\n\n        _ = self.translate\n        format = None\n        if not full_format:\n            if relative and days == 0:\n                if seconds < 50:\n                    return _(\"1 second ago\", \"%(seconds)d seconds ago\", seconds) % {\n                        \"seconds\": seconds\n                    }\n\n                if seconds < 50 * 60:\n                    minutes = round(seconds / 60.0)\n                    return _(\"1 minute ago\", \"%(minutes)d minutes ago\", minutes) % {\n                        \"minutes\": minutes\n                    }\n\n                hours = round(seconds / (60.0 * 60))\n                return _(\"1 hour ago\", \"%(hours)d hours ago\", hours) % {\"hours\": hours}\n\n            if days == 0:\n                format = _(\"%(time)s\")\n            elif days == 1 and local_date.day == local_yesterday.day and relative:\n                format = _(\"yesterday\") if shorter else _(\"yesterday at %(time)s\")\n            elif days < 5:\n                format = _(\"%(weekday)s\") if shorter else _(\"%(weekday)s at %(time)s\")\n            elif days < 334:  # 11mo, since confusing for same month last year\n                format = (\n                    _(\"%(month_name)s %(day)s\")\n                    if shorter\n                    else _(\"%(month_name)s %(day)s at %(time)s\")\n                )\n\n        if format is None:\n            format = (\n                _(\"%(month_name)s %(day)s, %(year)s\")\n                if shorter\n                else _(\"%(month_name)s %(day)s, %(year)s at %(time)s\")\n            )\n\n        tfhour_clock = self.code not in (\"en\", \"en_US\", \"zh_CN\")\n        if tfhour_clock:\n            str_time = \"%d:%02d\" % (local_date.hour, local_date.minute)\n        elif self.code == \"zh_CN\":\n            str_time = \"%s%d:%02d\" % (\n                (u\"\\u4e0a\\u5348\", u\"\\u4e0b\\u5348\")[local_date.hour >= 12],\n                local_date.hour % 12 or 12,\n                local_date.minute,\n            )\n        else:\n            str_time = \"%d:%02d %s\" % (\n                local_date.hour % 12 or 12,\n                local_date.minute,\n                (\"am\", \"pm\")[local_date.hour >= 12],\n            )\n\n        return format % {\n            \"month_name\": self._months[local_date.month - 1],\n            \"weekday\": self._weekdays[local_date.weekday()],\n            \"day\": str(local_date.day),\n            \"year\": str(local_date.year),\n            \"time\": str_time,\n        }", "is_method": true, "class_name": "Locale", "function_description": "Formats a given GMT date into a localized, human-readable string showing relative or absolute time. Useful for displaying past dates with options for concise, full, or culturally formatted timestamps."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "format_day", "line_number": 428, "body": "def format_day(\n        self, date: datetime.datetime, gmt_offset: int = 0, dow: bool = True\n    ) -> bool:\n        \"\"\"Formats the given date as a day of week.\n\n        Example: \"Monday, January 22\". You can remove the day of week with\n        ``dow=False``.\n        \"\"\"\n        local_date = date - datetime.timedelta(minutes=gmt_offset)\n        _ = self.translate\n        if dow:\n            return _(\"%(weekday)s, %(month_name)s %(day)s\") % {\n                \"month_name\": self._months[local_date.month - 1],\n                \"weekday\": self._weekdays[local_date.weekday()],\n                \"day\": str(local_date.day),\n            }\n        else:\n            return _(\"%(month_name)s %(day)s\") % {\n                \"month_name\": self._months[local_date.month - 1],\n                \"day\": str(local_date.day),\n            }", "is_method": true, "class_name": "Locale", "function_description": "Returns a formatted string representing a date as a day of the week with month and day, optionally omitting the weekday. This aids in displaying localized, human-readable date strings adjusted by GMT offset."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "list", "line_number": 450, "body": "def list(self, parts: Any) -> str:\n        \"\"\"Returns a comma-separated list for the given list of parts.\n\n        The format is, e.g., \"A, B and C\", \"A and B\" or just \"A\" for lists\n        of size 1.\n        \"\"\"\n        _ = self.translate\n        if len(parts) == 0:\n            return \"\"\n        if len(parts) == 1:\n            return parts[0]\n        comma = u\" \\u0648 \" if self.code.startswith(\"fa\") else u\", \"\n        return _(\"%(commas)s and %(last)s\") % {\n            \"commas\": comma.join(parts[:-1]),\n            \"last\": parts[len(parts) - 1],\n        }", "is_method": true, "class_name": "Locale", "function_description": "Utility method of the Locale class that formats a list of items into a natural language string with localized separators, supporting languages with different conjunction and comma usage. It improves readability when presenting item lists in user interfaces."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "friendly_number", "line_number": 467, "body": "def friendly_number(self, value: int) -> str:\n        \"\"\"Returns a comma-separated number for the given integer.\"\"\"\n        if self.code not in (\"en\", \"en_US\"):\n            return str(value)\n        s = str(value)\n        parts = []\n        while s:\n            parts.append(s[-3:])\n            s = s[:-3]\n        return \",\".join(reversed(parts))", "is_method": true, "class_name": "Locale", "function_description": "Method of the Locale class that formats integers with commas as thousands separators for English locales, improving number readability. It returns the number as-is for other locales without formatting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "translate", "line_number": 486, "body": "def translate(\n        self,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if plural_message is not None:\n            assert count is not None\n            if count != 1:\n                message = plural_message\n                message_dict = self.translations.get(\"plural\", {})\n            else:\n                message_dict = self.translations.get(\"singular\", {})\n        else:\n            message_dict = self.translations.get(\"unknown\", {})\n        return message_dict.get(message, message)", "is_method": true, "class_name": "CSVLocale", "function_description": "Provides localized translation for messages with optional pluralization based on a count, supporting singular and plural forms within the CSVLocale context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "pgettext", "line_number": 503, "body": "def pgettext(\n        self,\n        context: str,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if self.translations:\n            gen_log.warning(\"pgettext is not supported by CSVLocale\")\n        return self.translate(message, plural_message, count)", "is_method": true, "class_name": "CSVLocale", "function_description": "Method of CSVLocale that attempts contextual translation but falls back to basic translation, warning that contextual translations (pgettext) are unsupported by this locale type."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "translate", "line_number": 525, "body": "def translate(\n        self,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if plural_message is not None:\n            assert count is not None\n            return self.ngettext(message, plural_message, count)\n        else:\n            return self.gettext(message)", "is_method": true, "class_name": "GettextLocale", "function_description": "Method of GettextLocale that returns the translated form of a message, handling singular and plural forms based on an optional count to provide correct localized text. It supports pluralization-aware translation for internationalization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/locale.py", "function": "pgettext", "line_number": 537, "body": "def pgettext(\n        self,\n        context: str,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        \"\"\"Allows to set context for translation, accepts plural forms.\n\n        Usage example::\n\n            pgettext(\"law\", \"right\")\n            pgettext(\"good\", \"right\")\n\n        Plural message example::\n\n            pgettext(\"organization\", \"club\", \"clubs\", len(clubs))\n            pgettext(\"stick\", \"club\", \"clubs\", len(clubs))\n\n        To generate POT file with context, add following options to step 1\n        of `load_gettext_translations` sequence::\n\n            xgettext [basic options] --keyword=pgettext:1c,2 --keyword=pgettext:1c,2,3\n\n        .. versionadded:: 4.2\n        \"\"\"\n        if plural_message is not None:\n            assert count is not None\n            msgs_with_ctxt = (\n                \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message),\n                \"%s%s%s\" % (context, CONTEXT_SEPARATOR, plural_message),\n                count,\n            )\n            result = self.ngettext(*msgs_with_ctxt)\n            if CONTEXT_SEPARATOR in result:\n                # Translation not found\n                result = self.ngettext(message, plural_message, count)\n            return result\n        else:\n            msg_with_ctxt = \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message)\n            result = self.gettext(msg_with_ctxt)\n            if CONTEXT_SEPARATOR in result:\n                # Translation not found\n                result = message\n            return result", "is_method": true, "class_name": "GettextLocale", "function_description": "Retrieves translations for messages with contextual disambiguation, supporting singular and plural forms. Enables accurate localization by distinguishing identical words used in different contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "bind_sockets", "line_number": 55, "body": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n    if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"):\n        raise ValueError(\"the platform doesn't support SO_REUSEPORT\")\n\n    sockets = []\n    if address == \"\":\n        address = None\n    if not socket.has_ipv6 and family == socket.AF_UNSPEC:\n        # Python can be compiled with --disable-ipv6, which causes\n        # operations on AF_INET6 sockets to fail, but does not\n        # automatically exclude those results from getaddrinfo\n        # results.\n        # http://bugs.python.org/issue16208\n        family = socket.AF_INET\n    if flags is None:\n        flags = socket.AI_PASSIVE\n    bound_port = None\n    unique_addresses = set()  # type: set\n    for res in sorted(\n        socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags),\n        key=lambda x: x[0],\n    ):\n        if res in unique_addresses:\n            continue\n\n        unique_addresses.add(res)\n\n        af, socktype, proto, canonname, sockaddr = res\n        if (\n            sys.platform == \"darwin\"\n            and address == \"localhost\"\n            and af == socket.AF_INET6\n            and sockaddr[3] != 0\n        ):\n            # Mac OS X includes a link-local address fe80::1%lo0 in the\n            # getaddrinfo results for 'localhost'.  However, the firewall\n            # doesn't understand that this is a local address and will\n            # prompt for access (often repeatedly, due to an apparent\n            # bug in its ability to remember granting access to an\n            # application). Skip these addresses.\n            continue\n        try:\n            sock = socket.socket(af, socktype, proto)\n        except socket.error as e:\n            if errno_from_exception(e) == errno.EAFNOSUPPORT:\n                continue\n            raise\n        if os.name != \"nt\":\n            try:\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            except socket.error as e:\n                if errno_from_exception(e) != errno.ENOPROTOOPT:\n                    # Hurd doesn't support SO_REUSEADDR.\n                    raise\n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        if af == socket.AF_INET6:\n            # On linux, ipv6 sockets accept ipv4 too by default,\n            # but this makes it impossible to bind to both\n            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,\n            # separate sockets *must* be used to listen for both ipv4\n            # and ipv6.  For consistency, always disable ipv4 on our\n            # ipv6 sockets and use a separate ipv4 socket when needed.\n            #\n            # Python 2.x on windows doesn't have IPPROTO_IPV6.\n            if hasattr(socket, \"IPPROTO_IPV6\"):\n                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)\n\n        # automatic port allocation with port=None\n        # should bind on the same port on IPv4 and IPv6\n        host, requested_port = sockaddr[:2]\n        if requested_port == 0 and bound_port is not None:\n            sockaddr = tuple([host, bound_port] + list(sockaddr[2:]))\n\n        sock.setblocking(False)\n        try:\n            sock.bind(sockaddr)\n        except OSError as e:\n            if (\n                errno_from_exception(e) == errno.EADDRNOTAVAIL\n                and address == \"localhost\"\n                and sockaddr[0] == \"::1\"\n            ):\n                # On some systems (most notably docker with default\n                # configurations), ipv6 is partially disabled:\n                # socket.has_ipv6 is true, we can create AF_INET6\n                # sockets, and getaddrinfo(\"localhost\", ...,\n                # AF_PASSIVE) resolves to ::1, but we get an error\n                # when binding.\n                #\n                # Swallow the error, but only for this specific case.\n                # If EADDRNOTAVAIL occurs in other situations, it\n                # might be a real problem like a typo in a\n                # configuration.\n                sock.close()\n                continue\n            else:\n                raise\n        bound_port = sock.getsockname()[1]\n        sock.listen(backlog)\n        sockets.append(sock)\n    return sockets", "is_method": false, "function_description": "Creates and returns non-blocking listening sockets bound to a specified port and address, supporting multiple IPs and IPv4/IPv6. Useful for setting up server sockets with options like address reuse and port sharing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "add_accept_handler", "line_number": 226, "body": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n       A callable is returned (``None`` was returned before).\n    \"\"\"\n    io_loop = IOLoop.current()\n    removed = [False]\n\n    def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)\n\n    def remove_handler() -> None:\n        io_loop.remove_handler(sock)\n        removed[0] = True\n\n    io_loop.add_handler(sock, accept_handler, IOLoop.READ)\n    return remove_handler", "is_method": false, "function_description": "Function that adds an asynchronous event handler to accept new socket connections and runs a callback on each. It returns a callable to remove the handler and stop accepting further connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "is_valid_ip", "line_number": 286, "body": "def is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n    if not ip or \"\\x00\" in ip:\n        # getaddrinfo resolves empty strings to localhost, and truncates\n        # on zero bytes.\n        return False\n    try:\n        res = socket.getaddrinfo(\n            ip, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_NUMERICHOST\n        )\n        return bool(res)\n    except socket.gaierror as e:\n        if e.args[0] == socket.EAI_NONAME:\n            return False\n        raise\n    return True", "is_method": false, "function_description": "Utility function that verifies whether a given string is a valid IPv4 or IPv6 address, ensuring input correctness for networking applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "_resolve_addr", "line_number": 374, "body": "def _resolve_addr(\n    host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n) -> List[Tuple[int, Any]]:\n    # On Solaris, getaddrinfo fails if the given port is not found\n    # in /etc/services and no socket type is given, so we must pass\n    # one here.  The socket type used here doesn't seem to actually\n    # matter (we discard the one we get back in the results),\n    # so the addresses we return should still be usable with SOCK_DGRAM.\n    addrinfo = socket.getaddrinfo(host, port, family, socket.SOCK_STREAM)\n    results = []\n    for fam, socktype, proto, canonname, address in addrinfo:\n        results.append((fam, address))\n    return results", "is_method": false, "function_description": "Utility function that resolves a host and port to a list of socket address tuples filtered by address family, supporting network connection setup across different protocols and platforms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "ssl_options_to_context", "line_number": 555, "body": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n    if isinstance(ssl_options, ssl.SSLContext):\n        return ssl_options\n    assert isinstance(ssl_options, dict)\n    assert all(k in _SSL_CONTEXT_KEYWORDS for k in ssl_options), ssl_options\n    # Can't use create_default_context since this interface doesn't\n    # tell us client vs server.\n    context = ssl.SSLContext(ssl_options.get(\"ssl_version\", ssl.PROTOCOL_SSLv23))\n    if \"certfile\" in ssl_options:\n        context.load_cert_chain(\n            ssl_options[\"certfile\"], ssl_options.get(\"keyfile\", None)\n        )\n    if \"cert_reqs\" in ssl_options:\n        context.verify_mode = ssl_options[\"cert_reqs\"]\n    if \"ca_certs\" in ssl_options:\n        context.load_verify_locations(ssl_options[\"ca_certs\"])\n    if \"ciphers\" in ssl_options:\n        context.set_ciphers(ssl_options[\"ciphers\"])\n    if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n        # Disable TLS compression to avoid CRIME and related attacks.\n        # This constant depends on openssl version 1.0.\n        # TODO: Do we need to do this ourselves or can we trust\n        # the defaults?\n        context.options |= ssl.OP_NO_COMPRESSION\n    return context", "is_method": false, "function_description": "Converts SSL configuration from a dictionary to an ssl.SSLContext object, enabling modern SSL features and compatibility for components accepting either format. This facilitates secure socket setup using updated SSL context capabilities."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "ssl_wrap_socket", "line_number": 594, "body": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n    context = ssl_options_to_context(ssl_options)\n    if ssl.HAS_SNI:\n        # In python 3.4, wrap_socket only accepts the server_hostname\n        # argument if HAS_SNI is true.\n        # TODO: add a unittest (python added server-side SNI support in 3.4)\n        # In the meantime it can be manually tested with\n        # python3 -m tornado.httpclient https://sni.velox.ch\n        return context.wrap_socket(socket, server_hostname=server_hostname, **kwargs)\n    else:\n        return context.wrap_socket(socket, **kwargs)", "is_method": false, "function_description": "Utility function that wraps a given socket with SSL/TLS, supporting flexible SSL options and Server Name Indication (SNI) when available, to enable secure network communication over the socket."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "bind_unix_socket", "line_number": 191, "body": "def bind_unix_socket(\n        file: str, mode: int = 0o600, backlog: int = _DEFAULT_BACKLOG\n    ) -> socket.socket:\n        \"\"\"Creates a listening unix socket.\n\n        If a socket with the given name already exists, it will be deleted.\n        If any other file with that name exists, an exception will be\n        raised.\n\n        Returns a socket object (not a list of socket objects like\n        `bind_sockets`)\n        \"\"\"\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        try:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        except socket.error as e:\n            if errno_from_exception(e) != errno.ENOPROTOOPT:\n                # Hurd doesn't support SO_REUSEADDR\n                raise\n        sock.setblocking(False)\n        try:\n            st = os.stat(file)\n        except FileNotFoundError:\n            pass\n        else:\n            if stat.S_ISSOCK(st.st_mode):\n                os.remove(file)\n            else:\n                raise ValueError(\"File %s exists and is not a socket\", file)\n        sock.bind(file)\n        os.chmod(file, mode)\n        sock.listen(backlog)\n        return sock", "is_method": false, "function_description": "Creates and returns a non-blocking Unix domain socket bound to the specified file path, ensuring any existing socket file is replaced while preventing conflicts with non-socket files. Useful for setting up inter-process communication over Unix sockets."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "accept_handler", "line_number": 249, "body": "def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)", "is_method": false, "function_description": "Handles incoming socket connections by accepting and processing up to a limited number at once to avoid blocking other tasks, ensuring efficient load balancing in concurrent network servers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "configurable_base", "line_number": 332, "body": "def configurable_base(cls) -> Type[\"Resolver\"]:\n        return Resolver", "is_method": true, "class_name": "Resolver", "function_description": "Returns the Resolver class as the base class for configuration purposes. This method provides a consistent base type for subclasses in the Resolver hierarchy."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "configurable_default", "line_number": 336, "body": "def configurable_default(cls) -> Type[\"Resolver\"]:\n        return DefaultExecutorResolver", "is_method": true, "class_name": "Resolver", "function_description": "Returns the default executor resolver class used as a fallback configuration within the Resolver system. This enables standardized default behavior for resolver instances."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "initialize", "line_number": 422, "body": "def initialize(\n        self,\n        executor: Optional[concurrent.futures.Executor] = None,\n        close_executor: bool = True,\n    ) -> None:\n        self.io_loop = IOLoop.current()\n        if executor is not None:\n            self.executor = executor\n            self.close_executor = close_executor\n        else:\n            self.executor = dummy_executor\n            self.close_executor = False", "is_method": true, "class_name": "ExecutorResolver", "function_description": "Initializes the ExecutorResolver with a given or default executor and manages whether the executor should be closed on cleanup, enabling controlled execution environment setup for asynchronous or concurrent tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "close", "line_number": 435, "body": "def close(self) -> None:\n        if self.close_executor:\n            self.executor.shutdown()\n        self.executor = None", "is_method": true, "class_name": "ExecutorResolver", "function_description": "Method of the ExecutorResolver class that properly shuts down and cleans up the executor resource when requested, ensuring no further tasks are processed. It facilitates controlled termination of execution services."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "resolve", "line_number": 441, "body": "def resolve(\n        self, host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n    ) -> List[Tuple[int, Any]]:\n        return _resolve_addr(host, port, family)", "is_method": true, "class_name": "ExecutorResolver", "function_description": "Utility method in ExecutorResolver that resolves a network address for a given host and port, supporting different address families for flexible connectivity options. It provides foundational network resolution for executor communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "initialize", "line_number": 486, "body": "def initialize(self, num_threads: int = 10) -> None:  # type: ignore\n        threadpool = ThreadedResolver._create_threadpool(num_threads)\n        super().initialize(executor=threadpool, close_executor=False)", "is_method": true, "class_name": "ThreadedResolver", "function_description": "Initializes the ThreadedResolver with a thread pool of specified size to enable concurrent task execution, facilitating efficient parallel resolution of operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "_create_threadpool", "line_number": 491, "body": "def _create_threadpool(\n        cls, num_threads: int\n    ) -> concurrent.futures.ThreadPoolExecutor:\n        pid = os.getpid()\n        if cls._threadpool_pid != pid:\n            # Threads cannot survive after a fork, so if our pid isn't what it\n            # was when we created the pool then delete it.\n            cls._threadpool = None\n        if cls._threadpool is None:\n            cls._threadpool = concurrent.futures.ThreadPoolExecutor(num_threads)\n            cls._threadpool_pid = pid\n        return cls._threadpool", "is_method": true, "class_name": "ThreadedResolver", "function_description": "Creates or retrieves a thread pool executor with a specified number of threads, ensuring it resets after process forking to maintain valid thread management within the ThreadedResolver class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "close", "line_number": 532, "body": "def close(self) -> None:\n        self.resolver.close()", "is_method": true, "class_name": "OverrideResolver", "function_description": "Utility method in OverrideResolver that closes underlying resolver resources to facilitate proper cleanup and release of external connections or handles."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/netutil.py", "function": "resolve", "line_number": 535, "body": "def resolve(\n        self, host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n    ) -> Awaitable[List[Tuple[int, Any]]]:\n        if (host, port, family) in self.mapping:\n            host, port = self.mapping[(host, port, family)]\n        elif (host, port) in self.mapping:\n            host, port = self.mapping[(host, port)]\n        elif host in self.mapping:\n            host = self.mapping[host]\n        return self.resolver.resolve(host, port, family)", "is_method": true, "class_name": "OverrideResolver", "function_description": "Provides a customizable hostname and port resolution by applying user-defined overrides before delegating to an underlying resolver, enabling flexible network address mapping in asynchronous contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/wsgi.py", "function": "to_wsgi_str", "line_number": 51, "body": "def to_wsgi_str(s: bytes) -> str:\n    assert isinstance(s, bytes)\n    return s.decode(\"latin1\")", "is_method": false, "function_description": "Utility function that converts bytes to a string using Latin-1 encoding, ensuring compatibility with WSGI applications that require this specific string format for byte data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/wsgi.py", "function": "__call__", "line_number": 94, "body": "def __call__(self, request: httputil.HTTPServerRequest) -> None:\n        data = {}  # type: Dict[str, Any]\n        response = []  # type: List[bytes]\n\n        def start_response(\n            status: str,\n            headers: List[Tuple[str, str]],\n            exc_info: Optional[\n                Tuple[\n                    \"Optional[Type[BaseException]]\",\n                    Optional[BaseException],\n                    Optional[TracebackType],\n                ]\n            ] = None,\n        ) -> Callable[[bytes], Any]:\n            data[\"status\"] = status\n            data[\"headers\"] = headers\n            return response.append\n\n        app_response = self.wsgi_application(\n            WSGIContainer.environ(request), start_response\n        )\n        try:\n            response.extend(app_response)\n            body = b\"\".join(response)\n        finally:\n            if hasattr(app_response, \"close\"):\n                app_response.close()  # type: ignore\n        if not data:\n            raise Exception(\"WSGI app did not call start_response\")\n\n        status_code_str, reason = data[\"status\"].split(\" \", 1)\n        status_code = int(status_code_str)\n        headers = data[\"headers\"]  # type: List[Tuple[str, str]]\n        header_set = set(k.lower() for (k, v) in headers)\n        body = escape.utf8(body)\n        if status_code != 304:\n            if \"content-length\" not in header_set:\n                headers.append((\"Content-Length\", str(len(body))))\n            if \"content-type\" not in header_set:\n                headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))\n        if \"server\" not in header_set:\n            headers.append((\"Server\", \"TornadoServer/%s\" % tornado.version))\n\n        start_line = httputil.ResponseStartLine(\"HTTP/1.1\", status_code, reason)\n        header_obj = httputil.HTTPHeaders()\n        for key, value in headers:\n            header_obj.add(key, value)\n        assert request.connection is not None\n        request.connection.write_headers(start_line, header_obj, chunk=body)\n        request.connection.finish()\n        self._log(status_code, request)", "is_method": true, "class_name": "WSGIContainer", "function_description": "Method of WSGIContainer that adapts a WSGI application to handle an HTTP request, processes the response, sets appropriate headers, and sends the final HTTP response back to the client. It enables integration of WSGI apps within the Tornado web server environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/wsgi.py", "function": "environ", "line_number": 148, "body": "def environ(request: httputil.HTTPServerRequest) -> Dict[Text, Any]:\n        \"\"\"Converts a `tornado.httputil.HTTPServerRequest` to a WSGI environment.\n        \"\"\"\n        hostport = request.host.split(\":\")\n        if len(hostport) == 2:\n            host = hostport[0]\n            port = int(hostport[1])\n        else:\n            host = request.host\n            port = 443 if request.protocol == \"https\" else 80\n        environ = {\n            \"REQUEST_METHOD\": request.method,\n            \"SCRIPT_NAME\": \"\",\n            \"PATH_INFO\": to_wsgi_str(\n                escape.url_unescape(request.path, encoding=None, plus=False)\n            ),\n            \"QUERY_STRING\": request.query,\n            \"REMOTE_ADDR\": request.remote_ip,\n            \"SERVER_NAME\": host,\n            \"SERVER_PORT\": str(port),\n            \"SERVER_PROTOCOL\": request.version,\n            \"wsgi.version\": (1, 0),\n            \"wsgi.url_scheme\": request.protocol,\n            \"wsgi.input\": BytesIO(escape.utf8(request.body)),\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": False,\n            \"wsgi.multiprocess\": True,\n            \"wsgi.run_once\": False,\n        }\n        if \"Content-Type\" in request.headers:\n            environ[\"CONTENT_TYPE\"] = request.headers.pop(\"Content-Type\")\n        if \"Content-Length\" in request.headers:\n            environ[\"CONTENT_LENGTH\"] = request.headers.pop(\"Content-Length\")\n        for key, value in request.headers.items():\n            environ[\"HTTP_\" + key.replace(\"-\", \"_\").upper()] = value\n        return environ", "is_method": true, "class_name": "WSGIContainer", "function_description": "Converts a Tornado HTTP request into a standardized WSGI environment dictionary, enabling Tornado applications to interact with WSGI-compatible frameworks or middleware. This facilitates interoperability between Tornado and WSGI-based components."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/wsgi.py", "function": "_log", "line_number": 185, "body": "def _log(self, status_code: int, request: httputil.HTTPServerRequest) -> None:\n        if status_code < 400:\n            log_method = access_log.info\n        elif status_code < 500:\n            log_method = access_log.warning\n        else:\n            log_method = access_log.error\n        request_time = 1000.0 * request.request_time()\n        assert request.method is not None\n        assert request.uri is not None\n        summary = request.method + \" \" + request.uri + \" (\" + request.remote_ip + \")\"\n        log_method(\"%d %s %.2fms\", status_code, summary, request_time)", "is_method": true, "class_name": "WSGIContainer", "function_description": "Utility method in WSGIContainer that logs HTTP request details with severity based on status code, providing insight into request outcomes and performance timing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/wsgi.py", "function": "start_response", "line_number": 98, "body": "def start_response(\n            status: str,\n            headers: List[Tuple[str, str]],\n            exc_info: Optional[\n                Tuple[\n                    \"Optional[Type[BaseException]]\",\n                    Optional[BaseException],\n                    Optional[TracebackType],\n                ]\n            ] = None,\n        ) -> Callable[[bytes], Any]:\n            data[\"status\"] = status\n            data[\"headers\"] = headers\n            return response.append", "is_method": true, "class_name": "WSGIContainer", "function_description": "Service method of WSGIContainer that captures HTTP response status and headers, then returns a callable to append response body data for handling WSGI responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_set_timeout", "line_number": 59, "body": "def _set_timeout(\n    future: Future, timeout: Union[None, float, datetime.timedelta]\n) -> None:\n    if timeout:\n\n        def on_timeout() -> None:\n            if not future.done():\n                future.set_exception(gen.TimeoutError())\n\n        io_loop = ioloop.IOLoop.current()\n        timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n        future.add_done_callback(lambda _: io_loop.remove_timeout(timeout_handle))", "is_method": false, "function_description": "Sets a timeout on a Future, triggering a timeout exception if it isn't completed within the specified duration. This enables timeout management for asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "__anext__", "line_number": 77, "body": "def __anext__(self) -> Awaitable[_T]:\n        return self.q.get()", "is_method": true, "class_name": "_QueueIterator", "function_description": "Core asynchronous iterator method of the _QueueIterator class that awaits and returns the next item from an internal queue, facilitating asynchronous iteration over queued elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "maxsize", "line_number": 169, "body": "def maxsize(self) -> int:\n        \"\"\"Number of items allowed in the queue.\"\"\"\n        return self._maxsize", "is_method": true, "class_name": "Queue", "function_description": "Returns the maximum number of items the Queue can hold, defining its capacity limit for controlling queue size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "qsize", "line_number": 173, "body": "def qsize(self) -> int:\n        \"\"\"Number of items in the queue.\"\"\"\n        return len(self._queue)", "is_method": true, "class_name": "Queue", "function_description": "Returns the current number of items stored in the queue. This provides a quick way to check the queue's size for managing or monitoring queued elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "empty", "line_number": 177, "body": "def empty(self) -> bool:\n        return not self._queue", "is_method": true, "class_name": "Queue", "function_description": "Utility method of the Queue class that checks whether the queue is empty, returning True if it contains no elements and False otherwise. It enables other functions to verify the queue\u2019s state before processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "full", "line_number": 180, "body": "def full(self) -> bool:\n        if self.maxsize == 0:\n            return False\n        else:\n            return self.qsize() >= self.maxsize", "is_method": true, "class_name": "Queue", "function_description": "Returns whether the queue has reached its maximum capacity, indicating if no additional items can be added. Useful for managing bounded queues to prevent overflow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "put", "line_number": 186, "body": "def put(\n        self, item: _T, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> \"Future[None]\":\n        \"\"\"Put an item into the queue, perhaps waiting until there is room.\n\n        Returns a Future, which raises `tornado.util.TimeoutError` after a\n        timeout.\n\n        ``timeout`` may be a number denoting a time (on the same\n        scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.\n        \"\"\"\n        future = Future()  # type: Future[None]\n        try:\n            self.put_nowait(item)\n        except QueueFull:\n            self._putters.append((item, future))\n            _set_timeout(future, timeout)\n        else:\n            future.set_result(None)\n        return future", "is_method": true, "class_name": "Queue", "function_description": "Core method of the Queue class that asynchronously adds an item, returning a Future that completes immediately or waits with a timeout if the queue is full. It enables non-blocking item insertion with timeout handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "put_nowait", "line_number": 209, "body": "def put_nowait(self, item: _T) -> None:\n        \"\"\"Put an item into the queue without blocking.\n\n        If no free slot is immediately available, raise `QueueFull`.\n        \"\"\"\n        self._consume_expired()\n        if self._getters:\n            assert self.empty(), \"queue non-empty, why are getters waiting?\"\n            getter = self._getters.popleft()\n            self.__put_internal(item)\n            future_set_result_unless_cancelled(getter, self._get())\n        elif self.full():\n            raise QueueFull\n        else:\n            self.__put_internal(item)", "is_method": true, "class_name": "Queue", "function_description": "Non-blocking method of the Queue class that attempts to insert an item immediately, raising an exception if the queue is full, enabling efficient item addition without waiting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "get", "line_number": 225, "body": "def get(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_T]:\n        \"\"\"Remove and return an item from the queue.\n\n        Returns an awaitable which resolves once an item is available, or raises\n        `tornado.util.TimeoutError` after a timeout.\n\n        ``timeout`` may be a number denoting a time (on the same\n        scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.\n\n        .. note::\n\n           The ``timeout`` argument of this method differs from that\n           of the standard library's `queue.Queue.get`. That method\n           interprets numeric values as relative timeouts; this one\n           interprets them as absolute deadlines and requires\n           ``timedelta`` objects for relative timeouts (consistent\n           with other timeouts in Tornado).\n\n        \"\"\"\n        future = Future()  # type: Future[_T]\n        try:\n            future.set_result(self.get_nowait())\n        except QueueEmpty:\n            self._getters.append(future)\n            _set_timeout(future, timeout)\n        return future", "is_method": true, "class_name": "Queue", "function_description": "As a coroutine-compatible queue method, it provides asynchronous retrieval of items, returning a future that resolves when an item is available or raises a timeout error if a deadline is exceeded."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "get_nowait", "line_number": 256, "body": "def get_nowait(self) -> _T:\n        \"\"\"Remove and return an item from the queue without blocking.\n\n        Return an item if one is immediately available, else raise\n        `QueueEmpty`.\n        \"\"\"\n        self._consume_expired()\n        if self._putters:\n            assert self.full(), \"queue not full, why are putters waiting?\"\n            item, putter = self._putters.popleft()\n            self.__put_internal(item)\n            future_set_result_unless_cancelled(putter, None)\n            return self._get()\n        elif self.qsize():\n            return self._get()\n        else:\n            raise QueueEmpty", "is_method": true, "class_name": "Queue", "function_description": "Core Queue method that instantly removes and returns an item if available without waiting; it raises an exception if the queue is empty, supporting non-blocking retrieval in concurrent scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "task_done", "line_number": 274, "body": "def task_done(self) -> None:\n        \"\"\"Indicate that a formerly enqueued task is complete.\n\n        Used by queue consumers. For each `.get` used to fetch a task, a\n        subsequent call to `.task_done` tells the queue that the processing\n        on the task is complete.\n\n        If a `.join` is blocking, it resumes when all items have been\n        processed; that is, when every `.put` is matched by a `.task_done`.\n\n        Raises `ValueError` if called more times than `.put`.\n        \"\"\"\n        if self._unfinished_tasks <= 0:\n            raise ValueError(\"task_done() called too many times\")\n        self._unfinished_tasks -= 1\n        if self._unfinished_tasks == 0:\n            self._finished.set()", "is_method": true, "class_name": "Queue", "function_description": "Service method of the Queue class that marks a previously retrieved task as completed, helping track unfinished tasks and enabling synchronization when all tasks are processed. It supports coordination between producers and consumers in task management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "join", "line_number": 292, "body": "def join(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[None]:\n        \"\"\"Block until all items in the queue are processed.\n\n        Returns an awaitable, which raises `tornado.util.TimeoutError` after a\n        timeout.\n        \"\"\"\n        return self._finished.wait(timeout)", "is_method": true, "class_name": "Queue", "function_description": "Provides an awaitable that blocks until all queue items are processed or raises a timeout error if the wait exceeds the specified duration. Useful for synchronizing and ensuring task completion in asynchronous queue handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "__aiter__", "line_number": 302, "body": "def __aiter__(self) -> _QueueIterator[_T]:\n        return _QueueIterator(self)", "is_method": true, "class_name": "Queue", "function_description": "Enables asynchronous iteration over the Queue, allowing elements to be consumed using async for loops. This supports concurrent processing scenarios requiring non-blocking queue traversal."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_get", "line_number": 309, "body": "def _get(self) -> _T:\n        return self._queue.popleft()", "is_method": true, "class_name": "Queue", "function_description": "Core method of the Queue class that removes and returns the item at the front of the queue, supporting FIFO retrieval of elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_put", "line_number": 312, "body": "def _put(self, item: _T) -> None:\n        self._queue.append(item)", "is_method": true, "class_name": "Queue", "function_description": "Internal method of the Queue class that adds an item to the end of the queue, supporting enqueue operations within the queue management system."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "__put_internal", "line_number": 317, "body": "def __put_internal(self, item: _T) -> None:\n        self._unfinished_tasks += 1\n        self._finished.clear()\n        self._put(item)", "is_method": true, "class_name": "Queue", "function_description": "Internal method of the Queue class that adds an item while updating task tracking counters to manage completion status. It supports the queue's task coordination system."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_consume_expired", "line_number": 322, "body": "def _consume_expired(self) -> None:\n        # Remove timed-out waiters.\n        while self._putters and self._putters[0][1].done():\n            self._putters.popleft()\n\n        while self._getters and self._getters[0].done():\n            self._getters.popleft()", "is_method": true, "class_name": "Queue", "function_description": "Internal Queue method that clears out putters and getters whose wait operations have expired, maintaining queue integrity by removing stale or timed-out waiting tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "__repr__", "line_number": 330, "body": "def __repr__(self) -> str:\n        return \"<%s at %s %s>\" % (type(self).__name__, hex(id(self)), self._format())", "is_method": true, "class_name": "Queue", "function_description": "Provides a string representation of the Queue object showing its class name, memory address, and formatted internal state for debugging or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "__str__", "line_number": 333, "body": "def __str__(self) -> str:\n        return \"<%s %s>\" % (type(self).__name__, self._format())", "is_method": true, "class_name": "Queue", "function_description": "Provides a string representation of the Queue instance, displaying its class name and formatted contents for readable output. This aids debugging or logging by summarizing the queue state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_format", "line_number": 336, "body": "def _format(self) -> str:\n        result = \"maxsize=%r\" % (self.maxsize,)\n        if getattr(self, \"_queue\", None):\n            result += \" queue=%r\" % self._queue\n        if self._getters:\n            result += \" getters[%s]\" % len(self._getters)\n        if self._putters:\n            result += \" putters[%s]\" % len(self._putters)\n        if self._unfinished_tasks:\n            result += \" tasks=%s\" % self._unfinished_tasks\n        return result", "is_method": true, "class_name": "Queue", "function_description": "Internal method of the Queue class that generates a string representation of the queue's current state, including size limits and pending operations. It supports debugging by summarizing queue attributes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_init", "line_number": 374, "body": "def _init(self) -> None:\n        self._queue = []", "is_method": true, "class_name": "PriorityQueue", "function_description": "Initializes the PriorityQueue by creating an empty internal list to hold queue elements. This sets up the data structure for managing prioritized items."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_put", "line_number": 377, "body": "def _put(self, item: _T) -> None:\n        heapq.heappush(self._queue, item)", "is_method": true, "class_name": "PriorityQueue", "function_description": "Internal helper method of PriorityQueue that adds an item to the queue while maintaining heap order. It supports efficient priority-based insertion but is not intended for direct use."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_get", "line_number": 380, "body": "def _get(self) -> _T:\n        return heapq.heappop(self._queue)", "is_method": true, "class_name": "PriorityQueue", "function_description": "Internal method of PriorityQueue that removes and returns the highest-priority element from the queue. It provides the mechanism for retrieving items based on priority ordering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_put", "line_number": 410, "body": "def _put(self, item: _T) -> None:\n        self._queue.append(item)", "is_method": true, "class_name": "LifoQueue", "function_description": "Internal method of LifoQueue that adds an item to the queue following last-in, first-out order."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/queues.py", "function": "_get", "line_number": 413, "body": "def _get(self) -> _T:\n        return self._queue.pop()", "is_method": true, "class_name": "LifoQueue", "function_description": "Core method of the LifoQueue class that retrieves and removes the most recently added item, supporting last-in-first-out queue behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "initialize", "line_number": 49, "body": "def initialize(  # type: ignore\n        self, max_clients: int = 10, defaults: Optional[Dict[str, Any]] = None\n    ) -> None:\n        super().initialize(defaults=defaults)\n        # Typeshed is incomplete for CurlMulti, so just use Any for now.\n        self._multi = pycurl.CurlMulti()  # type: Any\n        self._multi.setopt(pycurl.M_TIMERFUNCTION, self._set_timeout)\n        self._multi.setopt(pycurl.M_SOCKETFUNCTION, self._handle_socket)\n        self._curls = [self._curl_create() for i in range(max_clients)]\n        self._free_list = self._curls[:]\n        self._requests = (\n            collections.deque()\n        )  # type: Deque[Tuple[HTTPRequest, Callable[[HTTPResponse], None], float]]\n        self._fds = {}  # type: Dict[int, int]\n        self._timeout = None  # type: Optional[object]\n\n        # libcurl has bugs that sometimes cause it to not report all\n        # relevant file descriptors and timeouts to TIMERFUNCTION/\n        # SOCKETFUNCTION.  Mitigate the effects of such bugs by\n        # forcing a periodic scan of all active requests.\n        self._force_timeout_callback = ioloop.PeriodicCallback(\n            self._handle_force_timeout, 1000\n        )\n        self._force_timeout_callback.start()\n\n        # Work around a bug in libcurl 7.29.0: Some fields in the curl\n        # multi object are initialized lazily, and its destructor will\n        # segfault if it is destroyed without having been used.  Add\n        # and remove a dummy handle to make sure everything is\n        # initialized.\n        dummy_curl_handle = pycurl.Curl()\n        self._multi.add_handle(dummy_curl_handle)\n        self._multi.remove_handle(dummy_curl_handle)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Initializes the CurlAsyncHTTPClient to manage multiple asynchronous HTTP requests concurrently, setting up internal client pools, event handlers, and workarounds for known libcurl bugs to ensure robust non-blocking network operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "close", "line_number": 83, "body": "def close(self) -> None:\n        self._force_timeout_callback.stop()\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n        for curl in self._curls:\n            curl.close()\n        self._multi.close()\n        super().close()\n\n        # Set below properties to None to reduce the reference count of current\n        # instance, because those properties hold some methods of current\n        # instance that will case circular reference.\n        self._force_timeout_callback = None  # type: ignore\n        self._multi = None", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Closes and cleans up all network connections and resources used by the CurlAsyncHTTPClient instance, ensuring proper shutdown and preventing resource leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "fetch_impl", "line_number": 98, "body": "def fetch_impl(\n        self, request: HTTPRequest, callback: Callable[[HTTPResponse], None]\n    ) -> None:\n        self._requests.append((request, callback, self.io_loop.time()))\n        self._process_queue()\n        self._set_timeout(0)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Core method of CurlAsyncHTTPClient that queues HTTP requests for asynchronous processing and sets up immediate timeout handling, enabling non-blocking HTTP call management with callback execution upon completion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_handle_socket", "line_number": 105, "body": "def _handle_socket(self, event: int, fd: int, multi: Any, data: bytes) -> None:\n        \"\"\"Called by libcurl when it wants to change the file descriptors\n        it cares about.\n        \"\"\"\n        event_map = {\n            pycurl.POLL_NONE: ioloop.IOLoop.NONE,\n            pycurl.POLL_IN: ioloop.IOLoop.READ,\n            pycurl.POLL_OUT: ioloop.IOLoop.WRITE,\n            pycurl.POLL_INOUT: ioloop.IOLoop.READ | ioloop.IOLoop.WRITE,\n        }\n        if event == pycurl.POLL_REMOVE:\n            if fd in self._fds:\n                self.io_loop.remove_handler(fd)\n                del self._fds[fd]\n        else:\n            ioloop_event = event_map[event]\n            # libcurl sometimes closes a socket and then opens a new\n            # one using the same FD without giving us a POLL_NONE in\n            # between.  This is a problem with the epoll IOLoop,\n            # because the kernel can tell when a socket is closed and\n            # removes it from the epoll automatically, causing future\n            # update_handler calls to fail.  Since we can't tell when\n            # this has happened, always use remove and re-add\n            # instead of update.\n            if fd in self._fds:\n                self.io_loop.remove_handler(fd)\n            self.io_loop.add_handler(fd, self._handle_events, ioloop_event)\n            self._fds[fd] = ioloop_event", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Core internal method of CurlAsyncHTTPClient that updates or removes I/O event handlers for socket file descriptors based on libcurl's notifications, enabling asynchronous socket event management integrated with the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_set_timeout", "line_number": 134, "body": "def _set_timeout(self, msecs: int) -> None:\n        \"\"\"Called by libcurl to schedule a timeout.\"\"\"\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n        self._timeout = self.io_loop.add_timeout(\n            self.io_loop.time() + msecs / 1000.0, self._handle_timeout\n        )", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Sets or resets an asynchronous timeout callback based on a given millisecond delay, ensuring proper scheduling within the CurlAsyncHTTPClient's event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_handle_events", "line_number": 142, "body": "def _handle_events(self, fd: int, events: int) -> None:\n        \"\"\"Called by IOLoop when there is activity on one of our\n        file descriptors.\n        \"\"\"\n        action = 0\n        if events & ioloop.IOLoop.READ:\n            action |= pycurl.CSELECT_IN\n        if events & ioloop.IOLoop.WRITE:\n            action |= pycurl.CSELECT_OUT\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_action(fd, action)\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Handles socket events triggered by the IOLoop, directing corresponding actions to the underlying pycurl multi interface and finalizing any pending HTTP requests asynchronously. It enables non-blocking, event-driven HTTP communication in CurlAsyncHTTPClient."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_handle_timeout", "line_number": 160, "body": "def _handle_timeout(self) -> None:\n        \"\"\"Called by IOLoop when the requested timeout has passed.\"\"\"\n        self._timeout = None\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_action(pycurl.SOCKET_TIMEOUT, 0)\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()\n\n        # In theory, we shouldn't have to do this because curl will\n        # call _set_timeout whenever the timeout changes.  However,\n        # sometimes after _handle_timeout we will need to reschedule\n        # immediately even though nothing has changed from curl's\n        # perspective.  This is because when socket_action is\n        # called with SOCKET_TIMEOUT, libcurl decides internally which\n        # timeouts need to be processed by using a monotonic clock\n        # (where available) while tornado uses python's time.time()\n        # to decide when timeouts have occurred.  When those clocks\n        # disagree on elapsed time (as they will whenever there is an\n        # NTP adjustment), tornado might call _handle_timeout before\n        # libcurl is ready.  After each timeout, resync the scheduled\n        # timeout with libcurl's current state.\n        new_timeout = self._multi.timeout()\n        if new_timeout >= 0:\n            self._set_timeout(new_timeout)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal method of CurlAsyncHTTPClient that processes timeout events from the IOLoop, handles libcurl socket timeouts, completes pending HTTP requests, and reschedules timing to stay synchronized with libcurl's timeout management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_handle_force_timeout", "line_number": 189, "body": "def _handle_force_timeout(self) -> None:\n        \"\"\"Called by IOLoop periodically to ask libcurl to process any\n        events it may have forgotten about.\n        \"\"\"\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_all()\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal method of CurlAsyncHTTPClient that prompts libcurl to process any pending network events and completes outstanding requests, ensuring timely handling of asynchronous HTTP operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_finish_pending_requests", "line_number": 202, "body": "def _finish_pending_requests(self) -> None:\n        \"\"\"Process any requests that were completed by the last\n        call to multi.socket_action.\n        \"\"\"\n        while True:\n            num_q, ok_list, err_list = self._multi.info_read()\n            for curl in ok_list:\n                self._finish(curl)\n            for curl, errnum, errmsg in err_list:\n                self._finish(curl, errnum, errmsg)\n            if num_q == 0:\n                break\n        self._process_queue()", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal method of CurlAsyncHTTPClient that finalizes and processes all HTTP requests completed during the latest socket actions, managing both successful and failed requests before handling any queued requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_process_queue", "line_number": 216, "body": "def _process_queue(self) -> None:\n        while True:\n            started = 0\n            while self._free_list and self._requests:\n                started += 1\n                curl = self._free_list.pop()\n                (request, callback, queue_start_time) = self._requests.popleft()\n                # TODO: Don't smuggle extra data on an attribute of the Curl object.\n                curl.info = {  # type: ignore\n                    \"headers\": httputil.HTTPHeaders(),\n                    \"buffer\": BytesIO(),\n                    \"request\": request,\n                    \"callback\": callback,\n                    \"queue_start_time\": queue_start_time,\n                    \"curl_start_time\": time.time(),\n                    \"curl_start_ioloop_time\": self.io_loop.current().time(),\n                }\n                try:\n                    self._curl_setup_request(\n                        curl,\n                        request,\n                        curl.info[\"buffer\"],  # type: ignore\n                        curl.info[\"headers\"],  # type: ignore\n                    )\n                except Exception as e:\n                    # If there was an error in setup, pass it on\n                    # to the callback. Note that allowing the\n                    # error to escape here will appear to work\n                    # most of the time since we are still in the\n                    # caller's original stack frame, but when\n                    # _process_queue() is called from\n                    # _finish_pending_requests the exceptions have\n                    # nowhere to go.\n                    self._free_list.append(curl)\n                    callback(HTTPResponse(request=request, code=599, error=e))\n                else:\n                    self._multi.add_handle(curl)\n\n            if not started:\n                break", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal method of CurlAsyncHTTPClient that processes queued HTTP requests and assigns them to available curl handles for asynchronous execution until no handles or requests remain."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_finish", "line_number": 257, "body": "def _finish(\n        self,\n        curl: pycurl.Curl,\n        curl_error: Optional[int] = None,\n        curl_message: Optional[str] = None,\n    ) -> None:\n        info = curl.info  # type: ignore\n        curl.info = None  # type: ignore\n        self._multi.remove_handle(curl)\n        self._free_list.append(curl)\n        buffer = info[\"buffer\"]\n        if curl_error:\n            assert curl_message is not None\n            error = CurlError(curl_error, curl_message)  # type: Optional[CurlError]\n            assert error is not None\n            code = error.code\n            effective_url = None\n            buffer.close()\n            buffer = None\n        else:\n            error = None\n            code = curl.getinfo(pycurl.HTTP_CODE)\n            effective_url = curl.getinfo(pycurl.EFFECTIVE_URL)\n            buffer.seek(0)\n        # the various curl timings are documented at\n        # http://curl.haxx.se/libcurl/c/curl_easy_getinfo.html\n        time_info = dict(\n            queue=info[\"curl_start_ioloop_time\"] - info[\"queue_start_time\"],\n            namelookup=curl.getinfo(pycurl.NAMELOOKUP_TIME),\n            connect=curl.getinfo(pycurl.CONNECT_TIME),\n            appconnect=curl.getinfo(pycurl.APPCONNECT_TIME),\n            pretransfer=curl.getinfo(pycurl.PRETRANSFER_TIME),\n            starttransfer=curl.getinfo(pycurl.STARTTRANSFER_TIME),\n            total=curl.getinfo(pycurl.TOTAL_TIME),\n            redirect=curl.getinfo(pycurl.REDIRECT_TIME),\n        )\n        try:\n            info[\"callback\"](\n                HTTPResponse(\n                    request=info[\"request\"],\n                    code=code,\n                    headers=info[\"headers\"],\n                    buffer=buffer,\n                    effective_url=effective_url,\n                    error=error,\n                    reason=info[\"headers\"].get(\"X-Http-Reason\", None),\n                    request_time=self.io_loop.time() - info[\"curl_start_ioloop_time\"],\n                    start_time=info[\"curl_start_time\"],\n                    time_info=time_info,\n                )\n            )\n        except Exception:\n            self.handle_callback_exception(info[\"callback\"])", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Handles completion of an asynchronous HTTP request by cleaning up resources, processing response data and timings, and invoking the user-defined callback with an HTTPResponse containing request results or errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "handle_callback_exception", "line_number": 311, "body": "def handle_callback_exception(self, callback: Any) -> None:\n        app_log.error(\"Exception in callback %r\", callback, exc_info=True)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Logs any exceptions that occur during the execution of asynchronous callbacks, aiding in debugging and error tracking within CurlAsyncHTTPClient operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_curl_create", "line_number": 314, "body": "def _curl_create(self) -> pycurl.Curl:\n        curl = pycurl.Curl()\n        if curl_log.isEnabledFor(logging.DEBUG):\n            curl.setopt(pycurl.VERBOSE, 1)\n            curl.setopt(pycurl.DEBUGFUNCTION, self._curl_debug)\n        if hasattr(\n            pycurl, \"PROTOCOLS\"\n        ):  # PROTOCOLS first appeared in pycurl 7.19.5 (2014-07-12)\n            curl.setopt(pycurl.PROTOCOLS, pycurl.PROTO_HTTP | pycurl.PROTO_HTTPS)\n            curl.setopt(pycurl.REDIR_PROTOCOLS, pycurl.PROTO_HTTP | pycurl.PROTO_HTTPS)\n        return curl", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal helper method of CurlAsyncHTTPClient that initializes and configures a pycurl.Curl object with debugging and protocol settings for HTTP/HTTPS requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_curl_setup_request", "line_number": 326, "body": "def _curl_setup_request(\n        self,\n        curl: pycurl.Curl,\n        request: HTTPRequest,\n        buffer: BytesIO,\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        curl.setopt(pycurl.URL, native_str(request.url))\n\n        # libcurl's magic \"Expect: 100-continue\" behavior causes delays\n        # with servers that don't support it (which include, among others,\n        # Google's OpenID endpoint).  Additionally, this behavior has\n        # a bug in conjunction with the curl_multi_socket_action API\n        # (https://sourceforge.net/tracker/?func=detail&atid=100976&aid=3039744&group_id=976),\n        # which increases the delays.  It's more trouble than it's worth,\n        # so just turn off the feature (yes, setting Expect: to an empty\n        # value is the official way to disable this)\n        if \"Expect\" not in request.headers:\n            request.headers[\"Expect\"] = \"\"\n\n        # libcurl adds Pragma: no-cache by default; disable that too\n        if \"Pragma\" not in request.headers:\n            request.headers[\"Pragma\"] = \"\"\n\n        curl.setopt(\n            pycurl.HTTPHEADER,\n            [\n                \"%s: %s\" % (native_str(k), native_str(v))\n                for k, v in request.headers.get_all()\n            ],\n        )\n\n        curl.setopt(\n            pycurl.HEADERFUNCTION,\n            functools.partial(\n                self._curl_header_callback, headers, request.header_callback\n            ),\n        )\n        if request.streaming_callback:\n\n            def write_function(b: Union[bytes, bytearray]) -> int:\n                assert request.streaming_callback is not None\n                self.io_loop.add_callback(request.streaming_callback, b)\n                return len(b)\n\n        else:\n            write_function = buffer.write\n        curl.setopt(pycurl.WRITEFUNCTION, write_function)\n        curl.setopt(pycurl.FOLLOWLOCATION, request.follow_redirects)\n        curl.setopt(pycurl.MAXREDIRS, request.max_redirects)\n        assert request.connect_timeout is not None\n        curl.setopt(pycurl.CONNECTTIMEOUT_MS, int(1000 * request.connect_timeout))\n        assert request.request_timeout is not None\n        curl.setopt(pycurl.TIMEOUT_MS, int(1000 * request.request_timeout))\n        if request.user_agent:\n            curl.setopt(pycurl.USERAGENT, native_str(request.user_agent))\n        else:\n            curl.setopt(pycurl.USERAGENT, \"Mozilla/5.0 (compatible; pycurl)\")\n        if request.network_interface:\n            curl.setopt(pycurl.INTERFACE, request.network_interface)\n        if request.decompress_response:\n            curl.setopt(pycurl.ENCODING, \"gzip,deflate\")\n        else:\n            curl.setopt(pycurl.ENCODING, None)\n        if request.proxy_host and request.proxy_port:\n            curl.setopt(pycurl.PROXY, request.proxy_host)\n            curl.setopt(pycurl.PROXYPORT, request.proxy_port)\n            if request.proxy_username:\n                assert request.proxy_password is not None\n                credentials = httputil.encode_username_password(\n                    request.proxy_username, request.proxy_password\n                )\n                curl.setopt(pycurl.PROXYUSERPWD, credentials)\n\n            if request.proxy_auth_mode is None or request.proxy_auth_mode == \"basic\":\n                curl.setopt(pycurl.PROXYAUTH, pycurl.HTTPAUTH_BASIC)\n            elif request.proxy_auth_mode == \"digest\":\n                curl.setopt(pycurl.PROXYAUTH, pycurl.HTTPAUTH_DIGEST)\n            else:\n                raise ValueError(\n                    \"Unsupported proxy_auth_mode %s\" % request.proxy_auth_mode\n                )\n        else:\n            try:\n                curl.unsetopt(pycurl.PROXY)\n            except TypeError:  # not supported, disable proxy\n                curl.setopt(pycurl.PROXY, \"\")\n            curl.unsetopt(pycurl.PROXYUSERPWD)\n        if request.validate_cert:\n            curl.setopt(pycurl.SSL_VERIFYPEER, 1)\n            curl.setopt(pycurl.SSL_VERIFYHOST, 2)\n        else:\n            curl.setopt(pycurl.SSL_VERIFYPEER, 0)\n            curl.setopt(pycurl.SSL_VERIFYHOST, 0)\n        if request.ca_certs is not None:\n            curl.setopt(pycurl.CAINFO, request.ca_certs)\n        else:\n            # There is no way to restore pycurl.CAINFO to its default value\n            # (Using unsetopt makes it reject all certificates).\n            # I don't see any way to read the default value from python so it\n            # can be restored later.  We'll have to just leave CAINFO untouched\n            # if no ca_certs file was specified, and require that if any\n            # request uses a custom ca_certs file, they all must.\n            pass\n\n        if request.allow_ipv6 is False:\n            # Curl behaves reasonably when DNS resolution gives an ipv6 address\n            # that we can't reach, so allow ipv6 unless the user asks to disable.\n            curl.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)\n        else:\n            curl.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_WHATEVER)\n\n        # Set the request method through curl's irritating interface which makes\n        # up names for almost every single method\n        curl_options = {\n            \"GET\": pycurl.HTTPGET,\n            \"POST\": pycurl.POST,\n            \"PUT\": pycurl.UPLOAD,\n            \"HEAD\": pycurl.NOBODY,\n        }\n        custom_methods = set([\"DELETE\", \"OPTIONS\", \"PATCH\"])\n        for o in curl_options.values():\n            curl.setopt(o, False)\n        if request.method in curl_options:\n            curl.unsetopt(pycurl.CUSTOMREQUEST)\n            curl.setopt(curl_options[request.method], True)\n        elif request.allow_nonstandard_methods or request.method in custom_methods:\n            curl.setopt(pycurl.CUSTOMREQUEST, request.method)\n        else:\n            raise KeyError(\"unknown method \" + request.method)\n\n        body_expected = request.method in (\"POST\", \"PATCH\", \"PUT\")\n        body_present = request.body is not None\n        if not request.allow_nonstandard_methods:\n            # Some HTTP methods nearly always have bodies while others\n            # almost never do. Fail in this case unless the user has\n            # opted out of sanity checks with allow_nonstandard_methods.\n            if (body_expected and not body_present) or (\n                body_present and not body_expected\n            ):\n                raise ValueError(\n                    \"Body must %sbe None for method %s (unless \"\n                    \"allow_nonstandard_methods is true)\"\n                    % (\"not \" if body_expected else \"\", request.method)\n                )\n\n        if body_expected or body_present:\n            if request.method == \"GET\":\n                # Even with `allow_nonstandard_methods` we disallow\n                # GET with a body (because libcurl doesn't allow it\n                # unless we use CUSTOMREQUEST). While the spec doesn't\n                # forbid clients from sending a body, it arguably\n                # disallows the server from doing anything with them.\n                raise ValueError(\"Body must be None for GET request\")\n            request_buffer = BytesIO(utf8(request.body or \"\"))\n\n            def ioctl(cmd: int) -> None:\n                if cmd == curl.IOCMD_RESTARTREAD:  # type: ignore\n                    request_buffer.seek(0)\n\n            curl.setopt(pycurl.READFUNCTION, request_buffer.read)\n            curl.setopt(pycurl.IOCTLFUNCTION, ioctl)\n            if request.method == \"POST\":\n                curl.setopt(pycurl.POSTFIELDSIZE, len(request.body or \"\"))\n            else:\n                curl.setopt(pycurl.UPLOAD, True)\n                curl.setopt(pycurl.INFILESIZE, len(request.body or \"\"))\n\n        if request.auth_username is not None:\n            assert request.auth_password is not None\n            if request.auth_mode is None or request.auth_mode == \"basic\":\n                curl.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_BASIC)\n            elif request.auth_mode == \"digest\":\n                curl.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_DIGEST)\n            else:\n                raise ValueError(\"Unsupported auth_mode %s\" % request.auth_mode)\n\n            userpwd = httputil.encode_username_password(\n                request.auth_username, request.auth_password\n            )\n            curl.setopt(pycurl.USERPWD, userpwd)\n            curl_log.debug(\n                \"%s %s (username: %r)\",\n                request.method,\n                request.url,\n                request.auth_username,\n            )\n        else:\n            curl.unsetopt(pycurl.USERPWD)\n            curl_log.debug(\"%s %s\", request.method, request.url)\n\n        if request.client_cert is not None:\n            curl.setopt(pycurl.SSLCERT, request.client_cert)\n\n        if request.client_key is not None:\n            curl.setopt(pycurl.SSLKEY, request.client_key)\n\n        if request.ssl_options is not None:\n            raise ValueError(\"ssl_options not supported in curl_httpclient\")\n\n        if threading.active_count() > 1:\n            # libcurl/pycurl is not thread-safe by default.  When multiple threads\n            # are used, signals should be disabled.  This has the side effect\n            # of disabling DNS timeouts in some environments (when libcurl is\n            # not linked against ares), so we don't do it when there is only one\n            # thread.  Applications that use many short-lived threads may need\n            # to set NOSIGNAL manually in a prepare_curl_callback since\n            # there may not be any other threads running at the time we call\n            # threading.activeCount.\n            curl.setopt(pycurl.NOSIGNAL, 1)\n        if request.prepare_curl_callback is not None:\n            request.prepare_curl_callback(curl)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Prepares and configures a pycurl.Curl object according to an HTTPRequest, setting options like headers, method, timeouts, authentication, proxy, and SSL settings to enable customized asynchronous HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_curl_header_callback", "line_number": 539, "body": "def _curl_header_callback(\n        self,\n        headers: httputil.HTTPHeaders,\n        header_callback: Callable[[str], None],\n        header_line_bytes: bytes,\n    ) -> None:\n        header_line = native_str(header_line_bytes.decode(\"latin1\"))\n        if header_callback is not None:\n            self.io_loop.add_callback(header_callback, header_line)\n        # header_line as returned by curl includes the end-of-line characters.\n        # whitespace at the start should be preserved to allow multi-line headers\n        header_line = header_line.rstrip()\n        if header_line.startswith(\"HTTP/\"):\n            headers.clear()\n            try:\n                (__, __, reason) = httputil.parse_response_start_line(header_line)\n                header_line = \"X-Http-Reason: %s\" % reason\n            except httputil.HTTPInputError:\n                return\n        if not header_line:\n            return\n        headers.parse_line(header_line)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal method of CurlAsyncHTTPClient that processes raw HTTP header lines from a curl response, updates header storage, and invokes optional callbacks for asynchronous header handling during HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "_curl_debug", "line_number": 562, "body": "def _curl_debug(self, debug_type: int, debug_msg: str) -> None:\n        debug_types = (\"I\", \"<\", \">\", \"<\", \">\")\n        if debug_type == 0:\n            debug_msg = native_str(debug_msg)\n            curl_log.debug(\"%s\", debug_msg.strip())\n        elif debug_type in (1, 2):\n            debug_msg = native_str(debug_msg)\n            for line in debug_msg.splitlines():\n                curl_log.debug(\"%s %s\", debug_types[debug_type], line)\n        elif debug_type == 4:\n            curl_log.debug(\"%s %r\", debug_types[debug_type], debug_msg)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Internal helper method of CurlAsyncHTTPClient that logs detailed debug messages from curl operations, aiding in diagnosing and tracing HTTP request and response activities during asynchronous interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/curl_httpclient.py", "function": "write_function", "line_number": 366, "body": "def write_function(b: Union[bytes, bytearray]) -> int:\n                assert request.streaming_callback is not None\n                self.io_loop.add_callback(request.streaming_callback, b)\n                return len(b)", "is_method": true, "class_name": "CurlAsyncHTTPClient", "function_description": "Method of CurlAsyncHTTPClient that streams byte data asynchronously by invoking a request's callback, enabling non-blocking data transmission in asynchronous HTTP operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "bind_unused_port", "line_number": 52, "body": "def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n       Always binds to ``127.0.0.1`` without resolving the name\n       ``localhost``.\n    \"\"\"\n    sock = netutil.bind_sockets(\n        0, \"127.0.0.1\", family=socket.AF_INET, reuse_port=reuse_port\n    )[0]\n    port = sock.getsockname()[1]\n    return sock, port", "is_method": false, "function_description": "Utility function that binds a server socket to an available localhost port, returning the socket and its assigned port number for network communication setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_async_test_timeout", "line_number": 68, "body": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n    env = os.environ.get(\"ASYNC_TEST_TIMEOUT\")\n    if env is not None:\n        try:\n            return float(env)\n        except ValueError:\n            pass\n    return 5", "is_method": false, "function_description": "Utility function that provides the global timeout duration for asynchronous tests, allowing configurable timeout via environment variable with a default fallback."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "gen_test", "line_number": 525, "body": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test\n            def test_something(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test(timeout=10)\n            def test_something_slow(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n       The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n       variable.\n\n    .. versionchanged:: 4.0\n       The wrapper now passes along ``*args, **kwargs`` so it can be used\n       on functions with arguments.\n\n    \"\"\"\n    if timeout is None:\n        timeout = get_async_test_timeout()\n\n    def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(type(e), e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine\n\n    if func is not None:\n        # Used like:\n        #     @gen_test\n        #     def f(self):\n        #         pass\n        return wrap(func)\n    else:\n        # Used like @gen_test(timeout=10)\n        return wrap", "is_method": false, "function_description": "Decorator that enables asynchronous test methods using generators or coroutines to run synchronously with a customizable timeout, facilitating async testing in subclasses of AsyncTestCase without a running IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "main", "line_number": 725, "body": "def main(**kwargs: Any) -> None:\n    \"\"\"A simple test runner.\n\n    This test runner is essentially equivalent to `unittest.main` from\n    the standard library, but adds support for Tornado-style option\n    parsing and log formatting. It is *not* necessary to use this\n    `main` function to run tests using `AsyncTestCase`; these tests\n    are self-contained and can run with any test runner.\n\n    The easiest way to run a test is via the command line::\n\n        python -m tornado.testing tornado.test.web_test\n\n    See the standard library ``unittest`` module for ways in which\n    tests can be specified.\n\n    Projects with many tests may wish to define a test script like\n    ``tornado/test/runtests.py``.  This script should define a method\n    ``all()`` which returns a test suite and then call\n    `tornado.testing.main()`.  Note that even when a test script is\n    used, the ``all()`` test suite may be overridden by naming a\n    single test on the command line::\n\n        # Runs all tests\n        python -m tornado.test.runtests\n        # Runs one test\n        python -m tornado.test.runtests tornado.test.web_test\n\n    Additional keyword arguments passed through to ``unittest.main()``.\n    For example, use ``tornado.testing.main(verbosity=2)``\n    to show many test details as they are run.\n    See http://docs.python.org/library/unittest.html#unittest.main\n    for full argument list.\n\n    .. versionchanged:: 5.0\n\n       This function produces no output of its own; only that produced\n       by the `unittest` module (previously it would add a PASS or FAIL\n       log message).\n    \"\"\"\n    from tornado.options import define, options, parse_command_line\n\n    define(\n        \"exception_on_interrupt\",\n        type=bool,\n        default=True,\n        help=(\n            \"If true (default), ctrl-c raises a KeyboardInterrupt \"\n            \"exception.  This prints a stack trace but cannot interrupt \"\n            \"certain operations.  If false, the process is more reliably \"\n            \"killed, but does not print a stack trace.\"\n        ),\n    )\n\n    # support the same options as unittest's command-line interface\n    define(\"verbose\", type=bool)\n    define(\"quiet\", type=bool)\n    define(\"failfast\", type=bool)\n    define(\"catch\", type=bool)\n    define(\"buffer\", type=bool)\n\n    argv = [sys.argv[0]] + parse_command_line(sys.argv)\n\n    if not options.exception_on_interrupt:\n        signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    if options.verbose is not None:\n        kwargs[\"verbosity\"] = 2\n    if options.quiet is not None:\n        kwargs[\"verbosity\"] = 0\n    if options.failfast is not None:\n        kwargs[\"failfast\"] = True\n    if options.catch is not None:\n        kwargs[\"catchbreak\"] = True\n    if options.buffer is not None:\n        kwargs[\"buffer\"] = True\n\n    if __name__ == \"__main__\" and len(argv) == 1:\n        print(\"No tests specified\", file=sys.stderr)\n        sys.exit(1)\n    # In order to be able to run tests by their fully-qualified name\n    # on the command line without importing all tests here,\n    # module must be set to None.  Python 3.2's unittest.main ignores\n    # defaultTest if no module is given (it tries to do its own\n    # test discovery, which is incompatible with auto2to3), so don't\n    # set module if we're not asking for a specific test.\n    if len(argv) > 1:\n        unittest.main(module=None, argv=argv, **kwargs)  # type: ignore\n    else:\n        unittest.main(defaultTest=\"all\", argv=argv, **kwargs)", "is_method": false, "function_description": "Utility function to run Tornado-compatible unit tests with enhanced option parsing and logging, serving as a flexible test runner that supports command-line test selection and integrates with Python\u2019s unittest framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "__call__", "line_number": 97, "body": "def __call__(self, *args: Any, **kwargs: Any) -> None:\n        result = self.orig_method(*args, **kwargs)\n        if isinstance(result, Generator) or inspect.iscoroutine(result):\n            raise TypeError(\n                \"Generator and coroutine test methods should be\"\n                \" decorated with tornado.testing.gen_test\"\n            )\n        elif result is not None:\n            raise ValueError(\"Return value from test method ignored: %r\" % result)", "is_method": true, "class_name": "_TestMethodWrapper", "function_description": "Raises errors if a test method returns a generator, coroutine, or any non-None value, ensuring test methods follow expected return conventions in the _TestMethodWrapper context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "__getattr__", "line_number": 107, "body": "def __getattr__(self, name: str) -> Any:\n        \"\"\"Proxy all unknown attributes to the original method.\n\n        This is important for some of the decorators in the `unittest`\n        module, such as `unittest.skipIf`.\n        \"\"\"\n        return getattr(self.orig_method, name)", "is_method": true, "class_name": "_TestMethodWrapper", "function_description": "Utility method in the _TestMethodWrapper class that delegates attribute access to the original method, enabling compatibility with unittest decorators by exposing their attributes transparently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "setUp", "line_number": 180, "body": "def setUp(self) -> None:\n        super().setUp()\n        self.io_loop = self.get_new_ioloop()\n        self.io_loop.make_current()", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Sets up an asynchronous test environment by initializing and activating a new event loop, preparing the test case to run async code within its own I/O loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "tearDown", "line_number": 185, "body": "def tearDown(self) -> None:\n        # Native coroutines tend to produce warnings if they're not\n        # allowed to run to completion. It's difficult to ensure that\n        # this always happens in tests, so cancel any tasks that are\n        # still pending by the time we get here.\n        asyncio_loop = self.io_loop.asyncio_loop  # type: ignore\n        if hasattr(asyncio, \"all_tasks\"):  # py37\n            tasks = asyncio.all_tasks(asyncio_loop)  # type: ignore\n        else:\n            tasks = asyncio.Task.all_tasks(asyncio_loop)\n        # Tasks that are done may still appear here and may contain\n        # non-cancellation exceptions, so filter them out.\n        tasks = [t for t in tasks if not t.done()]\n        for t in tasks:\n            t.cancel()\n        # Allow the tasks to run and finalize themselves (which means\n        # raising a CancelledError inside the coroutine). This may\n        # just transform the \"task was destroyed but it is pending\"\n        # warning into a \"uncaught CancelledError\" warning, but\n        # catching CancelledErrors in coroutines that may leak is\n        # simpler than ensuring that no coroutines leak.\n        if tasks:\n            done, pending = self.io_loop.run_sync(lambda: asyncio.wait(tasks))\n            assert not pending\n            # If any task failed with anything but a CancelledError, raise it.\n            for f in done:\n                try:\n                    f.result()\n                except asyncio.CancelledError:\n                    pass\n\n        # Clean up Subprocess, so it can be used again with a new ioloop.\n        Subprocess.uninitialize()\n        self.io_loop.clear_current()\n        if not isinstance(self.io_loop, _NON_OWNED_IOLOOPS):\n            # Try to clean up any file descriptors left open in the ioloop.\n            # This avoids leaks, especially when tests are run repeatedly\n            # in the same process with autoreload (because curl does not\n            # set FD_CLOEXEC on its file descriptors)\n            self.io_loop.close(all_fds=True)\n        super().tearDown()\n        # In case an exception escaped or the StackContext caught an exception\n        # when there wasn't a wait() to re-raise it, do so here.\n        # This is our last chance to raise an exception in a way that the\n        # unittest machinery understands.\n        self.__rethrow()", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Cleans up and cancels all pending asynchronous tasks after a test, ensuring no task leaks or warnings remain, and finalizes resources tied to the event loop to maintain test isolation and prevent resource leakage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_new_ioloop", "line_number": 232, "body": "def get_new_ioloop(self) -> IOLoop:\n        \"\"\"Returns the `.IOLoop` to use for this test.\n\n        By default, a new `.IOLoop` is created for each test.\n        Subclasses may override this method to return\n        `.IOLoop.current()` if it is not appropriate to use a new\n        `.IOLoop` in each tests (for example, if there are global\n        singletons using the default `.IOLoop`) or if a per-test event\n        loop is being provided by another system (such as\n        ``pytest-asyncio``).\n        \"\"\"\n        return IOLoop()", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Provides the event loop instance used in an asynchronous test case, typically creating a new `.IOLoop` per test but allowing subclasses to customize loop provision for shared or external event loops."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "_handle_exception", "line_number": 245, "body": "def _handle_exception(\n        self, typ: Type[Exception], value: Exception, tb: TracebackType\n    ) -> bool:\n        if self.__failure is None:\n            self.__failure = (typ, value, tb)\n        else:\n            app_log.error(\n                \"multiple unhandled exceptions in test\", exc_info=(typ, value, tb)\n            )\n        self.stop()\n        return True", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Handles the first unhandled exception during an asynchronous test, records it for failure reporting, stops the test, and logs any subsequent exceptions encountered."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "__rethrow", "line_number": 257, "body": "def __rethrow(self) -> None:\n        if self.__failure is not None:\n            failure = self.__failure\n            self.__failure = None\n            raise_exc_info(failure)", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Private method of AsyncTestCase that re-raises a previously recorded test failure, allowing deferred exception handling in asynchronous test execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "run", "line_number": 263, "body": "def run(\n        self, result: Optional[unittest.TestResult] = None\n    ) -> Optional[unittest.TestResult]:\n        ret = super().run(result)\n        # As a last resort, if an exception escaped super.run() and wasn't\n        # re-raised in tearDown, raise it here.  This will cause the\n        # unittest run to fail messily, but that's better than silently\n        # ignoring an error.\n        self.__rethrow()\n        return ret", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Method in AsyncTestCase that executes a test case, ensuring any uncaught exceptions are rethrown to prevent silent test failures. It enhances unittest's run method by improving error visibility in asynchronous testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "stop", "line_number": 274, "body": "def stop(self, _arg: Any = None, **kwargs: Any) -> None:\n        \"\"\"Stops the `.IOLoop`, causing one pending (or future) call to `wait()`\n        to return.\n\n        Keyword arguments or a single positional argument passed to `stop()` are\n        saved and will be returned by `wait()`.\n\n        .. deprecated:: 5.1\n\n           `stop` and `wait` are deprecated; use ``@gen_test`` instead.\n        \"\"\"\n        assert _arg is None or not kwargs\n        self.__stop_args = kwargs or _arg\n        if self.__running:\n            self.io_loop.stop()\n            self.__running = False\n        self.__stopped = True", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Utility method in AsyncTestCase that stops the IOLoop, causing a pending or future wait() call to return, optionally passing arguments to wait(). It facilitates control flow in asynchronous test execution but is deprecated in favor of @gen_test."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "wait", "line_number": 292, "body": "def wait(\n        self,\n        condition: Optional[Callable[..., bool]] = None,\n        timeout: Optional[float] = None,\n    ) -> Any:\n        \"\"\"Runs the `.IOLoop` until stop is called or timeout has passed.\n\n        In the event of a timeout, an exception will be thrown. The\n        default timeout is 5 seconds; it may be overridden with a\n        ``timeout`` keyword argument or globally with the\n        ``ASYNC_TEST_TIMEOUT`` environment variable.\n\n        If ``condition`` is not ``None``, the `.IOLoop` will be restarted\n        after `stop()` until ``condition()`` returns ``True``.\n\n        .. versionchanged:: 3.1\n           Added the ``ASYNC_TEST_TIMEOUT`` environment variable.\n\n        .. deprecated:: 5.1\n\n           `stop` and `wait` are deprecated; use ``@gen_test`` instead.\n        \"\"\"\n        if timeout is None:\n            timeout = get_async_test_timeout()\n\n        if not self.__stopped:\n            if timeout:\n\n                def timeout_func() -> None:\n                    try:\n                        raise self.failureException(\n                            \"Async operation timed out after %s seconds\" % timeout\n                        )\n                    except Exception:\n                        self.__failure = sys.exc_info()\n                    self.stop()\n\n                self.__timeout = self.io_loop.add_timeout(\n                    self.io_loop.time() + timeout, timeout_func\n                )\n            while True:\n                self.__running = True\n                self.io_loop.start()\n                if self.__failure is not None or condition is None or condition():\n                    break\n            if self.__timeout is not None:\n                self.io_loop.remove_timeout(self.__timeout)\n                self.__timeout = None\n        assert self.__stopped\n        self.__stopped = False\n        self.__rethrow()\n        result = self.__stop_args\n        self.__stop_args = None\n        return result", "is_method": true, "class_name": "AsyncTestCase", "function_description": "Utility method in AsyncTestCase that runs the IOLoop until a condition is met, a stop signal occurs, or a timeout elapses, facilitating asynchronous test synchronization with optional timeout enforcement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "setUp", "line_number": 381, "body": "def setUp(self) -> None:\n        super().setUp()\n        sock, port = bind_unused_port()\n        self.__port = port\n\n        self.http_client = self.get_http_client()\n        self._app = self.get_app()\n        self.http_server = self.get_http_server()\n        self.http_server.add_sockets([sock])", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Initializes an asynchronous HTTP test case by setting up an available port, HTTP client, application, and server to prepare for handling HTTP requests in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_http_client", "line_number": 391, "body": "def get_http_client(self) -> AsyncHTTPClient:\n        return AsyncHTTPClient()", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Returns a new instance of an asynchronous HTTP client for making non-blocking HTTP requests. This utility method simplifies acquiring a client for network operations within asynchronous test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_http_server", "line_number": 394, "body": "def get_http_server(self) -> HTTPServer:\n        return HTTPServer(self._app, **self.get_httpserver_options())", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Returns a configured HTTP server instance using the test case's application and server options, facilitating asynchronous HTTP testing setups."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_app", "line_number": 397, "body": "def get_app(self) -> Application:\n        \"\"\"Should be overridden by subclasses to return a\n        `tornado.web.Application` or other `.HTTPServer` callback.\n        \"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "This placeholder method in AsyncHTTPTestCase must be overridden to provide the web application instance used for asynchronous HTTP testing. It defines the application under test for the framework's test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "fetch", "line_number": 403, "body": "def fetch(\n        self, path: str, raise_error: bool = False, **kwargs: Any\n    ) -> HTTPResponse:\n        \"\"\"Convenience method to synchronously fetch a URL.\n\n        The given path will be appended to the local server's host and\n        port.  Any additional keyword arguments will be passed directly to\n        `.AsyncHTTPClient.fetch` (and so could be used to pass\n        ``method=\"POST\"``, ``body=\"...\"``, etc).\n\n        If the path begins with http:// or https://, it will be treated as a\n        full URL and will be fetched as-is.\n\n        If ``raise_error`` is ``True``, a `tornado.httpclient.HTTPError` will\n        be raised if the response code is not 200. This is the same behavior\n        as the ``raise_error`` argument to `.AsyncHTTPClient.fetch`, but\n        the default is ``False`` here (it's ``True`` in `.AsyncHTTPClient`)\n        because tests often need to deal with non-200 response codes.\n\n        .. versionchanged:: 5.0\n           Added support for absolute URLs.\n\n        .. versionchanged:: 5.1\n\n           Added the ``raise_error`` argument.\n\n        .. deprecated:: 5.1\n\n           This method currently turns any exception into an\n           `.HTTPResponse` with status code 599. In Tornado 6.0,\n           errors other than `tornado.httpclient.HTTPError` will be\n           passed through, and ``raise_error=False`` will only\n           suppress errors that would be raised due to non-200\n           response codes.\n\n        \"\"\"\n        if path.lower().startswith((\"http://\", \"https://\")):\n            url = path\n        else:\n            url = self.get_url(path)\n        return self.io_loop.run_sync(\n            lambda: self.http_client.fetch(url, raise_error=raise_error, **kwargs),\n            timeout=get_async_test_timeout(),\n        )", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Utility method in AsyncHTTPTestCase that synchronously fetches a URL, supporting both relative paths appended to the test server and absolute URLs, with optional error raising on non-200 HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_httpserver_options", "line_number": 448, "body": "def get_httpserver_options(self) -> Dict[str, Any]:\n        \"\"\"May be overridden by subclasses to return additional\n        keyword arguments for the server.\n        \"\"\"\n        return {}", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Provides customizable HTTP server configuration options for asynchronous HTTP tests, allowing subclasses to specify additional server parameters when needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_http_port", "line_number": 454, "body": "def get_http_port(self) -> int:\n        \"\"\"Returns the port used by the server.\n\n        A new port is chosen for each test.\n        \"\"\"\n        return self.__port", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Returns the network port number assigned to the server instance, ensuring each test operates on a unique port to avoid conflicts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_protocol", "line_number": 461, "body": "def get_protocol(self) -> str:\n        return \"http\"", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Returns the protocol type used by the AsyncHTTPTestCase, which is fixed as \"http\". This method standardizes protocol identification for HTTP-based asynchronous test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_url", "line_number": 464, "body": "def get_url(self, path: str) -> str:\n        \"\"\"Returns an absolute url for the given path on the test server.\"\"\"\n        return \"%s://127.0.0.1:%s%s\" % (self.get_protocol(), self.get_http_port(), path)", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Constructs and returns the full absolute URL for a given path on the test server, facilitating HTTP request targeting during asynchronous test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "tearDown", "line_number": 468, "body": "def tearDown(self) -> None:\n        self.http_server.stop()\n        self.io_loop.run_sync(\n            self.http_server.close_all_connections, timeout=get_async_test_timeout()\n        )\n        self.http_client.close()\n        del self.http_server\n        del self._app\n        super().tearDown()", "is_method": true, "class_name": "AsyncHTTPTestCase", "function_description": "Cleans up resources by stopping the HTTP server, closing all connections, and shutting down the HTTP client after an asynchronous HTTP test case finishes. It ensures proper teardown for reliable test isolation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_http_client", "line_number": 485, "body": "def get_http_client(self) -> AsyncHTTPClient:\n        return AsyncHTTPClient(force_instance=True, defaults=dict(validate_cert=False))", "is_method": true, "class_name": "AsyncHTTPSTestCase", "function_description": "Provides an HTTP client instance configured to skip SSL certificate validation, facilitating asynchronous HTTPS requests in test scenarios within the AsyncHTTPSTestCase context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_httpserver_options", "line_number": 488, "body": "def get_httpserver_options(self) -> Dict[str, Any]:\n        return dict(ssl_options=self.get_ssl_options())", "is_method": true, "class_name": "AsyncHTTPSTestCase", "function_description": "Provides HTTP server configuration options with SSL settings for secure communication, supporting test cases that require HTTPS connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_ssl_options", "line_number": 491, "body": "def get_ssl_options(self) -> Dict[str, Any]:\n        \"\"\"May be overridden by subclasses to select SSL options.\n\n        By default includes a self-signed testing certificate.\n        \"\"\"\n        return AsyncHTTPSTestCase.default_ssl_options()", "is_method": true, "class_name": "AsyncHTTPSTestCase", "function_description": "Provides SSL configuration options for HTTPS tests, defaulting to self-signed certificates; allows subclasses to customize SSL settings for secure asynchronous HTTP testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "default_ssl_options", "line_number": 499, "body": "def default_ssl_options() -> Dict[str, Any]:\n        # Testing keys were generated with:\n        # openssl req -new -keyout tornado/test/test.key \\\n        #                     -out tornado/test/test.crt -nodes -days 3650 -x509\n        module_dir = os.path.dirname(__file__)\n        return dict(\n            certfile=os.path.join(module_dir, \"test\", \"test.crt\"),\n            keyfile=os.path.join(module_dir, \"test\", \"test.key\"),\n        )", "is_method": true, "class_name": "AsyncHTTPSTestCase", "function_description": "Provides default SSL certificate and key file paths for HTTPS testing, facilitating secure connection setup in asynchronous HTTP test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "get_protocol", "line_number": 509, "body": "def get_protocol(self) -> str:\n        return \"https\"", "is_method": true, "class_name": "AsyncHTTPSTestCase", "function_description": "Returns the protocol scheme used by the AsyncHTTPSTestCase, indicating it operates over HTTPS connections. This supports test cases requiring secure HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "wrap", "line_number": 570, "body": "def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(type(e), e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine", "is_method": false, "function_description": "Decorator that converts asynchronous test methods into synchronous calls, enabling seamless execution and timeout handling of coroutine or generator-based tests within a testing framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "filter", "line_number": 690, "body": "def filter(self, record: logging.LogRecord) -> bool:\n        if record.exc_info:\n            self.logged_stack = True\n        message = record.getMessage()\n        if self.regex.match(message):\n            if self.level is not None and record.levelno != self.level:\n                app_log.warning(\n                    \"Got expected log message %r at unexpected level (%s vs %s)\"\n                    % (message, logging.getLevelName(self.level), record.levelname)\n                )\n                return True\n            self.matched = True\n            return False\n        return True", "is_method": true, "class_name": "ExpectLog", "function_description": "Filters log records by matching their messages against a regex and tracking if expected logs with or without specific levels have occurred. Useful for validating log outputs and handling expected log events during testing or monitoring."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "__enter__", "line_number": 705, "body": "def __enter__(self) -> \"ExpectLog\":\n        if self.level is not None and self.level < self.logger.getEffectiveLevel():\n            self.orig_level = self.logger.level\n            self.logger.setLevel(self.level)\n        self.logger.addFilter(self)\n        return self", "is_method": true, "class_name": "ExpectLog", "function_description": "Context manager entry for ExpectLog that optionally sets the logger\u2019s level and adds a log filter, enabling controlled logging behavior during the context block."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/testing.py", "function": "__exit__", "line_number": 712, "body": "def __exit__(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        if self.orig_level is not None:\n            self.logger.setLevel(self.orig_level)\n        self.logger.removeFilter(self)\n        if not typ and self.required and not self.matched:\n            raise Exception(\"did not get expected log message\")", "is_method": true, "class_name": "ExpectLog", "function_description": "Destructor method of the ExpectLog context manager that restores logger settings and raises an exception if an expected log message was not recorded during its scope. It ensures verification of specific log outputs in code sections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_signature", "line_number": 1102, "body": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n\n    key_elems = [escape.utf8(consumer_token[\"secret\"])]\n    key_elems.append(escape.utf8(token[\"secret\"] if token else \"\"))\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "is_method": false, "function_description": "Utility function that generates the HMAC-SHA1 OAuth signature for HTTP requests, enabling secure authorization by signing requests with consumer and token secrets according to the OAuth 1.0 protocol."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth10a_signature", "line_number": 1135, "body": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n    key_elems = [escape.utf8(urllib.parse.quote(consumer_token[\"secret\"], safe=\"~\"))]\n    key_elems.append(\n        escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n    )\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "is_method": false, "function_description": "Generates the HMAC-SHA1 signature for OAuth 1.0a requests using consumer and optional token secrets, supporting secure authentication in API interactions. It produces a base64-encoded signature for request validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_escape", "line_number": 1170, "body": "def _oauth_escape(val: Union[str, bytes]) -> str:\n    if isinstance(val, unicode_type):\n        val = val.encode(\"utf-8\")\n    return urllib.parse.quote(val, safe=\"~\")", "is_method": false, "function_description": "Utility function that encodes strings or bytes for safe inclusion in OAuth requests, ensuring proper percent-encoding with tilde characters unescaped."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_parse_response", "line_number": 1176, "body": "def _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n    # I can't find an officially-defined encoding for oauth responses and\n    # have never seen anyone use non-ascii.  Leave the response in a byte\n    # string for python 2, and use utf8 on python 3.\n    body_str = escape.native_str(body)\n    p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n    token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n\n    # Add the extra parameters the Provider included to the token\n    special = (\"oauth_token\", \"oauth_token_secret\")\n    token.update((k, p[k][0]) for k in p if k not in special)\n    return token", "is_method": false, "function_description": "Utility function that parses an OAuth response body to extract the OAuth token, secret, and any additional parameters, returning them as a dictionary for easier access in authentication workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "authenticate_redirect", "line_number": 88, "body": "def authenticate_redirect(\n        self,\n        callback_uri: Optional[str] = None,\n        ax_attrs: List[str] = [\"name\", \"email\", \"language\", \"username\"],\n    ) -> None:\n        \"\"\"Redirects to the authentication URL for this service.\n\n        After authentication, the service will redirect back to the given\n        callback URI with additional parameters including ``openid.mode``.\n\n        We request the given attributes for the authenticated user by\n        default (name, email, language, and username). If you don't need\n        all those attributes for your app, you can request fewer with\n        the ax_attrs keyword argument.\n\n        .. versionchanged:: 6.0\n\n            The ``callback`` argument was removed and this method no\n            longer returns an awaitable object. It is now an ordinary\n            synchronous function.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        callback_uri = callback_uri or handler.request.uri\n        assert callback_uri is not None\n        args = self._openid_args(callback_uri, ax_attrs=ax_attrs)\n        endpoint = self._OPENID_ENDPOINT  # type: ignore\n        handler.redirect(endpoint + \"?\" + urllib.parse.urlencode(args))", "is_method": true, "class_name": "OpenIdMixin", "function_description": "Method of the OpenIdMixin class that initiates OpenID authentication by redirecting the user to a login URL, requesting specified user attributes and ensuring return to a given callback URI after authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_openid_args", "line_number": 148, "body": "def _openid_args(\n        self,\n        callback_uri: str,\n        ax_attrs: Iterable[str] = [],\n        oauth_scope: Optional[str] = None,\n    ) -> Dict[str, str]:\n        handler = cast(RequestHandler, self)\n        url = urllib.parse.urljoin(handler.request.full_url(), callback_uri)\n        args = {\n            \"openid.ns\": \"http://specs.openid.net/auth/2.0\",\n            \"openid.claimed_id\": \"http://specs.openid.net/auth/2.0/identifier_select\",\n            \"openid.identity\": \"http://specs.openid.net/auth/2.0/identifier_select\",\n            \"openid.return_to\": url,\n            \"openid.realm\": urllib.parse.urljoin(url, \"/\"),\n            \"openid.mode\": \"checkid_setup\",\n        }\n        if ax_attrs:\n            args.update(\n                {\n                    \"openid.ns.ax\": \"http://openid.net/srv/ax/1.0\",\n                    \"openid.ax.mode\": \"fetch_request\",\n                }\n            )\n            ax_attrs = set(ax_attrs)\n            required = []  # type: List[str]\n            if \"name\" in ax_attrs:\n                ax_attrs -= set([\"name\", \"firstname\", \"fullname\", \"lastname\"])\n                required += [\"firstname\", \"fullname\", \"lastname\"]\n                args.update(\n                    {\n                        \"openid.ax.type.firstname\": \"http://axschema.org/namePerson/first\",\n                        \"openid.ax.type.fullname\": \"http://axschema.org/namePerson\",\n                        \"openid.ax.type.lastname\": \"http://axschema.org/namePerson/last\",\n                    }\n                )\n            known_attrs = {\n                \"email\": \"http://axschema.org/contact/email\",\n                \"language\": \"http://axschema.org/pref/language\",\n                \"username\": \"http://axschema.org/namePerson/friendly\",\n            }\n            for name in ax_attrs:\n                args[\"openid.ax.type.\" + name] = known_attrs[name]\n                required.append(name)\n            args[\"openid.ax.required\"] = \",\".join(required)\n        if oauth_scope:\n            args.update(\n                {\n                    \"openid.ns.oauth\": \"http://specs.openid.net/extensions/oauth/1.0\",\n                    \"openid.oauth.consumer\": handler.request.host.split(\":\")[0],\n                    \"openid.oauth.scope\": oauth_scope,\n                }\n            )\n        return args", "is_method": true, "class_name": "OpenIdMixin", "function_description": "Constructs and returns a dictionary of OpenID authentication parameters, including support for attribute exchange and optional OAuth scope, to facilitate OpenID login requests with customizable callback URIs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_on_authentication_verified", "line_number": 202, "body": "def _on_authentication_verified(\n        self, response: httpclient.HTTPResponse\n    ) -> Dict[str, Any]:\n        handler = cast(RequestHandler, self)\n        if b\"is_valid:true\" not in response.body:\n            raise AuthError(\"Invalid OpenID response: %r\" % response.body)\n\n        # Make sure we got back at least an email from attribute exchange\n        ax_ns = None\n        for key in handler.request.arguments:\n            if (\n                key.startswith(\"openid.ns.\")\n                and handler.get_argument(key) == u\"http://openid.net/srv/ax/1.0\"\n            ):\n                ax_ns = key[10:]\n                break\n\n        def get_ax_arg(uri: str) -> str:\n            if not ax_ns:\n                return u\"\"\n            prefix = \"openid.\" + ax_ns + \".type.\"\n            ax_name = None\n            for name in handler.request.arguments.keys():\n                if handler.get_argument(name) == uri and name.startswith(prefix):\n                    part = name[len(prefix) :]\n                    ax_name = \"openid.\" + ax_ns + \".value.\" + part\n                    break\n            if not ax_name:\n                return u\"\"\n            return handler.get_argument(ax_name, u\"\")\n\n        email = get_ax_arg(\"http://axschema.org/contact/email\")\n        name = get_ax_arg(\"http://axschema.org/namePerson\")\n        first_name = get_ax_arg(\"http://axschema.org/namePerson/first\")\n        last_name = get_ax_arg(\"http://axschema.org/namePerson/last\")\n        username = get_ax_arg(\"http://axschema.org/namePerson/friendly\")\n        locale = get_ax_arg(\"http://axschema.org/pref/language\").lower()\n        user = dict()\n        name_parts = []\n        if first_name:\n            user[\"first_name\"] = first_name\n            name_parts.append(first_name)\n        if last_name:\n            user[\"last_name\"] = last_name\n            name_parts.append(last_name)\n        if name:\n            user[\"name\"] = name\n        elif name_parts:\n            user[\"name\"] = u\" \".join(name_parts)\n        elif email:\n            user[\"name\"] = email.split(\"@\")[0]\n        if email:\n            user[\"email\"] = email\n        if locale:\n            user[\"locale\"] = locale\n        if username:\n            user[\"username\"] = username\n        claimed_id = handler.get_argument(\"openid.claimed_id\", None)\n        if claimed_id:\n            user[\"claimed_id\"] = claimed_id\n        return user", "is_method": true, "class_name": "OpenIdMixin", "function_description": "Processes and validates an OpenID authentication response, extracting and returning verified user attributes like email, name, and locale for use in user identification and session management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "get_auth_http_client", "line_number": 264, "body": "def get_auth_http_client(self) -> httpclient.AsyncHTTPClient:\n        \"\"\"Returns the `.AsyncHTTPClient` instance to be used for auth requests.\n\n        May be overridden by subclasses to use an HTTP client other than\n        the default.\n        \"\"\"\n        return httpclient.AsyncHTTPClient()", "is_method": true, "class_name": "OpenIdMixin", "function_description": "Returns the asynchronous HTTP client instance used for authentication requests, allowing subclasses to customize the HTTP client if needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_request_token_url", "line_number": 385, "body": "def _oauth_request_token_url(\n        self,\n        callback_uri: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n    ) -> str:\n        handler = cast(RequestHandler, self)\n        consumer_token = self._oauth_consumer_token()\n        url = self._OAUTH_REQUEST_TOKEN_URL  # type: ignore\n        args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            if callback_uri == \"oob\":\n                args[\"oauth_callback\"] = \"oob\"\n            elif callback_uri:\n                args[\"oauth_callback\"] = urllib.parse.urljoin(\n                    handler.request.full_url(), callback_uri\n                )\n            if extra_params:\n                args.update(extra_params)\n            signature = _oauth10a_signature(consumer_token, \"GET\", url, args)\n        else:\n            signature = _oauth_signature(consumer_token, \"GET\", url, args)\n\n        args[\"oauth_signature\"] = signature\n        return url + \"?\" + urllib.parse.urlencode(args)", "is_method": true, "class_name": "OAuthMixin", "function_description": "Constructs and returns a signed OAuth 1.0 or 1.0a request token URL, optionally incorporating a callback URI and extra parameters for authorization workflows. It enables initiating the OAuth token request step in authentication processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_on_request_token", "line_number": 416, "body": "def _on_request_token(\n        self,\n        authorize_url: str,\n        callback_uri: Optional[str],\n        response: httpclient.HTTPResponse,\n    ) -> None:\n        handler = cast(RequestHandler, self)\n        request_token = _oauth_parse_response(response.body)\n        data = (\n            base64.b64encode(escape.utf8(request_token[\"key\"]))\n            + b\"|\"\n            + base64.b64encode(escape.utf8(request_token[\"secret\"]))\n        )\n        handler.set_cookie(\"_oauth_request_token\", data)\n        args = dict(oauth_token=request_token[\"key\"])\n        if callback_uri == \"oob\":\n            handler.finish(authorize_url + \"?\" + urllib.parse.urlencode(args))\n            return\n        elif callback_uri:\n            args[\"oauth_callback\"] = urllib.parse.urljoin(\n                handler.request.full_url(), callback_uri\n            )\n        handler.redirect(authorize_url + \"?\" + urllib.parse.urlencode(args))", "is_method": true, "class_name": "OAuthMixin", "function_description": "Handles the OAuth request token response by storing the token in a cookie and redirecting or finishing the authorization flow based on the callback URI. It supports both out-of-band and URL-based OAuth callbacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_access_token_url", "line_number": 440, "body": "def _oauth_access_token_url(self, request_token: Dict[str, Any]) -> str:\n        consumer_token = self._oauth_consumer_token()\n        url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n        args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_token=escape.to_basestring(request_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        if \"verifier\" in request_token:\n            args[\"oauth_verifier\"] = request_token[\"verifier\"]\n\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            signature = _oauth10a_signature(\n                consumer_token, \"GET\", url, args, request_token\n            )\n        else:\n            signature = _oauth_signature(\n                consumer_token, \"GET\", url, args, request_token\n            )\n\n        args[\"oauth_signature\"] = signature\n        return url + \"?\" + urllib.parse.urlencode(args)", "is_method": true, "class_name": "OAuthMixin", "function_description": "Constructs and returns a complete OAuth access token request URL with all required parameters and a valid signature for authenticating OAuth 1.0/1.0a token exchanges. This facilitates obtaining access tokens during OAuth authorization flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_consumer_token", "line_number": 466, "body": "def _oauth_consumer_token(self) -> Dict[str, Any]:\n        \"\"\"Subclasses must override this to return their OAuth consumer keys.\n\n        The return value should be a `dict` with keys ``key`` and ``secret``.\n        \"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "OAuthMixin", "function_description": "Returns the OAuth consumer key and secret as a dictionary; subclasses must implement this to provide their specific OAuth credentials."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_request_parameters", "line_number": 497, "body": "def _oauth_request_parameters(\n        self,\n        url: str,\n        access_token: Dict[str, Any],\n        parameters: Dict[str, Any] = {},\n        method: str = \"GET\",\n    ) -> Dict[str, Any]:\n        \"\"\"Returns the OAuth parameters as a dict for the given request.\n\n        parameters should include all POST arguments and query string arguments\n        that will be sent with the request.\n        \"\"\"\n        consumer_token = self._oauth_consumer_token()\n        base_args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_token=escape.to_basestring(access_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        args = {}\n        args.update(base_args)\n        args.update(parameters)\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            signature = _oauth10a_signature(\n                consumer_token, method, url, args, access_token\n            )\n        else:\n            signature = _oauth_signature(\n                consumer_token, method, url, args, access_token\n            )\n        base_args[\"oauth_signature\"] = escape.to_basestring(signature)\n        return base_args", "is_method": true, "class_name": "OAuthMixin", "function_description": "Generates and returns the complete OAuth 1.0 authentication parameters, including the signature, for a given HTTP request to enable secure OAuth-signed API calls. This utility supports constructing properly authenticated requests with dynamic tokens and parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "get_auth_http_client", "line_number": 532, "body": "def get_auth_http_client(self) -> httpclient.AsyncHTTPClient:\n        \"\"\"Returns the `.AsyncHTTPClient` instance to be used for auth requests.\n\n        May be overridden by subclasses to use an HTTP client other than\n        the default.\n        \"\"\"\n        return httpclient.AsyncHTTPClient()", "is_method": true, "class_name": "OAuthMixin", "function_description": "Utility method in OAuthMixin that provides an asynchronous HTTP client instance for authentication requests, allowing subclasses to customize the HTTP client used during the auth process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "authorize_redirect", "line_number": 553, "body": "def authorize_redirect(\n        self,\n        redirect_uri: Optional[str] = None,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n        scope: Optional[List[str]] = None,\n        response_type: str = \"code\",\n    ) -> None:\n        \"\"\"Redirects the user to obtain OAuth authorization for this service.\n\n        Some providers require that you register a redirect URL with\n        your application instead of passing one via this method. You\n        should call this method to log the user in, and then call\n        ``get_authenticated_user`` in the handler for your\n        redirect URL to complete the authorization process.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument and returned awaitable were removed;\n           this is now an ordinary synchronous function.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        args = {\"response_type\": response_type}\n        if redirect_uri is not None:\n            args[\"redirect_uri\"] = redirect_uri\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if extra_params:\n            args.update(extra_params)\n        if scope:\n            args[\"scope\"] = \" \".join(scope)\n        url = self._OAUTH_AUTHORIZE_URL  # type: ignore\n        handler.redirect(url_concat(url, args))", "is_method": true, "class_name": "OAuth2Mixin", "function_description": "Initiates the OAuth2 authorization process by redirecting the user to the provider's consent page with specified parameters like redirect URI, client credentials, scope, and response type. This enables user login and authorization in OAuth2 flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_request_token_url", "line_number": 588, "body": "def _oauth_request_token_url(\n        self,\n        redirect_uri: Optional[str] = None,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        code: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n    ) -> str:\n        url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n        args = {}  # type: Dict[str, str]\n        if redirect_uri is not None:\n            args[\"redirect_uri\"] = redirect_uri\n        if code is not None:\n            args[\"code\"] = code\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if client_secret is not None:\n            args[\"client_secret\"] = client_secret\n        if extra_params:\n            args.update(extra_params)\n        return url_concat(url, args)", "is_method": true, "class_name": "OAuth2Mixin", "function_description": "Constructs and returns the OAuth2 access token request URL with optional parameters like redirect URI, client credentials, authorization code, and extra query arguments. Enables preparation of a properly formatted token exchange URL in OAuth2 authentication flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "get_auth_http_client", "line_number": 666, "body": "def get_auth_http_client(self) -> httpclient.AsyncHTTPClient:\n        \"\"\"Returns the `.AsyncHTTPClient` instance to be used for auth requests.\n\n        May be overridden by subclasses to use an HTTP client other than\n        the default.\n\n        .. versionadded:: 4.3\n        \"\"\"\n        return httpclient.AsyncHTTPClient()", "is_method": true, "class_name": "OAuth2Mixin", "function_description": "Provides the HTTP client instance used for authentication requests, allowing subclasses to customize the client for different auth communication needs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "_oauth_consumer_token", "line_number": 814, "body": "def _oauth_consumer_token(self) -> Dict[str, Any]:\n        handler = cast(RequestHandler, self)\n        handler.require_setting(\"twitter_consumer_key\", \"Twitter OAuth\")\n        handler.require_setting(\"twitter_consumer_secret\", \"Twitter OAuth\")\n        return dict(\n            key=handler.settings[\"twitter_consumer_key\"],\n            secret=handler.settings[\"twitter_consumer_secret\"],\n        )", "is_method": true, "class_name": "TwitterMixin", "function_description": "Internal method of TwitterMixin that retrieves OAuth consumer key and secret settings required for authenticating Twitter API requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/auth.py", "function": "get_ax_arg", "line_number": 219, "body": "def get_ax_arg(uri: str) -> str:\n            if not ax_ns:\n                return u\"\"\n            prefix = \"openid.\" + ax_ns + \".type.\"\n            ax_name = None\n            for name in handler.request.arguments.keys():\n                if handler.get_argument(name) == uri and name.startswith(prefix):\n                    part = name[len(prefix) :]\n                    ax_name = \"openid.\" + ax_ns + \".value.\" + part\n                    break\n            if not ax_name:\n                return u\"\"\n            return handler.get_argument(ax_name, u\"\")", "is_method": true, "class_name": "OpenIdMixin", "function_description": "Returns the value of an OpenID Attribute Exchange argument matching a given URI from the current request, supporting OpenID authentication protocols. It helps retrieve specific user attribute data during authentication processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "define", "line_number": 674, "body": "def define(\n    name: str,\n    default: Any = None,\n    type: Optional[type] = None,\n    help: Optional[str] = None,\n    metavar: Optional[str] = None,\n    multiple: bool = False,\n    group: Optional[str] = None,\n    callback: Optional[Callable[[Any], None]] = None,\n) -> None:\n    \"\"\"Defines an option in the global namespace.\n\n    See `OptionParser.define`.\n    \"\"\"\n    return options.define(\n        name,\n        default=default,\n        type=type,\n        help=help,\n        metavar=metavar,\n        multiple=multiple,\n        group=group,\n        callback=callback,\n    )", "is_method": false, "function_description": "This function registers a command-line option with specified attributes globally, enabling consistent option handling across an application. It serves as a centralized interface for defining configurable parameters and their behaviors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "parse_command_line", "line_number": 700, "body": "def parse_command_line(\n    args: Optional[List[str]] = None, final: bool = True\n) -> List[str]:\n    \"\"\"Parses global options from the command line.\n\n    See `OptionParser.parse_command_line`.\n    \"\"\"\n    return options.parse_command_line(args, final=final)", "is_method": false, "function_description": "Function that parses and returns global command-line options, optionally finalizing the parsing process, providing a utility for handling command-line arguments in applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "parse_config_file", "line_number": 710, "body": "def parse_config_file(path: str, final: bool = True) -> None:\n    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)", "is_method": false, "function_description": "This function parses global configuration options from a specified file, delegating to an underlying parser. It serves as a convenient interface for loading configuration settings into the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "print_help", "line_number": 718, "body": "def print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n\n    See `OptionParser.print_help`.\n    \"\"\"\n    return options.print_help(file)", "is_method": false, "function_description": "Utility function that outputs all available command-line options to a specified file or standard error, facilitating user guidance and command usage documentation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "add_parse_callback", "line_number": 726, "body": "def add_parse_callback(callback: Callable[[], None]) -> None:\n    \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n\n    See `OptionParser.add_parse_callback`\n    \"\"\"\n    options.add_parse_callback(callback)", "is_method": false, "function_description": "Service function that registers a callback to be executed after option parsing completes, enabling customized post-processing or actions once command-line options have been parsed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_normalize_name", "line_number": 145, "body": "def _normalize_name(self, name: str) -> str:\n        return name.replace(\"_\", \"-\")", "is_method": true, "class_name": "OptionParser", "function_description": "Converts option names by replacing underscores with hyphens, standardizing the format for consistent command-line option parsing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__getattr__", "line_number": 148, "body": "def __getattr__(self, name: str) -> Any:\n        name = self._normalize_name(name)\n        if isinstance(self._options.get(name), _Option):\n            return self._options[name].value()\n        raise AttributeError(\"Unrecognized option %r\" % name)", "is_method": true, "class_name": "OptionParser", "function_description": "Provides dynamic access to stored options by attribute name, returning the corresponding option's value or raising an error if the option is unrecognized."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__setattr__", "line_number": 154, "body": "def __setattr__(self, name: str, value: Any) -> None:\n        name = self._normalize_name(name)\n        if isinstance(self._options.get(name), _Option):\n            return self._options[name].set(value)\n        raise AttributeError(\"Unrecognized option %r\" % name)", "is_method": true, "class_name": "OptionParser", "function_description": "Overrides attribute assignment to set recognized options within the OptionParser, raising an error for unknown options. It enables controlled configuration of parser options via attribute access."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__iter__", "line_number": 160, "body": "def __iter__(self) -> Iterator:\n        return (opt.name for opt in self._options.values())", "is_method": true, "class_name": "OptionParser", "function_description": "Returns an iterator over the names of all available options in the OptionParser, facilitating easy iteration through configurable parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__contains__", "line_number": 163, "body": "def __contains__(self, name: str) -> bool:\n        name = self._normalize_name(name)\n        return name in self._options", "is_method": true, "class_name": "OptionParser", "function_description": "Checks if a normalized option name exists within the OptionParser's collection of options, enabling quick membership testing of options by their names."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__getitem__", "line_number": 167, "body": "def __getitem__(self, name: str) -> Any:\n        return self.__getattr__(name)", "is_method": true, "class_name": "OptionParser", "function_description": "Provides dictionary-like access to options by delegating key access to attribute retrieval within the OptionParser class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__setitem__", "line_number": 170, "body": "def __setitem__(self, name: str, value: Any) -> None:\n        return self.__setattr__(name, value)", "is_method": true, "class_name": "OptionParser", "function_description": "Allows setting an option's value using dictionary-like syntax, internally delegating to attribute assignment in the OptionParser class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "items", "line_number": 173, "body": "def items(self) -> Iterable[Tuple[str, Any]]:\n        \"\"\"An iterable of (name, value) pairs.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return [(opt.name, opt.value()) for name, opt in self._options.items()]", "is_method": true, "class_name": "OptionParser", "function_description": "Provides an iterable of option name and value pairs from the OptionParser, enabling easy access to all configured options and their current values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "groups", "line_number": 180, "body": "def groups(self) -> Set[str]:\n        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())", "is_method": true, "class_name": "OptionParser", "function_description": "Returns the set of all option groups defined within the OptionParser, allowing identification of distinct groups of command-line options configured in the parser."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "group_dict", "line_number": 187, "body": "def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict(\n            (opt.name, opt.value())\n            for name, opt in self._options.items()\n            if not group or group == opt.group_name\n        )", "is_method": true, "class_name": "OptionParser", "function_description": "Returns a dictionary of option names and values belonging to a specified group, facilitating the transfer of grouped configuration options to other components like application settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "as_dict", "line_number": 210, "body": "def as_dict(self) -> Dict[str, Any]:\n        \"\"\"The names and values of all options.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict((opt.name, opt.value()) for name, opt in self._options.items())", "is_method": true, "class_name": "OptionParser", "function_description": "Provides a dictionary mapping option names to their current values in the OptionParser, enabling easy access to all parsed options and their settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "define", "line_number": 217, "body": "def define(\n        self,\n        name: str,\n        default: Any = None,\n        type: Optional[type] = None,\n        help: Optional[str] = None,\n        metavar: Optional[str] = None,\n        multiple: bool = False,\n        group: Optional[str] = None,\n        callback: Optional[Callable[[Any], None]] = None,\n    ) -> None:\n        \"\"\"Defines a new command line option.\n\n        ``type`` can be any of `str`, `int`, `float`, `bool`,\n        `~datetime.datetime`, or `~datetime.timedelta`. If no ``type``\n        is given but a ``default`` is, ``type`` is the type of\n        ``default``. Otherwise, ``type`` defaults to `str`.\n\n        If ``multiple`` is True, the option value is a list of ``type``\n        instead of an instance of ``type``.\n\n        ``help`` and ``metavar`` are used to construct the\n        automatically generated command line help string. The help\n        message is formatted like::\n\n           --name=METAVAR      help string\n\n        ``group`` is used to group the defined options in logical\n        groups. By default, command line options are grouped by the\n        file in which they are defined.\n\n        Command line option names must be unique globally.\n\n        If a ``callback`` is given, it will be run with the new value whenever\n        the option is changed.  This can be used to combine command-line\n        and file-based options::\n\n            define(\"config\", type=str, help=\"path to config file\",\n                   callback=lambda path: parse_config_file(path, final=False))\n\n        With this definition, options in the file specified by ``--config`` will\n        override options set earlier on the command line, but can be overridden\n        by later flags.\n\n        \"\"\"\n        normalized = self._normalize_name(name)\n        if normalized in self._options:\n            raise Error(\n                \"Option %r already defined in %s\"\n                % (normalized, self._options[normalized].file_name)\n            )\n        frame = sys._getframe(0)\n        options_file = frame.f_code.co_filename\n\n        # Can be called directly, or through top level define() fn, in which\n        # case, step up above that frame to look for real caller.\n        if (\n            frame.f_back.f_code.co_filename == options_file\n            and frame.f_back.f_code.co_name == \"define\"\n        ):\n            frame = frame.f_back\n\n        file_name = frame.f_back.f_code.co_filename\n        if file_name == options_file:\n            file_name = \"\"\n        if type is None:\n            if not multiple and default is not None:\n                type = default.__class__\n            else:\n                type = str\n        if group:\n            group_name = group  # type: Optional[str]\n        else:\n            group_name = file_name\n        option = _Option(\n            name,\n            file_name=file_name,\n            default=default,\n            type=type,\n            help=help,\n            metavar=metavar,\n            multiple=multiple,\n            group_name=group_name,\n            callback=callback,\n        )\n        self._options[normalized] = option", "is_method": true, "class_name": "OptionParser", "function_description": "Defines and registers a new command-line option with specified attributes like type, default, help text, grouping, and change callback. It enables structured and extensible command-line argument handling in the OptionParser context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "parse_command_line", "line_number": 304, "body": "def parse_command_line(\n        self, args: Optional[List[str]] = None, final: bool = True\n    ) -> List[str]:\n        \"\"\"Parses all options given on the command line (defaults to\n        `sys.argv`).\n\n        Options look like ``--option=value`` and are parsed according\n        to their ``type``. For boolean options, ``--option`` is\n        equivalent to ``--option=true``\n\n        If the option has ``multiple=True``, comma-separated values\n        are accepted. For multi-value integer options, the syntax\n        ``x:y`` is also accepted and equivalent to ``range(x, y)``.\n\n        Note that ``args[0]`` is ignored since it is the program name\n        in `sys.argv`.\n\n        We return a list of all arguments that are not parsed as options.\n\n        If ``final`` is ``False``, parse callbacks will not be run.\n        This is useful for applications that wish to combine configurations\n        from multiple sources.\n\n        \"\"\"\n        if args is None:\n            args = sys.argv\n        remaining = []  # type: List[str]\n        for i in range(1, len(args)):\n            # All things after the last option are command line arguments\n            if not args[i].startswith(\"-\"):\n                remaining = args[i:]\n                break\n            if args[i] == \"--\":\n                remaining = args[i + 1 :]\n                break\n            arg = args[i].lstrip(\"-\")\n            name, equals, value = arg.partition(\"=\")\n            name = self._normalize_name(name)\n            if name not in self._options:\n                self.print_help()\n                raise Error(\"Unrecognized command line option: %r\" % name)\n            option = self._options[name]\n            if not equals:\n                if option.type == bool:\n                    value = \"true\"\n                else:\n                    raise Error(\"Option %r requires a value\" % name)\n            option.parse(value)\n\n        if final:\n            self.run_parse_callbacks()\n\n        return remaining", "is_method": true, "class_name": "OptionParser", "function_description": "Parses and validates command-line options from input arguments, converting them to their declared types and handling multi-value and boolean flags. It returns unparsed arguments, supporting flexible option processing and callback execution control."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "parse_config_file", "line_number": 358, "body": "def parse_config_file(self, path: str, final: bool = True) -> None:\n        \"\"\"Parses and loads the config file at the given path.\n\n        The config file contains Python code that will be executed (so\n        it is **not safe** to use untrusted config files). Anything in\n        the global namespace that matches a defined option will be\n        used to set that option's value.\n\n        Options may either be the specified type for the option or\n        strings (in which case they will be parsed the same way as in\n        `.parse_command_line`)\n\n        Example (using the options defined in the top-level docs of\n        this module)::\n\n            port = 80\n            mysql_host = 'mydb.example.com:3306'\n            # Both lists and comma-separated strings are allowed for\n            # multiple=True.\n            memcache_hosts = ['cache1.example.com:11011',\n                              'cache2.example.com:11011']\n            memcache_hosts = 'cache1.example.com:11011,cache2.example.com:11011'\n\n        If ``final`` is ``False``, parse callbacks will not be run.\n        This is useful for applications that wish to combine configurations\n        from multiple sources.\n\n        .. note::\n\n            `tornado.options` is primarily a command-line library.\n            Config file support is provided for applications that wish\n            to use it, but applications that prefer config files may\n            wish to look at other libraries instead.\n\n        .. versionchanged:: 4.1\n           Config files are now always interpreted as utf-8 instead of\n           the system default encoding.\n\n        .. versionchanged:: 4.4\n           The special variable ``__file__`` is available inside config\n           files, specifying the absolute path to the config file itself.\n\n        .. versionchanged:: 5.1\n           Added the ability to set options via strings in config files.\n\n        \"\"\"\n        config = {\"__file__\": os.path.abspath(path)}\n        with open(path, \"rb\") as f:\n            exec_in(native_str(f.read()), config, config)\n        for name in config:\n            normalized = self._normalize_name(name)\n            if normalized in self._options:\n                option = self._options[normalized]\n                if option.multiple:\n                    if not isinstance(config[name], (list, str)):\n                        raise Error(\n                            \"Option %r is required to be a list of %s \"\n                            \"or a comma-separated string\"\n                            % (option.name, option.type.__name__)\n                        )\n\n                if type(config[name]) == str and option.type != str:\n                    option.parse(config[name])\n                else:\n                    option.set(config[name])\n\n        if final:\n            self.run_parse_callbacks()", "is_method": true, "class_name": "OptionParser", "function_description": "Loads and applies configuration options by executing a Python config file, setting matching options from its global namespace. Useful for combining and finalizing app settings from trusted config files with flexible value parsing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "print_help", "line_number": 427, "body": "def print_help(self, file: Optional[TextIO] = None) -> None:\n        \"\"\"Prints all the command line options to stderr (or another file).\"\"\"\n        if file is None:\n            file = sys.stderr\n        print(\"Usage: %s [OPTIONS]\" % sys.argv[0], file=file)\n        print(\"\\nOptions:\\n\", file=file)\n        by_group = {}  # type: Dict[str, List[_Option]]\n        for option in self._options.values():\n            by_group.setdefault(option.group_name, []).append(option)\n\n        for filename, o in sorted(by_group.items()):\n            if filename:\n                print(\"\\n%s options:\\n\" % os.path.normpath(filename), file=file)\n            o.sort(key=lambda option: option.name)\n            for option in o:\n                # Always print names with dashes in a CLI context.\n                prefix = self._normalize_name(option.name)\n                if option.metavar:\n                    prefix += \"=\" + option.metavar\n                description = option.help or \"\"\n                if option.default is not None and option.default != \"\":\n                    description += \" (default %s)\" % option.default\n                lines = textwrap.wrap(description, 79 - 35)\n                if len(prefix) > 30 or len(lines) == 0:\n                    lines.insert(0, \"\")\n                print(\"  --%-30s %s\" % (prefix, lines[0]), file=file)\n                for line in lines[1:]:\n                    print(\"%-34s %s\" % (\" \", line), file=file)\n        print(file=file)", "is_method": true, "class_name": "OptionParser", "function_description": "Prints a formatted help message listing all available command line options, optionally grouped, to the specified file or standard error. This aids users in understanding and using the command line interface effectively."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_help_callback", "line_number": 457, "body": "def _help_callback(self, value: bool) -> None:\n        if value:\n            self.print_help()\n            sys.exit(0)", "is_method": true, "class_name": "OptionParser", "function_description": "Private helper method of the OptionParser class that displays help information and terminates the program when the help option is triggered. It supports command-line interfaces by providing usage guidance to users."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "add_parse_callback", "line_number": 462, "body": "def add_parse_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Adds a parse callback, to be invoked when option parsing is done.\"\"\"\n        self._parse_callbacks.append(callback)", "is_method": true, "class_name": "OptionParser", "function_description": "Adds a callback function to be executed after option parsing completes, allowing custom actions or processing triggered by the parser's completion event."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "run_parse_callbacks", "line_number": 466, "body": "def run_parse_callbacks(self) -> None:\n        for callback in self._parse_callbacks:\n            callback()", "is_method": true, "class_name": "OptionParser", "function_description": "Executes all registered parse callback functions in sequence, enabling custom processing during option parsing workflows within the OptionParser class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "mockable", "line_number": 470, "body": "def mockable(self) -> \"_Mockable\":\n        \"\"\"Returns a wrapper around self that is compatible with\n        `mock.patch <unittest.mock.patch>`.\n\n        The `mock.patch <unittest.mock.patch>` function (included in\n        the standard library `unittest.mock` package since Python 3.3,\n        or in the third-party ``mock`` package for older versions of\n        Python) is incompatible with objects like ``options`` that\n        override ``__getattr__`` and ``__setattr__``.  This function\n        returns an object that can be used with `mock.patch.object\n        <unittest.mock.patch.object>` to modify option values::\n\n            with mock.patch.object(options.mockable(), 'name', value):\n                assert options.name == value\n        \"\"\"\n        return _Mockable(self)", "is_method": true, "class_name": "OptionParser", "function_description": "Provides a mock-compatible wrapper for the OptionParser instance, enabling safe use with unittest.mock.patch to modify option attributes during testing despite dynamic attribute handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__getattr__", "line_number": 506, "body": "def __getattr__(self, name: str) -> Any:\n        return getattr(self._options, name)", "is_method": true, "class_name": "_Mockable", "function_description": "Provides transparent access to attributes of the internal _options object, allowing dynamic retrieval of its properties through the containing _Mockable instance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__setattr__", "line_number": 509, "body": "def __setattr__(self, name: str, value: Any) -> None:\n        assert name not in self._originals, \"don't reuse mockable objects\"\n        self._originals[name] = getattr(self._options, name)\n        setattr(self._options, name, value)", "is_method": true, "class_name": "_Mockable", "function_description": "Overrides attribute assignment to track and temporarily replace original attribute values for mocking purposes, preventing reuse of mocked attributes within the _Mockable context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "__delattr__", "line_number": 514, "body": "def __delattr__(self, name: str) -> None:\n        setattr(self._options, name, self._originals.pop(name))", "is_method": true, "class_name": "_Mockable", "function_description": "Overrides attribute deletion to restore the original value from stored backups in the _options attribute. This enables controlled rollback of attribute changes within the _Mockable context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "value", "line_number": 551, "body": "def value(self) -> Any:\n        return self.default if self._value is _Option.UNSET else self._value", "is_method": true, "class_name": "_Option", "function_description": "Returns the current value of the option, defaulting to a preset value if no explicit value is set. This method provides consistent access to an option's effective value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "parse", "line_number": 554, "body": "def parse(self, value: str) -> Any:\n        _parse = {\n            datetime.datetime: self._parse_datetime,\n            datetime.timedelta: self._parse_timedelta,\n            bool: self._parse_bool,\n            basestring_type: self._parse_string,\n        }.get(\n            self.type, self.type\n        )  # type: Callable[[str], Any]\n        if self.multiple:\n            self._value = []\n            for part in value.split(\",\"):\n                if issubclass(self.type, numbers.Integral):\n                    # allow ranges of the form X:Y (inclusive at both ends)\n                    lo_str, _, hi_str = part.partition(\":\")\n                    lo = _parse(lo_str)\n                    hi = _parse(hi_str) if hi_str else lo\n                    self._value.extend(range(lo, hi + 1))\n                else:\n                    self._value.append(_parse(part))\n        else:\n            self._value = _parse(value)\n        if self.callback is not None:\n            self.callback(self._value)\n        return self.value()", "is_method": true, "class_name": "_Option", "function_description": "Parses a string input into a typed value or list of values based on the option's expected type, supporting ranges for integer types, and triggers an optional callback with the parsed result."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "set", "line_number": 580, "body": "def set(self, value: Any) -> None:\n        if self.multiple:\n            if not isinstance(value, list):\n                raise Error(\n                    \"Option %r is required to be a list of %s\"\n                    % (self.name, self.type.__name__)\n                )\n            for item in value:\n                if item is not None and not isinstance(item, self.type):\n                    raise Error(\n                        \"Option %r is required to be a list of %s\"\n                        % (self.name, self.type.__name__)\n                    )\n        else:\n            if value is not None and not isinstance(value, self.type):\n                raise Error(\n                    \"Option %r is required to be a %s (%s given)\"\n                    % (self.name, self.type.__name__, type(value))\n                )\n        self._value = value\n        if self.callback is not None:\n            self.callback(self._value)", "is_method": true, "class_name": "_Option", "function_description": "Sets the value of the _Option instance with type validation, ensuring single or multiple values match the expected type, and triggers an optional callback after assignment. It provides controlled and type-safe option value assignment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_parse_datetime", "line_number": 617, "body": "def _parse_datetime(self, value: str) -> datetime.datetime:\n        for format in self._DATETIME_FORMATS:\n            try:\n                return datetime.datetime.strptime(value, format)\n            except ValueError:\n                pass\n        raise Error(\"Unrecognized date/time format: %r\" % value)", "is_method": true, "class_name": "_Option", "function_description": "Utility method of the _Option class that parses a string into a datetime object by matching it against predefined date/time formats. It enables reliable conversion of various date/time string formats into standardized datetime instances."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_parse_timedelta", "line_number": 643, "body": "def _parse_timedelta(self, value: str) -> datetime.timedelta:\n        try:\n            sum = datetime.timedelta()\n            start = 0\n            while start < len(value):\n                m = self._TIMEDELTA_PATTERN.match(value, start)\n                if not m:\n                    raise Exception()\n                num = float(m.group(1))\n                units = m.group(2) or \"seconds\"\n                units = self._TIMEDELTA_ABBREV_DICT.get(units, units)\n                sum += datetime.timedelta(**{units: num})\n                start = m.end()\n            return sum\n        except Exception:\n            raise", "is_method": true, "class_name": "_Option", "function_description": "Parses a string representing a duration into a datetime.timedelta object, interpreting various time units and abbreviations for flexible time interval conversion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_parse_bool", "line_number": 660, "body": "def _parse_bool(self, value: str) -> bool:\n        return value.lower() not in (\"false\", \"0\", \"f\")", "is_method": true, "class_name": "_Option", "function_description": "Utility method in the _Option class that interprets a string value as a boolean, returning False for common false representations and True otherwise. It facilitates consistent boolean parsing from string inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/options.py", "function": "_parse_string", "line_number": 663, "body": "def _parse_string(self, value: str) -> str:\n        return _unicode(value)", "is_method": true, "class_name": "_Option", "function_description": "Utility method in the _Option class that converts a given string value to its Unicode representation, ensuring consistent string encoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "start", "line_number": 118, "body": "def start(check_time: int = 500) -> None:\n    \"\"\"Begins watching source files for changes.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n    \"\"\"\n    io_loop = ioloop.IOLoop.current()\n    if io_loop in _io_loops:\n        return\n    _io_loops[io_loop] = True\n    if len(_io_loops) > 1:\n        gen_log.warning(\"tornado.autoreload started more than once in the same process\")\n    modify_times = {}  # type: Dict[str, float]\n    callback = functools.partial(_reload_on_update, modify_times)\n    scheduler = ioloop.PeriodicCallback(callback, check_time)\n    scheduler.start()", "is_method": false, "function_description": "Starts monitoring source files for changes, triggering reload actions at specified intervals; useful for enabling automatic code reload during development to reflect updates without manual restarts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "wait", "line_number": 136, "body": "def wait() -> None:\n    \"\"\"Wait for a watched file to change, then restart the process.\n\n    Intended to be used at the end of scripts like unit test runners,\n    to run the tests again after any source file changes (but see also\n    the command-line interface in `main`)\n    \"\"\"\n    io_loop = ioloop.IOLoop()\n    io_loop.add_callback(start)\n    io_loop.start()", "is_method": false, "function_description": "Utility function that watches for changes in source files and restarts the process, enabling automatic re-execution of scripts like unit tests upon file modifications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "watch", "line_number": 148, "body": "def watch(filename: str) -> None:\n    \"\"\"Add a file to the watch list.\n\n    All imported modules are watched by default.\n    \"\"\"\n    _watched_files.add(filename)", "is_method": false, "function_description": "Adds a specified file to a list monitored for changes, allowing the system to track modifications beyond default imported modules. This supports functions dependent on dynamic file updates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "add_reload_hook", "line_number": 156, "body": "def add_reload_hook(fn: Callable[[], None]) -> None:\n    \"\"\"Add a function to be called before reloading the process.\n\n    Note that for open file and socket handles it is generally\n    preferable to set the ``FD_CLOEXEC`` flag (using `fcntl` or\n    `os.set_inheritable`) instead of using a reload hook to close them.\n    \"\"\"\n    _reload_hooks.append(fn)", "is_method": false, "function_description": "Function that registers a callable to be executed before the process reloads, allowing for custom cleanup or preparation tasks prior to reload events."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "_reload_on_update", "line_number": 166, "body": "def _reload_on_update(modify_times: Dict[str, float]) -> None:\n    if _reload_attempted:\n        # We already tried to reload and it didn't work, so don't try again.\n        return\n    if process.task_id() is not None:\n        # We're in a child process created by fork_processes.  If child\n        # processes restarted themselves, they'd all restart and then\n        # all call fork_processes again.\n        return\n    for module in list(sys.modules.values()):\n        # Some modules play games with sys.modules (e.g. email/__init__.py\n        # in the standard library), and occasionally this can cause strange\n        # failures in getattr.  Just ignore anything that's not an ordinary\n        # module.\n        if not isinstance(module, types.ModuleType):\n            continue\n        path = getattr(module, \"__file__\", None)\n        if not path:\n            continue\n        if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n            path = path[:-1]\n        _check_file(modify_times, path)\n    for path in _watched_files:\n        _check_file(modify_times, path)", "is_method": false, "function_description": "Internal utility that checks if any loaded Python modules or watched files have changed on disk and triggers a reload to update them during runtime."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "_check_file", "line_number": 192, "body": "def _check_file(modify_times: Dict[str, float], path: str) -> None:\n    try:\n        modified = os.stat(path).st_mtime\n    except Exception:\n        return\n    if path not in modify_times:\n        modify_times[path] = modified\n        return\n    if modify_times[path] != modified:\n        gen_log.info(\"%s modified; restarting server\", path)\n        _reload()", "is_method": false, "function_description": "Internal utility that detects file modifications by comparing stored timestamps, triggering a server restart if changes are detected to ensure the system reflects the latest file state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "_reload", "line_number": 205, "body": "def _reload() -> None:\n    global _reload_attempted\n    _reload_attempted = True\n    for fn in _reload_hooks:\n        fn()\n    if hasattr(signal, \"setitimer\"):\n        # Clear the alarm signal set by\n        # ioloop.set_blocking_log_threshold so it doesn't fire\n        # after the exec.\n        signal.setitimer(signal.ITIMER_REAL, 0, 0)\n    # sys.path fixes: see comments at top of file.  If __main__.__spec__\n    # exists, we were invoked with -m and the effective path is about to\n    # change on re-exec.  Reconstruct the original command line to\n    # ensure that the new process sees the same path we did.  If\n    # __spec__ is not available (Python < 3.4), check instead if\n    # sys.path[0] is an empty string and add the current directory to\n    # $PYTHONPATH.\n    if _autoreload_is_main:\n        assert _original_argv is not None\n        spec = _original_spec\n        argv = _original_argv\n    else:\n        spec = getattr(sys.modules[\"__main__\"], \"__spec__\", None)\n        argv = sys.argv\n    if spec:\n        argv = [\"-m\", spec.name] + argv[1:]\n    else:\n        path_prefix = \".\" + os.pathsep\n        if sys.path[0] == \"\" and not os.environ.get(\"PYTHONPATH\", \"\").startswith(\n            path_prefix\n        ):\n            os.environ[\"PYTHONPATH\"] = path_prefix + os.environ.get(\"PYTHONPATH\", \"\")\n    if not _has_execv:\n        subprocess.Popen([sys.executable] + argv)\n        os._exit(0)\n    else:\n        try:\n            os.execv(sys.executable, [sys.executable] + argv)\n        except OSError:\n            # Mac OS X versions prior to 10.6 do not support execv in\n            # a process that contains multiple threads.  Instead of\n            # re-executing in the current process, start a new one\n            # and cause the current process to exit.  This isn't\n            # ideal since the new process is detached from the parent\n            # terminal and thus cannot easily be killed with ctrl-C,\n            # but it's better than not being able to autoreload at\n            # all.\n            # Unfortunately the errno returned in this case does not\n            # appear to be consistent, so we can't easily check for\n            # this error specifically.\n            os.spawnv(\n                os.P_NOWAIT, sys.executable, [sys.executable] + argv  # type: ignore\n            )\n            # At this point the IOLoop has been closed and finally\n            # blocks will experience errors if we allow the stack to\n            # unwind, so just exit uncleanly.\n            os._exit(0)", "is_method": false, "function_description": "Utility function that triggers registered reload hooks and safely restarts the Python process with the original execution context, supporting autoreload functionality in development environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/autoreload.py", "function": "main", "line_number": 271, "body": "def main() -> None:\n    \"\"\"Command-line wrapper to re-run a script whenever its source changes.\n\n    Scripts may be specified by filename or module name::\n\n        python -m tornado.autoreload -m tornado.test.runtests\n        python -m tornado.autoreload tornado/test/runtests.py\n\n    Running a script with this wrapper is similar to calling\n    `tornado.autoreload.wait` at the end of the script, but this wrapper\n    can catch import-time problems like syntax errors that would otherwise\n    prevent the script from reaching its call to `wait`.\n    \"\"\"\n    # Remember that we were launched with autoreload as main.\n    # The main module can be tricky; set the variables both in our globals\n    # (which may be __main__) and the real importable version.\n    import tornado.autoreload\n\n    global _autoreload_is_main\n    global _original_argv, _original_spec\n    tornado.autoreload._autoreload_is_main = _autoreload_is_main = True\n    original_argv = sys.argv\n    tornado.autoreload._original_argv = _original_argv = original_argv\n    original_spec = getattr(sys.modules[\"__main__\"], \"__spec__\", None)\n    tornado.autoreload._original_spec = _original_spec = original_spec\n    sys.argv = sys.argv[:]\n    if len(sys.argv) >= 3 and sys.argv[1] == \"-m\":\n        mode = \"module\"\n        module = sys.argv[2]\n        del sys.argv[1:3]\n    elif len(sys.argv) >= 2:\n        mode = \"script\"\n        script = sys.argv[1]\n        sys.argv = sys.argv[1:]\n    else:\n        print(_USAGE, file=sys.stderr)\n        sys.exit(1)\n\n    try:\n        if mode == \"module\":\n            import runpy\n\n            runpy.run_module(module, run_name=\"__main__\", alter_sys=True)\n        elif mode == \"script\":\n            with open(script) as f:\n                # Execute the script in our namespace instead of creating\n                # a new one so that something that tries to import __main__\n                # (e.g. the unittest module) will see names defined in the\n                # script instead of just those defined in this module.\n                global __file__\n                __file__ = script\n                # If __package__ is defined, imports may be incorrectly\n                # interpreted as relative to this module.\n                global __package__\n                del __package__\n                exec_in(f.read(), globals(), globals())\n    except SystemExit as e:\n        logging.basicConfig()\n        gen_log.info(\"Script exited with status %s\", e.code)\n    except Exception as e:\n        logging.basicConfig()\n        gen_log.warning(\"Script exited with uncaught exception\", exc_info=True)\n        # If an exception occurred at import time, the file with the error\n        # never made it into sys.modules and so we won't know to watch it.\n        # Just to make sure we've covered everything, walk the stack trace\n        # from the exception and watch every file.\n        for (filename, lineno, name, line) in traceback.extract_tb(sys.exc_info()[2]):\n            watch(filename)\n        if isinstance(e, SyntaxError):\n            # SyntaxErrors are special:  their innermost stack frame is fake\n            # so extract_tb won't see it and we have to get the filename\n            # from the exception object.\n            watch(e.filename)\n    else:\n        logging.basicConfig()\n        gen_log.info(\"Script exited normally\")\n    # restore sys.argv so subsequent executions will include autoreload\n    sys.argv = original_argv\n\n    if mode == \"module\":\n        # runpy did a fake import of the module as __main__, but now it's\n        # no longer in sys.modules.  Figure out where it is and watch it.\n        loader = pkgutil.get_loader(module)\n        if loader is not None:\n            watch(loader.get_filename())  # type: ignore\n\n    wait()", "is_method": false, "function_description": "Main command-line entry function that runs a specified Python script or module with automatic reloads on source changes, enabling live code updates and error handling during import-time failures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "stream_request_body", "line_number": 1821, "body": "def stream_request_body(cls: Type[RequestHandler]) -> Type[RequestHandler]:\n    \"\"\"Apply to `RequestHandler` subclasses to enable streaming body support.\n\n    This decorator implies the following changes:\n\n    * `.HTTPServerRequest.body` is undefined, and body arguments will not\n      be included in `RequestHandler.get_argument`.\n    * `RequestHandler.prepare` is called when the request headers have been\n      read instead of after the entire body has been read.\n    * The subclass must define a method ``data_received(self, data):``, which\n      will be called zero or more times as data is available.  Note that\n      if the request has an empty body, ``data_received`` may not be called.\n    * ``prepare`` and ``data_received`` may return Futures (such as via\n      ``@gen.coroutine``, in which case the next method will not be called\n      until those futures have completed.\n    * The regular HTTP method (``post``, ``put``, etc) will be called after\n      the entire body has been read.\n\n    See the `file receiver demo <https://github.com/tornadoweb/tornado/tree/master/demos/file_upload/>`_\n    for example usage.\n    \"\"\"  # noqa: E501\n    if not issubclass(cls, RequestHandler):\n        raise TypeError(\"expected subclass of RequestHandler, got %r\", cls)\n    cls._stream_request_body = True\n    return cls", "is_method": false, "function_description": "Decorator that enables streaming request body support for Tornado RequestHandler subclasses, allowing processing of incoming data chunks before the entire body is read. Useful for handling large uploads or asynchronous data reception efficiently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_has_stream_request_body", "line_number": 1848, "body": "def _has_stream_request_body(cls: Type[RequestHandler]) -> bool:\n    if not issubclass(cls, RequestHandler):\n        raise TypeError(\"expected subclass of RequestHandler, got %r\", cls)\n    return cls._stream_request_body", "is_method": false, "function_description": "Static utility function that checks if a RequestHandler subclass expects streamed request bodies, enabling appropriate handling of incoming request data in web server contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "removeslash", "line_number": 1854, "body": "def removeslash(\n    method: Callable[..., Optional[Awaitable[None]]]\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Use this decorator to remove trailing slashes from the request path.\n\n    For example, a request to ``/foo/`` would redirect to ``/foo`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/*'`` in conjunction with using the decorator.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return None\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)\n\n    return wrapper", "is_method": false, "function_description": "Decorator that ensures HTTP requests with trailing slashes redirect to the same path without the slash, supporting cleaner URLs and consistent request handling in web request handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "addslash", "line_number": 1883, "body": "def addslash(\n    method: Callable[..., Optional[Awaitable[None]]]\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Use this decorator to add a missing trailing slash to the request path.\n\n    For example, a request to ``/foo`` would redirect to ``/foo/`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/?'`` in conjunction with using the decorator.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path + \"/\"\n                if self.request.query:\n                    uri += \"?\" + self.request.query\n                self.redirect(uri, permanent=True)\n                return None\n            raise HTTPError(404)\n        return method(self, *args, **kwargs)\n\n    return wrapper", "is_method": false, "function_description": "Decorator for request handler methods that automatically redirects requests lacking a trailing slash to the equivalent URL with a trailing slash, ensuring consistent URL formatting and preventing 404 errors for GET or HEAD requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "authenticated", "line_number": 3141, "body": "def authenticated(\n    method: Callable[..., Optional[Awaitable[None]]]\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Decorate methods with this to require that the user be logged in.\n\n    If the user is not logged in, they will be redirected to the configured\n    `login url <RequestHandler.get_login_url>`.\n\n    If you configure a login url with a query parameter, Tornado will\n    assume you know what you're doing and use it as-is.  If not, it\n    will add a `next` parameter so the login page knows where to send\n    you once you're logged in.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urllib.parse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        assert self.request.uri is not None\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return None\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)\n\n    return wrapper", "is_method": false, "function_description": "Decorator that enforces user authentication for request handlers, redirecting unauthenticated users to a login page and preserving the original URL for post-login redirection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "create_signed_value", "line_number": 3345, "body": "def create_signed_value(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: Union[str, bytes],\n    version: Optional[int] = None,\n    clock: Optional[Callable[[], float]] = None,\n    key_version: Optional[int] = None,\n) -> bytes:\n    if version is None:\n        version = DEFAULT_SIGNED_VALUE_VERSION\n    if clock is None:\n        clock = time.time\n\n    timestamp = utf8(str(int(clock())))\n    value = base64.b64encode(utf8(value))\n    if version == 1:\n        assert not isinstance(secret, dict)\n        signature = _create_signature_v1(secret, name, value, timestamp)\n        value = b\"|\".join([value, timestamp, signature])\n        return value\n    elif version == 2:\n        # The v2 format consists of a version number and a series of\n        # length-prefixed fields \"%d:%s\", the last of which is a\n        # signature, all separated by pipes.  All numbers are in\n        # decimal format with no leading zeros.  The signature is an\n        # HMAC-SHA256 of the whole string up to that point, including\n        # the final pipe.\n        #\n        # The fields are:\n        # - format version (i.e. 2; no length prefix)\n        # - key version (integer, default is 0)\n        # - timestamp (integer seconds since epoch)\n        # - name (not encoded; assumed to be ~alphanumeric)\n        # - value (base64-encoded)\n        # - signature (hex-encoded; no length prefix)\n        def format_field(s: Union[str, bytes]) -> bytes:\n            return utf8(\"%d:\" % len(s)) + utf8(s)\n\n        to_sign = b\"|\".join(\n            [\n                b\"2\",\n                format_field(str(key_version or 0)),\n                format_field(timestamp),\n                format_field(name),\n                format_field(value),\n                b\"\",\n            ]\n        )\n\n        if isinstance(secret, dict):\n            assert (\n                key_version is not None\n            ), \"Key version must be set when sign key dict is used\"\n            assert version >= 2, \"Version must be at least 2 for key version support\"\n            secret = secret[key_version]\n\n        signature = _create_signature_v2(secret, to_sign)\n        return to_sign + signature\n    else:\n        raise ValueError(\"Unsupported version %d\" % version)", "is_method": false, "function_description": "Generates a cryptographically signed and timestamped value to ensure data integrity and authenticity. Supports multiple signature versions and optional key versioning for secure cookie or token creation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_version", "line_number": 3412, "body": "def _get_version(value: bytes) -> int:\n    # Figures out what version value is.  Version 1 did not include an\n    # explicit version field and started with arbitrary base64 data,\n    # which makes this tricky.\n    m = _signed_value_version_re.match(value)\n    if m is None:\n        version = 1\n    else:\n        try:\n            version = int(m.group(1))\n            if version > 999:\n                # Certain payloads from the version-less v1 format may\n                # be parsed as valid integers.  Due to base64 padding\n                # restrictions, this can only happen for numbers whose\n                # length is a multiple of 4, so we can treat all\n                # numbers up to 999 as versions, and for the rest we\n                # fall back to v1 format.\n                version = 1\n        except ValueError:\n            version = 1\n    return version", "is_method": false, "function_description": "Determines the version number from a byte string according to format rules, defaulting to version 1 if no explicit version is found. Useful for interpreting or validating data format versions in processing workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "decode_signed_value", "line_number": 3435, "body": "def decode_signed_value(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: Union[None, str, bytes],\n    max_age_days: float = 31,\n    clock: Optional[Callable[[], float]] = None,\n    min_version: Optional[int] = None,\n) -> Optional[bytes]:\n    if clock is None:\n        clock = time.time\n    if min_version is None:\n        min_version = DEFAULT_SIGNED_VALUE_MIN_VERSION\n    if min_version > 2:\n        raise ValueError(\"Unsupported min_version %d\" % min_version)\n    if not value:\n        return None\n\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None", "is_method": false, "function_description": "Function that verifies and decodes a signed value string using a secret key, ensuring it meets version and age constraints. It supports multiple signature versions for secure cookie or token validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_decode_signed_value_v1", "line_number": 3466, "body": "def _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,\n    clock: Callable[[], float],\n) -> Optional[bytes]:\n    parts = utf8(value).split(b\"|\")\n    if len(parts) != 3:\n        return None\n    signature = _create_signature_v1(secret, name, parts[0], parts[1])\n    if not hmac.compare_digest(parts[2], signature):\n        gen_log.warning(\"Invalid cookie signature %r\", value)\n        return None\n    timestamp = int(parts[1])\n    if timestamp < clock() - max_age_days * 86400:\n        gen_log.warning(\"Expired cookie %r\", value)\n        return None\n    if timestamp > clock() + 31 * 86400:\n        # _cookie_signature does not hash a delimiter between the\n        # parts of the cookie, so an attacker could transfer trailing\n        # digits from the payload to the timestamp without altering the\n        # signature.  For backwards compatibility, sanity-check timestamp\n        # here instead of modifying _cookie_signature.\n        gen_log.warning(\"Cookie timestamp in future; possible tampering %r\", value)\n        return None\n    if parts[1].startswith(b\"0\"):\n        gen_log.warning(\"Tampered cookie %r\", value)\n        return None\n    try:\n        return base64.b64decode(parts[0])\n    except Exception:\n        return None", "is_method": false, "function_description": "Internal utility function that validates, verifies the signature, and decodes a version 1 signed value with expiration checks, providing secure retrieval of tamper-proof data such as cookies or tokens."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_decode_fields_v2", "line_number": 3501, "body": "def _decode_fields_v2(value: bytes) -> Tuple[int, bytes, bytes, bytes, bytes]:\n    def _consume_field(s: bytes) -> Tuple[bytes, bytes]:\n        length, _, rest = s.partition(b\":\")\n        n = int(length)\n        field_value = rest[:n]\n        # In python 3, indexing bytes returns small integers; we must\n        # use a slice to get a byte string as in python 2.\n        if rest[n : n + 1] != b\"|\":\n            raise ValueError(\"malformed v2 signed value field\")\n        rest = rest[n + 1 :]\n        return field_value, rest\n\n    rest = value[2:]  # remove version number\n    key_version, rest = _consume_field(rest)\n    timestamp, rest = _consume_field(rest)\n    name_field, rest = _consume_field(rest)\n    value_field, passed_sig = _consume_field(rest)\n    return int(key_version), timestamp, name_field, value_field, passed_sig", "is_method": false, "function_description": "Parses a version 2 encoded byte string into its constituent fields, extracting key version, timestamp, name, value, and signature components for data integrity verification or further processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_decode_signed_value_v2", "line_number": 3521, "body": "def _decode_signed_value_v2(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: bytes,\n    max_age_days: float,\n    clock: Callable[[], float],\n) -> Optional[bytes]:\n    try:\n        (\n            key_version,\n            timestamp_bytes,\n            name_field,\n            value_field,\n            passed_sig,\n        ) = _decode_fields_v2(value)\n    except ValueError:\n        return None\n    signed_string = value[: -len(passed_sig)]\n\n    if isinstance(secret, dict):\n        try:\n            secret = secret[key_version]\n        except KeyError:\n            return None\n\n    expected_sig = _create_signature_v2(secret, signed_string)\n    if not hmac.compare_digest(passed_sig, expected_sig):\n        return None\n    if name_field != utf8(name):\n        return None\n    timestamp = int(timestamp_bytes)\n    if timestamp < clock() - max_age_days * 86400:\n        # The signature has expired.\n        return None\n    try:\n        return base64.b64decode(value_field)\n    except Exception:\n        return None", "is_method": false, "function_description": "Utility function that verifies and decodes a version 2 signed cookie value, ensuring authenticity, integrity, matching name, and expiration within a specified maximum age. It returns the original decoded bytes if validation succeeds, otherwise None."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_signature_key_version", "line_number": 3561, "body": "def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n    value = utf8(value)\n    version = _get_version(value)\n    if version < 2:\n        return None\n    try:\n        key_version, _, _, _, _ = _decode_fields_v2(value)\n    except ValueError:\n        return None\n\n    return key_version", "is_method": false, "function_description": "Function that extracts and returns the signature key version from a given input if it meets version criteria; otherwise, returns None. Useful for verifying or processing versioned cryptographic signatures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_create_signature_v1", "line_number": 3574, "body": "def _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())", "is_method": false, "function_description": "Generates an HMAC-SHA1 signature by combining a secret key with multiple message parts, ensuring data integrity and authenticity in security-related operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_create_signature_v2", "line_number": 3581, "body": "def _create_signature_v2(secret: Union[str, bytes], s: bytes) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n    hash.update(utf8(s))\n    return utf8(hash.hexdigest())", "is_method": false, "function_description": "Generates an HMAC-SHA256 signature of the input using the given secret key, supporting string or bytes keys. This function provides message authentication for data integrity and verification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "is_absolute", "line_number": 3587, "body": "def is_absolute(path: str) -> bool:\n    return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])", "is_method": false, "function_description": "Checks if a given path string is absolute by verifying if it starts with common absolute path indicators like \"/\", \"http:\", or \"https:\". This function helps determine path types for file handling or URL processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "settings", "line_number": 259, "body": "def settings(self) -> Dict[str, Any]:\n        \"\"\"An alias for `self.application.settings <Application.settings>`.\"\"\"\n        return self.application.settings", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides access to the application's configuration settings through the RequestHandler, enabling other functions to retrieve current application parameters easily."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_unimplemented_method", "line_number": 263, "body": "def _unimplemented_method(self, *args: str, **kwargs: str) -> None:\n        raise HTTPError(405)", "is_method": true, "class_name": "RequestHandler", "function_description": "This private method in RequestHandler consistently raises a 405 HTTP error, signaling that the called HTTP method is not allowed or implemented. It serves as a standardized way to block unsupported request types."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "on_connection_close", "line_number": 300, "body": "def on_connection_close(self) -> None:\n        \"\"\"Called in async handlers if the client closed the connection.\n\n        Override this to clean up resources associated with\n        long-lived connections.  Note that this method is called only if\n        the connection was closed during asynchronous processing; if you\n        need to do cleanup after every request override `on_finish`\n        instead.\n\n        Proxies may keep a connection open for a time (perhaps\n        indefinitely) after the client has gone away, so this method\n        may not be called promptly after the end user closes their\n        connection.\n        \"\"\"\n        if _has_stream_request_body(self.__class__):\n            if not self.request._body_future.done():\n                self.request._body_future.set_exception(iostream.StreamClosedError())\n                self.request._body_future.exception()", "is_method": true, "class_name": "RequestHandler", "function_description": "Service method in RequestHandler called upon client connection closure during async processing, allowing cleanup of resources tied to long-lived connections that end prematurely."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "clear", "line_number": 319, "body": "def clear(self) -> None:\n        \"\"\"Resets all headers and content for this response.\"\"\"\n        self._headers = httputil.HTTPHeaders(\n            {\n                \"Server\": \"TornadoServer/%s\" % tornado.version,\n                \"Content-Type\": \"text/html; charset=UTF-8\",\n                \"Date\": httputil.format_timestamp(time.time()),\n            }\n        )\n        self.set_default_headers()\n        self._write_buffer = []  # type: List[bytes]\n        self._status_code = 200\n        self._reason = httputil.responses[200]", "is_method": true, "class_name": "RequestHandler", "function_description": "Resets the response object by clearing headers, content, and status to default values. It prepares the response for reuse or new data in the RequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_default_headers", "line_number": 333, "body": "def set_default_headers(self) -> None:\n        \"\"\"Override this to set HTTP headers at the beginning of the request.\n\n        For example, this is the place to set a custom ``Server`` header.\n        Note that setting such headers in the normal flow of request\n        processing may not do what you want, since headers may be reset\n        during error handling.\n        \"\"\"\n        pass", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets default HTTP headers at the start of a request, allowing customization like setting a custom \"Server\" header before error handling occurs.  \nThis method is intended to initialize headers for all incoming HTTP requests in RequestHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_status", "line_number": 343, "body": "def set_status(self, status_code: int, reason: Optional[str] = None) -> None:\n        \"\"\"Sets the status code for our response.\n\n        :arg int status_code: Response status code.\n        :arg str reason: Human-readable reason phrase describing the status\n            code. If ``None``, it will be filled in from\n            `http.client.responses` or \"Unknown\".\n\n        .. versionchanged:: 5.0\n\n           No longer validates that the response code is in\n           `http.client.responses`.\n        \"\"\"\n        self._status_code = status_code\n        if reason is not None:\n            self._reason = escape.native_str(reason)\n        else:\n            self._reason = httputil.responses.get(status_code, \"Unknown\")", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets the HTTP response status code and its corresponding reason phrase for a request, allowing customization or automatic assignment based on standard HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_status", "line_number": 362, "body": "def get_status(self) -> int:\n        \"\"\"Returns the status code for our response.\"\"\"\n        return self._status_code", "is_method": true, "class_name": "RequestHandler", "function_description": "Returns the current HTTP status code stored in the RequestHandler, providing a way to check the response status of a request."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_header", "line_number": 366, "body": "def set_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Sets the given response header name and value.\n\n        All header values are converted to strings (`datetime` objects\n        are formatted according to the HTTP specification for the\n        ``Date`` header).\n\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets or updates a HTTP response header with a specified name and value, ensuring the value is properly formatted as a string according to HTTP standards. Useful for managing response metadata in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "add_header", "line_number": 376, "body": "def add_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Adds the given response header and value.\n\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.\n        \"\"\"\n        self._headers.add(name, self._convert_header_value(value))", "is_method": true, "class_name": "RequestHandler", "function_description": "Adds a header and its value to the response, allowing multiple values for the same header. Useful for building HTTP responses that require repeating headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "clear_header", "line_number": 384, "body": "def clear_header(self, name: str) -> None:\n        \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n\n        Note that this method does not apply to multi-valued headers\n        set by `add_header`.\n        \"\"\"\n        if name in self._headers:\n            del self._headers[name]", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of the RequestHandler class that removes a previously set single-value outgoing HTTP header. It helps manage and modify HTTP request headers by undoing set_header operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_convert_header_value", "line_number": 395, "body": "def _convert_header_value(self, value: _HeaderTypes) -> str:\n        # Convert the input value to a str. This type check is a bit\n        # subtle: The bytes case only executes on python 3, and the\n        # unicode case only executes on python 2, because the other\n        # cases are covered by the first match for str.\n        if isinstance(value, str):\n            retval = value\n        elif isinstance(value, bytes):  # py3\n            # Non-ascii characters in headers are not well supported,\n            # but if you pass bytes, use latin1 so they pass through as-is.\n            retval = value.decode(\"latin1\")\n        elif isinstance(value, unicode_type):  # py2\n            # TODO: This is inconsistent with the use of latin1 above,\n            # but it's been that way for a long time. Should it change?\n            retval = escape.utf8(value)\n        elif isinstance(value, numbers.Integral):\n            # return immediately since we know the converted value will be safe\n            return str(value)\n        elif isinstance(value, datetime.datetime):\n            return httputil.format_timestamp(value)\n        else:\n            raise TypeError(\"Unsupported header value %r\" % value)\n        # If \\n is allowed into the header, it is possible to inject\n        # additional headers or split the request.\n        if RequestHandler._INVALID_HEADER_CHAR_RE.search(retval):\n            raise ValueError(\"Unsafe header value %r\", retval)\n        return retval", "is_method": true, "class_name": "RequestHandler", "function_description": "Converts various input types into a safe string format suitable for HTTP headers, validating the value to prevent header injection. This function ensures consistent and secure header value formatting in HTTP request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_argument", "line_number": 439, "body": "def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the\n        last value.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Core method of RequestHandler that retrieves the value of a named request argument from query or body, enforcing required arguments or returning defaults, and handling multiple occurrences by returning the last value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_arguments", "line_number": 457, "body": "def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n\n        return self._get_arguments(name, self.request.arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Retrieves all values for a specified argument name from both query and body parameters, returning a list or empty list if none found. Useful for extracting multiple input values from a request in web handling contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_body_argument", "line_number": 472, "body": "def get_body_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of the RequestHandler class that retrieves a named argument's value from the request body, enforcing required arguments or returning a default. It handles multiple occurrences by returning the last value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_body_arguments", "line_number": 491, "body": "def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that retrieves all values of a specified argument from the request body, returning them as a list. It supports optional whitespace stripping and returns an empty list if the argument is absent."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_query_argument", "line_number": 500, "body": "def get_query_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of the RequestHandler class that retrieves a specific query string argument from an HTTP request, enforcing presence if required and optionally stripping whitespace. It returns the last occurrence's value when multiple exist."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_query_arguments", "line_number": 519, "body": "def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of the RequestHandler class that retrieves all query parameter values matching a given name from the request, optionally stripping whitespace. It helps extract multiple values for the same query argument efficiently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_argument", "line_number": 528, "body": "def _get_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]", "is_method": true, "class_name": "RequestHandler", "function_description": "Private method of RequestHandler that retrieves a single argument value from a specified data source, returning a default or raising an error if the argument is missing. It supports optional whitespace stripping and handles multiple byte-encoded values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_arguments", "line_number": 542, "body": "def _get_arguments(\n        self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n    ) -> List[str]:\n        values = []\n        for v in source.get(name, []):\n            s = self.decode_argument(v, name=name)\n            if isinstance(s, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n            if strip:\n                s = s.strip()\n            values.append(s)\n        return values", "is_method": true, "class_name": "RequestHandler", "function_description": "Processes and decodes a list of byte-encoded arguments from a data source, cleans control characters, and optionally trims whitespace, returning the resulting list of string values for further use in request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "decode_argument", "line_number": 557, "body": "def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n        \"\"\"Decodes an argument from the request.\n\n        The argument has been percent-decoded and is now a byte string.\n        By default, this method decodes the argument as utf-8 and returns\n        a unicode string, but this may be overridden in subclasses.\n\n        This method is used as a filter for both `get_argument()` and for\n        values extracted from the url and passed to `get()`/`post()`/etc.\n\n        The name of the argument is provided if known, but may be None\n        (e.g. for unnamed groups in the url regex).\n        \"\"\"\n        try:\n            return _unicode(value)\n        except UnicodeDecodeError:\n            raise HTTPError(\n                400, \"Invalid unicode in %s: %r\" % (name or \"url\", value[:40])\n            )", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that decodes percent-decoded byte arguments into UTF-8 strings, ensuring valid unicode input for request parameters and raising errors on invalid encoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "cookies", "line_number": 578, "body": "def cookies(self) -> Dict[str, http.cookies.Morsel]:\n        \"\"\"An alias for\n        `self.request.cookies <.httputil.HTTPServerRequest.cookies>`.\"\"\"\n        return self.request.cookies", "is_method": true, "class_name": "RequestHandler", "function_description": "Returns the cookies from the current HTTP request as a dictionary, providing easy access to client-sent cookie data within the RequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_cookie", "line_number": 583, "body": "def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n        \"\"\"Returns the value of the request cookie with the given name.\n\n        If the named cookie is not present, returns ``default``.\n\n        This method only returns cookies that were present in the request.\n        It does not see the outgoing cookies set by `set_cookie` in this\n        handler.\n        \"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that retrieves the value of a specified cookie from the incoming request, returning a default value if the cookie is absent."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_cookie", "line_number": 596, "body": "def set_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        domain: Optional[str] = None,\n        expires: Optional[Union[float, Tuple, datetime.datetime]] = None,\n        path: str = \"/\",\n        expires_days: Optional[float] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Sets an outgoing cookie name/value with the given options.\n\n        Newly-set cookies are not immediately visible via `get_cookie`;\n        they are not present until the next request.\n\n        expires may be a numeric timestamp as returned by `time.time`,\n        a time tuple as returned by `time.gmtime`, or a\n        `datetime.datetime` object.\n\n        Additional keyword arguments are set on the cookies.Morsel\n        directly.\n        See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel\n        for available attributes.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3\n        name = escape.native_str(name)\n        value = escape.native_str(value)\n        if re.search(r\"[\\x00-\\x20]\", name + value):\n            # Don't let us accidentally inject bad stuff\n            raise ValueError(\"Invalid cookie %r: %r\" % (name, value))\n        if not hasattr(self, \"_new_cookie\"):\n            self._new_cookie = (\n                http.cookies.SimpleCookie()\n            )  # type: http.cookies.SimpleCookie\n        if name in self._new_cookie:\n            del self._new_cookie[name]\n        self._new_cookie[name] = value\n        morsel = self._new_cookie[name]\n        if domain:\n            morsel[\"domain\"] = domain\n        if expires_days is not None and not expires:\n            expires = datetime.datetime.utcnow() + datetime.timedelta(days=expires_days)\n        if expires:\n            morsel[\"expires\"] = httputil.format_timestamp(expires)\n        if path:\n            morsel[\"path\"] = path\n        for k, v in kwargs.items():\n            if k == \"max_age\":\n                k = \"max-age\"\n\n            # skip falsy values for httponly and secure flags because\n            # SimpleCookie sets them regardless\n            if k in [\"httponly\", \"secure\"] and not v:\n                continue\n\n            morsel[k] = v", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets an HTTP cookie with specified attributes for the outgoing response, supporting flexible expiration and additional cookie parameters. This enables managing client state across requests within the RequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "clear_cookie", "line_number": 653, "body": "def clear_cookie(\n        self, name: str, path: str = \"/\", domain: Optional[str] = None\n    ) -> None:\n        \"\"\"Deletes the cookie with the given name.\n\n        Due to limitations of the cookie protocol, you must pass the same\n        path and domain to clear a cookie as were used when that cookie\n        was set (but there is no way to find out on the server side\n        which values were used for a given cookie).\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n        \"\"\"\n        expires = datetime.datetime.utcnow() - datetime.timedelta(days=365)\n        self.set_cookie(name, value=\"\", path=path, expires=expires, domain=domain)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of the RequestHandler class that deletes a specified cookie by setting it expired, ensuring subsequent requests no longer include it. It requires matching the original cookie's path and domain for effective removal."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "clear_all_cookies", "line_number": 669, "body": "def clear_all_cookies(self, path: str = \"/\", domain: Optional[str] = None) -> None:\n        \"\"\"Deletes all the cookies the user sent with this request.\n\n        See `clear_cookie` for more information on the path and domain\n        parameters.\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n\n        .. versionchanged:: 3.2\n\n           Added the ``path`` and ``domain`` parameters.\n        \"\"\"\n        for name in self.request.cookies:\n            self.clear_cookie(name, path=path, domain=domain)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that removes all cookies sent with the current request, optionally scoped by path and domain, to clear client-side stored data in preparation for subsequent requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_secure_cookie", "line_number": 685, "body": "def set_secure_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        expires_days: Optional[float] = 30,\n        version: Optional[int] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Signs and timestamps a cookie so it cannot be forged.\n\n        You must specify the ``cookie_secret`` setting in your Application\n        to use this method. It should be a long, random sequence of bytes\n        to be used as the HMAC secret for the signature.\n\n        To read a cookie set with this method, use `get_secure_cookie()`.\n\n        Note that the ``expires_days`` parameter sets the lifetime of the\n        cookie in the browser, but is independent of the ``max_age_days``\n        parameter to `get_secure_cookie`.\n        A value of None limits the lifetime to the current browser session.\n\n        Secure cookies may contain arbitrary byte values, not just unicode\n        strings (unlike regular cookies)\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.set_cookie(\n            name,\n            self.create_signed_value(name, value, version=version),\n            expires_days=expires_days,\n            **kwargs\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets a signed and timestamped cookie that prevents tampering by ensuring its integrity and authenticity. This enables secure client-side cookie storage with optional expiration control for web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "create_signed_value", "line_number": 724, "body": "def create_signed_value(\n        self, name: str, value: Union[str, bytes], version: Optional[int] = None\n    ) -> bytes:\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored\n        as a cookie use the optional value argument to get_secure_cookie.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        secret = self.application.settings[\"cookie_secret\"]\n        key_version = None\n        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Creates a cryptographically signed and timestamped value to prevent forgery, typically used for secure cookie handling or other confidential data transmission in web requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_secure_cookie", "line_number": 750, "body": "def get_secure_cookie(\n        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).\n\n        Similar to `get_cookie`, this method only returns cookies that\n        were present in the request. It does not see outgoing cookies set by\n        `set_secure_cookie` in this handler.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``min_version`` argument.  Introduced cookie version 2;\n           both versions 1 and 2 are accepted by default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        return decode_signed_value(\n            self.application.settings[\"cookie_secret\"],\n            name,\n            value,\n            max_age_days=max_age_days,\n            min_version=min_version,\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Retrieves and validates a signed cookie from an incoming request, returning its decoded value as bytes if valid and not expired. Useful for securely accessing client cookie data while enforcing integrity and optional version constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_secure_cookie_key_version", "line_number": 782, "body": "def get_secure_cookie_key_version(\n        self, name: str, value: Optional[str] = None\n    ) -> Optional[int]:\n        \"\"\"Returns the signing key version of the secure cookie.\n\n        The version is returned as int.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        if value is None:\n            return None\n        return get_signature_key_version(value)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of RequestHandler that retrieves the signing key version used for a secure cookie, aiding in validation or rotation of cookie signing keys."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "redirect", "line_number": 796, "body": "def redirect(\n        self, url: str, permanent: bool = False, status: Optional[int] = None\n    ) -> None:\n        \"\"\"Sends a redirect to the given (optionally relative) URL.\n\n        If the ``status`` argument is specified, that value is used as the\n        HTTP status code; otherwise either 301 (permanent) or 302\n        (temporary) is chosen based on the ``permanent`` argument.\n        The default is 302 (temporary).\n        \"\"\"\n        if self._headers_written:\n            raise Exception(\"Cannot redirect after headers have been written\")\n        if status is None:\n            status = 301 if permanent else 302\n        else:\n            assert isinstance(status, int) and 300 <= status <= 399\n        self.set_status(status)\n        self.set_header(\"Location\", utf8(url))\n        self.finish()", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a way for RequestHandler to send HTTP redirects to specified URLs, supporting both temporary and permanent redirects with customizable status codes. This enables redirecting client requests within web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "write", "line_number": 816, "body": "def write(self, chunk: Union[str, bytes, dict]) -> None:\n        \"\"\"Writes the given chunk to the output buffer.\n\n        To write the output to the network, use the `flush()` method below.\n\n        If the given chunk is a dictionary, we write it as JSON and set\n        the Content-Type of the response to be ``application/json``.\n        (if you want to send JSON as a different ``Content-Type``, call\n        ``set_header`` *after* calling ``write()``).\n\n        Note that lists are not converted to JSON because of a potential\n        cross-site security vulnerability.  All JSON output should be\n        wrapped in a dictionary.  More details at\n        http://haacked.com/archive/2009/06/25/json-hijacking.aspx/ and\n        https://github.com/facebook/tornado/issues/1009\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot write() after finish()\")\n        if not isinstance(chunk, (bytes, unicode_type, dict)):\n            message = \"write() only accepts bytes, unicode, and dict objects\"\n            if isinstance(chunk, list):\n                message += (\n                    \". Lists not accepted for security reasons; see \"\n                    + \"http://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.write\"  # noqa: E501\n                )\n            raise TypeError(message)\n        if isinstance(chunk, dict):\n            chunk = escape.json_encode(chunk)\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        chunk = utf8(chunk)\n        self._write_buffer.append(chunk)", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a method to write strings, bytes, or dictionaries as JSON to an HTTP response buffer, preparing output for later network transmission with content type handling and input validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render", "line_number": 848, "body": "def render(self, template_name: str, **kwargs: Any) -> \"Future[None]\":\n        \"\"\"Renders the template with the given arguments as the response.\n\n        ``render()`` calls ``finish()``, so no other output methods can be called\n        after it.\n\n        Returns a `.Future` with the same semantics as the one returned by `finish`.\n        Awaiting this `.Future` is optional.\n\n        .. versionchanged:: 5.1\n\n           Now returns a `.Future` instead of ``None``.\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot render() after finish()\")\n        html = self.render_string(template_name, **kwargs)\n\n        # Insert the additional JS and CSS added by the modules on the page\n        js_embed = []\n        js_files = []\n        css_embed = []\n        css_files = []\n        html_heads = []\n        html_bodies = []\n        for module in getattr(self, \"_active_modules\", {}).values():\n            embed_part = module.embedded_javascript()\n            if embed_part:\n                js_embed.append(utf8(embed_part))\n            file_part = module.javascript_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    js_files.append(_unicode(file_part))\n                else:\n                    js_files.extend(file_part)\n            embed_part = module.embedded_css()\n            if embed_part:\n                css_embed.append(utf8(embed_part))\n            file_part = module.css_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    css_files.append(_unicode(file_part))\n                else:\n                    css_files.extend(file_part)\n            head_part = module.html_head()\n            if head_part:\n                html_heads.append(utf8(head_part))\n            body_part = module.html_body()\n            if body_part:\n                html_bodies.append(utf8(body_part))\n\n        if js_files:\n            # Maintain order of JavaScript files given by modules\n            js = self.render_linked_js(js_files)\n            sloc = html.rindex(b\"</body>\")\n            html = html[:sloc] + utf8(js) + b\"\\n\" + html[sloc:]\n        if js_embed:\n            js_bytes = self.render_embed_js(js_embed)\n            sloc = html.rindex(b\"</body>\")\n            html = html[:sloc] + js_bytes + b\"\\n\" + html[sloc:]\n        if css_files:\n            css = self.render_linked_css(css_files)\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + utf8(css) + b\"\\n\" + html[hloc:]\n        if css_embed:\n            css_bytes = self.render_embed_css(css_embed)\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + css_bytes + b\"\\n\" + html[hloc:]\n        if html_heads:\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + b\"\".join(html_heads) + b\"\\n\" + html[hloc:]\n        if html_bodies:\n            hloc = html.index(b\"</body>\")\n            html = html[:hloc] + b\"\".join(html_bodies) + b\"\\n\" + html[hloc:]\n        return self.finish(html)", "is_method": true, "class_name": "RequestHandler", "function_description": "Method of RequestHandler that renders an HTML template with provided arguments, integrates additional JavaScript, CSS, and HTML content from active modules, and sends the complete response while preventing further output."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_linked_js", "line_number": 923, "body": "def render_linked_js(self, js_files: Iterable[str]) -> str:\n        \"\"\"Default method used to render the final js links for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        paths = []\n        unique_paths = set()  # type: Set[str]\n\n        for path in js_files:\n            if not is_absolute(path):\n                path = self.static_url(path)\n            if path not in unique_paths:\n                paths.append(path)\n                unique_paths.add(path)\n\n        return \"\".join(\n            '<script src=\"'\n            + escape.xhtml_escape(p)\n            + '\" type=\"text/javascript\"></script>'\n            for p in paths\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Generates HTML script tags for a set of JavaScript files, ensuring unique and properly formatted links for inclusion in a webpage. Enables customization of how JavaScript resources are referenced in web responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_embed_js", "line_number": 946, "body": "def render_embed_js(self, js_embed: Iterable[bytes]) -> bytes:\n        \"\"\"Default method used to render the final embedded js for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        return (\n            b'<script type=\"text/javascript\">\\n//<![CDATA[\\n'\n            + b\"\\n\".join(js_embed)\n            + b\"\\n//]]>\\n</script>\"\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Generates a complete HTML script tag containing embedded JavaScript code snippets, ready to be included in a rendered webpage. It provides a way to consolidate and format JS content for web responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_linked_css", "line_number": 958, "body": "def render_linked_css(self, css_files: Iterable[str]) -> str:\n        \"\"\"Default method used to render the final css links for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        paths = []\n        unique_paths = set()  # type: Set[str]\n\n        for path in css_files:\n            if not is_absolute(path):\n                path = self.static_url(path)\n            if path not in unique_paths:\n                paths.append(path)\n                unique_paths.add(path)\n\n        return \"\".join(\n            '<link href=\"' + escape.xhtml_escape(p) + '\" '\n            'type=\"text/css\" rel=\"stylesheet\"/>'\n            for p in paths\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Generates HTML link tags for a list of CSS files, ensuring unique URLs and converting relative paths to absolute static URLs. This supports consistent inclusion of stylesheets in web pages."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_embed_css", "line_number": 980, "body": "def render_embed_css(self, css_embed: Iterable[bytes]) -> bytes:\n        \"\"\"Default method used to render the final embedded css for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        return b'<style type=\"text/css\">\\n' + b\"\\n\".join(css_embed) + b\"\\n</style>\"", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides the final CSS block by combining embedded CSS bytes for webpage rendering. It serves as a customizable method to generate inline styles in HTML responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_string", "line_number": 988, "body": "def render_string(self, template_name: str, **kwargs: Any) -> bytes:\n        \"\"\"Generate the given template with the given arguments.\n\n        We return the generated byte string (in utf8). To generate and\n        write a template as a response, use render() above.\n        \"\"\"\n        # If no template_path is specified, use the path of the calling file\n        template_path = self.get_template_path()\n        if not template_path:\n            frame = sys._getframe(0)\n            web_file = frame.f_code.co_filename\n            while frame.f_code.co_filename == web_file:\n                frame = frame.f_back\n            assert frame.f_code.co_filename is not None\n            template_path = os.path.dirname(frame.f_code.co_filename)\n        with RequestHandler._template_loader_lock:\n            if template_path not in RequestHandler._template_loaders:\n                loader = self.create_template_loader(template_path)\n                RequestHandler._template_loaders[template_path] = loader\n            else:\n                loader = RequestHandler._template_loaders[template_path]\n        t = loader.load(template_name)\n        namespace = self.get_template_namespace()\n        namespace.update(kwargs)\n        return t.generate(**namespace)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of RequestHandler that generates and returns a UTF-8 encoded byte string from a specified template using provided arguments, supporting dynamic content rendering without directly sending an HTTP response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_template_namespace", "line_number": 1014, "body": "def get_template_namespace(self) -> Dict[str, Any]:\n        \"\"\"Returns a dictionary to be used as the default template namespace.\n\n        May be overridden by subclasses to add or modify values.\n\n        The results of this method will be combined with additional\n        defaults in the `tornado.template` module and keyword arguments\n        to `render` or `render_string`.\n        \"\"\"\n        namespace = dict(\n            handler=self,\n            request=self.request,\n            current_user=self.current_user,\n            locale=self.locale,\n            _=self.locale.translate,\n            pgettext=self.locale.pgettext,\n            static_url=self.static_url,\n            xsrf_form_html=self.xsrf_form_html,\n            reverse_url=self.reverse_url,\n        )\n        namespace.update(self.ui)\n        return namespace", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a default dictionary of context variables for template rendering in RequestHandler, enabling templates to access request, user, localization, and URL utilities. Subclasses can override to customize template context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "create_template_loader", "line_number": 1037, "body": "def create_template_loader(self, template_path: str) -> template.BaseLoader:\n        \"\"\"Returns a new template loader for the given path.\n\n        May be overridden by subclasses.  By default returns a\n        directory-based loader on the given path, using the\n        ``autoescape`` and ``template_whitespace`` application\n        settings.  If a ``template_loader`` application setting is\n        supplied, uses that instead.\n        \"\"\"\n        settings = self.application.settings\n        if \"template_loader\" in settings:\n            return settings[\"template_loader\"]\n        kwargs = {}\n        if \"autoescape\" in settings:\n            # autoescape=None means \"no escaping\", so we have to be sure\n            # to only pass this kwarg if the user asked for it.\n            kwargs[\"autoescape\"] = settings[\"autoescape\"]\n        if \"template_whitespace\" in settings:\n            kwargs[\"whitespace\"] = settings[\"template_whitespace\"]\n        return template.Loader(template_path, **kwargs)", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a customizable template loader for a given path using application settings, enabling flexible template rendering initialization based on directory, autoescape, and whitespace configurations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "flush", "line_number": 1058, "body": "def flush(self, include_footers: bool = False) -> \"Future[None]\":\n        \"\"\"Flushes the current output buffer to the network.\n\n        .. versionchanged:: 4.0\n           Now returns a `.Future` if no callback is given.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed.\n        \"\"\"\n        assert self.request.connection is not None\n        chunk = b\"\".join(self._write_buffer)\n        self._write_buffer = []\n        if not self._headers_written:\n            self._headers_written = True\n            for transform in self._transforms:\n                assert chunk is not None\n                (\n                    self._status_code,\n                    self._headers,\n                    chunk,\n                ) = transform.transform_first_chunk(\n                    self._status_code, self._headers, chunk, include_footers\n                )\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method == \"HEAD\":\n                chunk = b\"\"\n\n            # Finalize the cookie headers (which have been stored in a side\n            # object so an outgoing cookie could be overwritten before it\n            # is sent).\n            if hasattr(self, \"_new_cookie\"):\n                for cookie in self._new_cookie.values():\n                    self.add_header(\"Set-Cookie\", cookie.OutputString(None))\n\n            start_line = httputil.ResponseStartLine(\"\", self._status_code, self._reason)\n            return self.request.connection.write_headers(\n                start_line, self._headers, chunk\n            )\n        else:\n            for transform in self._transforms:\n                chunk = transform.transform_chunk(chunk, include_footers)\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method != \"HEAD\":\n                return self.request.connection.write(chunk)\n            else:\n                future = Future()  # type: Future[None]\n                future.set_result(None)\n                return future", "is_method": true, "class_name": "RequestHandler", "function_description": "Flushes the current output buffer by sending HTTP response headers and body data over the network, applying any transformations and handling special cases like HEAD requests and cookies. It ensures the buffered data is transmitted asynchronously for the associated request."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "finish", "line_number": 1108, "body": "def finish(self, chunk: Optional[Union[str, bytes, dict]] = None) -> \"Future[None]\":\n        \"\"\"Finishes this response, ending the HTTP request.\n\n        Passing a ``chunk`` to ``finish()`` is equivalent to passing that\n        chunk to ``write()`` and then calling ``finish()`` with no arguments.\n\n        Returns a `.Future` which may optionally be awaited to track the sending\n        of the response to the client. This `.Future` resolves when all the response\n        data has been sent, and raises an error if the connection is closed before all\n        data can be sent.\n\n        .. versionchanged:: 5.1\n\n           Now returns a `.Future` instead of ``None``.\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"finish() called twice\")\n\n        if chunk is not None:\n            self.write(chunk)\n\n        # Automatically support ETags and add the Content-Length header if\n        # we have not flushed any content yet.\n        if not self._headers_written:\n            if (\n                self._status_code == 200\n                and self.request.method in (\"GET\", \"HEAD\")\n                and \"Etag\" not in self._headers\n            ):\n                self.set_etag_header()\n                if self.check_etag_header():\n                    self._write_buffer = []\n                    self.set_status(304)\n            if self._status_code in (204, 304) or (100 <= self._status_code < 200):\n                assert not self._write_buffer, (\n                    \"Cannot send body with %s\" % self._status_code\n                )\n                self._clear_representation_headers()\n            elif \"Content-Length\" not in self._headers:\n                content_length = sum(len(part) for part in self._write_buffer)\n                self.set_header(\"Content-Length\", content_length)\n\n        assert self.request.connection is not None\n        # Now that the request is finished, clear the callback we\n        # set on the HTTPConnection (which would otherwise prevent the\n        # garbage collection of the RequestHandler when there\n        # are keepalive connections)\n        self.request.connection.set_close_callback(None)  # type: ignore\n\n        future = self.flush(include_footers=True)\n        self.request.connection.finish()\n        self._log()\n        self._finished = True\n        self.on_finish()\n        self._break_cycles()\n        return future", "is_method": true, "class_name": "RequestHandler", "function_description": "Finalizes the HTTP response by optionally sending a final chunk, completing the request, and returning a Future to track response delivery. It manages headers, supports caching, and triggers cleanup and callbacks upon completion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "detach", "line_number": 1165, "body": "def detach(self) -> iostream.IOStream:\n        \"\"\"Take control of the underlying stream.\n\n        Returns the underlying `.IOStream` object and stops all\n        further HTTP processing. Intended for implementing protocols\n        like websockets that tunnel over an HTTP handshake.\n\n        This method is only supported when HTTP/1.1 is used.\n\n        .. versionadded:: 5.1\n        \"\"\"\n        self._finished = True\n        # TODO: add detach to HTTPConnection?\n        return self.request.connection.detach()", "is_method": true, "class_name": "RequestHandler", "function_description": "Method of RequestHandler that transfers control of the underlying IO stream, halting HTTP processing to enable protocol upgrades like WebSocket tunneling over an HTTP/1.1 connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_break_cycles", "line_number": 1180, "body": "def _break_cycles(self) -> None:\n        # Break up a reference cycle between this handler and the\n        # _ui_module closures to allow for faster GC on CPython.\n        self.ui = None", "is_method": true, "class_name": "RequestHandler", "function_description": "Private method that breaks reference cycles involving UI module closures to facilitate faster garbage collection and memory cleanup within the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "send_error", "line_number": 1185, "body": "def send_error(self, status_code: int = 500, **kwargs: Any) -> None:\n        \"\"\"Sends the given HTTP error code to the browser.\n\n        If `flush()` has already been called, it is not possible to send\n        an error, so this method will simply terminate the response.\n        If output has been written but not yet flushed, it will be discarded\n        and replaced with the error page.\n\n        Override `write_error()` to customize the error page that is returned.\n        Additional keyword arguments are passed through to `write_error`.\n        \"\"\"\n        if self._headers_written:\n            gen_log.error(\"Cannot send error response after headers written\")\n            if not self._finished:\n                # If we get an error between writing headers and finishing,\n                # we are unlikely to be able to finish due to a\n                # Content-Length mismatch. Try anyway to release the\n                # socket.\n                try:\n                    self.finish()\n                except Exception:\n                    gen_log.error(\"Failed to flush partial response\", exc_info=True)\n            return\n        self.clear()\n\n        reason = kwargs.get(\"reason\")\n        if \"exc_info\" in kwargs:\n            exception = kwargs[\"exc_info\"][1]\n            if isinstance(exception, HTTPError) and exception.reason:\n                reason = exception.reason\n        self.set_status(status_code, reason=reason)\n        try:\n            self.write_error(status_code, **kwargs)\n        except Exception:\n            app_log.error(\"Uncaught exception in write_error\", exc_info=True)\n        if not self._finished:\n            self.finish()", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a mechanism to send HTTP error responses to the client, ensuring proper status codes and customizable error pages, even discarding partial output if necessary. It gracefully handles cases where headers are already sent or response is finalized."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "write_error", "line_number": 1223, "body": "def write_error(self, status_code: int, **kwargs: Any) -> None:\n        \"\"\"Override to implement custom error pages.\n\n        ``write_error`` may call `write`, `render`, `set_header`, etc\n        to produce output as usual.\n\n        If this error was caused by an uncaught exception (including\n        HTTPError), an ``exc_info`` triple will be available as\n        ``kwargs[\"exc_info\"]``.  Note that this exception may not be\n        the \"current\" exception for purposes of methods like\n        ``sys.exc_info()`` or ``traceback.format_exc``.\n        \"\"\"\n        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:\n            # in debug mode, try to send a traceback\n            self.set_header(\"Content-Type\", \"text/plain\")\n            for line in traceback.format_exception(*kwargs[\"exc_info\"]):\n                self.write(line)\n            self.finish()\n        else:\n            self.finish(\n                \"<html><title>%(code)d: %(message)s</title>\"\n                \"<body>%(code)d: %(message)s</body></html>\"\n                % {\"code\": status_code, \"message\": self._reason}\n            )", "is_method": true, "class_name": "RequestHandler", "function_description": "Customizes HTTP error responses by generating error pages or detailed tracebacks based on settings, enabling appropriate error reporting in web request handling scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "locale", "line_number": 1249, "body": "def locale(self) -> tornado.locale.Locale:\n        \"\"\"The locale for the current session.\n\n        Determined by either `get_user_locale`, which you can override to\n        set the locale based on, e.g., a user preference stored in a\n        database, or `get_browser_locale`, which uses the ``Accept-Language``\n        header.\n\n        .. versionchanged: 4.1\n           Added a property setter.\n        \"\"\"\n        if not hasattr(self, \"_locale\"):\n            loc = self.get_user_locale()\n            if loc is not None:\n                self._locale = loc\n            else:\n                self._locale = self.get_browser_locale()\n                assert self._locale\n        return self._locale", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides the locale setting for the current session by determining user-preferred or browser-defined language, supporting localization in request handling. Enables customization of locale retrieval for personalized user experiences."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "locale", "line_number": 1270, "body": "def locale(self, value: tornado.locale.Locale) -> None:\n        self._locale = value", "is_method": true, "class_name": "RequestHandler", "function_description": "Setter method of the RequestHandler class that assigns a localization setting for processing requests, enabling response customization based on locale preferences."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_user_locale", "line_number": 1273, "body": "def get_user_locale(self) -> Optional[tornado.locale.Locale]:\n        \"\"\"Override to determine the locale from the authenticated user.\n\n        If None is returned, we fall back to `get_browser_locale()`.\n\n        This method should return a `tornado.locale.Locale` object,\n        most likely obtained via a call like ``tornado.locale.get(\"en\")``\n        \"\"\"\n        return None", "is_method": true, "class_name": "RequestHandler", "function_description": "This RequestHandler method provides a way to determine the user's locale based on authentication, falling back to browser settings if unavailable. It supports locale-aware responses in web request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_browser_locale", "line_number": 1283, "body": "def get_browser_locale(self, default: str = \"en_US\") -> tornado.locale.Locale:\n        \"\"\"Determines the user's locale from ``Accept-Language`` header.\n\n        See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4\n        \"\"\"\n        if \"Accept-Language\" in self.request.headers:\n            languages = self.request.headers[\"Accept-Language\"].split(\",\")\n            locales = []\n            for language in languages:\n                parts = language.strip().split(\";\")\n                if len(parts) > 1 and parts[1].startswith(\"q=\"):\n                    try:\n                        score = float(parts[1][2:])\n                    except (ValueError, TypeError):\n                        score = 0.0\n                else:\n                    score = 1.0\n                locales.append((parts[0], score))\n            if locales:\n                locales.sort(key=lambda pair: pair[1], reverse=True)\n                codes = [loc[0] for loc in locales]\n                return locale.get(*codes)\n        return locale.get(default)", "is_method": true, "class_name": "RequestHandler", "function_description": "Returns the user's preferred locale based on the HTTP Accept-Language header, falling back to a default if none is specified. This enables localization by determining the best language setting for the request."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "current_user", "line_number": 1308, "body": "def current_user(self) -> Any:\n        \"\"\"The authenticated user for this request.\n\n        This is set in one of two ways:\n\n        * A subclass may override `get_current_user()`, which will be called\n          automatically the first time ``self.current_user`` is accessed.\n          `get_current_user()` will only be called once per request,\n          and is cached for future access::\n\n              def get_current_user(self):\n                  user_cookie = self.get_secure_cookie(\"user\")\n                  if user_cookie:\n                      return json.loads(user_cookie)\n                  return None\n\n        * It may be set as a normal variable, typically from an overridden\n          `prepare()`::\n\n              @gen.coroutine\n              def prepare(self):\n                  user_id_cookie = self.get_secure_cookie(\"user_id\")\n                  if user_id_cookie:\n                      self.current_user = yield load_user(user_id_cookie)\n\n        Note that `prepare()` may be a coroutine while `get_current_user()`\n        may not, so the latter form is necessary if loading the user requires\n        asynchronous operations.\n\n        The user object may be any type of the application's choosing.\n        \"\"\"\n        if not hasattr(self, \"_current_user\"):\n            self._current_user = self.get_current_user()\n        return self._current_user", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides the authenticated user for the current request by calling a method or using a pre-set value, caching the result for subsequent access. Essential for managing user identity within request handling workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "current_user", "line_number": 1344, "body": "def current_user(self, value: Any) -> None:\n        self._current_user = value", "is_method": true, "class_name": "RequestHandler", "function_description": "Sets the current user associated with the request, enabling user-specific handling or context within the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_login_url", "line_number": 1354, "body": "def get_login_url(self) -> str:\n        \"\"\"Override to customize the login URL based on the request.\n\n        By default, we use the ``login_url`` application setting.\n        \"\"\"\n        self.require_setting(\"login_url\", \"@tornado.web.authenticated\")\n        return self.application.settings[\"login_url\"]", "is_method": true, "class_name": "RequestHandler", "function_description": "Returns the login URL configured in the application settings, allowing customization for authentication redirects within the RequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_template_path", "line_number": 1362, "body": "def get_template_path(self) -> Optional[str]:\n        \"\"\"Override to customize template path for each handler.\n\n        By default, we use the ``template_path`` application setting.\n        Return None to load templates relative to the calling file.\n        \"\"\"\n        return self.application.settings.get(\"template_path\")", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides the template directory path for rendering views, defaulting to the application setting but allowing customization or relative loading per handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "xsrf_token", "line_number": 1371, "body": "def xsrf_token(self) -> bytes:\n        \"\"\"The XSRF-prevention token for the current user/session.\n\n        To prevent cross-site request forgery, we set an '_xsrf' cookie\n        and include the same '_xsrf' value as an argument with all POST\n        requests. If the two do not match, we reject the form submission\n        as a potential forgery.\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n\n        This property is of type `bytes`, but it contains only ASCII\n        characters. If a character string is required, there is no\n        need to base64-encode it; just decode the byte string as\n        UTF-8.\n\n        .. versionchanged:: 3.2.2\n           The xsrf token will now be have a random mask applied in every\n           request, which makes it safe to include the token in pages\n           that are compressed.  See http://breachattack.com for more\n           information on the issue fixed by this change.  Old (version 1)\n           cookies will be converted to version 2 when this method is called\n           unless the ``xsrf_cookie_version`` `Application` setting is\n           set to 1.\n\n        .. versionchanged:: 4.3\n           The ``xsrf_cookie_kwargs`` `Application` setting may be\n           used to supply additional cookie options (which will be\n           passed directly to `set_cookie`). For example,\n           ``xsrf_cookie_kwargs=dict(httponly=True, secure=True)``\n           will set the ``secure`` and ``httponly`` flags on the\n           ``_xsrf`` cookie.\n        \"\"\"\n        if not hasattr(self, \"_xsrf_token\"):\n            version, token, timestamp = self._get_raw_xsrf_token()\n            output_version = self.settings.get(\"xsrf_cookie_version\", 2)\n            cookie_kwargs = self.settings.get(\"xsrf_cookie_kwargs\", {})\n            if output_version == 1:\n                self._xsrf_token = binascii.b2a_hex(token)\n            elif output_version == 2:\n                mask = os.urandom(4)\n                self._xsrf_token = b\"|\".join(\n                    [\n                        b\"2\",\n                        binascii.b2a_hex(mask),\n                        binascii.b2a_hex(_websocket_mask(mask, token)),\n                        utf8(str(int(timestamp))),\n                    ]\n                )\n            else:\n                raise ValueError(\"unknown xsrf cookie version %d\", output_version)\n            if version is None:\n                if self.current_user and \"expires_days\" not in cookie_kwargs:\n                    cookie_kwargs[\"expires_days\"] = 30\n                self.set_cookie(\"_xsrf\", self._xsrf_token, **cookie_kwargs)\n        return self._xsrf_token", "is_method": true, "class_name": "RequestHandler", "function_description": "Generates and provides the cross-site request forgery (XSRF) prevention token for the current user session, ensuring request authenticity by setting and validating secure cookies with configurable options."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_raw_xsrf_token", "line_number": 1427, "body": "def _get_raw_xsrf_token(self) -> Tuple[Optional[int], bytes, float]:\n        \"\"\"Read or generate the xsrf token in its raw form.\n\n        The raw_xsrf_token is a tuple containing:\n\n        * version: the version of the cookie from which this token was read,\n          or None if we generated a new token in this request.\n        * token: the raw token data; random (non-ascii) bytes.\n        * timestamp: the time this token was generated (will not be accurate\n          for version 1 cookies)\n        \"\"\"\n        if not hasattr(self, \"_raw_xsrf_token\"):\n            cookie = self.get_cookie(\"_xsrf\")\n            if cookie:\n                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            assert token is not None\n            assert timestamp is not None\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides raw XSRF token data by retrieving it from a cookie or generating a new secure token with its version and timestamp, supporting request validation and protection against cross-site request forgery attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_decode_xsrf_token", "line_number": 1453, "body": "def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:\n            m = _signed_value_version_re.match(utf8(cookie))\n\n            if m:\n                version = int(m.group(1))\n                if version == 2:\n                    _, mask_str, masked_token, timestamp_str = cookie.split(\"|\")\n\n                    mask = binascii.a2b_hex(utf8(mask_str))\n                    token = _websocket_mask(mask, binascii.a2b_hex(utf8(masked_token)))\n                    timestamp = int(timestamp_str)\n                    return version, token, timestamp\n                else:\n                    # Treat unknown versions as not present instead of failing.\n                    raise Exception(\"Unknown xsrf cookie version\")\n            else:\n                version = 1\n                try:\n                    token = binascii.a2b_hex(utf8(cookie))\n                except (binascii.Error, TypeError):\n                    token = utf8(cookie)\n                # We don't have a usable timestamp in older versions.\n                timestamp = int(time.time())\n                return (version, token, timestamp)\n        except Exception:\n            # Catch exceptions and return nothing instead of failing.\n            gen_log.debug(\"Uncaught exception in _decode_xsrf_token\", exc_info=True)\n            return None, None, None", "is_method": true, "class_name": "RequestHandler", "function_description": "Internal utility of RequestHandler that decodes an XSRF cookie string into its version, token, and timestamp components for security validation purposes, supporting multiple token versions and handling errors gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "check_xsrf_cookie", "line_number": 1489, "body": "def check_xsrf_cookie(self) -> None:\n        \"\"\"Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.\n\n        To prevent cross-site request forgery, we set an ``_xsrf``\n        cookie and include the same value as a non-cookie\n        field with all ``POST`` requests. If the two do not match, we\n        reject the form submission as a potential forgery.\n\n        The ``_xsrf`` value may be set as either a form field named ``_xsrf``\n        or in a custom HTTP header named ``X-XSRFToken`` or ``X-CSRFToken``\n        (the latter is accepted for compatibility with Django).\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n\n        .. versionchanged:: 3.2.2\n           Added support for cookie version 2.  Both versions 1 and 2 are\n           supported.\n        \"\"\"\n        # Prior to release 1.1.1, this check was ignored if the HTTP header\n        # ``X-Requested-With: XMLHTTPRequest`` was present.  This exception\n        # has been shown to be insecure and has been removed.  For more\n        # information please see\n        # http://www.djangoproject.com/weblog/2011/feb/08/security/\n        # http://weblog.rubyonrails.org/2011/2/8/csrf-protection-bypass-in-ruby-on-rails\n        token = (\n            self.get_argument(\"_xsrf\", None)\n            or self.request.headers.get(\"X-Xsrftoken\")\n            or self.request.headers.get(\"X-Csrftoken\")\n        )\n        if not token:\n            raise HTTPError(403, \"'_xsrf' argument missing from POST\")\n        _, token, _ = self._decode_xsrf_token(token)\n        _, expected_token, _ = self._get_raw_xsrf_token()\n        if not token:\n            raise HTTPError(403, \"'_xsrf' argument has invalid format\")\n        if not hmac.compare_digest(utf8(token), utf8(expected_token)):\n            raise HTTPError(403, \"XSRF cookie does not match POST argument\")", "is_method": true, "class_name": "RequestHandler", "function_description": "Core utility of the RequestHandler class that validates the _xsrf cookie against request data to prevent cross-site request forgery (CSRF) attacks by ensuring token consistency in POST requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "xsrf_form_html", "line_number": 1527, "body": "def xsrf_form_html(self) -> str:\n        \"\"\"An HTML ``<input/>`` element to be included with all POST forms.\n\n        It defines the ``_xsrf`` input value, which we check on all POST\n        requests to prevent cross-site request forgery. If you have set\n        the ``xsrf_cookies`` application setting, you must include this\n        HTML within all of your HTML forms.\n\n        In a template, this method should be called with ``{% module\n        xsrf_form_html() %}``\n\n        See `check_xsrf_cookie()` above for more information.\n        \"\"\"\n        return (\n            '<input type=\"hidden\" name=\"_xsrf\" value=\"'\n            + escape.xhtml_escape(self.xsrf_token)\n            + '\"/>'\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides an HTML hidden input element containing the XSRF token to include in POST forms, enabling protection against cross-site request forgery attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "static_url", "line_number": 1546, "body": "def static_url(\n        self, path: str, include_host: Optional[bool] = None, **kwargs: Any\n    ) -> str:\n        \"\"\"Returns a static URL for the given relative static file path.\n\n        This method requires you set the ``static_path`` setting in your\n        application (which specifies the root directory of your static\n        files).\n\n        This method returns a versioned url (by default appending\n        ``?v=<signature>``), which allows the static files to be\n        cached indefinitely.  This can be disabled by passing\n        ``include_version=False`` (in the default implementation;\n        other static file implementations are not required to support\n        this, but they may support other options).\n\n        By default this method returns URLs relative to the current\n        host, but if ``include_host`` is true the URL returned will be\n        absolute.  If this handler has an ``include_host`` attribute,\n        that value will be used as the default for all `static_url`\n        calls that do not pass ``include_host`` as a keyword argument.\n\n        \"\"\"\n        self.require_setting(\"static_path\", \"static_url\")\n        get_url = self.settings.get(\n            \"static_handler_class\", StaticFileHandler\n        ).make_static_url\n\n        if include_host is None:\n            include_host = getattr(self, \"include_host\", False)\n\n        if include_host:\n            base = self.request.protocol + \"://\" + self.request.host\n        else:\n            base = \"\"\n\n        return base + get_url(self.settings, path, **kwargs)", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a versioned static file URL for a given path, supporting indefinite caching and optional absolute URL generation. It facilitates efficient referencing of static resources within web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "require_setting", "line_number": 1584, "body": "def require_setting(self, name: str, feature: str = \"this feature\") -> None:\n        \"\"\"Raises an exception if the given app setting is not defined.\"\"\"\n        if not self.application.settings.get(name):\n            raise Exception(\n                \"You must define the '%s' setting in your \"\n                \"application to use %s\" % (name, feature)\n            )", "is_method": true, "class_name": "RequestHandler", "function_description": "Ensures a required application setting is defined, raising an exception if missing, to enforce configuration dependencies critical for enabling specific features within the RequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "reverse_url", "line_number": 1592, "body": "def reverse_url(self, name: str, *args: Any) -> str:\n        \"\"\"Alias for `Application.reverse_url`.\"\"\"\n        return self.application.reverse_url(name, *args)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that provides convenient access to URL reversing by delegating to the Application's reverse_url function, facilitating URL generation by route name and parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "compute_etag", "line_number": 1596, "body": "def compute_etag(self) -> Optional[str]:\n        \"\"\"Computes the etag header to be used for this request.\n\n        By default uses a hash of the content written so far.\n\n        May be overridden to provide custom etag implementations,\n        or may return None to disable tornado's default etag support.\n        \"\"\"\n        hasher = hashlib.sha1()\n        for part in self._write_buffer:\n            hasher.update(part)\n        return '\"%s\"' % hasher.hexdigest()", "is_method": true, "class_name": "RequestHandler", "function_description": "Generates a unique ETag header by hashing the current response content, enabling efficient HTTP caching and conditional requests in the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_etag_header", "line_number": 1609, "body": "def set_etag_header(self) -> None:\n        \"\"\"Sets the response's Etag header using ``self.compute_etag()``.\n\n        Note: no header will be set if ``compute_etag()`` returns ``None``.\n\n        This method is called automatically when the request is finished.\n        \"\"\"\n        etag = self.compute_etag()\n        if etag is not None:\n            self.set_header(\"Etag\", etag)", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method of RequestHandler that sets the HTTP ETag header based on a computed value, aiding in efficient client-side caching and conditional request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "check_etag_header", "line_number": 1620, "body": "def check_etag_header(self) -> bool:\n        \"\"\"Checks the ``Etag`` header against requests's ``If-None-Match``.\n\n        Returns ``True`` if the request's Etag matches and a 304 should be\n        returned. For example::\n\n            self.set_etag_header()\n            if self.check_etag_header():\n                self.set_status(304)\n                return\n\n        This method is called automatically when the request is finished,\n        but may be called earlier for applications that override\n        `compute_etag` and want to do an early check for ``If-None-Match``\n        before completing the request.  The ``Etag`` header should be set\n        (perhaps with `set_etag_header`) before calling this method.\n        \"\"\"\n        computed_etag = utf8(self._headers.get(\"Etag\", \"\"))\n        # Find all weak and strong etag values from If-None-Match header\n        # because RFC 7232 allows multiple etag values in a single header.\n        etags = re.findall(\n            br'\\*|(?:W/)?\"[^\"]*\"', utf8(self.request.headers.get(\"If-None-Match\", \"\"))\n        )\n        if not computed_etag or not etags:\n            return False\n\n        match = False\n        if etags[0] == b\"*\":\n            match = True\n        else:\n            # Use a weak comparison when comparing entity-tags.\n            def val(x: bytes) -> bytes:\n                return x[2:] if x.startswith(b\"W/\") else x\n\n            for etag in etags:\n                if val(etag) == val(computed_etag):\n                    match = True\n                    break\n        return match", "is_method": true, "class_name": "RequestHandler", "function_description": "Method of RequestHandler that verifies if the current response's ETag matches the client's If-None-Match header, indicating whether a 304 Not Modified status should be returned to optimize HTTP caching."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_log", "line_number": 1730, "body": "def _log(self) -> None:\n        \"\"\"Logs the current request.\n\n        Sort of deprecated since this functionality was moved to the\n        Application, but left in place for the benefit of existing apps\n        that have overridden this method.\n        \"\"\"\n        self.application.log_request(self)", "is_method": true, "class_name": "RequestHandler", "function_description": "Helper method in RequestHandler that logs the current request by delegating to the Application's logging, maintained for backward compatibility with overridden implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_request_summary", "line_number": 1739, "body": "def _request_summary(self) -> str:\n        return \"%s %s (%s)\" % (\n            self.request.method,\n            self.request.uri,\n            self.request.remote_ip,\n        )", "is_method": true, "class_name": "RequestHandler", "function_description": "Returns a brief summary string of the request's method, URI, and remote IP address, useful for logging or debugging request details within the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_handle_request_exception", "line_number": 1746, "body": "def _handle_request_exception(self, e: BaseException) -> None:\n        if isinstance(e, Finish):\n            # Not an error; just finish the request without logging.\n            if not self._finished:\n                self.finish(*e.args)\n            return\n        try:\n            self.log_exception(*sys.exc_info())\n        except Exception:\n            # An error here should still get a best-effort send_error()\n            # to avoid leaking the connection.\n            app_log.error(\"Error in exception logger\", exc_info=True)\n        if self._finished:\n            # Extra errors after the request has been finished should\n            # be logged, but there is no reason to continue to try and\n            # send a response.\n            return\n        if isinstance(e, HTTPError):\n            self.send_error(e.status_code, exc_info=sys.exc_info())\n        else:\n            self.send_error(500, exc_info=sys.exc_info())", "is_method": true, "class_name": "RequestHandler", "function_description": "Handles exceptions during request processing by logging the error and sending an appropriate HTTP response, ensuring proper request finalization without leaking connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "log_exception", "line_number": 1768, "body": "def log_exception(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        \"\"\"Override to customize logging of uncaught exceptions.\n\n        By default logs instances of `HTTPError` as warnings without\n        stack traces (on the ``tornado.general`` logger), and all\n        other exceptions as errors with stack traces (on the\n        ``tornado.application`` logger).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        if isinstance(value, HTTPError):\n            if value.log_message:\n                format = \"%d %s: \" + value.log_message\n                args = [value.status_code, self._request_summary()] + list(value.args)\n                gen_log.warning(format, *args)\n        else:\n            app_log.error(\n                \"Uncaught exception %s\\n%r\",\n                self._request_summary(),\n                self.request,\n                exc_info=(typ, value, tb),  # type: ignore\n            )", "is_method": true, "class_name": "RequestHandler", "function_description": "Overrides default exception logging to record HTTP errors as warnings without stack traces and other uncaught exceptions as error entries with stack traces, enhancing request error tracking in the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_ui_module", "line_number": 1796, "body": "def _ui_module(self, name: str, module: Type[\"UIModule\"]) -> Callable[..., str]:\n        def render(*args, **kwargs) -> str:  # type: ignore\n            if not hasattr(self, \"_active_modules\"):\n                self._active_modules = {}  # type: Dict[str, UIModule]\n            if name not in self._active_modules:\n                self._active_modules[name] = module(self)\n            rendered = self._active_modules[name].render(*args, **kwargs)\n            return rendered\n\n        return render", "is_method": true, "class_name": "RequestHandler", "function_description": "Provides a utility to create or retrieve and render instances of UI modules by name, enabling dynamic, reusable UI component rendering within the RequestHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_ui_method", "line_number": 1807, "body": "def _ui_method(self, method: Callable[..., str]) -> Callable[..., str]:\n        return lambda *args, **kwargs: method(self, *args, **kwargs)", "is_method": true, "class_name": "RequestHandler", "function_description": "Private helper method in RequestHandler that wraps a callable to automatically pass the instance as the first argument, facilitating UI-related method invocation with instance context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_clear_representation_headers", "line_number": 1810, "body": "def _clear_representation_headers(self) -> None:\n        # 304 responses should not contain representation metadata\n        # headers (defined in\n        # https://tools.ietf.org/html/rfc7231#section-3.1)\n        # not explicitly allowed by\n        # https://tools.ietf.org/html/rfc7232#section-4.1\n        headers = [\"Content-Encoding\", \"Content-Language\", \"Content-Type\"]\n        for h in headers:\n            self.clear_header(h)", "is_method": true, "class_name": "RequestHandler", "function_description": "Clears representation-related HTTP headers to comply with 304 Not Modified response requirements, ensuring no inappropriate metadata is included in the response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "wrapper", "line_number": 1865, "body": "def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return None\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)", "is_method": false, "function_description": "This method in RequestHandler ensures URL paths do not end with a slash by redirecting GET or HEAD requests to the path without the trailing slash, supporting canonical URL handling and avoiding duplicate content issues."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "process_rule", "line_number": 1928, "body": "def process_rule(self, rule: Rule) -> Rule:\n        rule = super().process_rule(rule)\n\n        if isinstance(rule.target, (list, tuple)):\n            rule.target = _ApplicationRouter(\n                self.application, rule.target  # type: ignore\n            )\n\n        return rule", "is_method": true, "class_name": "_ApplicationRouter", "function_description": "Core method in _ApplicationRouter that processes and potentially wraps a rule's target into a nested router if it contains multiple targets, enabling hierarchical routing configurations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_target_delegate", "line_number": 1938, "body": "def get_target_delegate(\n        self, target: Any, request: httputil.HTTPServerRequest, **target_params: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        if isclass(target) and issubclass(target, RequestHandler):\n            return self.application.get_handler_delegate(\n                request, target, **target_params\n            )\n\n        return super().get_target_delegate(target, request, **target_params)", "is_method": true, "class_name": "_ApplicationRouter", "function_description": "Utility method of the _ApplicationRouter class that determines the appropriate request handler delegate based on the target type, enabling dynamic routing of HTTP requests within the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "listen", "line_number": 2089, "body": "def listen(self, port: int, address: str = \"\", **kwargs: Any) -> HTTPServer:\n        \"\"\"Starts an HTTP server for this application on the given port.\n\n        This is a convenience alias for creating an `.HTTPServer`\n        object and calling its listen method.  Keyword arguments not\n        supported by `HTTPServer.listen <.TCPServer.listen>` are passed to the\n        `.HTTPServer` constructor.  For advanced uses\n        (e.g. multi-process mode), do not use this method; create an\n        `.HTTPServer` and call its\n        `.TCPServer.bind`/`.TCPServer.start` methods directly.\n\n        Note that after calling this method you still need to call\n        ``IOLoop.current().start()`` to start the server.\n\n        Returns the `.HTTPServer` object.\n\n        .. versionchanged:: 4.3\n           Now returns the `.HTTPServer` object.\n        \"\"\"\n        server = HTTPServer(self, **kwargs)\n        server.listen(port, address)\n        return server", "is_method": true, "class_name": "Application", "function_description": "Utility method of the Application class that starts and returns an HTTP server listening on a specified port and address, simplifying server setup for handling HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "add_handlers", "line_number": 2112, "body": "def add_handlers(self, host_pattern: str, host_handlers: _RuleList) -> None:\n        \"\"\"Appends the given handlers to our handler list.\n\n        Host patterns are processed sequentially in the order they were\n        added. All matching patterns will be considered.\n        \"\"\"\n        host_matcher = HostMatches(host_pattern)\n        rule = Rule(host_matcher, _ApplicationRouter(self, host_handlers))\n\n        self.default_router.rules.insert(-1, rule)\n\n        if self.default_host is not None:\n            self.wildcard_router.add_rules(\n                [(DefaultHostMatches(self, host_matcher.host_pattern), host_handlers)]\n            )", "is_method": true, "class_name": "Application", "function_description": "Adds and organizes request handlers based on host patterns within the Application, enabling sequential matching and routing of incoming requests to the appropriate handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "add_transform", "line_number": 2128, "body": "def add_transform(self, transform_class: Type[\"OutputTransform\"]) -> None:\n        self.transforms.append(transform_class)", "is_method": true, "class_name": "Application", "function_description": "Adds a transformation class to the Application's list of output transforms, enabling dynamic extension or modification of output processing behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_load_ui_methods", "line_number": 2131, "body": "def _load_ui_methods(self, methods: Any) -> None:\n        if isinstance(methods, types.ModuleType):\n            self._load_ui_methods(dict((n, getattr(methods, n)) for n in dir(methods)))\n        elif isinstance(methods, list):\n            for m in methods:\n                self._load_ui_methods(m)\n        else:\n            for name, fn in methods.items():\n                if (\n                    not name.startswith(\"_\")\n                    and hasattr(fn, \"__call__\")\n                    and name[0].lower() == name[0]\n                ):\n                    self.ui_methods[name] = fn", "is_method": true, "class_name": "Application", "function_description": "Internal Application method that loads and registers public callable UI methods from modules, lists, or dictionaries into the app's interface for user interaction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_load_ui_modules", "line_number": 2146, "body": "def _load_ui_modules(self, modules: Any) -> None:\n        if isinstance(modules, types.ModuleType):\n            self._load_ui_modules(dict((n, getattr(modules, n)) for n in dir(modules)))\n        elif isinstance(modules, list):\n            for m in modules:\n                self._load_ui_modules(m)\n        else:\n            assert isinstance(modules, dict)\n            for name, cls in modules.items():\n                try:\n                    if issubclass(cls, UIModule):\n                        self.ui_modules[name] = cls\n                except TypeError:\n                    pass", "is_method": true, "class_name": "Application", "function_description": "Internal Application method that loads UI module classes from various input formats, registering all subclasses of UIModule for use in the application's user interface construction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "__call__", "line_number": 2161, "body": "def __call__(\n        self, request: httputil.HTTPServerRequest\n    ) -> Optional[Awaitable[None]]:\n        # Legacy HTTPServer interface\n        dispatcher = self.find_handler(request)\n        return dispatcher.execute()", "is_method": true, "class_name": "Application", "function_description": "Core method of the Application class that handles incoming HTTP requests by locating the appropriate request handler and executing it, enabling request dispatch and processing within the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "find_handler", "line_number": 2168, "body": "def find_handler(\n        self, request: httputil.HTTPServerRequest, **kwargs: Any\n    ) -> \"_HandlerDelegate\":\n        route = self.default_router.find_handler(request)\n        if route is not None:\n            return cast(\"_HandlerDelegate\", route)\n\n        if self.settings.get(\"default_handler_class\"):\n            return self.get_handler_delegate(\n                request,\n                self.settings[\"default_handler_class\"],\n                self.settings.get(\"default_handler_args\", {}),\n            )\n\n        return self.get_handler_delegate(request, ErrorHandler, {\"status_code\": 404})", "is_method": true, "class_name": "Application", "function_description": "Provides the HTTP request handler by matching routes or falling back to a default or error handler, enabling request processing within the Application framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_handler_delegate", "line_number": 2184, "body": "def get_handler_delegate(\n        self,\n        request: httputil.HTTPServerRequest,\n        target_class: Type[RequestHandler],\n        target_kwargs: Optional[Dict[str, Any]] = None,\n        path_args: Optional[List[bytes]] = None,\n        path_kwargs: Optional[Dict[str, bytes]] = None,\n    ) -> \"_HandlerDelegate\":\n        \"\"\"Returns `~.httputil.HTTPMessageDelegate` that can serve a request\n        for application and `RequestHandler` subclass.\n\n        :arg httputil.HTTPServerRequest request: current HTTP request.\n        :arg RequestHandler target_class: a `RequestHandler` class.\n        :arg dict target_kwargs: keyword arguments for ``target_class`` constructor.\n        :arg list path_args: positional arguments for ``target_class`` HTTP method that\n            will be executed while handling a request (``get``, ``post`` or any other).\n        :arg dict path_kwargs: keyword arguments for ``target_class`` HTTP method.\n        \"\"\"\n        return _HandlerDelegate(\n            self, request, target_class, target_kwargs, path_args, path_kwargs\n        )", "is_method": true, "class_name": "Application", "function_description": "Provides a handler delegate to process an HTTP request using a specified RequestHandler subclass, passing optional constructor and method arguments. This enables flexible request handling within the Application framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "reverse_url", "line_number": 2206, "body": "def reverse_url(self, name: str, *args: Any) -> str:\n        \"\"\"Returns a URL path for handler named ``name``\n\n        The handler must be added to the application as a named `URLSpec`.\n\n        Args will be substituted for capturing groups in the `URLSpec` regex.\n        They will be converted to strings if necessary, encoded as utf8,\n        and url-escaped.\n        \"\"\"\n        reversed_url = self.default_router.reverse_url(name, *args)\n        if reversed_url is not None:\n            return reversed_url\n\n        raise KeyError(\"%s not found in named urls\" % name)", "is_method": true, "class_name": "Application", "function_description": "Provides a way to retrieve a URL path by handler name with argument substitution, enabling dynamic URL generation within the Application's routing system. It raises an error if the named route is not found."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "log_request", "line_number": 2221, "body": "def log_request(self, handler: RequestHandler) -> None:\n        \"\"\"Writes a completed HTTP request to the logs.\n\n        By default writes to the python root logger.  To change\n        this behavior either subclass Application and override this method,\n        or pass a function in the application settings dictionary as\n        ``log_function``.\n        \"\"\"\n        if \"log_function\" in self.settings:\n            self.settings[\"log_function\"](handler)\n            return\n        if handler.get_status() < 400:\n            log_method = access_log.info\n        elif handler.get_status() < 500:\n            log_method = access_log.warning\n        else:\n            log_method = access_log.error\n        request_time = 1000.0 * handler.request.request_time()\n        log_method(\n            \"%d %s %.2fms\",\n            handler.get_status(),\n            handler._request_summary(),\n            request_time,\n        )", "is_method": true, "class_name": "Application", "function_description": "Logs details of completed HTTP requests with severity based on status codes, supporting customizable logging via application settings. It helps monitor and track web request outcomes for the Application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "headers_received", "line_number": 2267, "body": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        if self.stream_request_body:\n            self.request._body_future = Future()\n            return self.execute()\n        return None", "is_method": true, "class_name": "_HandlerDelegate", "function_description": "Handles the reception of HTTP headers, optionally initiating request body processing and triggering further execution when streaming is enabled. It facilitates controlled continuation of HTTP message handling in the _HandlerDelegate context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "data_received", "line_number": 2277, "body": "def data_received(self, data: bytes) -> Optional[Awaitable[None]]:\n        if self.stream_request_body:\n            return self.handler.data_received(data)\n        else:\n            self.chunks.append(data)\n            return None", "is_method": true, "class_name": "_HandlerDelegate", "function_description": "Core method of _HandlerDelegate that processes incoming byte data by either forwarding it to a handler or buffering it locally, supporting flexible data consumption strategies during streaming requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "finish", "line_number": 2284, "body": "def finish(self) -> None:\n        if self.stream_request_body:\n            future_set_result_unless_cancelled(self.request._body_future, None)\n        else:\n            self.request.body = b\"\".join(self.chunks)\n            self.request._parse_body()\n            self.execute()", "is_method": true, "class_name": "_HandlerDelegate", "function_description": "Finalizes request processing by completing the request body handling and triggering subsequent execution steps, ensuring the request is fully prepared for further handling or response generation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "on_connection_close", "line_number": 2292, "body": "def on_connection_close(self) -> None:\n        if self.stream_request_body:\n            self.handler.on_connection_close()\n        else:\n            self.chunks = None", "is_method": true, "class_name": "_HandlerDelegate", "function_description": "Handles cleanup actions when a connection closes, delegating to a handler if streaming request body; otherwise, it clears stored data chunks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "execute", "line_number": 2298, "body": "def execute(self) -> Optional[Awaitable[None]]:\n        # If template cache is disabled (usually in the debug mode),\n        # re-compile templates and reload static files on every\n        # request so you don't need to restart to see changes\n        if not self.application.settings.get(\"compiled_template_cache\", True):\n            with RequestHandler._template_loader_lock:\n                for loader in RequestHandler._template_loaders.values():\n                    loader.reset()\n        if not self.application.settings.get(\"static_hash_cache\", True):\n            StaticFileHandler.reset()\n\n        self.handler = self.handler_class(\n            self.application, self.request, **self.handler_kwargs\n        )\n        transforms = [t(self.request) for t in self.application.transforms]\n\n        if self.stream_request_body:\n            self.handler._prepared_future = Future()\n        # Note that if an exception escapes handler._execute it will be\n        # trapped in the Future it returns (which we are ignoring here,\n        # leaving it to be logged when the Future is GC'd).\n        # However, that shouldn't happen because _execute has a blanket\n        # except handler, and we cannot easily access the IOLoop here to\n        # call add_future (because of the requirement to remain compatible\n        # with WSGI)\n        fut = gen.convert_yielded(\n            self.handler._execute(transforms, *self.path_args, **self.path_kwargs)\n        )\n        fut.add_done_callback(lambda f: f.result())\n        # If we are streaming the request body, then execute() is finished\n        # when the handler has prepared to receive the body.  If not,\n        # it doesn't matter when execute() finishes (so we return None)\n        return self.handler._prepared_future", "is_method": true, "class_name": "_HandlerDelegate", "function_description": "Core method of the _HandlerDelegate class that initializes and executes a request handler, managing template and static file caching based on settings and supporting asynchronous request body streaming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "__str__", "line_number": 2370, "body": "def __str__(self) -> str:\n        message = \"HTTP %d: %s\" % (\n            self.status_code,\n            self.reason or httputil.responses.get(self.status_code, \"Unknown\"),\n        )\n        if self.log_message:\n            return message + \" (\" + (self.log_message % self.args) + \")\"\n        else:\n            return message", "is_method": true, "class_name": "HTTPError", "function_description": "Provides a descriptive string representation of an HTTPError, including status code, reason, and an optional detailed log message for clearer error reporting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "initialize", "line_number": 2426, "body": "def initialize(self, status_code: int) -> None:\n        self.set_status(status_code)", "is_method": true, "class_name": "ErrorHandler", "function_description": "Initializes the error handler by setting the HTTP status code, preparing it to represent a specific error state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "prepare", "line_number": 2429, "body": "def prepare(self) -> None:\n        raise HTTPError(self._status_code)", "is_method": true, "class_name": "ErrorHandler", "function_description": "Raises an HTTP error with a predefined status code, signaling an error condition during request handling. It provides a standardized way to trigger HTTP exceptions within the ErrorHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "initialize", "line_number": 2472, "body": "def initialize(self, url: str, permanent: bool = True) -> None:\n        self._url = url\n        self._permanent = permanent", "is_method": true, "class_name": "RedirectHandler", "function_description": "Initializes a RedirectHandler instance with a target URL and a flag indicating whether the redirect is permanent, setting up the necessary state for handling URL redirections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get", "line_number": 2476, "body": "def get(self, *args: Any, **kwargs: Any) -> None:\n        to_url = self._url.format(*args, **kwargs)\n        if self.request.query_arguments:\n            # TODO: figure out typing for the next line.\n            to_url = httputil.url_concat(\n                to_url,\n                list(httputil.qs_to_qsl(self.request.query_arguments)),  # type: ignore\n            )\n        self.redirect(to_url, permanent=self._permanent)", "is_method": true, "class_name": "RedirectHandler", "function_description": "Handles HTTP GET requests by redirecting the client to a dynamically formatted URL, preserving any query parameters. It serves as a utility for managing URL redirections within web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "initialize", "line_number": 2559, "body": "def initialize(self, path: str, default_filename: Optional[str] = None) -> None:\n        self.root = path\n        self.default_filename = default_filename", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Initializes the StaticFileHandler with a root directory and an optional default filename, setting up the base path for serving static files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "reset", "line_number": 2564, "body": "def reset(cls) -> None:\n        with cls._lock:\n            cls._static_hashes = {}", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Resets the internal cache of static file hashes within the StaticFileHandler, ensuring that any stored checksum data is cleared safely in a thread-safe manner. This supports updating or revalidating static file states."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "head", "line_number": 2568, "body": "def head(self, path: str) -> Awaitable[None]:\n        return self.get(path, include_body=False)", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides a HEAD HTTP request handler that retrieves response headers for a given file path without including the response body, useful for checking resource metadata efficiently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "compute_etag", "line_number": 2654, "body": "def compute_etag(self) -> Optional[str]:\n        \"\"\"Sets the ``Etag`` header based on static url version.\n\n        This allows efficient ``If-None-Match`` checks against cached\n        versions, and sends the correct ``Etag`` for a partial response\n        (i.e. the same ``Etag`` as the full file).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.absolute_path is not None\n        version_hash = self._get_cached_version(self.absolute_path)\n        if not version_hash:\n            return None\n        return '\"%s\"' % (version_hash,)", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Generates an ETag header value based on the file\u2019s version for efficient HTTP caching and conditional requests, ensuring proper validation even for partial responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_headers", "line_number": 2669, "body": "def set_headers(self) -> None:\n        \"\"\"Sets the content and caching headers on the response.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        self.set_header(\"Accept-Ranges\", \"bytes\")\n        self.set_etag_header()\n\n        if self.modified is not None:\n            self.set_header(\"Last-Modified\", self.modified)\n\n        content_type = self.get_content_type()\n        if content_type:\n            self.set_header(\"Content-Type\", content_type)\n\n        cache_time = self.get_cache_time(self.path, self.modified, content_type)\n        if cache_time > 0:\n            self.set_header(\n                \"Expires\",\n                datetime.datetime.utcnow() + datetime.timedelta(seconds=cache_time),\n            )\n            self.set_header(\"Cache-Control\", \"max-age=\" + str(cache_time))\n\n        self.set_extra_headers(self.path)", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Sets appropriate HTTP content and caching headers on the response to optimize browser caching and content handling for static files served by StaticFileHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "should_return_304", "line_number": 2694, "body": "def should_return_304(self) -> bool:\n        \"\"\"Returns True if the headers indicate that we should return 304.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        # If client sent If-None-Match, use it, ignore If-Modified-Since\n        if self.request.headers.get(\"If-None-Match\"):\n            return self.check_etag_header()\n\n        # Check the If-Modified-Since, and don't send the result if the\n        # content has not been modified\n        ims_value = self.request.headers.get(\"If-Modified-Since\")\n        if ims_value is not None:\n            date_tuple = email.utils.parsedate(ims_value)\n            if date_tuple is not None:\n                if_since = datetime.datetime(*date_tuple[:6])\n                assert self.modified is not None\n                if if_since >= self.modified:\n                    return True\n\n        return False", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Determines if the client's request headers indicate the server should respond with a 304 Not Modified status, supporting efficient caching by validating ETag or last modification date."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_absolute_path", "line_number": 2717, "body": "def get_absolute_path(cls, root: str, path: str) -> str:\n        \"\"\"Returns the absolute location of ``path`` relative to ``root``.\n\n        ``root`` is the path configured for this `StaticFileHandler`\n        (in most cases the ``static_path`` `Application` setting).\n\n        This class method may be overridden in subclasses.  By default\n        it returns a filesystem path, but other strings may be used\n        as long as they are unique and understood by the subclass's\n        overridden `get_content`.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        abspath = os.path.abspath(os.path.join(root, path))\n        return abspath", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides the absolute filesystem path for a given relative path based on the configured root directory. This enables consistent location resolution for static files managed by StaticFileHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "validate_absolute_path", "line_number": 2733, "body": "def validate_absolute_path(self, root: str, absolute_path: str) -> Optional[str]:\n        \"\"\"Validate and return the absolute path.\n\n        ``root`` is the configured path for the `StaticFileHandler`,\n        and ``path`` is the result of `get_absolute_path`\n\n        This is an instance method called during request processing,\n        so it may raise `HTTPError` or use methods like\n        `RequestHandler.redirect` (return None after redirecting to\n        halt further processing).  This is where 404 errors for missing files\n        are generated.\n\n        This method may modify the path before returning it, but note that\n        any such modifications will not be understood by `make_static_url`.\n\n        In instance methods, this method's result is available as\n        ``self.absolute_path``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        # os.path.abspath strips a trailing /.\n        # We must add it back to `root` so that we only match files\n        # in a directory named `root` instead of files starting with\n        # that prefix.\n        root = os.path.abspath(root)\n        if not root.endswith(os.path.sep):\n            # abspath always removes a trailing slash, except when\n            # root is '/'. This is an unusual case, but several projects\n            # have independently discovered this technique to disable\n            # Tornado's path validation and (hopefully) do their own,\n            # so we need to support it.\n            root += os.path.sep\n        # The trailing slash also needs to be temporarily added back\n        # the requested path so a request to root/ will match.\n        if not (absolute_path + os.path.sep).startswith(root):\n            raise HTTPError(403, \"%s is not in root static directory\", self.path)\n        if os.path.isdir(absolute_path) and self.default_filename is not None:\n            # need to look at the request.path here for when path is empty\n            # but there is some prefix to the path that was already\n            # trimmed by the routing\n            if not self.request.path.endswith(\"/\"):\n                self.redirect(self.request.path + \"/\", permanent=True)\n                return None\n            absolute_path = os.path.join(absolute_path, self.default_filename)\n        if not os.path.exists(absolute_path):\n            raise HTTPError(404)\n        if not os.path.isfile(absolute_path):\n            raise HTTPError(403, \"%s is not a file\", self.path)\n        return absolute_path", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Ensures a requested file path is valid and securely within the configured root directory for static files, handling directory defaults and issuing HTTP errors or redirects for invalid or missing paths. It safeguards static file serving in web requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_content", "line_number": 2784, "body": "def get_content(\n        cls, abspath: str, start: Optional[int] = None, end: Optional[int] = None\n    ) -> Generator[bytes, None, None]:\n        \"\"\"Retrieve the content of the requested resource which is located\n        at the given absolute path.\n\n        This class method may be overridden by subclasses.  Note that its\n        signature is different from other overridable class methods\n        (no ``settings`` argument); this is deliberate to ensure that\n        ``abspath`` is able to stand on its own as a cache key.\n\n        This method should either return a byte string or an iterator\n        of byte strings.  The latter is preferred for large files\n        as it helps reduce memory fragmentation.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        with open(abspath, \"rb\") as file:\n            if start is not None:\n                file.seek(start)\n            if end is not None:\n                remaining = end - (start or 0)  # type: Optional[int]\n            else:\n                remaining = None\n            while True:\n                chunk_size = 64 * 1024\n                if remaining is not None and remaining < chunk_size:\n                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Class StaticFileHandler method that streams byte content from a specified file path, optionally supporting partial reads via start and end byte positions. It facilitates efficient file content retrieval, especially for large files, by yielding data in chunks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_content_version", "line_number": 2823, "body": "def get_content_version(cls, abspath: str) -> str:\n        \"\"\"Returns a version string for the resource at the given path.\n\n        This class method may be overridden by subclasses.  The\n        default implementation is a SHA-512 hash of the file's contents.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        data = cls.get_content(abspath)\n        hasher = hashlib.sha512()\n        if isinstance(data, bytes):\n            hasher.update(data)\n        else:\n            for chunk in data:\n                hasher.update(chunk)\n        return hasher.hexdigest()", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides a version identifier for a file by returning a SHA-512 hash of its contents, allowing subclasses to override this method for custom versioning strategies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_stat", "line_number": 2840, "body": "def _stat(self) -> os.stat_result:\n        assert self.absolute_path is not None\n        if not hasattr(self, \"_stat_result\"):\n            self._stat_result = os.stat(self.absolute_path)\n        return self._stat_result", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Utility method of StaticFileHandler that retrieves and caches the file system status (metadata) of the associated static file for efficient repeated access."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_content_size", "line_number": 2846, "body": "def get_content_size(self) -> int:\n        \"\"\"Retrieve the total size of the resource at the given path.\n\n        This method may be overridden by subclasses.\n\n        .. versionadded:: 3.1\n\n        .. versionchanged:: 4.0\n           This method is now always called, instead of only when\n           partial results are requested.\n        \"\"\"\n        stat_result = self._stat()\n        return stat_result.st_size", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides the total size in bytes of the static file resource managed by StaticFileHandler, supporting file size retrieval for handling content delivery or validations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_modified_time", "line_number": 2860, "body": "def get_modified_time(self) -> Optional[datetime.datetime]:\n        \"\"\"Returns the time that ``self.absolute_path`` was last modified.\n\n        May be overridden in subclasses.  Should return a `~datetime.datetime`\n        object or None.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        stat_result = self._stat()\n        # NOTE: Historically, this used stat_result[stat.ST_MTIME],\n        # which truncates the fractional portion of the timestamp. It\n        # was changed from that form to stat_result.st_mtime to\n        # satisfy mypy (which disallows the bracket operator), but the\n        # latter form returns a float instead of an int. For\n        # consistency with the past (and because we have a unit test\n        # that relies on this), we truncate the float here, although\n        # I'm not sure that's the right thing to do.\n        modified = datetime.datetime.utcfromtimestamp(int(stat_result.st_mtime))\n        return modified", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides the last modification time of the file at the handler\u2019s path as a datetime object, supporting file change tracking or caching decisions in static file management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_content_type", "line_number": 2880, "body": "def get_content_type(self) -> str:\n        \"\"\"Returns the ``Content-Type`` header to be used for this request.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.absolute_path is not None\n        mime_type, encoding = mimetypes.guess_type(self.absolute_path)\n        # per RFC 6713, use the appropriate type for a gzip compressed file\n        if encoding == \"gzip\":\n            return \"application/gzip\"\n        # As of 2015-07-21 there is no bzip2 encoding defined at\n        # http://www.iana.org/assignments/media-types/media-types.xhtml\n        # So for that (and any other encoding), use octet-stream.\n        elif encoding is not None:\n            return \"application/octet-stream\"\n        elif mime_type is not None:\n            return mime_type\n        # if mime_type not detected, use application/octet-stream\n        else:\n            return \"application/octet-stream\"", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Determines the appropriate MIME Content-Type header based on a static file's path and encoding. This aids in correctly identifying file types for HTTP responses when serving static files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_cache_time", "line_number": 2905, "body": "def get_cache_time(\n        self, path: str, modified: Optional[datetime.datetime], mime_type: str\n    ) -> int:\n        \"\"\"Override to customize cache control behavior.\n\n        Return a positive number of seconds to make the result\n        cacheable for that amount of time or 0 to mark resource as\n        cacheable for an unspecified amount of time (subject to\n        browser heuristics).\n\n        By default returns cache expiry of 10 years for resources requested\n        with ``v`` argument.\n        \"\"\"\n        return self.CACHE_MAX_AGE if \"v\" in self.request.arguments else 0", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Provides a customizable cache duration for static files based on request parameters, enabling long-term caching for versioned resources and flexible cache control for others."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "make_static_url", "line_number": 2921, "body": "def make_static_url(\n        cls, settings: Dict[str, Any], path: str, include_version: bool = True\n    ) -> str:\n        \"\"\"Constructs a versioned url for the given path.\n\n        This method may be overridden in subclasses (but note that it\n        is a class method rather than an instance method).  Subclasses\n        are only required to implement the signature\n        ``make_static_url(cls, settings, path)``; other keyword\n        arguments may be passed through `~RequestHandler.static_url`\n        but are not standard.\n\n        ``settings`` is the `Application.settings` dictionary.  ``path``\n        is the static path being requested.  The url returned should be\n        relative to the current host.\n\n        ``include_version`` determines whether the generated URL should\n        include the query string containing the version hash of the\n        file corresponding to the given ``path``.\n\n        \"\"\"\n        url = settings.get(\"static_url_prefix\", \"/static/\") + path\n        if not include_version:\n            return url\n\n        version_hash = cls.get_version(settings, path)\n        if not version_hash:\n            return url\n\n        return \"%s?v=%s\" % (url, version_hash)", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Generates a URL for a static file, optionally appending a version query parameter for cache control. It supports customizable URL construction within application settings for consistent static resource referencing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "parse_url_path", "line_number": 2952, "body": "def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Converts a URL path segment from a static URL into a filesystem-compatible relative path, facilitating mapping between web paths and file storage in the StaticFileHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "get_version", "line_number": 2966, "body": "def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.\n        The returned value should be a string, or ``None`` if no version\n        could be determined.\n\n        .. versionchanged:: 3.1\n           This method was previously recommended for subclasses to override;\n           `get_content_version` is now preferred as it allows the base\n           class to handle caching of the result.\n        \"\"\"\n        abs_path = cls.get_absolute_path(settings[\"static_path\"], path)\n        return cls._get_cached_version(abs_path)", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Core method of StaticFileHandler that provides a version identifier for static file URLs based on file path and application settings, facilitating cache control and asset versioning in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_cached_version", "line_number": 2983, "body": "def _get_cached_version(cls, abs_path: str) -> Optional[str]:\n        with cls._lock:\n            hashes = cls._static_hashes\n            if abs_path not in hashes:\n                try:\n                    hashes[abs_path] = cls.get_content_version(abs_path)\n                except Exception:\n                    gen_log.error(\"Could not open static file %r\", abs_path)\n                    hashes[abs_path] = None\n            hsh = hashes.get(abs_path)\n            if hsh:\n                return hsh\n        return None", "is_method": true, "class_name": "StaticFileHandler", "function_description": "Utility method in StaticFileHandler that retrieves and caches a version identifier (e.g., a hash) for a given static file path, helping manage file versioning and cache efficiency."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "initialize", "line_number": 3015, "body": "def initialize(\n        self, fallback: Callable[[httputil.HTTPServerRequest], None]\n    ) -> None:\n        self.fallback = fallback", "is_method": true, "class_name": "FallbackHandler", "function_description": "Initializes the FallbackHandler with a fallback function to be called when no other handlers process an HTTP request. This allows customizable handling of unmatched requests within an HTTP server context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "prepare", "line_number": 3020, "body": "def prepare(self) -> None:\n        self.fallback(self.request)\n        self._finished = True\n        self.on_finish()", "is_method": true, "class_name": "FallbackHandler", "function_description": "Core method of FallbackHandler that executes a fallback process using the current request, marks the handling as complete, and triggers any finalization actions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "transform_first_chunk", "line_number": 3037, "body": "def transform_first_chunk(\n        self,\n        status_code: int,\n        headers: httputil.HTTPHeaders,\n        chunk: bytes,\n        finishing: bool,\n    ) -> Tuple[int, httputil.HTTPHeaders, bytes]:\n        return status_code, headers, chunk", "is_method": true, "class_name": "OutputTransform", "function_description": "Returns the initial HTTP response chunk unchanged, including status code and headers. This method provides a hook for optionally modifying the first chunk in output transformation processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "transform_chunk", "line_number": 3046, "body": "def transform_chunk(self, chunk: bytes, finishing: bool) -> bytes:\n        return chunk", "is_method": true, "class_name": "OutputTransform", "function_description": "Returns the input chunk unchanged, potentially as a placeholder for transforming output data in streaming or chunked processing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_compressible_type", "line_number": 3088, "body": "def _compressible_type(self, ctype: str) -> bool:\n        return ctype.startswith(\"text/\") or ctype in self.CONTENT_TYPES", "is_method": true, "class_name": "GZipContentEncoding", "function_description": "Determines if a content type is suitable for gzip compression by checking if it is a text type or belongs to predefined compressible content types. Useful for deciding when to apply gzip encoding in content delivery."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "transform_first_chunk", "line_number": 3091, "body": "def transform_first_chunk(\n        self,\n        status_code: int,\n        headers: httputil.HTTPHeaders,\n        chunk: bytes,\n        finishing: bool,\n    ) -> Tuple[int, httputil.HTTPHeaders, bytes]:\n        # TODO: can/should this type be inherited from the superclass?\n        if \"Vary\" in headers:\n            headers[\"Vary\"] += \", Accept-Encoding\"\n        else:\n            headers[\"Vary\"] = \"Accept-Encoding\"\n        if self._gzipping:\n            ctype = _unicode(headers.get(\"Content-Type\", \"\")).split(\";\")[0]\n            self._gzipping = (\n                self._compressible_type(ctype)\n                and (not finishing or len(chunk) >= self.MIN_LENGTH)\n                and (\"Content-Encoding\" not in headers)\n            )\n        if self._gzipping:\n            headers[\"Content-Encoding\"] = \"gzip\"\n            self._gzip_value = BytesIO()\n            self._gzip_file = gzip.GzipFile(\n                mode=\"w\", fileobj=self._gzip_value, compresslevel=self.GZIP_LEVEL\n            )\n            chunk = self.transform_chunk(chunk, finishing)\n            if \"Content-Length\" in headers:\n                # The original content length is no longer correct.\n                # If this is the last (and only) chunk, we can set the new\n                # content-length; otherwise we remove it and fall back to\n                # chunked encoding.\n                if finishing:\n                    headers[\"Content-Length\"] = str(len(chunk))\n                else:\n                    del headers[\"Content-Length\"]\n        return status_code, headers, chunk", "is_method": true, "class_name": "GZipContentEncoding", "function_description": "Method of GZipContentEncoding that modifies headers and compresses the first data chunk using gzip when appropriate, ensuring correct encoding and content length for HTTP responses. It facilitates transparent gzip compression based on content type and chunk size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "transform_chunk", "line_number": 3128, "body": "def transform_chunk(self, chunk: bytes, finishing: bool) -> bytes:\n        if self._gzipping:\n            self._gzip_file.write(chunk)\n            if finishing:\n                self._gzip_file.close()\n            else:\n                self._gzip_file.flush()\n            chunk = self._gzip_value.getvalue()\n            self._gzip_value.truncate(0)\n            self._gzip_value.seek(0)\n        return chunk", "is_method": true, "class_name": "GZipContentEncoding", "function_description": "Method of GZipContentEncoding class that compresses byte chunks using gzip, optionally finalizing the compression. It provides incremental gzip compression suitable for streaming or chunked data processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "wrapper", "line_number": 3156, "body": "def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urllib.parse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        assert self.request.uri is not None\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return None\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)", "is_method": false, "function_description": "Core method of the RequestHandler class that ensures user authentication by redirecting unauthenticated GET/HEAD requests to a login URL and raises a 403 error for other methods, enabling access control before proceeding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "current_user", "line_number": 3195, "body": "def current_user(self) -> Any:\n        return self.handler.current_user", "is_method": true, "class_name": "UIModule", "function_description": "Returns the current user associated with the UIModule's handler, enabling access to user-specific data or permissions within the UI context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "embedded_javascript", "line_number": 3202, "body": "def embedded_javascript(self) -> Optional[str]:\n        \"\"\"Override to return a JavaScript string\n        to be embedded in the page.\"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns a JavaScript string to embed in a UI page, if provided. Used to inject custom client-side scripts within the UIModule."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "javascript_files", "line_number": 3207, "body": "def javascript_files(self) -> Optional[Iterable[str]]:\n        \"\"\"Override to return a list of JavaScript files needed by this module.\n\n        If the return values are relative paths, they will be passed to\n        `RequestHandler.static_url`; otherwise they will be used as-is.\n        \"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns the list of JavaScript files required by the UI module for rendering or interaction, supporting both relative and absolute paths. This method aids in managing frontend dependencies specific to the module."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "embedded_css", "line_number": 3215, "body": "def embedded_css(self) -> Optional[str]:\n        \"\"\"Override to return a CSS string\n        that will be embedded in the page.\"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns a CSS string to be embedded in the page for customizing UI styles; by default, it provides no CSS. This allows subclasses to inject specific styling into the user interface."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "css_files", "line_number": 3220, "body": "def css_files(self) -> Optional[Iterable[str]]:\n        \"\"\"Override to returns a list of CSS files required by this module.\n\n        If the return values are relative paths, they will be passed to\n        `RequestHandler.static_url`; otherwise they will be used as-is.\n        \"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns a list of CSS files required by the UIModule for styling purposes, allowing integration with static resource handling. Returns None if no CSS files are needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "html_head", "line_number": 3228, "body": "def html_head(self) -> Optional[str]:\n        \"\"\"Override to return an HTML string that will be put in the <head/>\n        element.\n        \"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns custom HTML content to be inserted into the <head> section of a web page. Useful for adding metadata, styles, or scripts when extending the UIModule."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "html_body", "line_number": 3234, "body": "def html_body(self) -> Optional[str]:\n        \"\"\"Override to return an HTML string that will be put at the end of\n        the <body/> element.\n        \"\"\"\n        return None", "is_method": true, "class_name": "UIModule", "function_description": "Returns an optional HTML snippet to append at the end of the <body> element in a UI module, allowing customization of page content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render_string", "line_number": 3240, "body": "def render_string(self, path: str, **kwargs: Any) -> bytes:\n        \"\"\"Renders a template and returns it as a string.\"\"\"\n        return self.handler.render_string(path, **kwargs)", "is_method": true, "class_name": "UIModule", "function_description": "Utility method of UIModule that renders a specified template with given parameters and returns the resulting output as a byte string for further processing or display."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render", "line_number": 3246, "body": "def render(self, text: str, **kwargs: Any) -> str:  # type: ignore\n        return escape.linkify(text, **kwargs)", "is_method": true, "class_name": "_linkify", "function_description": "Utility method of the _linkify class that converts plain text URLs into clickable HTML links, supporting additional customization through keyword arguments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render", "line_number": 3251, "body": "def render(self) -> str:  # type: ignore\n        return self.handler.xsrf_form_html()", "is_method": true, "class_name": "_xsrf_form_html", "function_description": "Returns the HTML string for an XSRF protection form, enabling secure embedding of cross-site request forgery tokens in web forms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render", "line_number": 3277, "body": "def render(self, path: str, **kwargs: Any) -> bytes:  # type: ignore\n        def set_resources(**kwargs) -> str:  # type: ignore\n            if path not in self._resource_dict:\n                self._resource_list.append(kwargs)\n                self._resource_dict[path] = kwargs\n            else:\n                if self._resource_dict[path] != kwargs:\n                    raise ValueError(\n                        \"set_resources called with different \"\n                        \"resources for the same template\"\n                    )\n            return \"\"\n\n        return self.render_string(path, set_resources=set_resources, **kwargs)", "is_method": true, "class_name": "TemplateModule", "function_description": "Provides rendering of a template identified by a path with dynamic resources, ensuring consistent resource assignment per template during the rendering process. It supports injecting resources while preventing conflicting resource definitions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_get_resources", "line_number": 3292, "body": "def _get_resources(self, key: str) -> Iterable[str]:\n        return (r[key] for r in self._resource_list if key in r)", "is_method": true, "class_name": "TemplateModule", "function_description": "Internal utility of TemplateModule that yields values associated with a given key from a collection of resource dictionaries. It facilitates retrieving specific resource attributes when iterating over stored resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "embedded_javascript", "line_number": 3295, "body": "def embedded_javascript(self) -> str:\n        return \"\\n\".join(self._get_resources(\"embedded_javascript\"))", "is_method": true, "class_name": "TemplateModule", "function_description": "Returns a combined string of all embedded JavaScript resources associated with the TemplateModule, facilitating the inclusion of necessary scripts within templates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "javascript_files", "line_number": 3298, "body": "def javascript_files(self) -> Iterable[str]:\n        result = []\n        for f in self._get_resources(\"javascript_files\"):\n            if isinstance(f, (unicode_type, bytes)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result", "is_method": true, "class_name": "TemplateModule", "function_description": "Provides an iterable list of JavaScript file paths or names associated with the TemplateModule, handling both single and multiple resource entries uniformly for resource management purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "embedded_css", "line_number": 3307, "body": "def embedded_css(self) -> str:\n        return \"\\n\".join(self._get_resources(\"embedded_css\"))", "is_method": true, "class_name": "TemplateModule", "function_description": "Utility method of the TemplateModule class that collects and returns all embedded CSS resources as a single concatenated string. It provides convenient access to CSS content for rendering or further processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "css_files", "line_number": 3310, "body": "def css_files(self) -> Iterable[str]:\n        result = []\n        for f in self._get_resources(\"css_files\"):\n            if isinstance(f, (unicode_type, bytes)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result", "is_method": true, "class_name": "TemplateModule", "function_description": "Utility method in TemplateModule that retrieves and flattens the list of CSS resource files associated with the template, providing all relevant CSS file paths for use in rendering or resource management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "html_head", "line_number": 3319, "body": "def html_head(self) -> str:\n        return \"\".join(self._get_resources(\"html_head\"))", "is_method": true, "class_name": "TemplateModule", "function_description": "Returns the combined HTML head resources defined in the template, providing necessary metadata and links for rendering web pages within the TemplateModule."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "html_body", "line_number": 3322, "body": "def html_body(self) -> str:\n        return \"\".join(self._get_resources(\"html_body\"))", "is_method": true, "class_name": "TemplateModule", "function_description": "Returns the combined HTML content of the template's body by aggregating related resource elements. This method provides the main HTML structure for rendering the template."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "__getitem__", "line_number": 3335, "body": "def __getitem__(self, key: str) -> Callable[..., str]:\n        return self.handler._ui_module(key, self.ui_modules[key])", "is_method": true, "class_name": "_UIModuleNamespace", "function_description": "This function provides access to UI module handlers by key, returning a callable that generates UI components. It enables dynamic retrieval and invocation of UI modules within the _UIModuleNamespace."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "__getattr__", "line_number": 3338, "body": "def __getattr__(self, key: str) -> Callable[..., str]:\n        try:\n            return self[key]\n        except KeyError as e:\n            raise AttributeError(str(e))", "is_method": true, "class_name": "_UIModuleNamespace", "function_description": "Utility method in _UIModuleNamespace that enables attribute-style access to its items, raising an AttributeError if the requested key does not exist."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "_consume_field", "line_number": 3502, "body": "def _consume_field(s: bytes) -> Tuple[bytes, bytes]:\n        length, _, rest = s.partition(b\":\")\n        n = int(length)\n        field_value = rest[:n]\n        # In python 3, indexing bytes returns small integers; we must\n        # use a slice to get a byte string as in python 2.\n        if rest[n : n + 1] != b\"|\":\n            raise ValueError(\"malformed v2 signed value field\")\n        rest = rest[n + 1 :]\n        return field_value, rest", "is_method": false, "function_description": "Private utility function that extracts a length-prefixed field and the remaining bytes from a byte string, useful for parsing structured binary or encoded data formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "render", "line_number": 1797, "body": "def render(*args, **kwargs) -> str:  # type: ignore\n            if not hasattr(self, \"_active_modules\"):\n                self._active_modules = {}  # type: Dict[str, UIModule]\n            if name not in self._active_modules:\n                self._active_modules[name] = module(self)\n            rendered = self._active_modules[name].render(*args, **kwargs)\n            return rendered", "is_method": true, "class_name": "RequestHandler", "function_description": "Core method of RequestHandler that manages and renders UI modules, caching instances to avoid re-initialization and returning their rendered output for dynamic user interface generation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "set_resources", "line_number": 3278, "body": "def set_resources(**kwargs) -> str:  # type: ignore\n            if path not in self._resource_dict:\n                self._resource_list.append(kwargs)\n                self._resource_dict[path] = kwargs\n            else:\n                if self._resource_dict[path] != kwargs:\n                    raise ValueError(\n                        \"set_resources called with different \"\n                        \"resources for the same template\"\n                    )\n            return \"\"", "is_method": true, "class_name": "TemplateModule", "function_description": "Manages and stores resource configurations for templates, ensuring each template path has consistent associated resources. It prevents conflicting resource updates for the same template."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "val", "line_number": 1651, "body": "def val(x: bytes) -> bytes:\n                return x[2:] if x.startswith(b\"W/\") else x", "is_method": true, "class_name": "RequestHandler", "function_description": "Utility method in RequestHandler that normalizes byte strings by removing a weak validator prefix if present, facilitating consistent HTTP header value handling in request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/web.py", "function": "format_field", "line_number": 3380, "body": "def format_field(s: Union[str, bytes]) -> bytes:\n            return utf8(\"%d:\" % len(s)) + utf8(s)", "is_method": false, "function_description": "This function encodes a string or bytes value by prefixing it with its length followed by a colon, then returns the result as bytes. It is useful for preparing length-prefixed data for transmission or storage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_raise_not_supported_for_websockets", "line_number": 624, "body": "def _raise_not_supported_for_websockets(*args: Any, **kwargs: Any) -> None:\n    raise RuntimeError(\"Method not supported for Web Sockets\")", "is_method": false, "function_description": "Utility function that explicitly raises an error when a method is called in an unsupported context, specifically for Web Socket operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "websocket_connect", "line_number": 1589, "body": "def websocket_connect(\n    url: Union[str, httpclient.HTTPRequest],\n    callback: Optional[Callable[[\"Future[WebSocketClientConnection]\"], None]] = None,\n    connect_timeout: Optional[float] = None,\n    on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n    compression_options: Optional[Dict[str, Any]] = None,\n    ping_interval: Optional[float] = None,\n    ping_timeout: Optional[float] = None,\n    max_message_size: int = _default_max_message_size,\n    subprotocols: Optional[List[str]] = None,\n) -> \"Awaitable[WebSocketClientConnection]\":\n    \"\"\"Client-side websocket support.\n\n    Takes a url and returns a Future whose result is a\n    `WebSocketClientConnection`.\n\n    ``compression_options`` is interpreted in the same way as the\n    return value of `.WebSocketHandler.get_compression_options`.\n\n    The connection supports two styles of operation. In the coroutine\n    style, the application typically calls\n    `~.WebSocketClientConnection.read_message` in a loop::\n\n        conn = yield websocket_connect(url)\n        while True:\n            msg = yield conn.read_message()\n            if msg is None: break\n            # Do something with msg\n\n    In the callback style, pass an ``on_message_callback`` to\n    ``websocket_connect``. In both styles, a message of ``None``\n    indicates that the connection has been closed.\n\n    ``subprotocols`` may be a list of strings specifying proposed\n    subprotocols. The selected protocol may be found on the\n    ``selected_subprotocol`` attribute of the connection object\n    when the connection is complete.\n\n    .. versionchanged:: 3.2\n       Also accepts ``HTTPRequest`` objects in place of urls.\n\n    .. versionchanged:: 4.1\n       Added ``compression_options`` and ``on_message_callback``.\n\n    .. versionchanged:: 4.5\n       Added the ``ping_interval``, ``ping_timeout``, and ``max_message_size``\n       arguments, which have the same meaning as in `WebSocketHandler`.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.1\n       Added the ``subprotocols`` argument.\n    \"\"\"\n    if isinstance(url, httpclient.HTTPRequest):\n        assert connect_timeout is None\n        request = url\n        # Copy and convert the headers dict/object (see comments in\n        # AsyncHTTPClient.fetch)\n        request.headers = httputil.HTTPHeaders(request.headers)\n    else:\n        request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)\n    request = cast(\n        httpclient.HTTPRequest,\n        httpclient._RequestProxy(request, httpclient.HTTPRequest._DEFAULTS),\n    )\n    conn = WebSocketClientConnection(\n        request,\n        on_message_callback=on_message_callback,\n        compression_options=compression_options,\n        ping_interval=ping_interval,\n        ping_timeout=ping_timeout,\n        max_message_size=max_message_size,\n        subprotocols=subprotocols,\n    )\n    if callback is not None:\n        IOLoop.current().add_future(conn.connect_future, callback)\n    return conn.connect_future", "is_method": false, "function_description": "Function that initiates a client-side WebSocket connection to a given URL, returning a future for the connection object and supporting both coroutine and callback styles with options for message handling, compression, ping settings, and subprotocol negotiation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping_interval", "line_number": 284, "body": "def ping_interval(self) -> Optional[float]:\n        \"\"\"The interval for websocket keep-alive pings.\n\n        Set websocket_ping_interval = 0 to disable pings.\n        \"\"\"\n        return self.settings.get(\"websocket_ping_interval\", None)", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides the configured interval for sending WebSocket keep-alive pings, enabling connection health checks or disabling pings if set to zero."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping_timeout", "line_number": 292, "body": "def ping_timeout(self) -> Optional[float]:\n        \"\"\"If no ping is received in this many seconds,\n        close the websocket connection (VPNs, etc. can fail to cleanly close ws connections).\n        Default is max of 3 pings or 30 seconds.\n        \"\"\"\n        return self.settings.get(\"websocket_ping_timeout\", None)", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Returns the configured timeout duration for closing a WebSocket connection if no ping is received, helping to detect and handle stale or dropped connections automatically."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "max_message_size", "line_number": 300, "body": "def max_message_size(self) -> int:\n        \"\"\"Maximum allowed message size.\n\n        If the remote peer sends a message larger than this, the connection\n        will be closed.\n\n        Default is 10MiB.\n        \"\"\"\n        return self.settings.get(\n            \"websocket_max_message_size\", _default_max_message_size\n        )", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides the maximum permitted size for incoming WebSocket messages, ensuring connections are closed if messages exceed this limit to maintain stability and security."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "write_message", "line_number": 312, "body": "def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.\n\n        If the connection is already closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 3.2\n           `WebSocketClosedError` was added (previously a closed connection\n           would raise an `AttributeError`)\n\n        .. versionchanged:: 4.3\n           Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 5.0\n           Consistently raises `WebSocketClosedError`. Previously could\n           sometimes raise `.StreamClosedError`.\n        \"\"\"\n        if self.ws_connection is None or self.ws_connection.is_closing():\n            raise WebSocketClosedError()\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        return self.ws_connection.write_message(message, binary=binary)", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Sends a text, binary, or JSON-encoded message to a WebSocket client, providing asynchronous flow control and enforcing errors on closed connections. It supports flexible message formats for real-time web communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "select_subprotocol", "line_number": 342, "body": "def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n        \"\"\"Override to implement subprotocol negotiation.\n\n        ``subprotocols`` is a list of strings identifying the\n        subprotocols proposed by the client.  This method may be\n        overridden to return one of those strings to select it, or\n        ``None`` to not select a subprotocol.\n\n        Failure to select a subprotocol does not automatically abort\n        the connection, although clients may close the connection if\n        none of their proposed subprotocols was selected.\n\n        The list may be empty, in which case this method must return\n        None. This method is always called exactly once even if no\n        subprotocols were proposed so that the handler can be advised\n        of this fact.\n\n        .. versionchanged:: 5.1\n\n           Previously, this method was called with a list containing\n           an empty string instead of an empty list if no subprotocols\n           were proposed by the client.\n        \"\"\"\n        return None", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides a hook to select a WebSocket subprotocol from the client's proposals during handshake, facilitating protocol negotiation or returning None to accept no subprotocol. Useful for customizing supported WebSocket extensions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "selected_subprotocol", "line_number": 368, "body": "def selected_subprotocol(self) -> Optional[str]:\n        \"\"\"The subprotocol returned by `select_subprotocol`.\n\n        .. versionadded:: 5.1\n        \"\"\"\n        assert self.ws_connection is not None\n        return self.ws_connection.selected_subprotocol", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Method in WebSocketHandler that returns the subprotocol agreed upon during the WebSocket handshake, enabling communication using that specific subprotocol if one was selected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "get_compression_options", "line_number": 376, "body": "def get_compression_options(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Override to return compression options for the connection.\n\n        If this method returns None (the default), compression will\n        be disabled.  If it returns a dict (even an empty one), it\n        will be enabled.  The contents of the dict may be used to\n        control the following compression options:\n\n        ``compression_level`` specifies the compression level.\n\n        ``mem_level`` specifies the amount of memory used for the internal compression state.\n\n         These parameters are documented in details here:\n         https://docs.python.org/3.6/library/zlib.html#zlib.compressobj\n\n        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides optional compression settings for WebSocket connections, enabling or disabling data compression and specifying compression parameters to optimize network performance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping", "line_number": 427, "body": "def ping(self, data: Union[str, bytes] = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``websocket_ping_interval`` application\n        setting instead of sending pings manually.\n\n        .. versionchanged:: 5.1\n\n           The data argument is now optional.\n\n        \"\"\"\n        data = utf8(data)\n        if self.ws_connection is None or self.ws_connection.is_closing():\n            raise WebSocketClosedError()\n        self.ws_connection.write_ping(data)", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides the capability to send a ping frame with optional data over an active WebSocket connection, enabling connection health checks and keep-alive signaling to the remote endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "close", "line_number": 469, "body": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes this Web Socket.\n\n        Once the close handshake is successful the socket will be closed.\n\n        ``code`` may be a numeric status code, taken from the values\n        defined in `RFC 6455 section 7.4.1\n        <https://tools.ietf.org/html/rfc6455#section-7.4.1>`_.\n        ``reason`` may be a textual message about why the connection is\n        closing.  These values are made available to the client, but are\n        not otherwise interpreted by the websocket protocol.\n\n        .. versionchanged:: 4.0\n\n           Added the ``code`` and ``reason`` arguments.\n        \"\"\"\n        if self.ws_connection:\n            self.ws_connection.close(code, reason)\n            self.ws_connection = None", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides a method to gracefully close a WebSocket connection, optionally specifying a status code and reason to inform the client about the closure cause. Useful for managing WebSocket lifecycles and clean disconnects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "check_origin", "line_number": 489, "body": "def check_origin(self, origin: str) -> bool:\n        \"\"\"Override to enable support for allowing alternate origins.\n\n        The ``origin`` argument is the value of the ``Origin`` HTTP\n        header, the url responsible for initiating this request.  This\n        method is not called for clients that do not send this header;\n        such requests are always allowed (because all browsers that\n        implement WebSockets support this header, and non-browser\n        clients do not have the same cross-site security concerns).\n\n        Should return ``True`` to accept the request or ``False`` to\n        reject it. By default, rejects all requests with an origin on\n        a host other than this one.\n\n        This is a security protection against cross site scripting attacks on\n        browsers, since WebSockets are allowed to bypass the usual same-origin\n        policies and don't use CORS headers.\n\n        .. warning::\n\n           This is an important security measure; don't disable it\n           without understanding the security implications. In\n           particular, if your authentication is cookie-based, you\n           must either restrict the origins allowed by\n           ``check_origin()`` or implement your own XSRF-like\n           protection for websocket connections. See `these\n           <https://www.christian-schneider.net/CrossSiteWebSocketHijacking.html>`_\n           `articles\n           <https://devcenter.heroku.com/articles/websocket-security>`_\n           for more.\n\n        To accept all cross-origin traffic (which was the default prior to\n        Tornado 4.0), simply override this method to always return ``True``::\n\n            def check_origin(self, origin):\n                return True\n\n        To allow connections from any subdomain of your site, you might\n        do something like::\n\n            def check_origin(self, origin):\n                parsed_origin = urllib.parse.urlparse(origin)\n                return parsed_origin.netloc.endswith(\".mydomain.com\")\n\n        .. versionadded:: 4.0\n\n        \"\"\"\n        parsed_origin = urlparse(origin)\n        origin = parsed_origin.netloc\n        origin = origin.lower()\n\n        host = self.request.headers.get(\"Host\")\n\n        # Check to see that origin matches host directly, including ports\n        return origin == host", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides a customizable security check for WebSocket connection origins, allowing acceptance or rejection of requests based on their Origin header to prevent cross-site WebSocket hijacking attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "set_nodelay", "line_number": 545, "body": "def set_nodelay(self, value: bool) -> None:\n        \"\"\"Set the no-delay flag for this stream.\n\n        By default, small messages may be delayed and/or combined to minimize\n        the number of packets sent.  This can sometimes cause 200-500ms delays\n        due to the interaction between Nagle's algorithm and TCP delayed\n        ACKs.  To reduce this delay (at the expense of possibly increasing\n        bandwidth usage), call ``self.set_nodelay(True)`` once the websocket\n        connection is established.\n\n        See `.BaseIOStream.set_nodelay` for additional details.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.ws_connection is not None\n        self.ws_connection.set_nodelay(value)", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Enables or disables TCP no-delay for the WebSocket connection to reduce latency by preventing packet buffering and delays caused by Nagle's algorithm, improving real-time message transmission performance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_connection_close", "line_number": 562, "body": "def on_connection_close(self) -> None:\n        if self.ws_connection:\n            self.ws_connection.on_connection_close()\n            self.ws_connection = None\n        if not self._on_close_called:\n            self._on_close_called = True\n            self.on_close()\n            self._break_cycles()", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Handles the closure of a WebSocket connection by cleaning up resources, invoking close callbacks, and preventing repeated closure actions to ensure proper connection shutdown."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_ws_connection_close", "line_number": 571, "body": "def on_ws_connection_close(\n        self, close_code: Optional[int] = None, close_reason: Optional[str] = None\n    ) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        self.on_connection_close()", "is_method": true, "class_name": "WebSocketHandler", "function_description": "This method handles WebSocket connection closures by recording the close code and reason, then triggering any additional cleanup or notification logic. It provides a standardized way to manage connection termination events."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_break_cycles", "line_number": 578, "body": "def _break_cycles(self) -> None:\n        # WebSocketHandlers call finish() early, but we don't want to\n        # break up reference cycles (which makes it impossible to call\n        # self.render_string) until after we've really closed the\n        # connection (if it was established in the first place,\n        # indicated by status code 101).\n        if self.get_status() != 101 or self._on_close_called:\n            super()._break_cycles()", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Private method of WebSocketHandler that safely breaks reference cycles only after the WebSocket connection is fully closed, preventing premature cleanup that would hinder further response rendering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "send_error", "line_number": 587, "body": "def send_error(self, *args: Any, **kwargs: Any) -> None:\n        if self.stream is None:\n            super().send_error(*args, **kwargs)\n        else:\n            # If we get an uncaught exception during the handshake,\n            # we have no choice but to abruptly close the connection.\n            # TODO: for uncaught exceptions after the handshake,\n            # we can close the connection more gracefully.\n            self.stream.close()", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Handles sending error responses in a WebSocket connection, closing the connection immediately if an error occurs during the handshake phase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "get_websocket_protocol", "line_number": 597, "body": "def get_websocket_protocol(self) -> Optional[\"WebSocketProtocol\"]:\n        websocket_version = self.request.headers.get(\"Sec-WebSocket-Version\")\n        if websocket_version in (\"7\", \"8\", \"13\"):\n            params = _WebSocketParams(\n                ping_interval=self.ping_interval,\n                ping_timeout=self.ping_timeout,\n                max_message_size=self.max_message_size,\n                compression_options=self.get_compression_options(),\n            )\n            return WebSocketProtocol13(self, False, params)\n        return None", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Provides the appropriate WebSocket protocol instance based on the request's WebSocket version, enabling protocol-specific handling within the WebSocketHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_detach_stream", "line_number": 609, "body": "def _detach_stream(self) -> IOStream:\n        # disable non-WS methods\n        for method in [\n            \"write\",\n            \"redirect\",\n            \"set_header\",\n            \"set_cookie\",\n            \"set_status\",\n            \"flush\",\n            \"finish\",\n        ]:\n            setattr(self, method, _raise_not_supported_for_websockets)\n        return self.detach()", "is_method": true, "class_name": "WebSocketHandler", "function_description": "Core method in WebSocketHandler that disables HTTP-specific operations and detaches the underlying stream to provide direct access for WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_run_callback", "line_number": 638, "body": "def _run_callback(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> \"Optional[Future[Any]]\":\n        \"\"\"Runs the given callback with exception handling.\n\n        If the callback is a coroutine, returns its Future. On error, aborts the\n        websocket connection and returns None.\n        \"\"\"\n        try:\n            result = callback(*args, **kwargs)\n        except Exception:\n            self.handler.log_exception(*sys.exc_info())\n            self._abort()\n            return None\n        else:\n            if result is not None:\n                result = gen.convert_yielded(result)\n                assert self.stream is not None\n                self.stream.io_loop.add_future(result, lambda f: f.result())\n            return result", "is_method": true, "class_name": "WebSocketProtocol", "function_description": "Utility method in WebSocketProtocol that safely executes a callback, handling exceptions by aborting the connection and returning a Future for coroutine callbacks to manage asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_connection_close", "line_number": 659, "body": "def on_connection_close(self) -> None:\n        self._abort()", "is_method": true, "class_name": "WebSocketProtocol", "function_description": "Terminates the WebSocket connection by aborting ongoing processes when the connection is closed. It provides a cleanup mechanism to ensure proper shutdown of the WebSocket session."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_abort", "line_number": 662, "body": "def _abort(self) -> None:\n        \"\"\"Instantly aborts the WebSocket connection by closing the socket\"\"\"\n        self.client_terminated = True\n        self.server_terminated = True\n        if self.stream is not None:\n            self.stream.close()  # forcibly tear down the connection\n        self.close()", "is_method": true, "class_name": "WebSocketProtocol", "function_description": "Internal method of WebSocketProtocol that immediately terminates the WebSocket connection by forcefully closing the underlying socket and marking both client and server as terminated."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_create_compressor", "line_number": 756, "body": "def _create_compressor(self) -> \"_Compressor\":\n        return zlib.compressobj(\n            self._compression_level, zlib.DEFLATED, -self._max_wbits, self._mem_level\n        )", "is_method": true, "class_name": "_PerMessageDeflateCompressor", "function_description": "Internal helper method in _PerMessageDeflateCompressor that initializes and returns a configured zlib compressor object for data compression with specified compression settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "compress", "line_number": 761, "body": "def compress(self, data: bytes) -> bytes:\n        compressor = self._compressor or self._create_compressor()\n        data = compressor.compress(data) + compressor.flush(zlib.Z_SYNC_FLUSH)\n        assert data.endswith(b\"\\x00\\x00\\xff\\xff\")\n        return data[:-4]", "is_method": true, "class_name": "_PerMessageDeflateCompressor", "function_description": "Core method of _PerMessageDeflateCompressor that compresses binary data using a zlib-based deflate algorithm optimized for messaging, ensuring compatibility with WebSocket per-message compression standards."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_create_decompressor", "line_number": 793, "body": "def _create_decompressor(self) -> \"_Decompressor\":\n        return zlib.decompressobj(-self._max_wbits)", "is_method": true, "class_name": "_PerMessageDeflateDecompressor", "function_description": "Creates and returns a zlib decompression object configured with specific parameters. This function supports decompression of messages within the _PerMessageDeflateDecompressor class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "decompress", "line_number": 796, "body": "def decompress(self, data: bytes) -> bytes:\n        decompressor = self._decompressor or self._create_decompressor()\n        result = decompressor.decompress(\n            data + b\"\\x00\\x00\\xff\\xff\", self._max_message_size\n        )\n        if decompressor.unconsumed_tail:\n            raise _DecompressTooLargeError()\n        return result", "is_method": true, "class_name": "_PerMessageDeflateDecompressor", "function_description": "Core method of _PerMessageDeflateDecompressor that decompresses a byte stream using a configured decompressor, enforcing message size limits and signaling when decompressed data exceeds allowed size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "selected_subprotocol", "line_number": 861, "body": "def selected_subprotocol(self) -> Optional[str]:\n        return self._selected_subprotocol", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Returns the subprotocol selected during the WebSocket handshake, if any. This allows users to identify which subprotocol is active for the connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "selected_subprotocol", "line_number": 865, "body": "def selected_subprotocol(self, value: Optional[str]) -> None:\n        self._selected_subprotocol = value", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Setter method in WebSocketProtocol13 that assigns the selected WebSocket subprotocol for the current connection. It allows other parts of the system to specify which subprotocol should be used."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_handle_websocket_headers", "line_number": 888, "body": "def _handle_websocket_headers(self, handler: WebSocketHandler) -> None:\n        \"\"\"Verifies all invariant- and required headers\n\n        If a header is missing or have an incorrect value ValueError will be\n        raised\n        \"\"\"\n        fields = (\"Host\", \"Sec-Websocket-Key\", \"Sec-Websocket-Version\")\n        if not all(map(lambda f: handler.request.headers.get(f), fields)):\n            raise ValueError(\"Missing/Invalid WebSocket headers\")", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Ensures all mandatory WebSocket headers are present and valid during connection setup, raising an error if any are missing or incorrect. This validation supports compliant WebSocket handshake processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "compute_accept_value", "line_number": 899, "body": "def compute_accept_value(key: Union[str, bytes]) -> str:\n        \"\"\"Computes the value for the Sec-WebSocket-Accept header,\n        given the value for Sec-WebSocket-Key.\n        \"\"\"\n        sha1 = hashlib.sha1()\n        sha1.update(utf8(key))\n        sha1.update(b\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\")  # Magic value\n        return native_str(base64.b64encode(sha1.digest()))", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Generates the Sec-WebSocket-Accept header value required to complete a WebSocket handshake based on the client's Sec-WebSocket-Key. Essential for validating and establishing a WebSocket connection in compliance with RFC 6455."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_challenge_response", "line_number": 908, "body": "def _challenge_response(self, handler: WebSocketHandler) -> str:\n        return WebSocketProtocol13.compute_accept_value(\n            cast(str, handler.request.headers.get(\"Sec-Websocket-Key\"))\n        )", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Generates the WebSocket handshake response value based on the client's key header, facilitating the protocol's connection establishment process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_parse_extensions_header", "line_number": 964, "body": "def _parse_extensions_header(\n        self, headers: httputil.HTTPHeaders\n    ) -> List[Tuple[str, Dict[str, str]]]:\n        extensions = headers.get(\"Sec-WebSocket-Extensions\", \"\")\n        if extensions:\n            return [httputil._parse_header(e.strip()) for e in extensions.split(\",\")]\n        return []", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Internal method of WebSocketProtocol13 that parses the \"Sec-WebSocket-Extensions\" header, extracting and returning a list of WebSocket extension names with their parameters for use in connection negotiation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_process_server_headers", "line_number": 972, "body": "def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        \"\"\"Process the headers sent by the server to this client connection.\n\n        'key' is the websocket handshake challenge/response key.\n        \"\"\"\n        assert headers[\"Upgrade\"].lower() == \"websocket\"\n        assert headers[\"Connection\"].lower() == \"upgrade\"\n        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n\n        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Handles and validates server handshake headers during a WebSocket client connection, ensuring protocol compliance, negotiating extensions like permessage-deflate compression, and selecting the agreed subprotocol."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_get_compressor_options", "line_number": 993, "body": "def _get_compressor_options(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n        for our compressor objects.\n        \"\"\"\n        options = dict(\n            persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n        )  # type: Dict[str, Any]\n        wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n        if wbits_header is None:\n            options[\"max_wbits\"] = zlib.MAX_WBITS\n        else:\n            options[\"max_wbits\"] = int(wbits_header)\n        options[\"compression_options\"] = compression_options\n        return options", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Utility method of WebSocketProtocol13 that translates agreed websocket extension parameters into configuration options for compressor objects, enabling appropriate compression behavior for a given connection side."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_create_compressors", "line_number": 1013, "body": "def _create_compressors(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        # TODO: handle invalid parameters gracefully\n        allowed_keys = set(\n            [\n                \"server_no_context_takeover\",\n                \"client_no_context_takeover\",\n                \"server_max_window_bits\",\n                \"client_max_window_bits\",\n            ]\n        )\n        for key in agreed_parameters:\n            if key not in allowed_keys:\n                raise ValueError(\"unsupported compression parameter %r\" % key)\n        other_side = \"client\" if (side == \"server\") else \"server\"\n        self._compressor = _PerMessageDeflateCompressor(\n            **self._get_compressor_options(side, agreed_parameters, compression_options)\n        )\n        self._decompressor = _PerMessageDeflateDecompressor(\n            max_message_size=self.params.max_message_size,\n            **self._get_compressor_options(\n                other_side, agreed_parameters, compression_options\n            )\n        )", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Sets up compression and decompression objects using agreed parameters to enable per-message deflate compression in WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_write_frame", "line_number": 1042, "body": "def _write_frame(\n        self, fin: bool, opcode: int, data: bytes, flags: int = 0\n    ) -> \"Future[None]\":\n        data_len = len(data)\n        if opcode & 0x8:\n            # All control frames MUST have a payload length of 125\n            # bytes or less and MUST NOT be fragmented.\n            if not fin:\n                raise ValueError(\"control frames may not be fragmented\")\n            if data_len > 125:\n                raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n        if fin:\n            finbit = self.FIN\n        else:\n            finbit = 0\n        frame = struct.pack(\"B\", finbit | opcode | flags)\n        if self.mask_outgoing:\n            mask_bit = 0x80\n        else:\n            mask_bit = 0\n        if data_len < 126:\n            frame += struct.pack(\"B\", data_len | mask_bit)\n        elif data_len <= 0xFFFF:\n            frame += struct.pack(\"!BH\", 126 | mask_bit, data_len)\n        else:\n            frame += struct.pack(\"!BQ\", 127 | mask_bit, data_len)\n        if self.mask_outgoing:\n            mask = os.urandom(4)\n            data = mask + _websocket_mask(mask, data)\n        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Constructs and sends a properly formatted WebSocket frame with given parameters, handling masking, fragmentation rules, and payload length encoding to transmit data over the WebSocket connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "write_message", "line_number": 1075, "body": "def write_message(\n        self, message: Union[str, bytes], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        # For historical reasons, write methods in Tornado operate in a semi-synchronous\n        # mode in which awaiting the Future they return is optional (But errors can\n        # still be raised). This requires us to go through an awkward dance here\n        # to transform the errors that may be returned while presenting the same\n        # semi-synchronous interface.\n        try:\n            fut = self._write_frame(True, opcode, message, flags=flags)\n        except StreamClosedError:\n            raise WebSocketClosedError()\n\n        async def wrapper() -> None:\n            try:\n                await fut\n            except StreamClosedError:\n                raise WebSocketClosedError()\n\n        return asyncio.ensure_future(wrapper())", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Sends a text or binary message asynchronously to the client over the WebSocket connection, handling optional compression and stream closure errors. This enables communication through the WebSocketProtocol13 instance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "write_ping", "line_number": 1108, "body": "def write_ping(self, data: bytes) -> None:\n        \"\"\"Send ping frame.\"\"\"\n        assert isinstance(data, bytes)\n        self._write_frame(True, 0x9, data)", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Sends a WebSocket ping frame containing the specified binary data to check connection health and keep the connection alive. This method facilitates heartbeat signaling in WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_handle_message", "line_number": 1209, "body": "def _handle_message(self, opcode: int, data: bytes) -> \"Optional[Future[None]]\":\n        \"\"\"Execute on_message, returning its Future if it is a coroutine.\"\"\"\n        if self.client_terminated:\n            return None\n\n        if self._frame_compressed:\n            assert self._decompressor is not None\n            try:\n                data = self._decompressor.decompress(data)\n            except _DecompressTooLargeError:\n                self.close(1009, \"message too big after decompression\")\n                self._abort()\n                return None\n\n        if opcode == 0x1:\n            # UTF-8 data\n            self._message_bytes_in += len(data)\n            try:\n                decoded = data.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                self._abort()\n                return None\n            return self._run_callback(self.handler.on_message, decoded)\n        elif opcode == 0x2:\n            # Binary data\n            self._message_bytes_in += len(data)\n            return self._run_callback(self.handler.on_message, data)\n        elif opcode == 0x8:\n            # Close\n            self.client_terminated = True\n            if len(data) >= 2:\n                self.close_code = struct.unpack(\">H\", data[:2])[0]\n            if len(data) > 2:\n                self.close_reason = to_unicode(data[2:])\n            # Echo the received close code, if any (RFC 6455 section 5.5.1).\n            self.close(self.close_code)\n        elif opcode == 0x9:\n            # Ping\n            try:\n                self._write_frame(True, 0xA, data)\n            except StreamClosedError:\n                self._abort()\n            self._run_callback(self.handler.on_ping, data)\n        elif opcode == 0xA:\n            # Pong\n            self.last_pong = IOLoop.current().time()\n            return self._run_callback(self.handler.on_pong, data)\n        else:\n            self._abort()\n        return None", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Handles incoming WebSocket frames by processing messages based on their type (text, binary, close, ping, pong), invoking corresponding callbacks, managing connection state, and handling decompression and errors appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "close", "line_number": 1260, "body": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes the WebSocket connection.\"\"\"\n        if not self.server_terminated:\n            if not self.stream.closed():\n                if code is None and reason is not None:\n                    code = 1000  # \"normal closure\" status code\n                if code is None:\n                    close_data = b\"\"\n                else:\n                    close_data = struct.pack(\">H\", code)\n                if reason is not None:\n                    close_data += utf8(reason)\n                try:\n                    self._write_frame(True, 0x8, close_data)\n                except StreamClosedError:\n                    self._abort()\n            self.server_terminated = True\n        if self.client_terminated:\n            if self._waiting is not None:\n                self.stream.io_loop.remove_timeout(self._waiting)\n                self._waiting = None\n            self.stream.close()\n        elif self._waiting is None:\n            # Give the client a few seconds to complete a clean shutdown,\n            # otherwise just close the connection.\n            self._waiting = self.stream.io_loop.add_timeout(\n                self.stream.io_loop.time() + 5, self._abort\n            )\n        if self.ping_callback:\n            self.ping_callback.stop()\n            self.ping_callback = None", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Handles the orderly closure of a WebSocket connection, sending optional status codes and reasons, managing timeouts, and cleaning up related resources to ensure a clean shutdown from the server side."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "is_closing", "line_number": 1292, "body": "def is_closing(self) -> bool:\n        \"\"\"Return ``True`` if this connection is closing.\n\n        The connection is considered closing if either side has\n        initiated its closing handshake or if the stream has been\n        shut down uncleanly.\n        \"\"\"\n        return self.stream.closed() or self.client_terminated or self.server_terminated", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Indicates whether the WebSocket connection is in the process of closing due to a handshake initiation or unclean shutdown. This helps manage connection lifecycle states for WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping_interval", "line_number": 1302, "body": "def ping_interval(self) -> Optional[float]:\n        interval = self.params.ping_interval\n        if interval is not None:\n            return interval\n        return 0", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Returns the configured ping interval for maintaining the WebSocket connection, defaulting to 0 if not set. This supports connection health monitoring in WebSocketProtocol13."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping_timeout", "line_number": 1309, "body": "def ping_timeout(self) -> Optional[float]:\n        timeout = self.params.ping_timeout\n        if timeout is not None:\n            return timeout\n        assert self.ping_interval is not None\n        return max(3 * self.ping_interval, 30)", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Provides the configured ping timeout value for the WebSocket connection, defaulting to at least three times the ping interval or 30 seconds. This helps manage connection health by defining how long to wait for a ping response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "start_pinging", "line_number": 1316, "body": "def start_pinging(self) -> None:\n        \"\"\"Start sending periodic pings to keep the connection alive\"\"\"\n        assert self.ping_interval is not None\n        if self.ping_interval > 0:\n            self.last_ping = self.last_pong = IOLoop.current().time()\n            self.ping_callback = PeriodicCallback(\n                self.periodic_ping, self.ping_interval * 1000\n            )\n            self.ping_callback.start()", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Starts a periodic ping process to maintain a WebSocket connection\u2019s liveliness by sending regular ping frames based on a configured interval. This helps prevent connection timeouts in the WebSocketProtocol13 class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "periodic_ping", "line_number": 1326, "body": "def periodic_ping(self) -> None:\n        \"\"\"Send a ping to keep the websocket alive\n\n        Called periodically if the websocket_ping_interval is set and non-zero.\n        \"\"\"\n        if self.is_closing() and self.ping_callback is not None:\n            self.ping_callback.stop()\n            return\n\n        # Check for timeout on pong. Make sure that we really have\n        # sent a recent ping in case the machine with both server and\n        # client has been suspended since the last ping.\n        now = IOLoop.current().time()\n        since_last_pong = now - self.last_pong\n        since_last_ping = now - self.last_ping\n        assert self.ping_interval is not None\n        assert self.ping_timeout is not None\n        if (\n            since_last_ping < 2 * self.ping_interval\n            and since_last_pong > self.ping_timeout\n        ):\n            self.close()\n            return\n\n        self.write_ping(b\"\")\n        self.last_ping = now", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Periodic method of WebSocketProtocol13 that sends regular ping frames to maintain connection liveness and detects pong timeouts to close unresponsive websockets automatically."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "set_nodelay", "line_number": 1353, "body": "def set_nodelay(self, x: bool) -> None:\n        self.stream.set_nodelay(x)", "is_method": true, "class_name": "WebSocketProtocol13", "function_description": "Sets the TCP_NODELAY option on the underlying stream to enable or disable the Nagle algorithm, controlling packet send behavior for improved latency or bandwidth efficiency."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "close", "line_number": 1427, "body": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes the websocket connection.\n\n        ``code`` and ``reason`` are documented under\n        `WebSocketHandler.close`.\n\n        .. versionadded:: 3.2\n\n        .. versionchanged:: 4.0\n\n           Added the ``code`` and ``reason`` arguments.\n        \"\"\"\n        if self.protocol is not None:\n            self.protocol.close(code, reason)\n            self.protocol = None", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Method of WebSocketClientConnection that gracefully closes the websocket connection, optionally specifying a closure code and reason for termination. It ensures proper teardown of the protocol communication channel."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_connection_close", "line_number": 1443, "body": "def on_connection_close(self) -> None:\n        if not self.connect_future.done():\n            self.connect_future.set_exception(StreamClosedError())\n        self._on_message(None)\n        self.tcp_client.close()\n        super().on_connection_close()", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Handles the cleanup and state update when a WebSocket connection closes, ensuring associated tasks are notified and the underlying TCP client is properly closed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_ws_connection_close", "line_number": 1450, "body": "def on_ws_connection_close(\n        self, close_code: Optional[int] = None, close_reason: Optional[str] = None\n    ) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        self.on_connection_close()", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Handles the closing of a WebSocket connection by recording the close code and reason, then triggering any additional cleanup or logic associated with the connection closing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_on_http_response", "line_number": 1457, "body": "def _on_http_response(self, response: httpclient.HTTPResponse) -> None:\n        if not self.connect_future.done():\n            if response.error:\n                self.connect_future.set_exception(response.error)\n            else:\n                self.connect_future.set_exception(\n                    WebSocketError(\"Non-websocket response\")\n                )", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Internal handler in WebSocketClientConnection that processes HTTP responses during connection, signaling connection failure if the response indicates an error or is not a WebSocket upgrade."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "write_message", "line_number": 1496, "body": "def write_message(\n        self, message: Union[str, bytes], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends a message to the WebSocket server.\n\n        If the stream is closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 5.0\n           Exception raised on a closed stream changed from `.StreamClosedError`\n           to `WebSocketClosedError`.\n        \"\"\"\n        return self.protocol.write_message(message, binary=binary)", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Sends a text or binary message to a WebSocket server, returning a Future for asynchronous flow control and raising an error if the connection is closed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "read_message", "line_number": 1510, "body": "def read_message(\n        self,\n        callback: Optional[Callable[[\"Future[Union[None, str, bytes]]\"], None]] = None,\n    ) -> Awaitable[Union[None, str, bytes]]:\n        \"\"\"Reads a message from the WebSocket server.\n\n        If on_message_callback was specified at WebSocket\n        initialization, this function will never return messages\n\n        Returns a future whose result is the message, or None\n        if the connection is closed.  If a callback argument\n        is given it will be called with the future when it is\n        ready.\n        \"\"\"\n\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Provides an asynchronous method to read messages from a WebSocket server, returning a future for the incoming message or None on closure, optionally invoking a callback upon message receipt."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "on_message", "line_number": 1530, "body": "def on_message(self, message: Union[str, bytes]) -> Optional[Awaitable[None]]:\n        return self._on_message(message)", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Handles incoming WebSocket messages by delegating processing to an internal handler, enabling the client connection to respond to text or binary data received."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "_on_message", "line_number": 1533, "body": "def _on_message(\n        self, message: Union[None, str, bytes]\n    ) -> Optional[Awaitable[None]]:\n        if self._on_message_callback:\n            self._on_message_callback(message)\n            return None\n        else:\n            return self.read_queue.put(message)", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Handles incoming WebSocket messages by either invoking a callback or queuing the message for processing, enabling flexible message reception management within a WebSocketClientConnection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "ping", "line_number": 1542, "body": "def ping(self, data: bytes = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``ping_interval`` argument to\n        `websocket_connect` instead of sending pings manually.\n\n        .. versionadded:: 5.1\n\n        \"\"\"\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Sends a WebSocket ping frame with optional data to keep the connection alive or check its status. Useful for signaling activity or detecting disconnections in real-time communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "get_websocket_protocol", "line_number": 1567, "body": "def get_websocket_protocol(self) -> WebSocketProtocol:\n        return WebSocketProtocol13(self, mask_outgoing=True, params=self.params)", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Returns a WebSocketProtocol13 instance configured for this connection, enabling standardized communication over a WebSocket with specific parameters and outgoing message masking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "selected_subprotocol", "line_number": 1571, "body": "def selected_subprotocol(self) -> Optional[str]:\n        \"\"\"The subprotocol selected by the server.\n\n        .. versionadded:: 5.1\n        \"\"\"\n        return self.protocol.selected_subprotocol", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Returns the subprotocol chosen by the server during the WebSocket handshake, enabling clients to identify which communication protocol is active. Useful for managing protocol-specific behavior in WebSocket connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/websocket.py", "function": "log_exception", "line_number": 1578, "body": "def log_exception(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        assert typ is not None\n        assert value is not None\n        app_log.error(\"Uncaught exception %s\", value, exc_info=(typ, value, tb))", "is_method": true, "class_name": "WebSocketClientConnection", "function_description": "Logs uncaught exceptions occurring during the WebSocket client connection, capturing exception details for error monitoring and debugging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "configure", "line_number": 165, "body": "def configure(\n        cls, impl: \"Union[None, str, Type[Configurable]]\", **kwargs: Any\n    ) -> None:\n        if asyncio is not None:\n            from tornado.platform.asyncio import BaseAsyncIOLoop\n\n            if isinstance(impl, str):\n                impl = import_object(impl)\n            if isinstance(impl, type) and not issubclass(impl, BaseAsyncIOLoop):\n                raise RuntimeError(\n                    \"only AsyncIOLoop is allowed when asyncio is available\"\n                )\n        super(IOLoop, cls).configure(impl, **kwargs)", "is_method": true, "class_name": "IOLoop", "function_description": "Sets or updates the asynchronous event loop implementation for the IOLoop class, enforcing compatibility with asyncio when available. This enables customized or default event loop configuration for asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "instance", "line_number": 180, "body": "def instance() -> \"IOLoop\":\n        \"\"\"Deprecated alias for `IOLoop.current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method returned a global singleton\n           `IOLoop`, in contrast with the per-thread `IOLoop` returned\n           by `current()`. In nearly all cases the two were the same\n           (when they differed, it was generally used from non-Tornado\n           threads to communicate back to the main thread's `IOLoop`).\n           This distinction is not present in `asyncio`, so in order\n           to facilitate integration with that package `instance()`\n           was changed to be an alias to `current()`. Applications\n           using the cross-thread communications aspect of\n           `instance()` should instead set their own global variable\n           to point to the `IOLoop` they want to use.\n\n        .. deprecated:: 5.0\n        \"\"\"\n        return IOLoop.current()", "is_method": true, "class_name": "IOLoop", "function_description": "Returns the current thread\u2019s IOLoop instance, serving as a deprecated alias for IOLoop.current() to maintain backward compatibility with older code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "install", "line_number": 201, "body": "def install(self) -> None:\n        \"\"\"Deprecated alias for `make_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would set this `IOLoop` as the\n           global singleton used by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`, `install()`\n           is an alias for `make_current()`.\n\n        .. deprecated:: 5.0\n        \"\"\"\n        self.make_current()", "is_method": true, "class_name": "IOLoop", "function_description": "Deprecated method of the IOLoop class that sets this IOLoop instance as the current one, serving as an alias for `make_current()`. It is retained for backward compatibility but should be avoided in new code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "clear_instance", "line_number": 216, "body": "def clear_instance() -> None:\n        \"\"\"Deprecated alias for `clear_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would clear the `IOLoop` used as\n           the global singleton by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`,\n           `clear_instance()` is an alias for `clear_current()`.\n\n        .. deprecated:: 5.0\n\n        \"\"\"\n        IOLoop.clear_current()", "is_method": true, "class_name": "IOLoop", "function_description": "Deprecated method in IOLoop that clears the current global event loop instance; it serves as an alias for clear_current() to maintain backward compatibility."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "current", "line_number": 242, "body": "def current(instance: bool = True) -> Optional[\"IOLoop\"]:  # noqa: F811\n        \"\"\"Returns the current thread's `IOLoop`.\n\n        If an `IOLoop` is currently running or has been marked as\n        current by `make_current`, returns that instance.  If there is\n        no current `IOLoop` and ``instance`` is true, creates one.\n\n        .. versionchanged:: 4.1\n           Added ``instance`` argument to control the fallback to\n           `IOLoop.instance()`.\n        .. versionchanged:: 5.0\n           On Python 3, control of the current `IOLoop` is delegated\n           to `asyncio`, with this and other methods as pass-through accessors.\n           The ``instance`` argument now controls whether an `IOLoop`\n           is created automatically when there is none, instead of\n           whether we fall back to `IOLoop.instance()` (which is now\n           an alias for this method). ``instance=False`` is deprecated,\n           since even if we do not create an `IOLoop`, this method\n           may initialize the asyncio loop.\n        \"\"\"\n        try:\n            loop = asyncio.get_event_loop()\n        except (RuntimeError, AssertionError):\n            if not instance:\n                return None\n            raise\n        try:\n            return IOLoop._ioloop_for_asyncio[loop]\n        except KeyError:\n            if instance:\n                from tornado.platform.asyncio import AsyncIOMainLoop\n\n                current = AsyncIOMainLoop(make_current=True)  # type: Optional[IOLoop]\n            else:\n                current = None\n        return current", "is_method": true, "class_name": "IOLoop", "function_description": "Provides the current thread's IOLoop instance or creates one if none exists and creation is allowed, facilitating asynchronous event loop management within the Tornado framework. Useful for accessing or initializing the active event loop in concurrent applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "clear_current", "line_number": 299, "body": "def clear_current() -> None:\n        \"\"\"Clears the `IOLoop` for the current thread.\n\n        Intended primarily for use by test frameworks in between tests.\n\n        .. versionchanged:: 5.0\n           This method also clears the current `asyncio` event loop.\n        \"\"\"\n        old = IOLoop.current(instance=False)\n        if old is not None:\n            old._clear_current_hook()\n        if asyncio is None:\n            IOLoop._current.instance = None", "is_method": true, "class_name": "IOLoop", "function_description": "Clears the current thread's IOLoop and associated asyncio event loop, primarily supporting test frameworks by resetting event loop state between tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "configurable_base", "line_number": 321, "body": "def configurable_base(cls) -> Type[Configurable]:\n        return IOLoop", "is_method": true, "class_name": "IOLoop", "function_description": "Returns the IOLoop class as the configurable base type, serving as a reference point for configuration in the IOLoop context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "configurable_default", "line_number": 325, "body": "def configurable_default(cls) -> Type[Configurable]:\n        from tornado.platform.asyncio import AsyncIOLoop\n\n        return AsyncIOLoop", "is_method": true, "class_name": "IOLoop", "function_description": "Returns the default asynchronous I/O loop class used for event handling, allowing customization of the IOLoop implementation in asynchronous applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "initialize", "line_number": 330, "body": "def initialize(self, make_current: Optional[bool] = None) -> None:\n        if make_current is None:\n            if IOLoop.current(instance=False) is None:\n                self.make_current()\n        elif make_current:\n            current = IOLoop.current(instance=False)\n            # AsyncIO loops can already be current by this point.\n            if current is not None and current is not self:\n                raise RuntimeError(\"current IOLoop already exists\")\n            self.make_current()", "is_method": true, "class_name": "IOLoop", "function_description": "Initializes the IOLoop instance and optionally sets it as the current active loop, ensuring only one current loop exists at a time. This method manages the event loop's current context to avoid conflicts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_setup_logging", "line_number": 425, "body": "def _setup_logging(self) -> None:\n        \"\"\"The IOLoop catches and logs exceptions, so it's\n        important that log output be visible.  However, python's\n        default behavior for non-root loggers (prior to python\n        3.2) is to print an unhelpful \"no handlers could be\n        found\" message rather than the actual log entry, so we\n        must explicitly configure logging if we've made it this\n        far without anything.\n\n        This method should be called from start() in subclasses.\n        \"\"\"\n        if not any(\n            [\n                logging.getLogger().handlers,\n                logging.getLogger(\"tornado\").handlers,\n                logging.getLogger(\"tornado.application\").handlers,\n            ]\n        ):\n            logging.basicConfig()", "is_method": true, "class_name": "IOLoop", "function_description": "Sets up basic logging if no handlers exist, ensuring that the IOLoop's exception logs are visible. This supports subclasses in properly configuring logging during their startup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "run_sync", "line_number": 458, "body": "def run_sync(self, func: Callable, timeout: Optional[float] = None) -> Any:\n        \"\"\"Starts the `IOLoop`, runs the given function, and stops the loop.\n\n        The function must return either an awaitable object or\n        ``None``. If the function returns an awaitable object, the\n        `IOLoop` will run until the awaitable is resolved (and\n        `run_sync()` will return the awaitable's result). If it raises\n        an exception, the `IOLoop` will stop and the exception will be\n        re-raised to the caller.\n\n        The keyword-only argument ``timeout`` may be used to set\n        a maximum duration for the function.  If the timeout expires,\n        a `tornado.util.TimeoutError` is raised.\n\n        This method is useful to allow asynchronous calls in a\n        ``main()`` function::\n\n            async def main():\n                # do stuff...\n\n            if __name__ == '__main__':\n                IOLoop.current().run_sync(main)\n\n        .. versionchanged:: 4.3\n           Returning a non-``None``, non-awaitable value is now an error.\n\n        .. versionchanged:: 5.0\n           If a timeout occurs, the ``func`` coroutine will be cancelled.\n\n        \"\"\"\n        future_cell = [None]  # type: List[Optional[Future]]\n\n        def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[0] = fut\n                future_set_exc_info(fut, sys.exc_info())\n            else:\n                if is_future(result):\n                    future_cell[0] = result\n                else:\n                    fut = Future()\n                    future_cell[0] = fut\n                    fut.set_result(result)\n            assert future_cell[0] is not None\n            self.add_future(future_cell[0], lambda future: self.stop())\n\n        self.add_callback(run)\n        if timeout is not None:\n\n            def timeout_callback() -> None:\n                # If we can cancel the future, do so and wait on it. If not,\n                # Just stop the loop and return with the task still pending.\n                # (If we neither cancel nor wait for the task, a warning\n                # will be logged).\n                assert future_cell[0] is not None\n                if not future_cell[0].cancel():\n                    self.stop()\n\n            timeout_handle = self.add_timeout(self.time() + timeout, timeout_callback)\n        self.start()\n        if timeout is not None:\n            self.remove_timeout(timeout_handle)\n        assert future_cell[0] is not None\n        if future_cell[0].cancelled() or not future_cell[0].done():\n            raise TimeoutError(\"Operation timed out after %s seconds\" % timeout)\n        return future_cell[0].result()", "is_method": true, "class_name": "IOLoop", "function_description": "Runs a given asynchronous function synchronously within the IOLoop, blocking until completion or timeout, and returns its result. It enables seamless integration of async code in synchronous contexts with optional execution timeout handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "time", "line_number": 532, "body": "def time(self) -> float:\n        \"\"\"Returns the current time according to the `IOLoop`'s clock.\n\n        The return value is a floating-point number relative to an\n        unspecified time in the past.\n\n        Historically, the IOLoop could be customized to use e.g.\n        `time.monotonic` instead of `time.time`, but this is not\n        currently supported and so this method is equivalent to\n        `time.time`.\n\n        \"\"\"\n        return time.time()", "is_method": true, "class_name": "IOLoop", "function_description": "Returns the current time based on the IOLoop's internal clock, providing a floating-point timestamp useful for time-related operations within the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "add_timeout", "line_number": 546, "body": "def add_timeout(\n        self,\n        deadline: Union[float, datetime.timedelta],\n        callback: Callable[..., None],\n        *args: Any,\n        **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n\n        Returns an opaque handle that may be passed to\n        `remove_timeout` to cancel.\n\n        ``deadline`` may be a number denoting a time (on the same\n        scale as `IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.  Since Tornado 4.0, `call_later` is a more\n        convenient alternative for the relative case since it does not\n        require a timedelta object.\n\n        Note that it is not safe to call `add_timeout` from other threads.\n        Instead, you must use `add_callback` to transfer control to the\n        `IOLoop`'s thread, and then call `add_timeout` from there.\n\n        Subclasses of IOLoop must implement either `add_timeout` or\n        `call_at`; the default implementations of each will call\n        the other.  `call_at` is usually easier to implement, but\n        subclasses that wish to maintain compatibility with Tornado\n        versions prior to 4.0 must use `add_timeout` instead.\n\n        .. versionchanged:: 4.0\n           Now passes through ``*args`` and ``**kwargs`` to the callback.\n        \"\"\"\n        if isinstance(deadline, numbers.Real):\n            return self.call_at(deadline, callback, *args, **kwargs)\n        elif isinstance(deadline, datetime.timedelta):\n            return self.call_at(\n                self.time() + deadline.total_seconds(), callback, *args, **kwargs\n            )\n        else:\n            raise TypeError(\"Unsupported deadline %r\" % deadline)", "is_method": true, "class_name": "IOLoop", "function_description": "Schedules a callback to run at a specified absolute time or after a relative delay within the IOLoop, returning a handle for possible cancellation. It enables timed execution of functions in asynchronous event-driven applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "call_later", "line_number": 587, "body": "def call_later(\n        self, delay: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` after ``delay`` seconds have passed.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.call_at(self.time() + delay, callback, *args, **kwargs)", "is_method": true, "class_name": "IOLoop", "function_description": "Provides a way to schedule a callback function to execute after a specified delay, returning a handle that can be used to cancel the scheduled call if needed. This supports timed, deferred execution within an IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "call_at", "line_number": 602, "body": "def call_at(\n        self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n\n        ``when`` must be a number using the same reference point as\n        `IOLoop.time`.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.add_timeout(when, callback, *args, **kwargs)", "is_method": true, "class_name": "IOLoop", "function_description": "Schedules a callback to execute at a specific absolute time on the IOLoop, returning a handle that can be used to cancel the callback if needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "remove_timeout", "line_number": 620, "body": "def remove_timeout(self, timeout: object) -> None:\n        \"\"\"Cancels a pending timeout.\n\n        The argument is a handle as returned by `add_timeout`.  It is\n        safe to call `remove_timeout` even if the callback has already\n        been run.\n        \"\"\"\n        raise NotImplementedError()", "is_method": true, "class_name": "IOLoop", "function_description": "Cancels a previously scheduled timeout callback, ensuring safe removal even if the callback has already executed. This helps manage and control timed events within the IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "spawn_callback", "line_number": 654, "body": "def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next IOLoop iteration.\n\n        As of Tornado 6.0, this method is equivalent to `add_callback`.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        self.add_callback(callback, *args, **kwargs)", "is_method": true, "class_name": "IOLoop", "function_description": "Utility method of the IOLoop class that schedules a callback to be executed in the next event loop iteration, facilitating asynchronous task execution without blocking current operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "add_future", "line_number": 663, "body": "def add_future(\n        self,\n        future: \"Union[Future[_T], concurrent.futures.Future[_T]]\",\n        callback: Callable[[\"Future[_T]\"], None],\n    ) -> None:\n        \"\"\"Schedules a callback on the ``IOLoop`` when the given\n        `.Future` is finished.\n\n        The callback is invoked with one argument, the\n        `.Future`.\n\n        This method only accepts `.Future` objects and not other\n        awaitables (unlike most of Tornado where the two are\n        interchangeable).\n        \"\"\"\n        if isinstance(future, Future):\n            # Note that we specifically do not want the inline behavior of\n            # tornado.concurrent.future_add_done_callback. We always want\n            # this callback scheduled on the next IOLoop iteration (which\n            # asyncio.Future always does).\n            #\n            # Wrap the callback in self._run_callback so we control\n            # the error logging (i.e. it goes to tornado.log.app_log\n            # instead of asyncio's log).\n            future.add_done_callback(\n                lambda f: self._run_callback(functools.partial(callback, future))\n            )\n        else:\n            assert is_future(future)\n            # For concurrent futures, we use self.add_callback, so\n            # it's fine if future_add_done_callback inlines that call.\n            future_add_done_callback(\n                future, lambda f: self.add_callback(callback, future)\n            )", "is_method": true, "class_name": "IOLoop", "function_description": "Schedules a callback to run on the IOLoop once a given Future completes, ensuring the callback is executed within the event loop's context. This enables integration of asynchronous results with IOLoop-based event handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "run_in_executor", "line_number": 698, "body": "def run_in_executor(\n        self,\n        executor: Optional[concurrent.futures.Executor],\n        func: Callable[..., _T],\n        *args: Any\n    ) -> Awaitable[_T]:\n        \"\"\"Runs a function in a ``concurrent.futures.Executor``. If\n        ``executor`` is ``None``, the IO loop's default executor will be used.\n\n        Use `functools.partial` to pass keyword arguments to ``func``.\n\n        .. versionadded:: 5.0\n        \"\"\"\n        if executor is None:\n            if not hasattr(self, \"_executor\"):\n                from tornado.process import cpu_count\n\n                self._executor = concurrent.futures.ThreadPoolExecutor(\n                    max_workers=(cpu_count() * 5)\n                )  # type: concurrent.futures.Executor\n            executor = self._executor\n        c_future = executor.submit(func, *args)\n        # Concurrent Futures are not usable with await. Wrap this in a\n        # Tornado Future instead, using self.add_future for thread-safety.\n        t_future = Future()  # type: Future[_T]\n        self.add_future(c_future, lambda f: chain_future(f, t_future))\n        return t_future", "is_method": true, "class_name": "IOLoop", "function_description": "Provides a way to run a blocking function asynchronously within an event loop by submitting it to a thread or process executor, returning an awaitable for integration with async workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "set_default_executor", "line_number": 726, "body": "def set_default_executor(self, executor: concurrent.futures.Executor) -> None:\n        \"\"\"Sets the default executor to use with :meth:`run_in_executor`.\n\n        .. versionadded:: 5.0\n        \"\"\"\n        self._executor = executor", "is_method": true, "class_name": "IOLoop", "function_description": "Sets the default thread or process executor used by the IOLoop to run blocking functions asynchronously. This enables integration of custom executors for concurrent task execution within the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_run_callback", "line_number": 733, "body": "def _run_callback(self, callback: Callable[[], Any]) -> None:\n        \"\"\"Runs a callback with error handling.\n\n        .. versionchanged:: 6.0\n\n           CancelledErrors are no longer logged.\n        \"\"\"\n        try:\n            ret = callback()\n            if ret is not None:\n                from tornado import gen\n\n                # Functions that return Futures typically swallow all\n                # exceptions and store them in the Future.  If a Future\n                # makes it out to the IOLoop, ensure its exception (if any)\n                # gets logged too.\n                try:\n                    ret = gen.convert_yielded(ret)\n                except gen.BadYieldError:\n                    # It's not unusual for add_callback to be used with\n                    # methods returning a non-None and non-yieldable\n                    # result, which should just be ignored.\n                    pass\n                else:\n                    self.add_future(ret, self._discard_future_result)\n        except asyncio.CancelledError:\n            pass\n        except Exception:\n            app_log.error(\"Exception in callback %r\", callback, exc_info=True)", "is_method": true, "class_name": "IOLoop", "function_description": "Runs a given callback function with error handling, ensuring any exceptions are logged except cancellation errors. It also manages asynchronous results by adding returned futures for completion tracking within the IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_discard_future_result", "line_number": 763, "body": "def _discard_future_result(self, future: Future) -> None:\n        \"\"\"Avoid unhandled-exception warnings from spawned coroutines.\"\"\"\n        future.result()", "is_method": true, "class_name": "IOLoop", "function_description": "Private method of the IOLoop class that suppresses unhandled exception warnings by retrieving and discarding the result of a future, useful for managing coroutine exceptions silently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "split_fd", "line_number": 767, "body": "def split_fd(\n        self, fd: Union[int, _Selectable]\n    ) -> Tuple[int, Union[int, _Selectable]]:\n        # \"\"\"Returns an (fd, obj) pair from an ``fd`` parameter.\n\n        # We accept both raw file descriptors and file-like objects as\n        # input to `add_handler` and related methods.  When a file-like\n        # object is passed, we must retain the object itself so we can\n        # close it correctly when the `IOLoop` shuts down, but the\n        # poller interfaces favor file descriptors (they will accept\n        # file-like objects and call ``fileno()`` for you, but they\n        # always return the descriptor itself).\n\n        # This method is provided for use by `IOLoop` subclasses and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        if isinstance(fd, int):\n            return fd, fd\n        return fd.fileno(), fd", "is_method": true, "class_name": "IOLoop", "function_description": "Utility method of the IOLoop class that standardizes input by returning a tuple of a file descriptor and its associated object, supporting both raw descriptors and file-like objects for consistent event loop handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "close_fd", "line_number": 789, "body": "def close_fd(self, fd: Union[int, _Selectable]) -> None:\n        # \"\"\"Utility method to close an ``fd``.\n\n        # If ``fd`` is a file-like object, we close it directly; otherwise\n        # we use `os.close`.\n\n        # This method is provided for use by `IOLoop` subclasses (in\n        # implementations of ``IOLoop.close(all_fds=True)`` and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        try:\n            if isinstance(fd, int):\n                os.close(fd)\n            else:\n                fd.close()\n        except OSError:\n            pass", "is_method": true, "class_name": "IOLoop", "function_description": "Utility method in IOLoop that closes a file descriptor or file-like object safely, handling any errors silently. It supports resource cleanup within IOLoop subclasses but is not intended for general application use."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "__lt__", "line_number": 832, "body": "def __lt__(self, other: \"_Timeout\") -> bool:\n        return self.tdeadline < other.tdeadline", "is_method": true, "class_name": "_Timeout", "function_description": "Comparison method of the _Timeout class that determines if one timeout instance expires before another, enabling sorting or ordering based on deadline times."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "__le__", "line_number": 835, "body": "def __le__(self, other: \"_Timeout\") -> bool:\n        return self.tdeadline <= other.tdeadline", "is_method": true, "class_name": "_Timeout", "function_description": "Comparison operator method of the _Timeout class that determines if one timeout instance occurs before or at the same time as another, enabling timeout ordering and scheduling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "start", "line_number": 877, "body": "def start(self) -> None:\n        \"\"\"Starts the timer.\"\"\"\n        # Looking up the IOLoop here allows to first instantiate the\n        # PeriodicCallback in another thread, then start it using\n        # IOLoop.add_callback().\n        self.io_loop = IOLoop.current()\n        self._running = True\n        self._next_timeout = self.io_loop.time()\n        self._schedule_next()", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Starts the periodic timer to schedule recurring execution of a callback within the current IOLoop. It enables initiating timed, repeated operations in asynchronous applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "stop", "line_number": 887, "body": "def stop(self) -> None:\n        \"\"\"Stops the timer.\"\"\"\n        self._running = False\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Stops the periodic callback by halting its timer and removing any scheduled timeout, effectively preventing further executions. This method is useful for controlling or canceling ongoing timed operations in asynchronous environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "is_running", "line_number": 894, "body": "def is_running(self) -> bool:\n        \"\"\"Returns ``True`` if this `.PeriodicCallback` has been started.\n\n        .. versionadded:: 4.1\n        \"\"\"\n        return self._running", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Checks whether the PeriodicCallback is currently active, allowing other components to determine if the periodic task is running."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_run", "line_number": 901, "body": "def _run(self) -> None:\n        if not self._running:\n            return\n        try:\n            return self.callback()\n        except Exception:\n            app_log.error(\"Exception in callback %r\", self.callback, exc_info=True)\n        finally:\n            self._schedule_next()", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Private method of PeriodicCallback that executes the registered callback while handling exceptions and ensuring the next scheduled run occurs. It manages reliable periodic execution of tasks with error logging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_schedule_next", "line_number": 911, "body": "def _schedule_next(self) -> None:\n        if self._running:\n            self._update_next(self.io_loop.time())\n            self._timeout = self.io_loop.add_timeout(self._next_timeout, self._run)", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Internal method of the PeriodicCallback class that schedules the next execution of the callback if it is currently running, integrating with the event loop's timing mechanism."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "_update_next", "line_number": 916, "body": "def _update_next(self, current_time: float) -> None:\n        callback_time_sec = self.callback_time / 1000.0\n        if self.jitter:\n            # apply jitter fraction\n            callback_time_sec *= 1 + (self.jitter * (random.random() - 0.5))\n        if self._next_timeout <= current_time:\n            # The period should be measured from the start of one call\n            # to the start of the next. If one call takes too long,\n            # skip cycles to get back to a multiple of the original\n            # schedule.\n            self._next_timeout += (\n                math.floor((current_time - self._next_timeout) / callback_time_sec) + 1\n            ) * callback_time_sec\n        else:\n            # If the clock moved backwards, ensure we advance the next\n            # timeout instead of recomputing the same value again.\n            # This may result in long gaps between callbacks if the\n            # clock jumps backwards by a lot, but the far more common\n            # scenario is a small NTP adjustment that should just be\n            # ignored.\n            #\n            # Note that on some systems if time.time() runs slower\n            # than time.monotonic() (most common on windows), we\n            # effectively experience a small backwards time jump on\n            # every iteration because PeriodicCallback uses\n            # time.time() while asyncio schedules callbacks using\n            # time.monotonic().\n            # https://github.com/tornadoweb/tornado/issues/2333\n            self._next_timeout += callback_time_sec", "is_method": true, "class_name": "PeriodicCallback", "function_description": "Internal method of PeriodicCallback that calculates and updates the next scheduled callback time, adjusting for jitter and handling clock irregularities to maintain consistent periodic execution intervals."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/ioloop.py", "function": "run", "line_number": 490, "body": "def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[0] = fut\n                future_set_exc_info(fut, sys.exc_info())\n            else:\n                if is_future(result):\n                    future_cell[0] = result\n                else:\n                    fut = Future()\n                    future_cell[0] = fut\n                    fut.set_result(result)\n            assert future_cell[0] is not None\n            self.add_future(future_cell[0], lambda future: self.stop())", "is_method": true, "class_name": "IOLoop", "function_description": "Core method of the IOLoop class that executes a provided function, handling both synchronous and asynchronous results, and manages the event loop lifecycle by stopping it when the function completes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/caresresolver.py", "function": "initialize", "line_number": 31, "body": "def initialize(self) -> None:\n        self.io_loop = IOLoop.current()\n        self.channel = pycares.Channel(sock_state_cb=self._sock_state_cb)\n        self.fds = {}", "is_method": true, "class_name": "CaresResolver", "function_description": "Initializes the CaresResolver by setting up the asynchronous I/O loop, creating a DNS resolution channel, and preparing a file descriptor tracking structure for managing socket states during DNS queries."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/caresresolver.py", "function": "_sock_state_cb", "line_number": 36, "body": "def _sock_state_cb(self, fd: int, readable: bool, writable: bool) -> None:\n        state = (IOLoop.READ if readable else 0) | (IOLoop.WRITE if writable else 0)\n        if not state:\n            self.io_loop.remove_handler(fd)\n            del self.fds[fd]\n        elif fd in self.fds:\n            self.io_loop.update_handler(fd, state)\n            self.fds[fd] = state\n        else:\n            self.io_loop.add_handler(fd, self._handle_events, state)\n            self.fds[fd] = state", "is_method": true, "class_name": "CaresResolver", "function_description": "Manages and updates I/O event handlers for a given socket file descriptor within the event loop, ensuring correct monitoring of read/write states or removing handlers when inactive."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/caresresolver.py", "function": "_handle_events", "line_number": 48, "body": "def _handle_events(self, fd: int, events: int) -> None:\n        read_fd = pycares.ARES_SOCKET_BAD\n        write_fd = pycares.ARES_SOCKET_BAD\n        if events & IOLoop.READ:\n            read_fd = fd\n        if events & IOLoop.WRITE:\n            write_fd = fd\n        self.channel.process_fd(read_fd, write_fd)", "is_method": true, "class_name": "CaresResolver", "function_description": "Internal method of CaresResolver that processes socket file descriptor events by mapping them to read or write operations for handling asynchronous DNS resolution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/caresresolver.py", "function": "resolve", "line_number": 58, "body": "def resolve(\n        self, host: str, port: int, family: int = 0\n    ) -> \"Generator[Any, Any, List[Tuple[int, Any]]]\":\n        if is_valid_ip(host):\n            addresses = [host]\n        else:\n            # gethostbyname doesn't take callback as a kwarg\n            fut = Future()  # type: Future[Tuple[Any, Any]]\n            self.channel.gethostbyname(\n                host, family, lambda result, error: fut.set_result((result, error))\n            )\n            result, error = yield fut\n            if error:\n                raise IOError(\n                    \"C-Ares returned error %s: %s while resolving %s\"\n                    % (error, pycares.errno.strerror(error), host)\n                )\n            addresses = result.addresses\n        addrinfo = []\n        for address in addresses:\n            if \".\" in address:\n                address_family = socket.AF_INET\n            elif \":\" in address:\n                address_family = socket.AF_INET6\n            else:\n                address_family = socket.AF_UNSPEC\n            if family != socket.AF_UNSPEC and family != address_family:\n                raise IOError(\n                    \"Requested socket family %d but got %d\" % (family, address_family)\n                )\n            addrinfo.append((typing.cast(int, address_family), (address, port)))\n        return addrinfo", "is_method": true, "class_name": "CaresResolver", "function_description": "Core method of the CaresResolver class that resolves a hostname to its network addresses and port tuples, supporting both IP validation and asynchronous DNS resolution with error handling. It provides socket address information compatible with the specified address family."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/twisted.py", "function": "install", "line_number": 107, "body": "def install() -> None:\n    \"\"\"Install ``AsyncioSelectorReactor`` as the default Twisted reactor.\n\n    .. deprecated:: 5.1\n\n       This function is provided for backwards compatibility; code\n       that does not require compatibility with older versions of\n       Tornado should use\n       ``twisted.internet.asyncioreactor.install()`` directly.\n\n    .. versionchanged:: 6.0.3\n\n       In Tornado 5.x and before, this function installed a reactor\n       based on the Tornado ``IOLoop``. When that reactor\n       implementation was removed in Tornado 6.0.0, this function was\n       removed as well. It was restored in Tornado 6.0.3 using the\n       ``asyncio`` reactor instead.\n\n    \"\"\"\n    from twisted.internet.asyncioreactor import install\n\n    install()", "is_method": false, "function_description": "Utility function to set AsyncioSelectorReactor as the default Twisted reactor, mainly for backward compatibility in Tornado projects using older reactor setups."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/twisted.py", "function": "initialize", "line_number": 57, "body": "def initialize(self) -> None:\n        # partial copy of twisted.names.client.createResolver, which doesn't\n        # allow for a reactor to be passed in.\n        self.reactor = twisted.internet.asyncioreactor.AsyncioSelectorReactor()\n\n        host_resolver = twisted.names.hosts.Resolver(\"/etc/hosts\")\n        cache_resolver = twisted.names.cache.CacheResolver(reactor=self.reactor)\n        real_resolver = twisted.names.client.Resolver(\n            \"/etc/resolv.conf\", reactor=self.reactor\n        )\n        self.resolver = twisted.names.resolve.ResolverChain(\n            [host_resolver, cache_resolver, real_resolver]\n        )", "is_method": true, "class_name": "TwistedResolver", "function_description": "Initializes the TwistedResolver by setting up a chained DNS resolver combining host, cache, and system resolvers using an AsyncioSelectorReactor. This enables asynchronous, layered DNS resolution within the Twisted networking framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/twisted.py", "function": "resolve", "line_number": 72, "body": "def resolve(\n        self, host: str, port: int, family: int = 0\n    ) -> \"Generator[Any, Any, List[Tuple[int, Any]]]\":\n        # getHostByName doesn't accept IP addresses, so if the input\n        # looks like an IP address just return it immediately.\n        if twisted.internet.abstract.isIPAddress(host):\n            resolved = host\n            resolved_family = socket.AF_INET\n        elif twisted.internet.abstract.isIPv6Address(host):\n            resolved = host\n            resolved_family = socket.AF_INET6\n        else:\n            deferred = self.resolver.getHostByName(utf8(host))\n            fut = Future()  # type: Future[Any]\n            deferred.addBoth(fut.set_result)\n            resolved = yield fut\n            if isinstance(resolved, failure.Failure):\n                try:\n                    resolved.raiseException()\n                except twisted.names.error.DomainError as e:\n                    raise IOError(e)\n            elif twisted.internet.abstract.isIPAddress(resolved):\n                resolved_family = socket.AF_INET\n            elif twisted.internet.abstract.isIPv6Address(resolved):\n                resolved_family = socket.AF_INET6\n            else:\n                resolved_family = socket.AF_UNSPEC\n        if family != socket.AF_UNSPEC and family != resolved_family:\n            raise Exception(\n                \"Requested socket family %d but got %d\" % (family, resolved_family)\n            )\n        result = [(typing.cast(int, resolved_family), (resolved, port))]\n        return result", "is_method": true, "class_name": "TwistedResolver", "function_description": "Provides asynchronous hostname resolution to IP addresses with support for IPv4, IPv6, and direct IP inputs, returning results with socket family info for network connection setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/twisted.py", "function": "errback", "line_number": 137, "body": "def errback(failure: failure.Failure) -> None:\n            try:\n                failure.raiseException()\n                # Should never happen, but just in case\n                raise Exception(\"errback called without error\")\n            except:\n                future_set_exc_info(f, sys.exc_info())", "is_method": false, "function_description": "Utility function that processes a failure by raising its associated exception and sets the exception info on a related future, enabling asynchronous error handling and propagation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_atexit_callback", "line_number": 57, "body": "def _atexit_callback() -> None:\n    for loop in _selector_loops:\n        with loop._select_cond:\n            loop._closing_selector = True\n            loop._select_cond.notify()\n        try:\n            loop._waker_w.send(b\"a\")\n        except BlockingIOError:\n            pass\n        # If we don't join our (daemon) thread here, we may get a deadlock\n        # during interpreter shutdown. I don't really understand why. This\n        # deadlock happens every time in CI (both travis and appveyor) but\n        # I've never been able to reproduce locally.\n        loop._thread.join()\n    _selector_loops.clear()", "is_method": false, "function_description": "Function that ensures all selector event loops are properly closed and their threads joined during interpreter shutdown, preventing deadlocks. It facilitates clean termination of async I/O loops at program exit."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "to_tornado_future", "line_number": 338, "body": "def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future", "is_method": false, "function_description": "Function that converts an asyncio.Future to a tornado.concurrent.Future, though now deprecated since Tornado Futures merged with asyncio Futures, making this conversion unnecessary."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "to_asyncio_future", "line_number": 350, "body": "def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now equivalent to `tornado.gen.convert_yielded`.\n    \"\"\"\n    return convert_yielded(tornado_future)", "is_method": false, "function_description": "Function that converts a Tornado yieldable object into an asyncio Future, enabling compatibility between Tornado's asynchronous constructs and asyncio's event loop. Useful for integrating Tornado code with asyncio-based applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "initialize", "line_number": 78, "body": "def initialize(  # type: ignore\n        self, asyncio_loop: asyncio.AbstractEventLoop, **kwargs: Any\n    ) -> None:\n        # asyncio_loop is always the real underlying IOLoop. This is used in\n        # ioloop.py to maintain the asyncio-to-ioloop mappings.\n        self.asyncio_loop = asyncio_loop\n        # selector_loop is an event loop that implements the add_reader family of\n        # methods. Usually the same as asyncio_loop but differs on platforms such\n        # as windows where the default event loop does not implement these methods.\n        self.selector_loop = asyncio_loop\n        if hasattr(asyncio, \"ProactorEventLoop\") and isinstance(\n            asyncio_loop, asyncio.ProactorEventLoop  # type: ignore\n        ):\n            # Ignore this line for mypy because the abstract method checker\n            # doesn't understand dynamic proxies.\n            self.selector_loop = AddThreadSelectorEventLoop(asyncio_loop)  # type: ignore\n        # Maps fd to (fileobj, handler function) pair (as in IOLoop.add_handler)\n        self.handlers = {}  # type: Dict[int, Tuple[Union[int, _Selectable], Callable]]\n        # Set of fds listening for reads/writes\n        self.readers = set()  # type: Set[int]\n        self.writers = set()  # type: Set[int]\n        self.closing = False\n        # If an asyncio loop was closed through an asyncio interface\n        # instead of IOLoop.close(), we'd never hear about it and may\n        # have left a dangling reference in our map. In case an\n        # application (or, more likely, a test suite) creates and\n        # destroys a lot of event loops in this way, check here to\n        # ensure that we don't have a lot of dead loops building up in\n        # the map.\n        #\n        # TODO(bdarnell): consider making self.asyncio_loop a weakref\n        # for AsyncIOMainLoop and make _ioloop_for_asyncio a\n        # WeakKeyDictionary.\n        for loop in list(IOLoop._ioloop_for_asyncio):\n            if loop.is_closed():\n                del IOLoop._ioloop_for_asyncio[loop]\n        IOLoop._ioloop_for_asyncio[asyncio_loop] = self\n\n        self._thread_identity = 0\n\n        super().initialize(**kwargs)\n\n        def assign_thread_identity() -> None:\n            self._thread_identity = threading.get_ident()\n\n        self.add_callback(assign_thread_identity)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Initializer for BaseAsyncIOLoop that sets up event loop mappings, file descriptor handlers, and thread identity management to integrate asyncio event loops with the IOLoop abstraction, handling platform-specific loop differences."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "close", "line_number": 125, "body": "def close(self, all_fds: bool = False) -> None:\n        self.closing = True\n        for fd in list(self.handlers):\n            fileobj, handler_func = self.handlers[fd]\n            self.remove_handler(fd)\n            if all_fds:\n                self.close_fd(fileobj)\n        # Remove the mapping before closing the asyncio loop. If this\n        # happened in the other order, we could race against another\n        # initialize() call which would see the closed asyncio loop,\n        # assume it was closed from the asyncio side, and do this\n        # cleanup for us, leading to a KeyError.\n        del IOLoop._ioloop_for_asyncio[self.asyncio_loop]\n        if self.selector_loop is not self.asyncio_loop:\n            self.selector_loop.close()\n        self.asyncio_loop.close()", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Closes the asynchronous I/O loop by removing all handlers and optionally closing file descriptors, ensuring a clean shutdown and releasing associated system resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "add_handler", "line_number": 142, "body": "def add_handler(\n        self, fd: Union[int, _Selectable], handler: Callable[..., None], events: int\n    ) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if fd in self.handlers:\n            raise ValueError(\"fd %s added twice\" % fd)\n        self.handlers[fd] = (fileobj, handler)\n        if events & IOLoop.READ:\n            self.selector_loop.add_reader(fd, self._handle_events, fd, IOLoop.READ)\n            self.readers.add(fd)\n        if events & IOLoop.WRITE:\n            self.selector_loop.add_writer(fd, self._handle_events, fd, IOLoop.WRITE)\n            self.writers.add(fd)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Registers a callback handler for specified I/O events (read/write) on a file descriptor within an asynchronous event loop, enabling event-driven handling of I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "update_handler", "line_number": 156, "body": "def update_handler(self, fd: Union[int, _Selectable], events: int) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if events & IOLoop.READ:\n            if fd not in self.readers:\n                self.selector_loop.add_reader(fd, self._handle_events, fd, IOLoop.READ)\n                self.readers.add(fd)\n        else:\n            if fd in self.readers:\n                self.selector_loop.remove_reader(fd)\n                self.readers.remove(fd)\n        if events & IOLoop.WRITE:\n            if fd not in self.writers:\n                self.selector_loop.add_writer(fd, self._handle_events, fd, IOLoop.WRITE)\n                self.writers.add(fd)\n        else:\n            if fd in self.writers:\n                self.selector_loop.remove_writer(fd)\n                self.writers.remove(fd)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Core method of BaseAsyncIOLoop that manages registration and deregistration of file descriptors for read and write event notifications, enabling asynchronous I/O event handling in an event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "remove_handler", "line_number": 175, "body": "def remove_handler(self, fd: Union[int, _Selectable]) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if fd not in self.handlers:\n            return\n        if fd in self.readers:\n            self.selector_loop.remove_reader(fd)\n            self.readers.remove(fd)\n        if fd in self.writers:\n            self.selector_loop.remove_writer(fd)\n            self.writers.remove(fd)\n        del self.handlers[fd]", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Utility method of BaseAsyncIOLoop that removes event handlers and associated readers or writers for a given file descriptor, managing asynchronous I/O event monitoring and cleanup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_handle_events", "line_number": 187, "body": "def _handle_events(self, fd: int, events: int) -> None:\n        fileobj, handler_func = self.handlers[fd]\n        handler_func(fileobj, events)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Internal method of BaseAsyncIOLoop that dispatches I/O events to the registered handler function for a given file descriptor, enabling asynchronous event-driven programming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "start", "line_number": 191, "body": "def start(self) -> None:\n        try:\n            old_loop = asyncio.get_event_loop()\n        except (RuntimeError, AssertionError):\n            old_loop = None  # type: ignore\n        try:\n            self._setup_logging()\n            asyncio.set_event_loop(self.asyncio_loop)\n            self.asyncio_loop.run_forever()\n        finally:\n            asyncio.set_event_loop(old_loop)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Starts and runs the asynchronous event loop, managing the loop lifecycle and restoring the previous event loop upon completion. This enables asynchronous task scheduling and execution in applications using asyncio."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "stop", "line_number": 203, "body": "def stop(self) -> None:\n        self.asyncio_loop.stop()", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Stops the asynchronous I/O event loop, halting all ongoing asynchronous operations managed by it. This function is essential for gracefully terminating the event loop's execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "call_at", "line_number": 206, "body": "def call_at(\n        self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> object:\n        # asyncio.call_at supports *args but not **kwargs, so bind them here.\n        # We do not synchronize self.time and asyncio_loop.time, so\n        # convert from absolute to relative.\n        return self.asyncio_loop.call_later(\n            max(0, when - self.time()),\n            self._run_callback,\n            functools.partial(callback, *args, **kwargs),\n        )", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Schedules a callback to run at a specific absolute time on the event loop, supporting both positional and keyword arguments. Enables precise timed execution within asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "remove_timeout", "line_number": 218, "body": "def remove_timeout(self, timeout: object) -> None:\n        timeout.cancel()", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Cancels a scheduled timeout operation within an asynchronous I/O loop, allowing for dynamic management of timed events or tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "add_callback", "line_number": 221, "body": "def add_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        if threading.get_ident() == self._thread_identity:\n            call_soon = self.asyncio_loop.call_soon\n        else:\n            call_soon = self.asyncio_loop.call_soon_threadsafe\n        try:\n            call_soon(self._run_callback, functools.partial(callback, *args, **kwargs))\n        except RuntimeError:\n            # \"Event loop is closed\". Swallow the exception for\n            # consistency with PollIOLoop (and logical consistency\n            # with the fact that we can't guarantee that an\n            # add_callback that completes without error will\n            # eventually execute).\n            pass\n        except AttributeError:\n            # ProactorEventLoop may raise this instead of RuntimeError\n            # if call_soon_threadsafe races with a call to close().\n            # Swallow it too for consistency.\n            pass", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Provides a thread-safe way to schedule callbacks to run soon on the event loop, ensuring execution even from different threads while handling event loop closure gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "add_callback_from_signal", "line_number": 241, "body": "def add_callback_from_signal(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> None:\n        try:\n            self.asyncio_loop.call_soon_threadsafe(\n                self._run_callback, functools.partial(callback, *args, **kwargs)\n            )\n        except RuntimeError:\n            pass", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Provides a thread-safe way to schedule a callback on the event loop from a signal handler or another thread, ensuring the callback runs asynchronously within the loop's context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "run_in_executor", "line_number": 251, "body": "def run_in_executor(\n        self,\n        executor: Optional[concurrent.futures.Executor],\n        func: Callable[..., _T],\n        *args: Any\n    ) -> Awaitable[_T]:\n        return self.asyncio_loop.run_in_executor(executor, func, *args)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Utility method in BaseAsyncIOLoop that schedules a synchronous function to run asynchronously via an executor, allowing non-blocking execution in async programs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "set_default_executor", "line_number": 259, "body": "def set_default_executor(self, executor: concurrent.futures.Executor) -> None:\n        return self.asyncio_loop.set_default_executor(executor)", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Sets the default executor for asynchronous task execution within the BaseAsyncIOLoop, allowing customization of how concurrent operations are run. This enables integration with different thread or process pools for async workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "initialize", "line_number": 278, "body": "def initialize(self, **kwargs: Any) -> None:  # type: ignore\n        super().initialize(asyncio.get_event_loop(), **kwargs)", "is_method": true, "class_name": "AsyncIOMainLoop", "function_description": "Initializes the AsyncIOMainLoop by setting up the asyncio event loop for asynchronous operations. This method enables integration of asyncio's event loop within the main loop framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "initialize", "line_number": 307, "body": "def initialize(self, **kwargs: Any) -> None:  # type: ignore\n        self.is_current = False\n        loop = asyncio.new_event_loop()\n        try:\n            super().initialize(loop, **kwargs)\n        except Exception:\n            # If initialize() does not succeed (taking ownership of the loop),\n            # we have to close it.\n            loop.close()\n            raise", "is_method": true, "class_name": "AsyncIOLoop", "function_description": "Initializes an asynchronous event loop and integrates it into the AsyncIOLoop instance, ensuring proper setup or cleanup on failure. It provides the necessary event loop context for asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "close", "line_number": 318, "body": "def close(self, all_fds: bool = False) -> None:\n        if self.is_current:\n            self.clear_current()\n        super().close(all_fds=all_fds)", "is_method": true, "class_name": "AsyncIOLoop", "function_description": "Closes the current AsyncIOLoop instance, optionally closing all associated file descriptors, and ensures the loop is properly deregistered if it is the current active loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "make_current", "line_number": 323, "body": "def make_current(self) -> None:\n        if not self.is_current:\n            try:\n                self.old_asyncio = asyncio.get_event_loop()\n            except (RuntimeError, AssertionError):\n                self.old_asyncio = None  # type: ignore\n            self.is_current = True\n        asyncio.set_event_loop(self.asyncio_loop)", "is_method": true, "class_name": "AsyncIOLoop", "function_description": "Sets this AsyncIOLoop instance as the current asyncio event loop, preserving the previous loop to manage asynchronous execution context correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_clear_current_hook", "line_number": 332, "body": "def _clear_current_hook(self) -> None:\n        if self.is_current:\n            asyncio.set_event_loop(self.old_asyncio)\n            self.is_current = False", "is_method": true, "class_name": "AsyncIOLoop", "function_description": "Internal method of AsyncIOLoop that resets the current event loop to its previous state, ensuring the correct event loop is restored when this loop is no longer the active one."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "get_event_loop", "line_number": 392, "body": "def get_event_loop(self) -> asyncio.AbstractEventLoop:\n        try:\n            return super().get_event_loop()\n        except (RuntimeError, AssertionError):\n            # This was an AssertionError in Python 3.4.2 (which ships with Debian Jessie)\n            # and changed to a RuntimeError in 3.4.3.\n            # \"There is no current event loop in thread %r\"\n            loop = self.new_event_loop()\n            self.set_event_loop(loop)\n            return loop", "is_method": true, "class_name": "AnyThreadEventLoopPolicy", "function_description": "Provides an event loop for the current thread, creating and setting a new one if none exists, ensuring asynchronous operations have a valid loop to run on."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "__getattribute__", "line_number": 447, "body": "def __getattribute__(self, name: str) -> Any:\n        if name in AddThreadSelectorEventLoop.MY_ATTRIBUTES:\n            return super().__getattribute__(name)\n        return getattr(self._real_loop, name)", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Overrides attribute access to either return specified local attributes or delegate to an internal event loop, enabling controlled attribute management within the AddThreadSelectorEventLoop class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "__del__", "line_number": 483, "body": "def __del__(self) -> None:\n        # If the top-level application code uses asyncio interfaces to\n        # start and stop the event loop, no objects created in Tornado\n        # can get a clean shutdown notification. If we're just left to\n        # be GC'd, we must explicitly close our sockets to avoid\n        # logging warnings.\n        _selector_loops.discard(self)\n        self._waker_r.close()\n        self._waker_w.close()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Destructor method of AddThreadSelectorEventLoop that ensures proper cleanup of resources by closing sockets and removing the event loop from active tracking to prevent warnings during garbage collection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "close", "line_number": 493, "body": "def close(self) -> None:\n        with self._select_cond:\n            self._closing_selector = True\n            self._select_cond.notify()\n        self._wake_selector()\n        self._thread.join()\n        _selector_loops.discard(self)\n        self._waker_r.close()\n        self._waker_w.close()\n        self._real_loop.close()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Method of AddThreadSelectorEventLoop that safely closes the event loop by signaling shutdown, stopping the selector thread, releasing resources, and cleaning up internal state. It ensures orderly termination of asynchronous event processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_wake_selector", "line_number": 504, "body": "def _wake_selector(self) -> None:\n        try:\n            self._waker_w.send(b\"a\")\n        except BlockingIOError:\n            pass", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Internal helper method of AddThreadSelectorEventLoop that attempts to wake the selector by sending a signal, ensuring the event loop can promptly respond to new events without blocking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_consume_waker", "line_number": 510, "body": "def _consume_waker(self) -> None:\n        try:\n            self._waker_r.recv(1024)\n        except BlockingIOError:\n            pass", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Internal helper method of AddThreadSelectorEventLoop that consumes and clears the waker signal to manage event loop wake-ups without blocking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_start_select", "line_number": 516, "body": "def _start_select(self) -> None:\n        # Capture reader and writer sets here in the event loop\n        # thread to avoid any problems with concurrent\n        # modification while the select loop uses them.\n        with self._select_cond:\n            assert self._select_args is None\n            self._select_args = (list(self._readers.keys()), list(self._writers.keys()))\n            self._select_cond.notify()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Internal method of AddThreadSelectorEventLoop that prepares and signals the sets of current reader and writer file descriptors for the select event loop, ensuring thread-safe access during I/O multiplexing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_run_select", "line_number": 525, "body": "def _run_select(self) -> None:\n        while True:\n            with self._select_cond:\n                while self._select_args is None and not self._closing_selector:\n                    self._select_cond.wait()\n                if self._closing_selector:\n                    return\n                assert self._select_args is not None\n                to_read, to_write = self._select_args\n                self._select_args = None\n\n            # We use the simpler interface of the select module instead of\n            # the more stateful interface in the selectors module because\n            # this class is only intended for use on windows, where\n            # select.select is the only option. The selector interface\n            # does not have well-documented thread-safety semantics that\n            # we can rely on so ensuring proper synchronization would be\n            # tricky.\n            try:\n                # On windows, selecting on a socket for write will not\n                # return the socket when there is an error (but selecting\n                # for reads works). Also select for errors when selecting\n                # for writes, and merge the results.\n                #\n                # This pattern is also used in\n                # https://github.com/python/cpython/blob/v3.8.0/Lib/selectors.py#L312-L317\n                rs, ws, xs = select.select(to_read, to_write, to_write)\n                ws = ws + xs\n            except OSError as e:\n                # After remove_reader or remove_writer is called, the file\n                # descriptor may subsequently be closed on the event loop\n                # thread. It's possible that this select thread hasn't\n                # gotten into the select system call by the time that\n                # happens in which case (at least on macOS), select may\n                # raise a \"bad file descriptor\" error. If we get that\n                # error, check and see if we're also being woken up by\n                # polling the waker alone. If we are, just return to the\n                # event loop and we'll get the updated set of file\n                # descriptors on the next iteration. Otherwise, raise the\n                # original error.\n                if e.errno == getattr(errno, \"WSAENOTSOCK\", errno.EBADF):\n                    rs, _, _ = select.select([self._waker_r.fileno()], [], [], 0)\n                    if rs:\n                        ws = []\n                    else:\n                        raise\n                else:\n                    raise\n            self._real_loop.call_soon_threadsafe(self._handle_select, rs, ws)", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Continuously performs thread-safe I/O multiplexing using select on specified read/write sockets, and schedules their handling in the associated event loop. It enables cross-thread socket readiness monitoring and event dispatching on Windows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_handle_select", "line_number": 575, "body": "def _handle_select(\n        self, rs: List[\"_FileDescriptorLike\"], ws: List[\"_FileDescriptorLike\"]\n    ) -> None:\n        for r in rs:\n            self._handle_event(r, self._readers)\n        for w in ws:\n            self._handle_event(w, self._writers)\n        self._start_select()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Internal method of AddThreadSelectorEventLoop that processes ready-to-read and ready-to-write file descriptors by delegating events and then restarts the select loop to continue monitoring I/O readiness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "_handle_event", "line_number": 584, "body": "def _handle_event(\n        self, fd: \"_FileDescriptorLike\", cb_map: Dict[\"_FileDescriptorLike\", Callable],\n    ) -> None:\n        try:\n            callback = cb_map[fd]\n        except KeyError:\n            return\n        callback()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Internal method of AddThreadSelectorEventLoop that executes the callback associated with a given file descriptor if it exists in the callback map; it manages event handling by invoking relevant functions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "add_reader", "line_number": 593, "body": "def add_reader(\n        self, fd: \"_FileDescriptorLike\", callback: Callable[..., None], *args: Any\n    ) -> None:\n        self._readers[fd] = functools.partial(callback, *args)\n        self._wake_selector()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Adds a file descriptor with its callback to be monitored for readiness, allowing the event loop to trigger the callback when the descriptor is ready for reading. This enables asynchronous I/O event handling within the AddThreadSelectorEventLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "add_writer", "line_number": 599, "body": "def add_writer(\n        self, fd: \"_FileDescriptorLike\", callback: Callable[..., None], *args: Any\n    ) -> None:\n        self._writers[fd] = functools.partial(callback, *args)\n        self._wake_selector()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Adds a file descriptor and its associated callback to the event loop's writer set, enabling asynchronous write event handling and ensuring the selector is notified to process the new writer."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "remove_reader", "line_number": 605, "body": "def remove_reader(self, fd: \"_FileDescriptorLike\") -> None:\n        del self._readers[fd]\n        self._wake_selector()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Removes a file descriptor from the set of read event watchers in the AddThreadSelectorEventLoop and signals the event loop to update its internal selector state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "remove_writer", "line_number": 609, "body": "def remove_writer(self, fd: \"_FileDescriptorLike\") -> None:\n        del self._writers[fd]\n        self._wake_selector()", "is_method": true, "class_name": "AddThreadSelectorEventLoop", "function_description": "Removes a registered writer identified by the given file descriptor from the event loop and triggers the selector to update its state accordingly. This enables dynamic management of writable event sources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/platform/asyncio.py", "function": "assign_thread_identity", "line_number": 120, "body": "def assign_thread_identity() -> None:\n            self._thread_identity = threading.get_ident()", "is_method": true, "class_name": "BaseAsyncIOLoop", "function_description": "Sets the current thread's unique identifier to track execution context within the asynchronous IO loop. This enables thread-specific operations or checks in async runtime management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "setUp", "line_number": 24, "body": "def setUp(self):\n        super().setUp()\n        self.history = []", "is_method": true, "class_name": "ConditionTest", "function_description": "Initializes the testing environment by calling the parent setup method and preparing an empty history list to track events or states during tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "record_done", "line_number": 28, "body": "def record_done(self, future, key):\n        \"\"\"Record the resolution of a Future returned by Condition.wait.\"\"\"\n\n        def callback(_):\n            if not future.result():\n                # wait() resolved to False, meaning it timed out.\n                self.history.append(\"timeout\")\n            else:\n                self.history.append(key)\n\n        future.add_done_callback(callback)", "is_method": true, "class_name": "ConditionTest", "function_description": "Records the outcome of a Future from Condition.wait by appending either a timeout note or a specified key to the history, tracking whether the wait completed or timed out."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "loop_briefly", "line_number": 40, "body": "def loop_briefly(self):\n        \"\"\"Run all queued callbacks on the IOLoop.\n\n        In these tests, this method is used after calling notify() to\n        preserve the pre-5.0 behavior in which callbacks ran\n        synchronously.\n        \"\"\"\n        self.io_loop.add_callback(self.stop)\n        self.wait()", "is_method": true, "class_name": "ConditionTest", "function_description": "Utility method in ConditionTest that processes all pending IOLoop callbacks synchronously, ensuring pre-5.0 style immediate callback execution during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_repr", "line_number": 50, "body": "def test_repr(self):\n        c = locks.Condition()\n        self.assertIn(\"Condition\", repr(c))\n        self.assertNotIn(\"waiters\", repr(c))\n        c.wait()\n        self.assertIn(\"waiters\", repr(c))", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests that the string representation of a Condition object reflects its state correctly, showing waiter information only when threads are waiting. This supports debugging and introspection of concurrency primitives."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_notify", "line_number": 58, "body": "def test_notify(self):\n        c = locks.Condition()\n        self.io_loop.call_later(0.01, c.notify)\n        yield c.wait()", "is_method": true, "class_name": "ConditionTest", "function_description": "Utility method in ConditionTest that schedules a notification shortly and waits for it, demonstrating asynchronous synchronization using condition variables."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_notify_1", "line_number": 63, "body": "def test_notify_1(self):\n        c = locks.Condition()\n        self.record_done(c.wait(), \"wait1\")\n        self.record_done(c.wait(), \"wait2\")\n        c.notify(1)\n        self.loop_briefly()\n        self.history.append(\"notify1\")\n        c.notify(1)\n        self.loop_briefly()\n        self.history.append(\"notify2\")\n        self.assertEqual([\"wait1\", \"notify1\", \"wait2\", \"notify2\"], self.history)", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests the behavior of a Condition's notify method, verifying that notifying one waiter at a time wakes them in sequence and that the notification order matches expected wait and notify calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_notify_n", "line_number": 75, "body": "def test_notify_n(self):\n        c = locks.Condition()\n        for i in range(6):\n            self.record_done(c.wait(), i)\n\n        c.notify(3)\n        self.loop_briefly()\n\n        # Callbacks execute in the order they were registered.\n        self.assertEqual(list(range(3)), self.history)\n        c.notify(1)\n        self.loop_briefly()\n        self.assertEqual(list(range(4)), self.history)\n        c.notify(2)\n        self.loop_briefly()\n        self.assertEqual(list(range(6)), self.history)", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests the notification behavior of a condition variable, verifying that waiting threads are notified and callbacks execute in the order they were registered. Useful for ensuring correct concurrency signaling in synchronization primitives."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_notify_all", "line_number": 92, "body": "def test_notify_all(self):\n        c = locks.Condition()\n        for i in range(4):\n            self.record_done(c.wait(), i)\n\n        c.notify_all()\n        self.loop_briefly()\n        self.history.append(\"notify_all\")\n\n        # Callbacks execute in the order they were registered.\n        self.assertEqual(list(range(4)) + [\"notify_all\"], self.history)", "is_method": true, "class_name": "ConditionTest", "function_description": "Test method in ConditionTest that verifies notify_all awakens all waiting callbacks in order, ensuring correct callback execution sequence after notification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_wait_timeout", "line_number": 105, "body": "def test_wait_timeout(self):\n        c = locks.Condition()\n        wait = c.wait(timedelta(seconds=0.01))\n        self.io_loop.call_later(0.02, c.notify)  # Too late.\n        yield gen.sleep(0.03)\n        self.assertFalse((yield wait))", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests that a condition variable's wait method correctly times out when notification occurs after the specified timeout period. Useful for verifying timeout behavior in asynchronous synchronization primitives."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_wait_timeout_preempted", "line_number": 113, "body": "def test_wait_timeout_preempted(self):\n        c = locks.Condition()\n\n        # This fires before the wait times out.\n        self.io_loop.call_later(0.01, c.notify)\n        wait = c.wait(timedelta(seconds=0.02))\n        yield gen.sleep(0.03)\n        yield wait", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests that a Condition's wait method correctly returns early if notified before the specified timeout, validating asynchronous synchronization behavior with timeout preemption."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_notify_all_with_timeout", "line_number": 147, "body": "def test_notify_all_with_timeout(self):\n        c = locks.Condition()\n        self.record_done(c.wait(), 0)\n        self.record_done(c.wait(timedelta(seconds=0.01)), 1)\n        self.record_done(c.wait(), 2)\n\n        # Wait for callback 1 to time out.\n        yield gen.sleep(0.02)\n        self.assertEqual([\"timeout\"], self.history)\n\n        c.notify_all()\n        yield\n        self.assertEqual([\"timeout\", 0, 2], self.history)", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests the Condition class's wait and notify_all behavior with and without timeouts, verifying callback order and timeout handling within asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_nested_notify", "line_number": 162, "body": "def test_nested_notify(self):\n        # Ensure no notifications lost, even if notify() is reentered by a\n        # waiter calling notify().\n        c = locks.Condition()\n\n        # Three waiters.\n        futures = [asyncio.ensure_future(c.wait()) for _ in range(3)]\n\n        # First and second futures resolved. Second future reenters notify(),\n        # resolving third future.\n        futures[1].add_done_callback(lambda _: c.notify())\n        c.notify(2)\n        yield\n        self.assertTrue(all(f.done() for f in futures))", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests that nested calls to notify on a Condition object correctly wake all waiting coroutines without losing notifications, ensuring proper handling of reentrant notify scenarios in asynchronous synchronization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_garbage_collection", "line_number": 178, "body": "def test_garbage_collection(self):\n        # Test that timed-out waiters are occasionally cleaned from the queue.\n        c = locks.Condition()\n        for _ in range(101):\n            c.wait(timedelta(seconds=0.01))\n\n        future = asyncio.ensure_future(c.wait())\n        self.assertEqual(102, len(c._waiters))\n\n        # Let first 101 waiters time out, triggering a collection.\n        yield gen.sleep(0.02)\n        self.assertEqual(1, len(c._waiters))\n\n        # Final waiter is still active.\n        self.assertFalse(future.done())\n        c.notify()\n        self.assertTrue(future.done())", "is_method": true, "class_name": "ConditionTest", "function_description": "Tests that timed-out waiters in a Condition's queue are properly cleaned up, ensuring resource management and correct notification behavior in asynchronous waiting scenarios. Useful for validating concurrency control and garbage collection in asynchronous conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_repr", "line_number": 198, "body": "def test_repr(self):\n        event = locks.Event()\n        self.assertTrue(\"clear\" in str(event))\n        self.assertFalse(\"set\" in str(event))\n        event.set()\n        self.assertFalse(\"clear\" in str(event))\n        self.assertTrue(\"set\" in str(event))", "is_method": true, "class_name": "EventTest", "function_description": "Tests the string representation of an Event object to verify it correctly reflects the event\u2019s current state (set or clear). It ensures accurate status display for debugging or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_event", "line_number": 206, "body": "def test_event(self):\n        e = locks.Event()\n        future_0 = asyncio.ensure_future(e.wait())\n        e.set()\n        future_1 = asyncio.ensure_future(e.wait())\n        e.clear()\n        future_2 = asyncio.ensure_future(e.wait())\n\n        self.assertTrue(future_0.done())\n        self.assertTrue(future_1.done())\n        self.assertFalse(future_2.done())", "is_method": true, "class_name": "EventTest", "function_description": "Tests the behavior of an Event synchronization primitive, verifying that waiting futures complete when the event is set and remain pending when the event is cleared. It validates correct event signaling and waiting functionality in asynchronous contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_event_timeout", "line_number": 219, "body": "def test_event_timeout(self):\n        e = locks.Event()\n        with self.assertRaises(TimeoutError):\n            yield e.wait(timedelta(seconds=0.01))\n\n        # After a timed-out waiter, normal operation works.\n        self.io_loop.add_timeout(timedelta(seconds=0.01), e.set)\n        yield e.wait(timedelta(seconds=1))", "is_method": true, "class_name": "EventTest", "function_description": "Tests that the Event class correctly raises a TimeoutError when waiting times out and verifies normal operation resumes afterward. Useful for validating event wait timeout behavior in asynchronous environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_event_set_multiple", "line_number": 228, "body": "def test_event_set_multiple(self):\n        e = locks.Event()\n        e.set()\n        e.set()\n        self.assertTrue(e.is_set())", "is_method": true, "class_name": "EventTest", "function_description": "Unit test verifying that the Event class correctly maintains its set state after multiple set calls, ensuring reliable event signaling behavior in concurrent programming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_event_wait_clear", "line_number": 234, "body": "def test_event_wait_clear(self):\n        e = locks.Event()\n        f0 = asyncio.ensure_future(e.wait())\n        e.clear()\n        f1 = asyncio.ensure_future(e.wait())\n        e.set()\n        self.assertTrue(f0.done())\n        self.assertTrue(f1.done())", "is_method": true, "class_name": "EventTest", "function_description": "Test method in EventTest that verifies an event\u2019s wait functionality responds correctly to clear and set operations, ensuring waiting tasks complete when the event state changes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_negative_value", "line_number": 245, "body": "def test_negative_value(self):\n        self.assertRaises(ValueError, locks.Semaphore, value=-1)", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Test method in SemaphoreTest that verifies creating a semaphore with a negative initial value raises a ValueError, ensuring correct input validation for semaphore initialization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_repr", "line_number": 248, "body": "def test_repr(self):\n        sem = locks.Semaphore()\n        self.assertIn(\"Semaphore\", repr(sem))\n        self.assertIn(\"unlocked,value:1\", repr(sem))\n        sem.acquire()\n        self.assertIn(\"locked\", repr(sem))\n        self.assertNotIn(\"waiters\", repr(sem))\n        sem.acquire()\n        self.assertIn(\"waiters\", repr(sem))", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Test method ensuring the Semaphore class's string representation accurately reflects its lock state and waiting threads for debugging and status monitoring purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire", "line_number": 258, "body": "def test_acquire(self):\n        sem = locks.Semaphore()\n        f0 = asyncio.ensure_future(sem.acquire())\n        self.assertTrue(f0.done())\n\n        # Wait for release().\n        f1 = asyncio.ensure_future(sem.acquire())\n        self.assertFalse(f1.done())\n        f2 = asyncio.ensure_future(sem.acquire())\n        sem.release()\n        self.assertTrue(f1.done())\n        self.assertFalse(f2.done())\n        sem.release()\n        self.assertTrue(f2.done())\n\n        sem.release()\n        # Now acquire() is instant.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())\n        self.assertEqual(0, len(sem._waiters))", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Tests the asynchronous semaphore's acquire and release behavior, verifying immediate and delayed acquisition of permits to ensure correct synchronization handling in concurrent contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_timeout", "line_number": 279, "body": "def test_acquire_timeout(self):\n        sem = locks.Semaphore(2)\n        yield sem.acquire()\n        yield sem.acquire()\n        acquire = sem.acquire(timedelta(seconds=0.01))\n        self.io_loop.call_later(0.02, sem.release)  # Too late.\n        yield gen.sleep(0.3)\n        with self.assertRaises(gen.TimeoutError):\n            yield acquire\n\n        sem.acquire()\n        f = asyncio.ensure_future(sem.acquire())\n        self.assertFalse(f.done())\n        sem.release()\n        self.assertTrue(f.done())", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Tests the Semaphore's acquire method for correct timeout behavior, ensuring it raises TimeoutError when acquisition takes too long and properly completes when released. It verifies semaphore synchronization under timeout conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_timeout_preempted", "line_number": 296, "body": "def test_acquire_timeout_preempted(self):\n        sem = locks.Semaphore(1)\n        yield sem.acquire()\n\n        # This fires before the wait times out.\n        self.io_loop.call_later(0.01, sem.release)\n        acquire = sem.acquire(timedelta(seconds=0.02))\n        yield gen.sleep(0.03)\n        yield acquire", "is_method": true, "class_name": "SemaphoreTest", "function_description": "This test method verifies that a semaphore acquisition with a timeout is correctly preempted by a release call before the timeout expires, ensuring proper semaphore behavior under timing conditions. It is useful for validating concurrency controls in asynchronous code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_release_unacquired", "line_number": 306, "body": "def test_release_unacquired(self):\n        # Unbounded releases are allowed, and increment the semaphore's value.\n        sem = locks.Semaphore()\n        sem.release()\n        sem.release()\n\n        # Now the counter is 3. We can acquire three times before blocking.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())\n        self.assertFalse(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Tests that releasing an unacquired semaphore correctly increments its counter, allowing subsequent acquires up to that count before blocking. Useful for verifying semaphore behavior in async synchronization scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_garbage_collection", "line_number": 319, "body": "def test_garbage_collection(self):\n        # Test that timed-out waiters are occasionally cleaned from the queue.\n        sem = locks.Semaphore(value=0)\n        futures = [\n            asyncio.ensure_future(sem.acquire(timedelta(seconds=0.01)))\n            for _ in range(101)\n        ]\n\n        future = asyncio.ensure_future(sem.acquire())\n        self.assertEqual(102, len(sem._waiters))\n\n        # Let first 101 waiters time out, triggering a collection.\n        yield gen.sleep(0.02)\n        self.assertEqual(1, len(sem._waiters))\n\n        # Final waiter is still active.\n        self.assertFalse(future.done())\n        sem.release()\n        self.assertTrue(future.done())\n\n        # Prevent \"Future exception was never retrieved\" messages.\n        for future in futures:\n            self.assertRaises(TimeoutError, future.result)", "is_method": true, "class_name": "SemaphoreTest", "function_description": "Tests that the Semaphore correctly removes timed-out waiters from its queue while preserving active ones, ensuring proper cleanup and synchronization behavior under timeout conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager", "line_number": 346, "body": "def test_context_manager(self):\n        sem = locks.Semaphore()\n        with (yield sem.acquire()) as yielded:\n            self.assertTrue(yielded is None)\n\n        # Semaphore was released and can be acquired again.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Tests that the semaphore's asynchronous context manager correctly acquires and releases the lock, ensuring it can be reacquired afterward. This verifies proper semaphore behavior in async context management scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_async_await", "line_number": 355, "body": "def test_context_manager_async_await(self):\n        # Repeat the above test using 'async with'.\n        sem = locks.Semaphore()\n\n        async def f():\n            async with sem as yielded:\n                self.assertTrue(yielded is None)\n\n        yield f()\n\n        # Semaphore was released and can be acquired again.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Tests asynchronous context manager functionality of the Semaphore class, ensuring correct semaphore acquisition and release using 'async with' syntax in async-await code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_exception", "line_number": 369, "body": "def test_context_manager_exception(self):\n        sem = locks.Semaphore()\n        with self.assertRaises(ZeroDivisionError):\n            with (yield sem.acquire()):\n                1 / 0\n\n        # Semaphore was released and can be acquired again.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Test method verifying that the semaphore context manager properly releases the semaphore after an exception occurs within its managed block, ensuring subsequent acquisitions are possible."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_timeout", "line_number": 379, "body": "def test_context_manager_timeout(self):\n        sem = locks.Semaphore()\n        with (yield sem.acquire(timedelta(seconds=0.01))):\n            pass\n\n        # Semaphore was released and can be acquired again.\n        self.assertTrue(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Tests that the Semaphore context manager correctly releases the semaphore after a timeout, allowing it to be acquired again immediately. This verifies proper timeout and release behavior in asynchronous semaphore usage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_timeout_error", "line_number": 388, "body": "def test_context_manager_timeout_error(self):\n        sem = locks.Semaphore(value=0)\n        with self.assertRaises(gen.TimeoutError):\n            with (yield sem.acquire(timedelta(seconds=0.01))):\n                pass\n\n        # Counter is still 0.\n        self.assertFalse(asyncio.ensure_future(sem.acquire()).done())", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "This test function verifies that acquiring a semaphore times out correctly and raises a TimeoutError, ensuring proper semaphore behavior under timeout conditions in asynchronous contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_contended", "line_number": 398, "body": "def test_context_manager_contended(self):\n        sem = locks.Semaphore()\n        history = []\n\n        @gen.coroutine\n        def f(index):\n            with (yield sem.acquire()):\n                history.append(\"acquired %d\" % index)\n                yield gen.sleep(0.01)\n                history.append(\"release %d\" % index)\n\n        yield [f(i) for i in range(2)]\n\n        expected_history = []\n        for i in range(2):\n            expected_history.extend([\"acquired %d\" % i, \"release %d\" % i])\n\n        self.assertEqual(expected_history, history)", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Tests that the Semaphore context manager correctly serializes access among concurrent coroutines, ensuring mutual exclusion and proper acquisition and release order under contention."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_yield_sem", "line_number": 418, "body": "def test_yield_sem(self):\n        # Ensure we catch a \"with (yield sem)\", which should be\n        # \"with (yield sem.acquire())\".\n        with self.assertRaises(gen.BadYieldError):\n            with (yield locks.Semaphore()):\n                pass", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Tests that using a Semaphore instance directly as a context manager with yield raises a BadYieldError, ensuring correct usage requires yielding Semaphore's acquire method. It verifies proper asynchronous semaphore context management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_misuse", "line_number": 425, "body": "def test_context_manager_misuse(self):\n        # Ensure we catch a \"with sem\", which should be\n        # \"with (yield sem.acquire())\".\n        with self.assertRaises(RuntimeError):\n            with locks.Semaphore():\n                pass", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "Test method in SemaphoreContextManagerTest that verifies using Semaphore as a context manager without proper acquisition raises a RuntimeError, ensuring correct usage patterns are enforced."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_release_unacquired", "line_number": 434, "body": "def test_release_unacquired(self):\n        sem = locks.BoundedSemaphore()\n        self.assertRaises(ValueError, sem.release)\n        # Value is 0.\n        sem.acquire()\n        # Block on acquire().\n        future = asyncio.ensure_future(sem.acquire())\n        self.assertFalse(future.done())\n        sem.release()\n        self.assertTrue(future.done())\n        # Value is 1.\n        sem.release()\n        self.assertRaises(ValueError, sem.release)", "is_method": true, "class_name": "BoundedSemaphoreTest", "function_description": "Tests that BoundedSemaphore correctly raises errors when releasing more times than acquired and properly unblocks tasks waiting to acquire. It verifies the semaphore\u2019s behavior under over-release and concurrent acquire scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_repr", "line_number": 450, "body": "def test_repr(self):\n        lock = locks.Lock()\n        # No errors.\n        repr(lock)\n        lock.acquire()\n        repr(lock)", "is_method": true, "class_name": "LockTests", "function_description": "Test method verifying that the string representation of a Lock object can be generated both before and after acquiring the lock without errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_release", "line_number": 457, "body": "def test_acquire_release(self):\n        lock = locks.Lock()\n        self.assertTrue(asyncio.ensure_future(lock.acquire()).done())\n        future = asyncio.ensure_future(lock.acquire())\n        self.assertFalse(future.done())\n        lock.release()\n        self.assertTrue(future.done())", "is_method": true, "class_name": "LockTests", "function_description": "Test method that verifies correct acquisition and release behavior of an asynchronous lock, ensuring it properly manages lock state and coroutine waiting status during concurrent access."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_fifo", "line_number": 466, "body": "def test_acquire_fifo(self):\n        lock = locks.Lock()\n        self.assertTrue(asyncio.ensure_future(lock.acquire()).done())\n        N = 5\n        history = []\n\n        @gen.coroutine\n        def f(idx):\n            with (yield lock.acquire()):\n                history.append(idx)\n\n        futures = [f(i) for i in range(N)]\n        self.assertFalse(any(future.done() for future in futures))\n        lock.release()\n        yield futures\n        self.assertEqual(list(range(N)), history)", "is_method": true, "class_name": "LockTests", "function_description": "Tests that the Lock class correctly enforces first-in-first-out (FIFO) order when acquiring the lock, ensuring queued tasks obtain the lock strictly in request sequence."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_fifo_async_with", "line_number": 484, "body": "def test_acquire_fifo_async_with(self):\n        # Repeat the above test using `async with lock:`\n        # instead of `with (yield lock.acquire()):`.\n        lock = locks.Lock()\n        self.assertTrue(asyncio.ensure_future(lock.acquire()).done())\n        N = 5\n        history = []\n\n        async def f(idx):\n            async with lock:\n                history.append(idx)\n\n        futures = [f(i) for i in range(N)]\n        lock.release()\n        yield futures\n        self.assertEqual(list(range(N)), history)", "is_method": true, "class_name": "LockTests", "function_description": "Tests that the asynchronous FIFO lock correctly manages concurrent access using async context management, ensuring tasks acquire the lock in order and update shared state as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_acquire_timeout", "line_number": 502, "body": "def test_acquire_timeout(self):\n        lock = locks.Lock()\n        lock.acquire()\n        with self.assertRaises(gen.TimeoutError):\n            yield lock.acquire(timeout=timedelta(seconds=0.01))\n\n        # Still locked.\n        self.assertFalse(asyncio.ensure_future(lock.acquire()).done())", "is_method": true, "class_name": "LockTests", "function_description": "Tests that acquiring a lock with a timeout raises a TimeoutError if the lock is already held, ensuring the lock correctly handles acquisition timeouts. This method verifies the Lock class's timeout behavior under contention."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_multi_release", "line_number": 511, "body": "def test_multi_release(self):\n        lock = locks.Lock()\n        self.assertRaises(RuntimeError, lock.release)\n        lock.acquire()\n        lock.release()\n        self.assertRaises(RuntimeError, lock.release)", "is_method": true, "class_name": "LockTests", "function_description": "Tests that the Lock class raises errors when releasing an unacquired or already released lock, verifying correct lock acquisition and release behavior. It ensures proper usage enforcement of lock release operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_yield_lock", "line_number": 519, "body": "def test_yield_lock(self):\n        # Ensure we catch a \"with (yield lock)\", which should be\n        # \"with (yield lock.acquire())\".\n        with self.assertRaises(gen.BadYieldError):\n            with (yield locks.Lock()):\n                pass", "is_method": true, "class_name": "LockTests", "function_description": "Test method in LockTests that verifies using a yield expression improperly with a lock raises a specific BadYieldError exception. It ensures correct coroutine usage when acquiring locks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "test_context_manager_misuse", "line_number": 526, "body": "def test_context_manager_misuse(self):\n        # Ensure we catch a \"with lock\", which should be\n        # \"with (yield lock.acquire())\".\n        with self.assertRaises(RuntimeError):\n            with locks.Lock():\n                pass", "is_method": true, "class_name": "LockTests", "function_description": "Test method in LockTests that verifies misuse of the lock context manager raises a RuntimeError, ensuring correct lock acquisition syntax within context blocks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locks_test.py", "function": "f", "line_number": 403, "body": "def f(index):\n            with (yield sem.acquire()):\n                history.append(\"acquired %d\" % index)\n                yield gen.sleep(0.01)\n                history.append(\"release %d\" % index)", "is_method": true, "class_name": "SemaphoreContextManagerTest", "function_description": "This generator function manages semaphore acquisition and release around a timed operation, recording the acquisition and release events with an index for concurrency testing or synchronization tracking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "all", "line_number": 57, "body": "def all():\n    return unittest.defaultTestLoader.loadTestsFromNames(TEST_MODULES)", "is_method": false, "function_description": "Load and return all unittest test cases specified in predefined test modules for execution. This function simplifies running a full suite of tests by aggregating them from multiple sources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "test_runner_factory", "line_number": 61, "body": "def test_runner_factory(stderr):\n    class TornadoTextTestRunner(unittest.TextTestRunner):\n        def __init__(self, *args, **kwargs):\n            kwargs[\"stream\"] = stderr\n            super().__init__(*args, **kwargs)\n\n        def run(self, test):\n            result = super().run(test)\n            if result.skipped:\n                skip_reasons = set(reason for (test, reason) in result.skipped)\n                self.stream.write(  # type: ignore\n                    textwrap.fill(\n                        \"Some tests were skipped because: %s\"\n                        % \", \".join(sorted(skip_reasons))\n                    )\n                )\n                self.stream.write(\"\\n\")  # type: ignore\n            return result\n\n    return TornadoTextTestRunner", "is_method": false, "function_description": "Factory function that creates a custom unittest runner class which directs output to a specified stream and reports skipped test reasons after running tests. It enables tailored test result handling and reporting in different output environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "main", "line_number": 113, "body": "def main():\n    # Be strict about most warnings (This is set in our test running\n    # scripts to catch import-time warnings, but set it again here to\n    # be sure). This also turns on warnings that are ignored by\n    # default, including DeprecationWarnings and python 3.2's\n    # ResourceWarnings.\n    warnings.filterwarnings(\"error\")\n    # setuptools sometimes gives ImportWarnings about things that are on\n    # sys.path even if they're not being used.\n    warnings.filterwarnings(\"ignore\", category=ImportWarning)\n    # Tornado generally shouldn't use anything deprecated, but some of\n    # our dependencies do (last match wins).\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    warnings.filterwarnings(\"error\", category=DeprecationWarning, module=r\"tornado\\..*\")\n    warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n    warnings.filterwarnings(\n        \"error\", category=PendingDeprecationWarning, module=r\"tornado\\..*\"\n    )\n    # The unittest module is aggressive about deprecating redundant methods,\n    # leaving some without non-deprecated spellings that work on both\n    # 2.7 and 3.2\n    warnings.filterwarnings(\n        \"ignore\", category=DeprecationWarning, message=\"Please use assert.* instead\"\n    )\n    warnings.filterwarnings(\n        \"ignore\",\n        category=PendingDeprecationWarning,\n        message=\"Please use assert.* instead\",\n    )\n    # Twisted 15.0.0 triggers some warnings on py3 with -bb.\n    warnings.filterwarnings(\"ignore\", category=BytesWarning, module=r\"twisted\\..*\")\n    if (3,) < sys.version_info < (3, 6):\n        # Prior to 3.6, async ResourceWarnings were rather noisy\n        # and even\n        # `python3.4 -W error -c 'import asyncio; asyncio.get_event_loop()'`\n        # would generate a warning.\n        warnings.filterwarnings(\n            \"ignore\", category=ResourceWarning, module=r\"asyncio\\..*\"\n        )\n    # This deprecation warning is introduced in Python 3.8 and is\n    # triggered by pycurl. Unforunately, because it is raised in the C\n    # layer it can't be filtered by module and we must match the\n    # message text instead (Tornado's C module uses PY_SSIZE_T_CLEAN\n    # so it's not at risk of running into this issue).\n    warnings.filterwarnings(\n        \"ignore\",\n        category=DeprecationWarning,\n        message=\"PY_SSIZE_T_CLEAN will be required\",\n    )\n\n    logging.getLogger(\"tornado.access\").setLevel(logging.CRITICAL)\n\n    define(\n        \"httpclient\",\n        type=str,\n        default=None,\n        callback=lambda s: AsyncHTTPClient.configure(\n            s, defaults=dict(allow_ipv6=False)\n        ),\n    )\n    define(\"httpserver\", type=str, default=None, callback=HTTPServer.configure)\n    define(\"resolver\", type=str, default=None, callback=Resolver.configure)\n    define(\n        \"debug_gc\",\n        type=str,\n        multiple=True,\n        help=\"A comma-separated list of gc module debug constants, \"\n        \"e.g. DEBUG_STATS or DEBUG_COLLECTABLE,DEBUG_OBJECTS\",\n        callback=lambda values: gc.set_debug(\n            reduce(operator.or_, (getattr(gc, v) for v in values))\n        ),\n    )\n    define(\n        \"fail-if-logs\",\n        default=True,\n        help=\"If true, fail the tests if any log output is produced (unless captured by ExpectLog)\",\n    )\n\n    def set_locale(x):\n        locale.setlocale(locale.LC_ALL, x)\n\n    define(\"locale\", type=str, default=None, callback=set_locale)\n\n    log_counter = LogCounter()\n    add_parse_callback(lambda: logging.getLogger().handlers[0].addFilter(log_counter))\n\n    # Certain errors (especially \"unclosed resource\" errors raised in\n    # destructors) go directly to stderr instead of logging. Count\n    # anything written by anything but the test runner as an error.\n    orig_stderr = sys.stderr\n    counting_stderr = CountingStderr(orig_stderr)\n    sys.stderr = counting_stderr  # type: ignore\n\n    import tornado.testing\n\n    kwargs = {}\n\n    # HACK:  unittest.main will make its own changes to the warning\n    # configuration, which may conflict with the settings above\n    # or command-line flags like -bb.  Passing warnings=False\n    # suppresses this behavior, although this looks like an implementation\n    # detail.  http://bugs.python.org/issue15626\n    kwargs[\"warnings\"] = False\n\n    kwargs[\"testRunner\"] = test_runner_factory(orig_stderr)\n    try:\n        tornado.testing.main(**kwargs)\n    finally:\n        # The tests should run clean; consider it a failure if they\n        # logged anything at info level or above.\n        if (\n            log_counter.info_count > 0\n            or log_counter.warning_count > 0\n            or log_counter.error_count > 0\n            or counting_stderr.byte_count > 0\n        ):\n            logging.error(\n                \"logged %d infos, %d warnings, %d errors, and %d bytes to stderr\",\n                log_counter.info_count,\n                log_counter.warning_count,\n                log_counter.error_count,\n                counting_stderr.byte_count,\n            )\n            if options.fail_if_logs:\n                sys.exit(1)", "is_method": false, "function_description": "Function that configures strict warning and logging behavior, sets runtime options, and runs Tornado test suites while monitoring for unexpected log outputs or errors during test execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "filter", "line_number": 90, "body": "def filter(self, record):\n        if record.levelno >= logging.ERROR:\n            self.error_count += 1\n        elif record.levelno >= logging.WARNING:\n            self.warning_count += 1\n        elif record.levelno >= logging.INFO:\n            self.info_count += 1\n        return True", "is_method": true, "class_name": "LogCounter", "function_description": "Core method of LogCounter that processes log records to count occurrences by severity level (info, warning, error), enabling tracking of log event frequencies during runtime."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "write", "line_number": 105, "body": "def write(self, data):\n        self.byte_count += len(data)\n        return self.real.write(data)", "is_method": true, "class_name": "CountingStderr", "function_description": "Method of CountingStderr that writes data to an underlying stream while tracking the total number of bytes written. Useful for monitoring output size during streaming operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "flush", "line_number": 109, "body": "def flush(self):\n        return self.real.flush()", "is_method": true, "class_name": "CountingStderr", "function_description": "Method of CountingStderr that flushes the underlying stream, ensuring all buffered output is written immediately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "set_locale", "line_number": 191, "body": "def set_locale(x):\n        locale.setlocale(locale.LC_ALL, x)", "is_method": false, "function_description": "Sets the program's locale settings to the specified value, affecting formatting of dates, numbers, and strings system-wide. Useful for adapting applications to different regional settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/runtests.py", "function": "run", "line_number": 67, "body": "def run(self, test):\n            result = super().run(test)\n            if result.skipped:\n                skip_reasons = set(reason for (test, reason) in result.skipped)\n                self.stream.write(  # type: ignore\n                    textwrap.fill(\n                        \"Some tests were skipped because: %s\"\n                        % \", \".join(sorted(skip_reasons))\n                    )\n                )\n                self.stream.write(\"\\n\")  # type: ignore\n            return result", "is_method": true, "class_name": "TornadoTextTestRunner", "function_description": "Overrides the test runner to execute tests and report any skip reasons in the output stream. It enhances test result reporting by summarizing why tests were skipped."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "get_app", "line_number": 24, "body": "def get_app(self):\n        class ProcessHandler(RequestHandler):\n            def get(self):\n                if self.get_argument(\"exit\", None):\n                    # must use os._exit instead of sys.exit so unittest's\n                    # exception handler doesn't catch it\n                    os._exit(int(self.get_argument(\"exit\")))\n                if self.get_argument(\"signal\", None):\n                    os.kill(os.getpid(), int(self.get_argument(\"signal\")))\n                self.write(str(os.getpid()))\n\n        return Application([(\"/\", ProcessHandler)])", "is_method": true, "class_name": "ProcessTest", "function_description": "Provides a Tornado web application that handles HTTP GET requests to trigger process actions like exiting or sending signals, or returning the current process ID. Useful for testing and controlling process behavior in a web-based environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "tearDown", "line_number": 37, "body": "def tearDown(self):\n        if task_id() is not None:\n            # We're in a child process, and probably got to this point\n            # via an uncaught exception.  If we return now, both\n            # processes will continue with the rest of the test suite.\n            # Exit now so the parent process will restart the child\n            # (since we don't have a clean way to signal failure to\n            # the parent that won't restart)\n            logging.error(\"aborting child process from tearDown\")\n            logging.shutdown()\n            os._exit(1)\n        # In the surviving process, clear the alarm we set earlier\n        signal.alarm(0)\n        super().tearDown()", "is_method": true, "class_name": "ProcessTest", "function_description": "Terminates a child test process on failure to prevent continuation, while clearing any set alarms and performing standard teardown in the main process. Ensures proper test isolation and failure handling in multiprocessing environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_multi_process", "line_number": 52, "body": "def test_multi_process(self):\n        # This test doesn't work on twisted because we use the global\n        # reactor and don't restore it to a sane state after the fork\n        # (asyncio has the same issue, but we have a special case in\n        # place for it).\n        with ExpectLog(\n            gen_log, \"(Starting .* processes|child .* exited|uncaught exception)\"\n        ):\n            sock, port = bind_unused_port()\n\n            def get_url(path):\n                return \"http://127.0.0.1:%d%s\" % (port, path)\n\n            # ensure that none of these processes live too long\n            signal.alarm(5)  # master process\n            try:\n                id = fork_processes(3, max_restarts=3)\n                self.assertTrue(id is not None)\n                signal.alarm(5)  # child processes\n            except SystemExit as e:\n                # if we exit cleanly from fork_processes, all the child processes\n                # finished with status 0\n                self.assertEqual(e.code, 0)\n                self.assertTrue(task_id() is None)\n                sock.close()\n                return\n            try:\n                if asyncio is not None:\n                    # Reset the global asyncio event loop, which was put into\n                    # a broken state by the fork.\n                    asyncio.set_event_loop(asyncio.new_event_loop())\n                if id in (0, 1):\n                    self.assertEqual(id, task_id())\n                    server = HTTPServer(self.get_app())\n                    server.add_sockets([sock])\n                    IOLoop.current().start()\n                elif id == 2:\n                    self.assertEqual(id, task_id())\n                    sock.close()\n                    # Always use SimpleAsyncHTTPClient here; the curl\n                    # version appears to get confused sometimes if the\n                    # connection gets closed before it's had a chance to\n                    # switch from writing mode to reading mode.\n                    client = HTTPClient(SimpleAsyncHTTPClient)\n\n                    def fetch(url, fail_ok=False):\n                        try:\n                            return client.fetch(get_url(url))\n                        except HTTPError as e:\n                            if not (fail_ok and e.code == 599):\n                                raise\n\n                    # Make two processes exit abnormally\n                    fetch(\"/?exit=2\", fail_ok=True)\n                    fetch(\"/?exit=3\", fail_ok=True)\n\n                    # They've been restarted, so a new fetch will work\n                    int(fetch(\"/\").body)\n\n                    # Now the same with signals\n                    # Disabled because on the mac a process dying with a signal\n                    # can trigger an \"Application exited abnormally; send error\n                    # report to Apple?\" prompt.\n                    # fetch(\"/?signal=%d\" % signal.SIGTERM, fail_ok=True)\n                    # fetch(\"/?signal=%d\" % signal.SIGABRT, fail_ok=True)\n                    # int(fetch(\"/\").body)\n\n                    # Now kill them normally so they won't be restarted\n                    fetch(\"/?exit=0\", fail_ok=True)\n                    # One process left; watch it's pid change\n                    pid = int(fetch(\"/\").body)\n                    fetch(\"/?exit=4\", fail_ok=True)\n                    pid2 = int(fetch(\"/\").body)\n                    self.assertNotEqual(pid, pid2)\n\n                    # Kill the last one so we shut down cleanly\n                    fetch(\"/?exit=0\", fail_ok=True)\n\n                    os._exit(0)\n            except Exception:\n                logging.error(\"exception in child process %d\", id, exc_info=True)\n                raise", "is_method": true, "class_name": "ProcessTest", "function_description": "Testing method in ProcessTest that verifies multi-process management, including process forking, automated restarts on abnormal exits, and clean shutdowns, by simulating HTTP requests and process lifecycle events."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "term_and_wait", "line_number": 138, "body": "def term_and_wait(self, subproc):\n        subproc.proc.terminate()\n        subproc.proc.wait()", "is_method": true, "class_name": "SubprocessTest", "function_description": "Terminates a subprocess and waits for it to fully exit, ensuring orderly shutdown within the SubprocessTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_subprocess", "line_number": 143, "body": "def test_subprocess(self):\n        if IOLoop.configured_class().__name__.endswith(\"LayeredTwistedIOLoop\"):\n            # This test fails non-deterministically with LayeredTwistedIOLoop.\n            # (the read_until('\\n') returns '\\n' instead of 'hello\\n')\n            # This probably indicates a problem with either TornadoReactor\n            # or TwistedIOLoop, but I haven't been able to track it down\n            # and for now this is just causing spurious travis-ci failures.\n            raise unittest.SkipTest(\n                \"Subprocess tests not compatible with \" \"LayeredTwistedIOLoop\"\n            )\n        subproc = Subprocess(\n            [sys.executable, \"-u\", \"-i\"],\n            stdin=Subprocess.STREAM,\n            stdout=Subprocess.STREAM,\n            stderr=subprocess.STDOUT,\n        )\n        self.addCleanup(lambda: self.term_and_wait(subproc))\n        self.addCleanup(subproc.stdout.close)\n        self.addCleanup(subproc.stdin.close)\n        yield subproc.stdout.read_until(b\">>> \")\n        subproc.stdin.write(b\"print('hello')\\n\")\n        data = yield subproc.stdout.read_until(b\"\\n\")\n        self.assertEqual(data, b\"hello\\n\")\n\n        yield subproc.stdout.read_until(b\">>> \")\n        subproc.stdin.write(b\"raise SystemExit\\n\")\n        data = yield subproc.stdout.read_until_close()\n        self.assertEqual(data, b\"\")", "is_method": true, "class_name": "SubprocessTest", "function_description": "Core test method of SubprocessTest that verifies subprocess I/O functionality by running an interactive Python process, ensuring correct output reading and subprocess termination while handling specific event loop incompatibilities."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_close_stdin", "line_number": 173, "body": "def test_close_stdin(self):\n        # Close the parent's stdin handle and see that the child recognizes it.\n        subproc = Subprocess(\n            [sys.executable, \"-u\", \"-i\"],\n            stdin=Subprocess.STREAM,\n            stdout=Subprocess.STREAM,\n            stderr=subprocess.STDOUT,\n        )\n        self.addCleanup(lambda: self.term_and_wait(subproc))\n        yield subproc.stdout.read_until(b\">>> \")\n        subproc.stdin.close()\n        data = yield subproc.stdout.read_until_close()\n        self.assertEqual(data, b\"\\n\")", "is_method": true, "class_name": "SubprocessTest", "function_description": "Tests that closing the parent's standard input is correctly detected by a child subprocess, ensuring proper communication and termination behavior in interactive subprocess management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_stderr", "line_number": 188, "body": "def test_stderr(self):\n        # This test is mysteriously flaky on twisted: it succeeds, but logs\n        # an error of EBADF on closing a file descriptor.\n        subproc = Subprocess(\n            [sys.executable, \"-u\", \"-c\", r\"import sys; sys.stderr.write('hello\\n')\"],\n            stderr=Subprocess.STREAM,\n        )\n        self.addCleanup(lambda: self.term_and_wait(subproc))\n        data = yield subproc.stderr.read_until(b\"\\n\")\n        self.assertEqual(data, b\"hello\\n\")\n        # More mysterious EBADF: This fails if done with self.addCleanup instead of here.\n        subproc.stderr.close()", "is_method": true, "class_name": "SubprocessTest", "function_description": "Test method in SubprocessTest that verifies capturing and reading a subprocess's standard error output, ensuring the subprocess writes expected data to stderr correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_sigchild", "line_number": 201, "body": "def test_sigchild(self):\n        Subprocess.initialize()\n        self.addCleanup(Subprocess.uninitialize)\n        subproc = Subprocess([sys.executable, \"-c\", \"pass\"])\n        subproc.set_exit_callback(self.stop)\n        ret = self.wait()\n        self.assertEqual(ret, 0)\n        self.assertEqual(subproc.returncode, ret)", "is_method": true, "class_name": "SubprocessTest", "function_description": "Core test method of the SubprocessTest class that verifies subprocess initialization, execution, and proper exit handling via callbacks, ensuring subprocesses return expected status codes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_sigchild_future", "line_number": 211, "body": "def test_sigchild_future(self):\n        Subprocess.initialize()\n        self.addCleanup(Subprocess.uninitialize)\n        subproc = Subprocess([sys.executable, \"-c\", \"pass\"])\n        ret = yield subproc.wait_for_exit()\n        self.assertEqual(ret, 0)\n        self.assertEqual(subproc.returncode, ret)", "is_method": true, "class_name": "SubprocessTest", "function_description": "Tests that a subprocess initialized via the Subprocess class completes successfully with the expected exit code, verifying subprocess management and cleanup functionality in asynchronous contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_sigchild_signal", "line_number": 219, "body": "def test_sigchild_signal(self):\n        Subprocess.initialize()\n        self.addCleanup(Subprocess.uninitialize)\n        subproc = Subprocess(\n            [sys.executable, \"-c\", \"import time; time.sleep(30)\"],\n            stdout=Subprocess.STREAM,\n        )\n        self.addCleanup(subproc.stdout.close)\n        subproc.set_exit_callback(self.stop)\n\n        # For unclear reasons, killing a process too soon after\n        # creating it can result in an exit status corresponding to\n        # SIGKILL instead of the actual signal involved. This has been\n        # observed on macOS 10.15 with Python 3.8 installed via brew,\n        # but not with the system-installed Python 3.7.\n        time.sleep(0.1)\n\n        os.kill(subproc.pid, signal.SIGTERM)\n        try:\n            ret = self.wait()\n        except AssertionError:\n            # We failed to get the termination signal. This test is\n            # occasionally flaky on pypy, so try to get a little more\n            # information: did the process close its stdout\n            # (indicating that the problem is in the parent process's\n            # signal handling) or did the child process somehow fail\n            # to terminate?\n            fut = subproc.stdout.read_until_close()\n            fut.add_done_callback(lambda f: self.stop())  # type: ignore\n            try:\n                self.wait()\n            except AssertionError:\n                raise AssertionError(\"subprocess failed to terminate\")\n            else:\n                raise AssertionError(\n                    \"subprocess closed stdout but failed to \" \"get termination signal\"\n                )\n        self.assertEqual(subproc.returncode, ret)\n        self.assertEqual(ret, -signal.SIGTERM)", "is_method": true, "class_name": "SubprocessTest", "function_description": "Unit test method in SubprocessTest that verifies correct signal handling and termination of a subprocess, ensuring it properly receives and reports a SIGTERM signal."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_wait_for_exit_raise", "line_number": 260, "body": "def test_wait_for_exit_raise(self):\n        Subprocess.initialize()\n        self.addCleanup(Subprocess.uninitialize)\n        subproc = Subprocess([sys.executable, \"-c\", \"import sys; sys.exit(1)\"])\n        with self.assertRaises(subprocess.CalledProcessError) as cm:\n            yield subproc.wait_for_exit()\n        self.assertEqual(cm.exception.returncode, 1)", "is_method": true, "class_name": "SubprocessTest", "function_description": "Utility test method in the SubprocessTest class that verifies wait_for_exit correctly raises an error when a subprocess exits with a non-zero status code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "test_wait_for_exit_raise_disabled", "line_number": 269, "body": "def test_wait_for_exit_raise_disabled(self):\n        Subprocess.initialize()\n        self.addCleanup(Subprocess.uninitialize)\n        subproc = Subprocess([sys.executable, \"-c\", \"import sys; sys.exit(1)\"])\n        ret = yield subproc.wait_for_exit(raise_error=False)\n        self.assertEqual(ret, 1)", "is_method": true, "class_name": "SubprocessTest", "function_description": "Tests that a subprocess exits with the correct return code without raising an error when error raising is disabled, ensuring controlled subprocess termination management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "get", "line_number": 26, "body": "def get(self):\n                if self.get_argument(\"exit\", None):\n                    # must use os._exit instead of sys.exit so unittest's\n                    # exception handler doesn't catch it\n                    os._exit(int(self.get_argument(\"exit\")))\n                if self.get_argument(\"signal\", None):\n                    os.kill(os.getpid(), int(self.get_argument(\"signal\")))\n                self.write(str(os.getpid()))", "is_method": true, "class_name": "ProcessHandler", "function_description": "Handles HTTP GET requests to trigger process termination via exit code or signal, or returns the current process ID; useful for controlling or monitoring process state remotely."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "get_url", "line_number": 62, "body": "def get_url(path):\n                return \"http://127.0.0.1:%d%s\" % (port, path)", "is_method": true, "class_name": "ProcessTest", "function_description": "Returns a full local URL by combining a fixed localhost address, a specified port, and the given path. This method simplifies generating consistent request URLs in a local testing environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/process_test.py", "function": "fetch", "line_number": 97, "body": "def fetch(url, fail_ok=False):\n                        try:\n                            return client.fetch(get_url(url))\n                        except HTTPError as e:\n                            if not (fail_ok and e.code == 599):\n                                raise", "is_method": true, "class_name": "ProcessTest", "function_description": "Function providing a safe HTTP fetch mechanism that retrieves content from a URL, optionally allowing silent failure for specific connection errors without raising exceptions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "handle_stream", "line_number": 50, "body": "def handle_stream(self, stream, address):\n        self.streams.append(stream)\n        self.queue.put(stream)", "is_method": true, "class_name": "TestTCPServer", "function_description": "Adds an incoming network stream to internal tracking and queues it for further processing. This function supports managing active connections in a TCP server context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "stop", "line_number": 54, "body": "def stop(self):\n        super().stop()\n        for stream in self.streams:\n            stream.close()", "is_method": true, "class_name": "TestTCPServer", "function_description": "Stops the TCP server and closes all associated streams, ensuring a clean shutdown of network connections. This facilitates proper resource cleanup in network server management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "setUp", "line_number": 61, "body": "def setUp(self):\n        super().setUp()\n        self.server = None\n        self.client = TCPClient()", "is_method": true, "class_name": "TCPClientTest", "function_description": "Initializes the TCPClientTest by setting up a TCP client instance and preparing the test environment. This method ensures each test starts with a fresh client for reliable network communication testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "start_server", "line_number": 66, "body": "def start_server(self, family):\n        if family == socket.AF_UNSPEC and \"TRAVIS\" in os.environ:\n            self.skipTest(\"dual-stack servers often have port conflicts on travis\")\n        self.server = TestTCPServer(family)\n        return self.server.port", "is_method": true, "class_name": "TCPClientTest", "function_description": "Utility method in TCPClientTest that initializes a test TCP server for the specified address family and returns its listening port, with environment-aware handling to avoid conflicts in certain CI environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "stop_server", "line_number": 72, "body": "def stop_server(self):\n        if self.server is not None:\n            self.server.stop()\n            self.server = None", "is_method": true, "class_name": "TCPClientTest", "function_description": "Stops and cleans up an existing server instance managed by the TCPClientTest class, ensuring the server is properly terminated and its reference cleared."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "tearDown", "line_number": 77, "body": "def tearDown(self):\n        self.client.close()\n        self.stop_server()\n        super().tearDown()", "is_method": true, "class_name": "TCPClientTest", "function_description": "Cleans up resources after a test by closing the client connection and stopping the server, ensuring a proper teardown in TCPClientTest tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "skipIfLocalhostV4", "line_number": 82, "body": "def skipIfLocalhostV4(self):\n        # The port used here doesn't matter, but some systems require it\n        # to be non-zero if we do not also pass AI_PASSIVE.\n        addrinfo = self.io_loop.run_sync(lambda: Resolver().resolve(\"localhost\", 80))\n        families = set(addr[0] for addr in addrinfo)\n        if socket.AF_INET6 not in families:\n            self.skipTest(\"localhost does not resolve to ipv6\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "This method checks if \"localhost\" resolves to an IPv6 address and skips the test if it doesn't, ensuring IPv6 availability before running network-related tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "do_test_connect", "line_number": 91, "body": "def do_test_connect(self, family, host, source_ip=None, source_port=None):\n        port = self.start_server(family)\n        stream = yield self.client.connect(\n            host, port, source_ip=source_ip, source_port=source_port\n        )\n        assert self.server is not None\n        server_stream = yield self.server.queue.get()\n        with closing(stream):\n            stream.write(b\"hello\")\n            data = yield server_stream.read_bytes(5)\n            self.assertEqual(data, b\"hello\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Utility method in TCPClientTest that establishes a client-server connection, sends data, and verifies correct transmission, facilitating testing of TCP connectivity and data exchange behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_ipv4_ipv4", "line_number": 103, "body": "def test_connect_ipv4_ipv4(self):\n        self.do_test_connect(socket.AF_INET, \"127.0.0.1\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Test method in TCPClientTest that verifies establishing a TCP connection using IPv4 protocol to the local host address. It ensures correct connectivity behavior for IPv4 socket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_ipv4_dual", "line_number": 106, "body": "def test_connect_ipv4_dual(self):\n        self.do_test_connect(socket.AF_INET, \"localhost\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Function in TCPClientTest that initiates an IPv4 connection test to the local host by invoking a generic connection test method with appropriate address family and target parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_ipv6_ipv6", "line_number": 110, "body": "def test_connect_ipv6_ipv6(self):\n        self.skipIfLocalhostV4()\n        self.do_test_connect(socket.AF_INET6, \"::1\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests establishing a TCP connection over IPv6 to the localhost address \"::1\". It validates IPv6 connectivity support in the TCP client implementation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_ipv6_dual", "line_number": 115, "body": "def test_connect_ipv6_dual(self):\n        self.skipIfLocalhostV4()\n        if Resolver.configured_class().__name__.endswith(\"TwistedResolver\"):\n            self.skipTest(\"TwistedResolver does not support multiple addresses\")\n        self.do_test_connect(socket.AF_INET6, \"localhost\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests establishing an IPv6 connection to a dual-stack localhost, skipping the test under specific unsupported conditions. It validates IPv6 connectivity functionality in the TCPClientTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_unspec_ipv4", "line_number": 121, "body": "def test_connect_unspec_ipv4(self):\n        self.do_test_connect(socket.AF_UNSPEC, \"127.0.0.1\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests the TCP client\u2019s ability to connect using an unspecified IPv4 address family, verifying connection handling with the IPv4 loopback address."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_unspec_ipv6", "line_number": 125, "body": "def test_connect_unspec_ipv6(self):\n        self.skipIfLocalhostV4()\n        self.do_test_connect(socket.AF_UNSPEC, \"::1\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests TCP client connectivity using an unspecified IPv6 address, verifying the client can connect to the loopback address \"::1\" under IPv6 conditions. Used to ensure IPv6 connection support in network communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_unspec_dual", "line_number": 129, "body": "def test_connect_unspec_dual(self):\n        self.do_test_connect(socket.AF_UNSPEC, \"localhost\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "Calls a connection test using an unspecified address family to the localhost. It facilitates testing network connectivity in dual-stack (IPv4/IPv6) environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_refused_ipv4", "line_number": 133, "body": "def test_refused_ipv4(self):\n        cleanup_func, port = refusing_port()\n        self.addCleanup(cleanup_func)\n        with self.assertRaises(IOError):\n            yield self.client.connect(\"127.0.0.1\", port)", "is_method": true, "class_name": "TCPClientTest", "function_description": "This test method verifies that the TCP client properly raises an IOError when attempting to connect to a refused IPv4 port. It ensures correct error handling for connection refusals in network operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_source_ip_fail", "line_number": 139, "body": "def test_source_ip_fail(self):\n        \"\"\"Fail when trying to use the source IP Address '8.8.8.8'.\n        \"\"\"\n        self.assertRaises(\n            socket.error,\n            self.do_test_connect,\n            socket.AF_INET,\n            \"127.0.0.1\",\n            source_ip=\"8.8.8.8\",\n        )", "is_method": true, "class_name": "TCPClientTest", "function_description": "Unit test method of TCPClientTest that verifies a connection attempt fails when using the disallowed source IP address \"8.8.8.8\". It ensures proper error handling for invalid source IP use cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_source_ip_success", "line_number": 150, "body": "def test_source_ip_success(self):\n        \"\"\"Success when trying to use the source IP Address '127.0.0.1'.\n        \"\"\"\n        self.do_test_connect(socket.AF_INET, \"127.0.0.1\", source_ip=\"127.0.0.1\")", "is_method": true, "class_name": "TCPClientTest", "function_description": "This test method verifies successful TCP connection establishment using the source IP address '127.0.0.1'. It ensures the TCP client can bind and connect properly with the specified local IP."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_source_port_fail", "line_number": 156, "body": "def test_source_port_fail(self):\n        \"\"\"Fail when trying to use source port 1.\n        \"\"\"\n        if getpass.getuser() == \"root\":\n            # Root can use any port so we can't easily force this to fail.\n            # This is mainly relevant for docker.\n            self.skipTest(\"running as root\")\n        self.assertRaises(\n            socket.error,\n            self.do_test_connect,\n            socket.AF_INET,\n            \"127.0.0.1\",\n            source_port=1,\n        )", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests that attempting to connect using the restricted source port 1 raises an error, ensuring proper failure behavior for unauthorized port usage in TCPClientTest environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_connect_timeout", "line_number": 172, "body": "def test_connect_timeout(self):\n        timeout = 0.05\n\n        class TimeoutResolver(Resolver):\n            def resolve(self, *args, **kwargs):\n                return Future()  # never completes\n\n        with self.assertRaises(TimeoutError):\n            yield TCPClient(resolver=TimeoutResolver()).connect(\n                \"1.2.3.4\", 12345, timeout=timeout\n            )", "is_method": true, "class_name": "TCPClientTest", "function_description": "Tests that TCPClient raises a TimeoutError when a connection attempt exceeds a specified short timeout period using a resolver that never completes. It verifies proper handling of connection timeouts in TCPClient."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family", "line_number": 186, "body": "def test_one_family(self):\n        # These addresses aren't in the right format, but split doesn't care.\n        primary, secondary = _Connector.split([(AF1, \"a\"), (AF1, \"b\")])\n        self.assertEqual(primary, [(AF1, \"a\"), (AF1, \"b\")])\n        self.assertEqual(secondary, [])", "is_method": true, "class_name": "TestConnectorSplit", "function_description": "Test method of the TestConnectorSplit class that verifies the split function correctly separates primary addresses when only one family is present, ensuring secondary addresses list remains empty."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_mixed", "line_number": 192, "body": "def test_mixed(self):\n        primary, secondary = _Connector.split(\n            [(AF1, \"a\"), (AF2, \"b\"), (AF1, \"c\"), (AF2, \"d\")]\n        )\n        self.assertEqual(primary, [(AF1, \"a\"), (AF1, \"c\")])\n        self.assertEqual(secondary, [(AF2, \"b\"), (AF2, \"d\")])", "is_method": true, "class_name": "TestConnectorSplit", "function_description": "This test method verifies that the split function correctly separates a list of tuples into two groups based on their first element. It ensures mixed input is divided into primary and secondary categories as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "setUp", "line_number": 208, "body": "def setUp(self):\n        super().setUp()\n        self.connect_futures = (\n            {}\n        )  # type: Dict[Tuple[int, typing.Any], Future[ConnectorTest.FakeStream]]\n        self.streams = {}  # type: Dict[typing.Any, ConnectorTest.FakeStream]\n        self.addrinfo = [(AF1, \"a\"), (AF1, \"b\"), (AF2, \"c\"), (AF2, \"d\")]", "is_method": true, "class_name": "ConnectorTest", "function_description": "Initializes test-specific data structures and state for connection-related tests in the ConnectorTest class, preparing futures, streams, and address information for use in subsequent test methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "tearDown", "line_number": 216, "body": "def tearDown(self):\n        # Unless explicitly checked (and popped) in the test, we shouldn't\n        # be closing any streams\n        for stream in self.streams.values():\n            self.assertFalse(stream.closed)\n        super().tearDown()", "is_method": true, "class_name": "ConnectorTest", "function_description": "Ensures that no streams have been closed during a test by verifying their state in tearDown, supporting reliable resource management validation within the ConnectorTest test suite."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "create_stream", "line_number": 223, "body": "def create_stream(self, af, addr):\n        stream = ConnectorTest.FakeStream()\n        self.streams[addr] = stream\n        future = Future()  # type: Future[ConnectorTest.FakeStream]\n        self.connect_futures[(af, addr)] = future\n        return stream, future", "is_method": true, "class_name": "ConnectorTest", "function_description": "Creates and registers a fake stream object associated with an address and returns it alongside a future, facilitating asynchronous connection handling in testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "assert_pending", "line_number": 230, "body": "def assert_pending(self, *keys):\n        self.assertEqual(sorted(self.connect_futures.keys()), sorted(keys))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Utility method in ConnectorTest that verifies the current set of pending connection keys matches the expected keys, ensuring consistency in asynchronous connection tracking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "resolve_connect", "line_number": 233, "body": "def resolve_connect(self, af, addr, success):\n        future = self.connect_futures.pop((af, addr))\n        if success:\n            future.set_result(self.streams[addr])\n        else:\n            self.streams.pop(addr)\n            future.set_exception(IOError())\n        # Run the loop to allow callbacks to be run.\n        self.io_loop.add_callback(self.stop)\n        self.wait()", "is_method": true, "class_name": "ConnectorTest", "function_description": "Handles the result of a connection attempt by resolving or rejecting the associated future based on success, managing connection streams accordingly within asynchronous I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "assert_connector_streams_closed", "line_number": 244, "body": "def assert_connector_streams_closed(self, conn):\n        for stream in conn.streams:\n            self.assertTrue(stream.closed)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Utility method in ConnectorTest that verifies all streams in a given connection are properly closed, ensuring resource cleanup and preventing potential leaks during connection handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "start_connect", "line_number": 248, "body": "def start_connect(self, addrinfo):\n        conn = _Connector(addrinfo, self.create_stream)\n        # Give it a huge timeout; we'll trigger timeouts manually.\n        future = conn.start(3600, connect_timeout=self.io_loop.time() + 3600)\n        return conn, future", "is_method": true, "class_name": "ConnectorTest", "function_description": "Starts a connector to initiate a network connection using provided address information, returning the connector instance and a future representing the connection attempt's result."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_immediate_success", "line_number": 254, "body": "def test_immediate_success(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assertEqual(list(self.connect_futures.keys()), [(AF1, \"a\")])\n        self.resolve_connect(AF1, \"a\", True)\n        self.assertEqual(future.result(), (AF1, \"a\", self.streams[\"a\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Unit test method in ConnectorTest that verifies successful immediate connection establishment and correct future result handling using internal connect and resolve mechanisms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_immediate_failure", "line_number": 260, "body": "def test_immediate_failure(self):\n        # Fail with just one address.\n        conn, future = self.start_connect([(AF1, \"a\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assertRaises(IOError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests that a connection attempt to a single address fails immediately, raising an IOError. Useful for verifying connection failure handling in asynchronous connection logic."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_second_try", "line_number": 267, "body": "def test_one_family_second_try(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        self.resolve_connect(AF1, \"b\", True)\n        self.assertEqual(future.result(), (AF1, \"b\", self.streams[\"b\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests connection retry logic by attempting to connect to two endpoints sequentially until success, validating that the second attempt succeeds and returns the expected result. It ensures reliable fallback behavior in the ConnectorTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_second_try_failure", "line_number": 275, "body": "def test_one_family_second_try_failure(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        self.resolve_connect(AF1, \"b\", False)\n        self.assertRaises(IOError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Unit test method in ConnectorTest that verifies connection attempts to a family fail gracefully on the second try, ensuring proper error handling and state management during sequential connection failures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_second_try_timeout", "line_number": 283, "body": "def test_one_family_second_try_timeout(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        # trigger the timeout while the first lookup is pending;\n        # nothing happens.\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        self.resolve_connect(AF1, \"b\", True)\n        self.assertEqual(future.result(), (AF1, \"b\", self.streams[\"b\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests the ConnectorTest class behavior when a timeout occurs during the first connection attempt in a sequence, ensuring the second attempt proceeds correctly and returns the expected result."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_two_families_immediate_failure", "line_number": 295, "body": "def test_two_families_immediate_failure(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"), (AF2, \"c\"))\n        self.resolve_connect(AF1, \"b\", False)\n        self.resolve_connect(AF2, \"c\", True)\n        self.assertEqual(future.result(), (AF2, \"c\", self.streams[\"c\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Test method in ConnectorTest that verifies connection attempts to two address families fail immediately for the first family but succeed for the second, ensuring correct handling of mixed connection outcomes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_two_families_timeout", "line_number": 304, "body": "def test_two_families_timeout(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"), (AF2, \"c\"))\n        self.resolve_connect(AF2, \"c\", True)\n        self.assertEqual(future.result(), (AF2, \"c\", self.streams[\"c\"]))\n        # resolving 'a' after the connection has completed doesn't start 'b'\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending()", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests the behavior of connection attempts for two address families with a timeout, ensuring proper handling and resolution order during concurrent connection processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_success_after_timeout", "line_number": 315, "body": "def test_success_after_timeout(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"), (AF2, \"c\"))\n        self.resolve_connect(AF1, \"a\", True)\n        self.assertEqual(future.result(), (AF1, \"a\", self.streams[\"a\"]))\n        # resolving 'c' after completion closes the connection.\n        self.resolve_connect(AF2, \"c\", True)\n        self.assertTrue(self.streams.pop(\"c\").closed)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Core test method of the ConnectorTest class that verifies connection attempts succeed correctly after timeouts and ensures proper handling of multiple connection results including cleanup of unused streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_all_fail", "line_number": 326, "body": "def test_all_fail(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"), (AF2, \"c\"))\n        self.resolve_connect(AF2, \"c\", False)\n        self.assert_pending((AF1, \"a\"), (AF2, \"d\"))\n        self.resolve_connect(AF2, \"d\", False)\n        # one queue is now empty\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        self.assertFalse(future.done())\n        self.resolve_connect(AF1, \"b\", False)\n        self.assertRaises(IOError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Simulates multiple connection attempts that all fail, verifying the ConnectorTest's handling of successive connection timeouts and errors until an overall failure is confirmed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_timeout_after_connect_timeout", "line_number": 342, "body": "def test_one_family_timeout_after_connect_timeout(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        conn.on_connect_timeout()\n        # the connector will close all streams on connect timeout, we\n        # should explicitly pop the connect_future.\n        self.connect_futures.pop((AF1, \"a\"))\n        self.assertTrue(self.streams.pop(\"a\").closed)\n        conn.on_timeout()\n        # if the future is set with TimeoutError, we will not iterate next\n        # possible address.\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 1)\n        self.assert_connector_streams_closed(conn)\n        self.assertRaises(TimeoutError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Core test method of ConnectorTest that verifies proper handling of connection timeouts, ensuring streams close and futures raise TimeoutError without retrying additional addresses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_success_before_connect_timeout", "line_number": 358, "body": "def test_one_family_success_before_connect_timeout(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", True)\n        conn.on_connect_timeout()\n        self.assert_pending()\n        self.assertEqual(self.streams[\"a\"].closed, False)\n        # success stream will be pop\n        self.assertEqual(len(conn.streams), 0)\n        # streams in connector should be closed after connect timeout\n        self.assert_connector_streams_closed(conn)\n        self.assertEqual(future.result(), (AF1, \"a\", self.streams[\"a\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Simulates a connection scenario to verify that a successful connection before timeout properly maintains the stream state and closes other streams, ensuring correct handling of connection timeouts in the ConnectorTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_second_try_after_connect_timeout", "line_number": 371, "body": "def test_one_family_second_try_after_connect_timeout(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        conn.on_connect_timeout()\n        self.connect_futures.pop((AF1, \"b\"))\n        self.assertTrue(self.streams.pop(\"b\").closed)\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 2)\n        self.assert_connector_streams_closed(conn)\n        self.assertRaises(TimeoutError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests that a connection attempt times out correctly and ensures proper cleanup and error handling when retrying a failed connection within the ConnectorTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_one_family_second_try_failure_before_connect_timeout", "line_number": 384, "body": "def test_one_family_second_try_failure_before_connect_timeout(self):\n        conn, future = self.start_connect([(AF1, \"a\"), (AF1, \"b\")])\n        self.assert_pending((AF1, \"a\"))\n        self.resolve_connect(AF1, \"a\", False)\n        self.assert_pending((AF1, \"b\"))\n        self.resolve_connect(AF1, \"b\", False)\n        conn.on_connect_timeout()\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 2)\n        self.assert_connector_streams_closed(conn)\n        self.assertRaises(IOError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests the ConnectorTest class behavior when multiple connection attempts fail before a connection timeout, ensuring streams are closed and connection errors are properly reported. It verifies the handling of retry and timeout failure scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_two_family_timeout_before_connect_timeout", "line_number": 396, "body": "def test_two_family_timeout_before_connect_timeout(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"), (AF2, \"c\"))\n        conn.on_connect_timeout()\n        self.connect_futures.pop((AF1, \"a\"))\n        self.assertTrue(self.streams.pop(\"a\").closed)\n        self.connect_futures.pop((AF2, \"c\"))\n        self.assertTrue(self.streams.pop(\"c\").closed)\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 2)\n        self.assert_connector_streams_closed(conn)\n        self.assertRaises(TimeoutError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests the ConnectorTest class's handling of connection timeouts for two address families, verifying proper closure of streams and raising a TimeoutError when connection attempts exceed time limits."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_two_family_success_after_timeout", "line_number": 411, "body": "def test_two_family_success_after_timeout(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_timeout()\n        self.assert_pending((AF1, \"a\"), (AF2, \"c\"))\n        self.resolve_connect(AF1, \"a\", True)\n        # if one of streams succeed, connector will close all other streams\n        self.connect_futures.pop((AF2, \"c\"))\n        self.assertTrue(self.streams.pop(\"c\").closed)\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 1)\n        self.assert_connector_streams_closed(conn)\n        self.assertEqual(future.result(), (AF1, \"a\", self.streams[\"a\"]))", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests that upon a connection timeout, a fallback connection attempt succeeds and properly closes alternative streams. It verifies the connector handles multiple connection families and cleans up unused streams after success."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "test_two_family_timeout_after_connect_timeout", "line_number": 425, "body": "def test_two_family_timeout_after_connect_timeout(self):\n        conn, future = self.start_connect(self.addrinfo)\n        self.assert_pending((AF1, \"a\"))\n        conn.on_connect_timeout()\n        self.connect_futures.pop((AF1, \"a\"))\n        self.assertTrue(self.streams.pop(\"a\").closed)\n        self.assert_pending()\n        conn.on_timeout()\n        # if the future is set with TimeoutError, connector will not\n        # trigger secondary address.\n        self.assert_pending()\n        self.assertEqual(len(conn.streams), 1)\n        self.assert_connector_streams_closed(conn)\n        self.assertRaises(TimeoutError, future.result)", "is_method": true, "class_name": "ConnectorTest", "function_description": "Tests that a connection properly handles timeouts during multiple address family connection attempts, ensuring streams close and timeouts propagate without triggering fallback addresses. It verifies correct timeout behavior in the ConnectorTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpclient_test.py", "function": "close", "line_number": 205, "body": "def close(self):\n            self.closed = True", "is_method": true, "class_name": "FakeStream", "function_description": "Marks the FakeStream instance as closed by setting its closed status to True, signaling that no further operations should be performed on it."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "_get_named_handler", "line_number": 101, "body": "def _get_named_handler(handler_name):\n    class Handler(RequestHandler):\n        def get(self, *args, **kwargs):\n            if self.application.settings.get(\"app_name\") is not None:\n                self.write(self.application.settings[\"app_name\"] + \": \")\n\n            self.finish(handler_name + \": \" + self.reverse_url(handler_name))\n\n    return Handler", "is_method": false, "function_description": "This function dynamically creates a request handler class that responds by outputting the application name and URL associated with a given handler name. It enables generating simple HTTP handlers tied to specific route names for web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "find_handler", "line_number": 35, "body": "def find_handler(self, request, **kwargs):\n        class MessageDelegate(HTTPMessageDelegate):\n            def __init__(self, connection):\n                self.connection = connection\n\n            def finish(self):\n                self.connection.write_headers(\n                    ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                    HTTPHeaders({\"Content-Length\": \"2\"}),\n                    b\"OK\",\n                )\n                self.connection.finish()\n\n        return MessageDelegate(request.connection)", "is_method": true, "class_name": "BasicRouter", "function_description": "Instantiates and returns a message delegate tailored to handle an HTTP request by sending a basic 200 OK response. This method supports routing by providing a handler that manages low-level HTTP connection responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get_app", "line_number": 52, "body": "def get_app(self):\n        return BasicRouter()", "is_method": true, "class_name": "BasicRouterTestCase", "function_description": "Returns a BasicRouter instance, facilitating access to the router within test cases for routing behavior verification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_basic_router", "line_number": 55, "body": "def test_basic_router(self):\n        response = self.fetch(\"/any_request\")\n        self.assertEqual(response.body, b\"OK\")", "is_method": true, "class_name": "BasicRouterTestCase", "function_description": "Simple test method in BasicRouterTestCase that verifies the router responds with \"OK\" to any request, ensuring basic routing functionality works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get", "line_number": 64, "body": "def get(self, path):\n        if path not in resources:\n            raise HTTPError(404)\n\n        self.finish(resources[path])", "is_method": true, "class_name": "GetResource", "function_description": "Handles HTTP GET requests by returning the resource content for a given path or raising a 404 error if the resource is not found. It provides a simple resource retrieval mechanism for web requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "post", "line_number": 72, "body": "def post(self, path):\n        resources[path] = self.request.body", "is_method": true, "class_name": "PostResource", "function_description": "Stores the request body in a resource dictionary under the specified path, enabling data posting and storage within the PostResource context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "find_handler", "line_number": 80, "body": "def find_handler(self, request, **kwargs):\n        handler = GetResource if request.method == \"GET\" else PostResource\n        return self.app.get_handler_delegate(request, handler, path_args=[request.path])", "is_method": true, "class_name": "HTTPMethodRouter", "function_description": "Core method of the HTTPMethodRouter class that selects and returns the appropriate request handler based on the HTTP method, facilitating routing of GET and POST requests within an application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get_app", "line_number": 86, "body": "def get_app(self):\n        return HTTPMethodRouter(Application())", "is_method": true, "class_name": "HTTPMethodRouterTestCase", "function_description": "Returns an HTTPMethodRouter instance initialized with an Application, facilitating routing setup for HTTP method-based request handling in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_http_method_router", "line_number": 89, "body": "def test_http_method_router(self):\n        response = self.fetch(\"/post_resource\", method=\"POST\", body=\"data\")\n        self.assertEqual(response.code, 200)\n\n        response = self.fetch(\"/get_resource\")\n        self.assertEqual(response.code, 404)\n\n        response = self.fetch(\"/post_resource\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.body, b\"data\")", "is_method": true, "class_name": "HTTPMethodRouterTestCase", "function_description": "Unit test method for HTTPMethodRouter that verifies correct handling of HTTP methods and resource responses, ensuring POST and GET requests return expected status codes and data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "add_routes", "line_number": 121, "body": "def add_routes(self, routes):\n        self.routes.update(routes)", "is_method": true, "class_name": "CustomRouter", "function_description": "Adds multiple routes to the CustomRouter's routing table, enabling dynamic extension of available routes for handling requests or actions within the router."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "find_handler", "line_number": 124, "body": "def find_handler(self, request, **kwargs):\n        if request.path in self.routes:\n            app, handler = self.routes[request.path]\n            return app.get_handler_delegate(request, handler)", "is_method": true, "class_name": "CustomRouter", "function_description": "Core utility of the CustomRouter class that identifies and returns the appropriate handler delegate for a given request based on its path, enabling dynamic request routing to corresponding application logic."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "reverse_url", "line_number": 129, "body": "def reverse_url(self, name, *args):\n        handler_path = \"/\" + name\n        return handler_path if handler_path in self.routes else None", "is_method": true, "class_name": "CustomRouter", "function_description": "Utility method in CustomRouter that returns the URL path for a given route name if it exists, enabling reverse lookup of registered routes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get_app", "line_number": 135, "body": "def get_app(self):\n        router = CustomRouter()\n\n        class CustomApplication(Application):\n            def reverse_url(self, name, *args):\n                return router.reverse_url(name, *args)\n\n        app1 = CustomApplication(app_name=\"app1\")\n        app2 = CustomApplication(app_name=\"app2\")\n\n        router.add_routes(\n            {\n                \"/first_handler\": (app1, FirstHandler),\n                \"/second_handler\": (app2, SecondHandler),\n                \"/first_handler_second_app\": (app2, FirstHandler),\n            }\n        )\n\n        return router", "is_method": true, "class_name": "CustomRouterTestCase", "function_description": "Provides a configured CustomRouter instance with multiple applications and routes for testing URL reversing and handler dispatching in the CustomRouterTestCase context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_custom_router", "line_number": 155, "body": "def test_custom_router(self):\n        response = self.fetch(\"/first_handler\")\n        self.assertEqual(response.body, b\"app1: first_handler: /first_handler\")\n        response = self.fetch(\"/second_handler\")\n        self.assertEqual(response.body, b\"app2: second_handler: /second_handler\")\n        response = self.fetch(\"/first_handler_second_app\")\n        self.assertEqual(response.body, b\"app2: first_handler: /first_handler\")", "is_method": true, "class_name": "CustomRouterTestCase", "function_description": "Tests that the custom router correctly routes requests to the expected handlers and verifies the response content for multiple URL paths in a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "start_request", "line_number": 165, "body": "def start_request(self, server_conn, request_conn):\n        class MessageDelegate(HTTPMessageDelegate):\n            def __init__(self, connection):\n                self.connection = connection\n\n            def finish(self):\n                response_body = b\"OK\"\n                self.connection.write_headers(\n                    ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                    HTTPHeaders({\"Content-Length\": str(len(response_body))}),\n                )\n                self.connection.write(response_body)\n                self.connection.finish()\n\n        return MessageDelegate(request_conn)", "is_method": true, "class_name": "ConnectionDelegate", "function_description": "Provides an HTTP message handler that responds to requests with a simple 200 OK response and a fixed \"OK\" body, facilitating basic request handling in connection management scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get_app", "line_number": 183, "body": "def get_app(self):\n        app = Application()\n\n        def request_callable(request):\n            request.connection.write_headers(\n                ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                HTTPHeaders({\"Content-Length\": \"2\"}),\n            )\n            request.connection.write(b\"OK\")\n            request.connection.finish()\n\n        router = CustomRouter()\n        router.add_routes(\n            {\"/nested_handler\": (app, _get_named_handler(\"nested_handler\"))}\n        )\n\n        app.add_handlers(\n            \".*\",\n            [\n                (\n                    HostMatches(\"www.example.com\"),\n                    [\n                        (\n                            PathMatches(\"/first_handler\"),\n                            \"tornado.test.routing_test.SecondHandler\",\n                            {},\n                            \"second_handler\",\n                        )\n                    ],\n                ),\n                Rule(PathMatches(\"/.*handler\"), router),\n                Rule(PathMatches(\"/first_handler\"), FirstHandler, name=\"first_handler\"),\n                Rule(PathMatches(\"/request_callable\"), request_callable),\n                (\"/connection_delegate\", ConnectionDelegate()),\n            ],\n        )\n\n        return app", "is_method": true, "class_name": "RuleRouterTest", "function_description": "Constructs and configures a web application with multiple nested routing rules and handlers for testing diverse URL matching scenarios. Enables simulation of complex request routing behaviors within the RuleRouterTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_rule_based_router", "line_number": 222, "body": "def test_rule_based_router(self):\n        response = self.fetch(\"/first_handler\")\n        self.assertEqual(response.body, b\"first_handler: /first_handler\")\n\n        response = self.fetch(\"/first_handler\", headers={\"Host\": \"www.example.com\"})\n        self.assertEqual(response.body, b\"second_handler: /first_handler\")\n\n        response = self.fetch(\"/nested_handler\")\n        self.assertEqual(response.body, b\"nested_handler: /nested_handler\")\n\n        response = self.fetch(\"/nested_not_found_handler\")\n        self.assertEqual(response.code, 404)\n\n        response = self.fetch(\"/connection_delegate\")\n        self.assertEqual(response.body, b\"OK\")\n\n        response = self.fetch(\"/request_callable\")\n        self.assertEqual(response.body, b\"OK\")\n\n        response = self.fetch(\"/404\")\n        self.assertEqual(response.code, 404)", "is_method": true, "class_name": "RuleRouterTest", "function_description": "Tests the RuleRouter's ability to route requests to correct handlers and return expected responses or error codes, verifying proper URL and host-based dispatching behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get_app", "line_number": 246, "body": "def get_app(self):\n        wsgi_app = WSGIContainer(self.wsgi_app)\n\n        class Handler(RequestHandler):\n            def get(self, *args, **kwargs):\n                self.finish(self.reverse_url(\"tornado\"))\n\n        return RuleRouter(\n            [\n                (\n                    PathMatches(\"/tornado.*\"),\n                    Application([(r\"/tornado/test\", Handler, {}, \"tornado\")]),\n                ),\n                (PathMatches(\"/wsgi\"), wsgi_app),\n            ]\n        )", "is_method": true, "class_name": "WSGIContainerTestCase", "function_description": "Provides a configured routing application that integrates a WSGI app with Tornado handlers, enabling testing of both WSGI and Tornado request handling within a unified URL routing structure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "wsgi_app", "line_number": 263, "body": "def wsgi_app(self, environ, start_response):\n        start_response(\"200 OK\", [])\n        return [b\"WSGI\"]", "is_method": true, "class_name": "WSGIContainerTestCase", "function_description": "Simple WSGI application method that returns a fixed \"200 OK\" response with \"WSGI\" content, useful for testing WSGI server integrations or middleware behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_wsgi_container", "line_number": 267, "body": "def test_wsgi_container(self):\n        response = self.fetch(\"/tornado/test\")\n        self.assertEqual(response.body, b\"/tornado/test\")\n\n        response = self.fetch(\"/wsgi\")\n        self.assertEqual(response.body, b\"WSGI\")", "is_method": true, "class_name": "WSGIContainerTestCase", "function_description": "Tests that the WSGI container correctly handles requests by verifying expected response bodies for specific endpoints, ensuring proper integration within the web application environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "test_delegate_not_found", "line_number": 274, "body": "def test_delegate_not_found(self):\n        response = self.fetch(\"/404\")\n        self.assertEqual(response.code, 404)", "is_method": true, "class_name": "WSGIContainerTestCase", "function_description": "Test method in WSGIContainerTestCase that verifies handling of requests to non-existent routes by asserting a 404 Not Found response code. It ensures correct error delegation in HTTP request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get", "line_number": 103, "body": "def get(self, *args, **kwargs):\n            if self.application.settings.get(\"app_name\") is not None:\n                self.write(self.application.settings[\"app_name\"] + \": \")\n\n            self.finish(handler_name + \": \" + self.reverse_url(handler_name))", "is_method": true, "class_name": "Handler", "function_description": "Returns a response containing the application name followed by a handler-specific URL for use in web request processing and routing within the Handler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "request_callable", "line_number": 186, "body": "def request_callable(request):\n            request.connection.write_headers(\n                ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                HTTPHeaders({\"Content-Length\": \"2\"}),\n            )\n            request.connection.write(b\"OK\")\n            request.connection.finish()", "is_method": true, "class_name": "RuleRouterTest", "function_description": "Provides a simple HTTP request handler that responds with a fixed \"OK\" message and a successful status, useful for testing HTTP routing and connection handling in the RuleRouterTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "finish", "line_number": 40, "body": "def finish(self):\n                self.connection.write_headers(\n                    ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                    HTTPHeaders({\"Content-Length\": \"2\"}),\n                    b\"OK\",\n                )\n                self.connection.finish()", "is_method": true, "class_name": "MessageDelegate", "function_description": "Completes and finalizes an HTTP response by sending an OK status with a small confirmation message, then closes the connection. This is useful for signaling successful request handling in HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "reverse_url", "line_number": 139, "body": "def reverse_url(self, name, *args):\n                return router.reverse_url(name, *args)", "is_method": true, "class_name": "CustomApplication", "function_description": "Utility method of CustomApplication that returns a URL string by reversing a named route with given arguments, facilitating dynamic URL generation within the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "finish", "line_number": 170, "body": "def finish(self):\n                response_body = b\"OK\"\n                self.connection.write_headers(\n                    ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                    HTTPHeaders({\"Content-Length\": str(len(response_body))}),\n                )\n                self.connection.write(response_body)\n                self.connection.finish()", "is_method": true, "class_name": "MessageDelegate", "function_description": "Finalizes an HTTP response by sending a 200 OK status with a simple body and closing the connection, supporting proper completion of message handling in HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/routing_test.py", "function": "get", "line_number": 250, "body": "def get(self, *args, **kwargs):\n                self.finish(self.reverse_url(\"tornado\"))", "is_method": true, "class_name": "Handler", "function_description": "This method completes a request by redirecting to a predefined URL named \"tornado,\" facilitating streamlined navigation within a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "save_signal_handlers", "line_number": 52, "body": "def save_signal_handlers():\n    saved = {}\n    signals = [signal.SIGINT, signal.SIGTERM]\n    if hasattr(signal, \"SIGCHLD\"):\n        signals.append(signal.SIGCHLD)\n    for sig in signals:\n        saved[sig] = signal.getsignal(sig)\n    if \"twisted\" in repr(saved):\n        # This indicates we're not cleaning up after ourselves properly.\n        raise Exception(\"twisted signal handlers already installed\")\n    return saved", "is_method": false, "function_description": "Function that captures and returns the current handlers for common system signals, ensuring no conflicting handlers (like Twisted's) are already installed. It enables safe management and restoration of signal handling in applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "restore_signal_handlers", "line_number": 65, "body": "def restore_signal_handlers(saved):\n    for sig, handler in saved.items():\n        signal.signal(sig, handler)", "is_method": false, "function_description": "Restores previously saved signal handlers for the process, ensuring that signals are handled as originally configured. Useful for resetting or undoing temporary signal handler changes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "setUp", "line_number": 76, "body": "def setUp(self):\n        self.saved_signals = save_signal_handlers()\n        self.saved_policy = asyncio.get_event_loop_policy()\n        if hasattr(asyncio, \"WindowsSelectorEventLoopPolicy\"):\n            # Twisted requires a selector event loop, even if Tornado is\n            # doing its own tricks in AsyncIOLoop to support proactors.\n            # Setting an AddThreadSelectorEventLoop exposes various edge\n            # cases so just use a regular selector.\n            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())  # type: ignore\n        self.io_loop = IOLoop()\n        self.io_loop.make_current()\n        self.reactor = AsyncioSelectorReactor()", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Sets up an asynchronous test environment by configuring event loop policies, initializing an I/O loop, and preparing a reactor, ensuring compatibility for async tests in different system contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "tearDown", "line_number": 89, "body": "def tearDown(self):\n        self.reactor.disconnectAll()\n        self.io_loop.clear_current()\n        self.io_loop.close(all_fds=True)\n        asyncio.set_event_loop_policy(self.saved_policy)\n        restore_signal_handlers(self.saved_signals)", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Method of CompatibilityTests that cleans up and resets the testing environment after each test by disconnecting reactors, clearing the IO loop, restoring event loop policies, and resetting signal handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "start_twisted_server", "line_number": 96, "body": "def start_twisted_server(self):\n        class HelloResource(Resource):\n            isLeaf = True\n\n            def render_GET(self, request):\n                return b\"Hello from twisted!\"\n\n        site = Site(HelloResource())\n        port = self.reactor.listenTCP(0, site, interface=\"127.0.0.1\")\n        self.twisted_port = port.getHost().port", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Sets up and starts a lightweight Twisted HTTP server on localhost that responds with a greeting message, facilitating testing of asynchronous networking components within the CompatibilityTests class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "start_tornado_server", "line_number": 107, "body": "def start_tornado_server(self):\n        class HelloHandler(RequestHandler):\n            def get(self):\n                self.write(\"Hello from tornado!\")\n\n        app = Application([(\"/\", HelloHandler)], log_function=lambda x: None)\n        server = HTTPServer(app)\n        sock, self.tornado_port = bind_unused_port()\n        server.add_sockets([sock])", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Starts a Tornado HTTP server that responds with a simple greeting on the root path, enabling basic testability of server functionality within compatibility checks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "run_reactor", "line_number": 117, "body": "def run_reactor(self):\n        # In theory, we can run the event loop through Tornado,\n        # Twisted, or asyncio interfaces. However, since we're trying\n        # to avoid installing anything as the global event loop, only\n        # the twisted interface gets everything wired up correectly\n        # without extra hacks. This method is a part of a\n        # no-longer-used generalization that allowed us to test\n        # different combinations.\n        self.stop_loop = self.reactor.stop\n        self.stop = self.reactor.stop\n        self.reactor.run()", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Runs the reactor's event loop using the Twisted interface, facilitating asynchronous operations within compatibility tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "tornado_fetch", "line_number": 129, "body": "def tornado_fetch(self, url, runner):\n        client = AsyncHTTPClient()\n        fut = asyncio.ensure_future(client.fetch(url))\n        fut.add_done_callback(lambda f: self.stop_loop())\n        runner()\n        return fut.result()", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Utility method in CompatibilityTests that performs an asynchronous HTTP fetch and runs a provided callback, returning the final fetch result once complete."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "twisted_fetch", "line_number": 136, "body": "def twisted_fetch(self, url, runner):\n        # http://twistedmatrix.com/documents/current/web/howto/client.html\n        chunks = []\n        client = Agent(self.reactor)\n        d = client.request(b\"GET\", utf8(url))\n\n        class Accumulator(Protocol):\n            def __init__(self, finished):\n                self.finished = finished\n\n            def dataReceived(self, data):\n                chunks.append(data)\n\n            def connectionLost(self, reason):\n                self.finished.callback(None)\n\n        def callback(response):\n            finished = Deferred()\n            response.deliverBody(Accumulator(finished))\n            return finished\n\n        d.addCallback(callback)\n\n        def shutdown(failure):\n            if hasattr(self, \"stop_loop\"):\n                self.stop_loop()\n            elif failure is not None:\n                # loop hasn't been initialized yet; try our best to\n                # get an error message out. (the runner() interaction\n                # should probably be refactored).\n                try:\n                    failure.raiseException()\n                except:\n                    logging.error(\"exception before starting loop\", exc_info=True)\n\n        d.addBoth(shutdown)\n        runner()\n        self.assertTrue(chunks)\n        return b\"\".join(chunks)", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Performs an asynchronous HTTP GET request to fetch data from a URL using Twisted, running a given reactor loop and returning the complete response body as bytes. Useful for testing network interactions within an asynchronous framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "twisted_coroutine_fetch", "line_number": 176, "body": "def twisted_coroutine_fetch(self, url, runner):\n        body = [None]\n\n        @gen.coroutine\n        def f():\n            # This is simpler than the non-coroutine version, but it cheats\n            # by reading the body in one blob instead of streaming it with\n            # a Protocol.\n            client = Agent(self.reactor)\n            response = yield client.request(b\"GET\", utf8(url))\n            with warnings.catch_warnings():\n                # readBody has a buggy DeprecationWarning in Twisted 15.0:\n                # https://twistedmatrix.com/trac/changeset/43379\n                warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n                body[0] = yield readBody(response)\n            self.stop_loop()\n\n        self.io_loop.add_callback(f)\n        runner()\n        return body[0]", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Method of CompatibilityTests that performs an asynchronous HTTP GET request using Twisted coroutines, returning the full response body after running an event loop controlled by the provided runner function."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "testTwistedServerTornadoClientReactor", "line_number": 197, "body": "def testTwistedServerTornadoClientReactor(self):\n        self.start_twisted_server()\n        response = self.tornado_fetch(\n            \"http://127.0.0.1:%d\" % self.twisted_port, self.run_reactor\n        )\n        self.assertEqual(response.body, b\"Hello from twisted!\")", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Tests interoperability between a Twisted server and a Tornado client by starting the server, making a request, and verifying the expected response to ensure compatibility between these frameworks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "testTornadoServerTwistedClientReactor", "line_number": 204, "body": "def testTornadoServerTwistedClientReactor(self):\n        self.start_tornado_server()\n        response = self.twisted_fetch(\n            \"http://127.0.0.1:%d\" % self.tornado_port, self.run_reactor\n        )\n        self.assertEqual(response, b\"Hello from tornado!\")", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Test method in CompatibilityTests that verifies communication between a Tornado server and a Twisted client reactor by ensuring the server responds with the expected message."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "testTornadoServerTwistedCoroutineClientReactor", "line_number": 211, "body": "def testTornadoServerTwistedCoroutineClientReactor(self):\n        self.start_tornado_server()\n        response = self.twisted_coroutine_fetch(\n            \"http://127.0.0.1:%d\" % self.tornado_port, self.run_reactor\n        )\n        self.assertEqual(response, b\"Hello from tornado!\")", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Test method in CompatibilityTests that verifies a Tornado server responds correctly when accessed via a Twisted coroutine client using a reactor, ensuring interoperability between Tornado and Twisted components."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "test_success", "line_number": 222, "body": "def test_success(self):\n        @inlineCallbacks\n        def fn():\n            if False:\n                # inlineCallbacks doesn't work with regular functions;\n                # must have a yield even if it's unreachable.\n                yield\n            returnValue(42)\n\n        res = yield fn()\n        self.assertEqual(res, 42)", "is_method": true, "class_name": "ConvertDeferredTest", "function_description": "Unit test method in ConvertDeferredTest that verifies an asynchronous function correctly returns the expected result when using inlineCallbacks with a deferred return value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "test_failure", "line_number": 235, "body": "def test_failure(self):\n        @inlineCallbacks\n        def fn():\n            if False:\n                yield\n            1 / 0\n\n        with self.assertRaises(ZeroDivisionError):\n            yield fn()", "is_method": true, "class_name": "ConvertDeferredTest", "function_description": "Test method in ConvertDeferredTest that verifies a ZeroDivisionError is correctly raised within an asynchronous deferred function. It ensures proper error handling in deferred coroutine execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "callback", "line_number": 152, "body": "def callback(response):\n            finished = Deferred()\n            response.deliverBody(Accumulator(finished))\n            return finished", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Utility method in CompatibilityTests that processes a response asynchronously and returns a Deferred signaling when the response body delivery is complete."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "shutdown", "line_number": 159, "body": "def shutdown(failure):\n            if hasattr(self, \"stop_loop\"):\n                self.stop_loop()\n            elif failure is not None:\n                # loop hasn't been initialized yet; try our best to\n                # get an error message out. (the runner() interaction\n                # should probably be refactored).\n                try:\n                    failure.raiseException()\n                except:\n                    logging.error(\"exception before starting loop\", exc_info=True)", "is_method": true, "class_name": "CompatibilityTests", "function_description": "Method in CompatibilityTests that attempts to halt ongoing operations and logs initialization errors if shutdown is triggered before the process starts. It ensures graceful cessation and error visibility during failure scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "render_GET", "line_number": 100, "body": "def render_GET(self, request):\n                return b\"Hello from twisted!\"", "is_method": true, "class_name": "HelloResource", "function_description": "Returns a simple byte string greeting in response to a GET request, serving as a basic HTTP resource endpoint in a Twisted web server context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "get", "line_number": 109, "body": "def get(self):\n                self.write(\"Hello from tornado!\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Handles HTTP GET requests by responding with a simple greeting message, useful for testing or confirming server responsiveness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/twisted_test.py", "function": "connectionLost", "line_number": 149, "body": "def connectionLost(self, reason):\n                self.finished.callback(None)", "is_method": true, "class_name": "Accumulator", "function_description": "Handles the event when a connection is lost by signaling the completion of an associated asynchronous operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "clear_locale_cache", "line_number": 16, "body": "def clear_locale_cache(self):\n        tornado.locale.Locale._cache = {}", "is_method": true, "class_name": "TranslationLoaderTest", "function_description": "Clears the cached locale data used for translations, ensuring that any changes to localization resources are reloaded. This supports testing by resetting translation states in the TranslationLoader context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "setUp", "line_number": 19, "body": "def setUp(self):\n        self.saved = {}  # type: dict\n        for var in TranslationLoaderTest.SAVE_VARS:\n            self.saved[var] = getattr(tornado.locale, var)\n        self.clear_locale_cache()", "is_method": true, "class_name": "TranslationLoaderTest", "function_description": "Sets up the test environment by saving specific locale-related variables and clearing the locale cache to ensure a clean state for TranslationLoaderTest unit tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "tearDown", "line_number": 25, "body": "def tearDown(self):\n        for k, v in self.saved.items():\n            setattr(tornado.locale, k, v)\n        self.clear_locale_cache()", "is_method": true, "class_name": "TranslationLoaderTest", "function_description": "Restores saved locale attributes and clears the locale cache after tests. This ensures test isolation by resetting any locale changes made during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_csv", "line_number": 30, "body": "def test_csv(self):\n        tornado.locale.load_translations(\n            os.path.join(os.path.dirname(__file__), \"csv_translations\")\n        )\n        locale = tornado.locale.get(\"fr_FR\")\n        self.assertTrue(isinstance(locale, tornado.locale.CSVLocale))\n        self.assertEqual(locale.translate(\"school\"), u\"\\u00e9cole\")", "is_method": true, "class_name": "TranslationLoaderTest", "function_description": "Test method that verifies loading CSV-based translations and ensures correct retrieval of translated strings for a specific locale, validating the functionality of the CSV translation loader in the TranslationLoaderTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_csv_bom", "line_number": 38, "body": "def test_csv_bom(self):\n        with open(\n            os.path.join(os.path.dirname(__file__), \"csv_translations\", \"fr_FR.csv\"),\n            \"rb\",\n        ) as f:\n            char_data = to_unicode(f.read())\n        # Re-encode our input data (which is utf-8 without BOM) in\n        # encodings that use the BOM and ensure that we can still load\n        # it. Note that utf-16-le and utf-16-be do not write a BOM,\n        # so we only test whichver variant is native to our platform.\n        for encoding in [\"utf-8-sig\", \"utf-16\"]:\n            tmpdir = tempfile.mkdtemp()\n            try:\n                with open(os.path.join(tmpdir, \"fr_FR.csv\"), \"wb\") as f:\n                    f.write(char_data.encode(encoding))\n                tornado.locale.load_translations(tmpdir)\n                locale = tornado.locale.get(\"fr_FR\")\n                self.assertIsInstance(locale, tornado.locale.CSVLocale)\n                self.assertEqual(locale.translate(\"school\"), u\"\\u00e9cole\")\n            finally:\n                shutil.rmtree(tmpdir)", "is_method": true, "class_name": "TranslationLoaderTest", "function_description": "Tests that CSV translation files encoded with BOMs (Byte Order Marks) are correctly loaded and the translations are properly recognized, ensuring encoding compatibility in the TranslationLoader context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_non_ascii_name", "line_number": 81, "body": "def test_non_ascii_name(self):\n        name = tornado.locale.LOCALE_NAMES[\"es_LA\"][\"name\"]\n        self.assertTrue(isinstance(name, unicode_type))\n        self.assertEqual(name, u\"Espa\\u00f1ol\")\n        self.assertEqual(utf8(name), b\"Espa\\xc3\\xb1ol\")", "is_method": true, "class_name": "LocaleDataTest", "function_description": "Test method in LocaleDataTest that verifies the Spanish (es_LA) locale name is correctly stored as a Unicode string and properly encoded in UTF-8. It ensures locale name data integrity and encoding correctness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_format_date", "line_number": 89, "body": "def test_format_date(self):\n        locale = tornado.locale.get(\"en_US\")\n        date = datetime.datetime(2013, 4, 28, 18, 35)\n        self.assertEqual(\n            locale.format_date(date, full_format=True), \"April 28, 2013 at 6:35 pm\"\n        )\n\n        now = datetime.datetime.utcnow()\n\n        self.assertEqual(\n            locale.format_date(now - datetime.timedelta(seconds=2), full_format=False),\n            \"2 seconds ago\",\n        )\n        self.assertEqual(\n            locale.format_date(now - datetime.timedelta(minutes=2), full_format=False),\n            \"2 minutes ago\",\n        )\n        self.assertEqual(\n            locale.format_date(now - datetime.timedelta(hours=2), full_format=False),\n            \"2 hours ago\",\n        )\n\n        self.assertEqual(\n            locale.format_date(\n                now - datetime.timedelta(days=1), full_format=False, shorter=True\n            ),\n            \"yesterday\",\n        )\n\n        date = now - datetime.timedelta(days=2)\n        self.assertEqual(\n            locale.format_date(date, full_format=False, shorter=True),\n            locale._weekdays[date.weekday()],\n        )\n\n        date = now - datetime.timedelta(days=300)\n        self.assertEqual(\n            locale.format_date(date, full_format=False, shorter=True),\n            \"%s %d\" % (locale._months[date.month - 1], date.day),\n        )\n\n        date = now - datetime.timedelta(days=500)\n        self.assertEqual(\n            locale.format_date(date, full_format=False, shorter=True),\n            \"%s %d, %d\" % (locale._months[date.month - 1], date.day, date.year),\n        )", "is_method": true, "class_name": "EnglishTest", "function_description": "Unit test method of the EnglishTest class that verifies correct formatting of dates and relative time descriptions in U.S. English locale, ensuring different formats like full dates, recent time intervals, and shortened date representations are handled as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_friendly_number", "line_number": 136, "body": "def test_friendly_number(self):\n        locale = tornado.locale.get(\"en_US\")\n        self.assertEqual(locale.friendly_number(1000000), \"1,000,000\")", "is_method": true, "class_name": "EnglishTest", "function_description": "Unit test method in EnglishTest verifying that the US English locale correctly formats large integers into comma-separated, human-friendly strings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_list", "line_number": 140, "body": "def test_list(self):\n        locale = tornado.locale.get(\"en_US\")\n        self.assertEqual(locale.list([]), \"\")\n        self.assertEqual(locale.list([\"A\"]), \"A\")\n        self.assertEqual(locale.list([\"A\", \"B\"]), \"A and B\")\n        self.assertEqual(locale.list([\"A\", \"B\", \"C\"]), \"A, B and C\")", "is_method": true, "class_name": "EnglishTest", "function_description": "Unit test method of the EnglishTest class that verifies the English locale's list formatting behavior for different list lengths, ensuring correct string representation with proper conjunctions and punctuation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/locale_test.py", "function": "test_format_day", "line_number": 147, "body": "def test_format_day(self):\n        locale = tornado.locale.get(\"en_US\")\n        date = datetime.datetime(2013, 4, 28, 18, 35)\n        self.assertEqual(locale.format_day(date=date, dow=True), \"Sunday, April 28\")\n        self.assertEqual(locale.format_day(date=date, dow=False), \"April 28\")", "is_method": true, "class_name": "EnglishTest", "function_description": "Tests that the English (US) locale correctly formats dates with and without the day of the week, ensuring accurate date string presentation. It verifies the formatting output for given datetime inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 31, "body": "def initialize(self, test):\n        self._OPENID_ENDPOINT = test.get_url(\"/openid/server/authenticate\")", "is_method": true, "class_name": "OpenIdClientLoginHandler", "function_description": "Initialize the OpenIdClientLoginHandler with the OpenID authentication endpoint URL derived from a test configuration. This setup enables the handler to direct authentication requests appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 35, "body": "def get(self):\n        if self.get_argument(\"openid.mode\", None):\n            user = yield self.get_authenticated_user(\n                http_client=self.settings[\"http_client\"]\n            )\n            if user is None:\n                raise Exception(\"user is None\")\n            self.finish(user)\n            return\n        res = self.authenticate_redirect()  # type: ignore\n        assert res is None", "is_method": true, "class_name": "OpenIdClientLoginHandler", "function_description": "Handles OpenID login by authenticating users when OpenID mode is present; otherwise, initiates authentication redirection. It supports user login flow in web applications using OpenID protocol."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "post", "line_number": 49, "body": "def post(self):\n        if self.get_argument(\"openid.mode\") != \"check_authentication\":\n            raise Exception(\"incorrect openid.mode %r\")\n        self.write(\"is_valid:true\")", "is_method": true, "class_name": "OpenIdServerAuthenticateHandler", "function_description": "Handles OpenID POST requests to confirm authentication status by validating the mode and responding with an \"is_valid:true\" confirmation. It supports OpenID authentication verification in server workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 56, "body": "def initialize(self, test, version):\n        self._OAUTH_VERSION = version\n        self._OAUTH_REQUEST_TOKEN_URL = test.get_url(\"/oauth1/server/request_token\")\n        self._OAUTH_AUTHORIZE_URL = test.get_url(\"/oauth1/server/authorize\")\n        self._OAUTH_ACCESS_TOKEN_URL = test.get_url(\"/oauth1/server/access_token\")", "is_method": true, "class_name": "OAuth1ClientLoginHandler", "function_description": "Initializes OAuth1 client endpoint URLs and version using a test configuration, setting up necessary URLs for request token, authorization, and access token retrieval during the OAuth1 login process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "_oauth_consumer_token", "line_number": 62, "body": "def _oauth_consumer_token(self):\n        return dict(key=\"asdf\", secret=\"qwer\")", "is_method": true, "class_name": "OAuth1ClientLoginHandler", "function_description": "Private method providing fixed OAuth consumer credentials as a dictionary, likely used internally for authentication in the OAuth1ClientLoginHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 66, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            user = yield self.get_authenticated_user(\n                http_client=self.settings[\"http_client\"]\n            )\n            if user is None:\n                raise Exception(\"user is None\")\n            self.finish(user)\n            return\n        yield self.authorize_redirect(http_client=self.settings[\"http_client\"])", "is_method": true, "class_name": "OAuth1ClientLoginHandler", "function_description": "Handles OAuth1 login by either retrieving the authenticated user if a token is provided or initiating the OAuth authorization redirect when no token is present. It facilitates user authentication flow in OAuth1 contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "_oauth_get_user_future", "line_number": 78, "body": "def _oauth_get_user_future(self, access_token):\n        if self.get_argument(\"fail_in_get_user\", None):\n            raise Exception(\"failing in get_user\")\n        if access_token != dict(key=\"uiop\", secret=\"5678\"):\n            raise Exception(\"incorrect access token %r\" % access_token)\n        return dict(email=\"foo@example.com\")", "is_method": true, "class_name": "OAuth1ClientLoginHandler", "function_description": "Provides a simulated user retrieval method for testing OAuth1 login, validating the access token and optionally triggering a failure to verify error handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 90, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            # Ensure that any exceptions are set on the returned Future,\n            # not simply thrown into the surrounding StackContext.\n            try:\n                yield self.get_authenticated_user()\n            except Exception as e:\n                self.set_status(503)\n                self.write(\"got exception: %s\" % e)\n        else:\n            yield self.authorize_redirect()", "is_method": true, "class_name": "OAuth1ClientLoginCoroutineHandler", "function_description": "Handles OAuth1 login flow by either authenticating the user with provided oauth_token or redirecting to the authorization URL if no token is present, facilitating secure client login management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 104, "body": "def initialize(self, version):\n        self._OAUTH_VERSION = version", "is_method": true, "class_name": "OAuth1ClientRequestParametersHandler", "function_description": "Sets the OAuth version for the OAuth1ClientRequestParametersHandler instance, configuring it to use a specific OAuth protocol version in subsequent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "_oauth_consumer_token", "line_number": 107, "body": "def _oauth_consumer_token(self):\n        return dict(key=\"asdf\", secret=\"qwer\")", "is_method": true, "class_name": "OAuth1ClientRequestParametersHandler", "function_description": "Private method that provides hardcoded OAuth1 consumer token credentials for authentication purposes within the OAuth1ClientRequestParametersHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 110, "body": "def get(self):\n        params = self._oauth_request_parameters(\n            \"http://www.example.com/api/asdf\",\n            dict(key=\"uiop\", secret=\"5678\"),\n            parameters=dict(foo=\"bar\"),\n        )\n        self.write(params)", "is_method": true, "class_name": "OAuth1ClientRequestParametersHandler", "function_description": "Core method of OAuth1ClientRequestParametersHandler that generates OAuth1 request parameters for a given URL and credentials, then outputs them; useful for preparing authenticated API requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 120, "body": "def get(self):\n        self.write(\"oauth_token=zxcv&oauth_token_secret=1234\")", "is_method": true, "class_name": "OAuth1ServerRequestTokenHandler", "function_description": "Returns a fixed OAuth 1.0 request token and secret as a plain text response, typically used to simulate or handle OAuth request token issuance in server authorization flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 125, "body": "def get(self):\n        self.write(\"oauth_token=uiop&oauth_token_secret=5678\")", "is_method": true, "class_name": "OAuth1ServerAccessTokenHandler", "function_description": "Returns a fixed OAuth 1.0 access token and secret string, simulating an access token response typically used in OAuth authentication flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 130, "body": "def initialize(self, test):\n        self._OAUTH_AUTHORIZE_URL = test.get_url(\"/oauth2/server/authorize\")", "is_method": true, "class_name": "OAuth2ClientLoginHandler", "function_description": "Initializes the OAuth2ClientLoginHandler by setting the OAuth authorization URL based on a test server URL. This setup prepares the handler for OAuth2 authorization requests during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 133, "body": "def get(self):\n        res = self.authorize_redirect()  # type: ignore\n        assert res is None", "is_method": true, "class_name": "OAuth2ClientLoginHandler", "function_description": "Initiates an OAuth2 authorization flow by redirecting the client to the authorization endpoint. This method serves as the entry point to start the login process via OAuth2."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 139, "body": "def initialize(self, test):\n        self._OAUTH_AUTHORIZE_URL = test.get_url(\"/facebook/server/authorize\")\n        self._OAUTH_ACCESS_TOKEN_URL = test.get_url(\"/facebook/server/access_token\")\n        self._FACEBOOK_BASE_URL = test.get_url(\"/facebook/server\")", "is_method": true, "class_name": "FacebookClientLoginHandler", "function_description": "Initializes URL endpoints for Facebook OAuth authorization and token exchange based on the provided test environment, preparing the client for authentication workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 145, "body": "def get(self):\n        if self.get_argument(\"code\", None):\n            user = yield self.get_authenticated_user(\n                redirect_uri=self.request.full_url(),\n                client_id=self.settings[\"facebook_api_key\"],\n                client_secret=self.settings[\"facebook_secret\"],\n                code=self.get_argument(\"code\"),\n            )\n            self.write(user)\n        else:\n            self.authorize_redirect(\n                redirect_uri=self.request.full_url(),\n                client_id=self.settings[\"facebook_api_key\"],\n                extra_params={\"scope\": \"read_stream,offline_access\"},\n            )", "is_method": true, "class_name": "FacebookClientLoginHandler", "function_description": "Handles Facebook OAuth login by either redirecting for authorization or retrieving and returning the authenticated user information upon callback with an authorization code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 163, "body": "def get(self):\n        self.write(dict(access_token=\"asdf\", expires_in=3600))", "is_method": true, "class_name": "FacebookServerAccessTokenHandler", "function_description": "Returns a fixed Facebook access token and its expiration time, providing a simple token retrieval endpoint in the FacebookServerAccessTokenHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 168, "body": "def get(self):\n        self.write(\"{}\")", "is_method": true, "class_name": "FacebookServerMeHandler", "function_description": "Minimal HTTP GET handler method that responds with an empty JSON object, typically used as a placeholder or health check endpoint in the FacebookServerMeHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 173, "body": "def initialize(self, test):\n        self._OAUTH_REQUEST_TOKEN_URL = test.get_url(\"/oauth1/server/request_token\")\n        self._OAUTH_ACCESS_TOKEN_URL = test.get_url(\"/twitter/server/access_token\")\n        self._OAUTH_AUTHORIZE_URL = test.get_url(\"/oauth1/server/authorize\")\n        self._OAUTH_AUTHENTICATE_URL = test.get_url(\"/twitter/server/authenticate\")\n        self._TWITTER_BASE_URL = test.get_url(\"/twitter/api\")", "is_method": true, "class_name": "TwitterClientHandler", "function_description": "Initializes TwitterClientHandler instance URLs for OAuth and Twitter API endpoints based on a given test environment configuration, preparing the client for authentication and API requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get_auth_http_client", "line_number": 180, "body": "def get_auth_http_client(self):\n        return self.settings[\"http_client\"]", "is_method": true, "class_name": "TwitterClientHandler", "function_description": "Returns the HTTP client used for making authenticated requests within the TwitterClientHandler, enabling consistent and authorized communication with Twitter's API."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 186, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            user = yield self.get_authenticated_user()\n            if user is None:\n                raise Exception(\"user is None\")\n            self.finish(user)\n            return\n        yield self.authorize_redirect()", "is_method": true, "class_name": "TwitterClientLoginHandler", "function_description": "Handles Twitter OAuth login by retrieving authenticated user info if returning from OAuth flow, or initiating the OAuth authorization redirect for login if not yet authenticated."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 200, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            user = yield self.get_authenticated_user()\n            if user is None:\n                raise Exception(\"user is None\")\n            self.finish(user)\n            return\n        yield self.authenticate_redirect()", "is_method": true, "class_name": "TwitterClientAuthenticateHandler", "function_description": "Handles Twitter OAuth authentication by retrieving the authenticated user if an OAuth token is provided; otherwise, it initiates the OAuth authentication redirect process to obtain user credentials."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 212, "body": "def get(self):\n        if self.get_argument(\"oauth_token\", None):\n            user = yield self.get_authenticated_user()\n            self.finish(user)\n        else:\n            # New style: with @gen.coroutine the result must be yielded\n            # or else the request will be auto-finished too soon.\n            yield self.authorize_redirect()", "is_method": true, "class_name": "TwitterClientLoginGenCoroutineHandler", "function_description": "Handles Twitter OAuth login by either returning authenticated user info if an OAuth token is present or initiating the OAuth authorization redirect otherwise, managing asynchronous login flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 224, "body": "def get(self):\n        # TODO: would be nice to go through the login flow instead of\n        # cheating with a hard-coded access token.\n        try:\n            response = yield self.twitter_request(\n                \"/users/show/%s\" % self.get_argument(\"name\"),\n                access_token=dict(key=\"hjkl\", secret=\"vbnm\"),\n            )\n        except HTTPClientError:\n            # TODO(bdarnell): Should we catch HTTP errors and\n            # transform some of them (like 403s) into AuthError?\n            self.set_status(500)\n            self.finish(\"error from twitter request\")\n        else:\n            self.finish(response)", "is_method": true, "class_name": "TwitterClientShowUserHandler", "function_description": "Handles an HTTP GET request to fetch and return a Twitter user's information by username using a predefined access token, managing errors from the Twitter API call gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 242, "body": "def get(self):\n        self.write(\"oauth_token=hjkl&oauth_token_secret=vbnm&screen_name=foo\")", "is_method": true, "class_name": "TwitterServerAccessTokenHandler", "function_description": "Returns a fixed OAuth token, token secret, and screen name string simulating access token retrieval for Twitter API authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 247, "body": "def get(self, screen_name):\n        if screen_name == \"error\":\n            raise HTTPError(500)\n        assert \"oauth_nonce\" in self.request.arguments\n        assert \"oauth_timestamp\" in self.request.arguments\n        assert \"oauth_signature\" in self.request.arguments\n        assert self.get_argument(\"oauth_consumer_key\") == \"test_twitter_consumer_key\"\n        assert self.get_argument(\"oauth_signature_method\") == \"HMAC-SHA1\"\n        assert self.get_argument(\"oauth_version\") == \"1.0\"\n        assert self.get_argument(\"oauth_token\") == \"hjkl\"\n        self.write(dict(screen_name=screen_name, name=screen_name.capitalize()))", "is_method": true, "class_name": "TwitterServerShowUserHandler", "function_description": "Handles a GET request to retrieve and respond with user information based on a Twitter screen name, validating OAuth parameters to simulate authenticated access. Used in testing or mocking Twitter user data responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 261, "body": "def get(self):\n        assert \"oauth_nonce\" in self.request.arguments\n        assert \"oauth_timestamp\" in self.request.arguments\n        assert \"oauth_signature\" in self.request.arguments\n        assert self.get_argument(\"oauth_consumer_key\") == \"test_twitter_consumer_key\"\n        assert self.get_argument(\"oauth_signature_method\") == \"HMAC-SHA1\"\n        assert self.get_argument(\"oauth_version\") == \"1.0\"\n        assert self.get_argument(\"oauth_token\") == \"hjkl\"\n        self.write(dict(screen_name=\"foo\", name=\"Foo\"))", "is_method": true, "class_name": "TwitterServerVerifyCredentialsHandler", "function_description": "Handles OAuth 1.0 credential verification for Twitter API requests, validating required parameters and returning user identity details upon successful authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get_app", "line_number": 273, "body": "def get_app(self):\n        return Application(\n            [\n                # test endpoints\n                (\"/openid/client/login\", OpenIdClientLoginHandler, dict(test=self)),\n                (\n                    \"/oauth10/client/login\",\n                    OAuth1ClientLoginHandler,\n                    dict(test=self, version=\"1.0\"),\n                ),\n                (\n                    \"/oauth10/client/request_params\",\n                    OAuth1ClientRequestParametersHandler,\n                    dict(version=\"1.0\"),\n                ),\n                (\n                    \"/oauth10a/client/login\",\n                    OAuth1ClientLoginHandler,\n                    dict(test=self, version=\"1.0a\"),\n                ),\n                (\n                    \"/oauth10a/client/login_coroutine\",\n                    OAuth1ClientLoginCoroutineHandler,\n                    dict(test=self, version=\"1.0a\"),\n                ),\n                (\n                    \"/oauth10a/client/request_params\",\n                    OAuth1ClientRequestParametersHandler,\n                    dict(version=\"1.0a\"),\n                ),\n                (\"/oauth2/client/login\", OAuth2ClientLoginHandler, dict(test=self)),\n                (\"/facebook/client/login\", FacebookClientLoginHandler, dict(test=self)),\n                (\"/twitter/client/login\", TwitterClientLoginHandler, dict(test=self)),\n                (\n                    \"/twitter/client/authenticate\",\n                    TwitterClientAuthenticateHandler,\n                    dict(test=self),\n                ),\n                (\n                    \"/twitter/client/login_gen_coroutine\",\n                    TwitterClientLoginGenCoroutineHandler,\n                    dict(test=self),\n                ),\n                (\n                    \"/twitter/client/show_user\",\n                    TwitterClientShowUserHandler,\n                    dict(test=self),\n                ),\n                # simulated servers\n                (\"/openid/server/authenticate\", OpenIdServerAuthenticateHandler),\n                (\"/oauth1/server/request_token\", OAuth1ServerRequestTokenHandler),\n                (\"/oauth1/server/access_token\", OAuth1ServerAccessTokenHandler),\n                (\"/facebook/server/access_token\", FacebookServerAccessTokenHandler),\n                (\"/facebook/server/me\", FacebookServerMeHandler),\n                (\"/twitter/server/access_token\", TwitterServerAccessTokenHandler),\n                (r\"/twitter/api/users/show/(.*)\\.json\", TwitterServerShowUserHandler),\n                (\n                    r\"/twitter/api/account/verify_credentials\\.json\",\n                    TwitterServerVerifyCredentialsHandler,\n                ),\n            ],\n            http_client=self.http_client,\n            twitter_consumer_key=\"test_twitter_consumer_key\",\n            twitter_consumer_secret=\"test_twitter_consumer_secret\",\n            facebook_api_key=\"test_facebook_api_key\",\n            facebook_secret=\"test_facebook_secret\",\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Constructs and returns a configured web Application with multiple OAuth, OpenID, Facebook, and Twitter authentication endpoints for testing various client and server authentication flows within the AuthTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_openid_redirect", "line_number": 341, "body": "def test_openid_redirect(self):\n        response = self.fetch(\"/openid/client/login\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\"/openid/server/authenticate?\" in response.headers[\"Location\"])", "is_method": true, "class_name": "AuthTest", "function_description": "Simple test method in AuthTest that verifies the /openid/client/login endpoint redirects correctly to the OpenID server authentication URL. It ensures proper redirection behavior in the OpenID login flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_openid_get_user", "line_number": 346, "body": "def test_openid_get_user(self):\n        response = self.fetch(\n            \"/openid/client/login?openid.mode=blah\"\n            \"&openid.ns.ax=http://openid.net/srv/ax/1.0\"\n            \"&openid.ax.type.email=http://axschema.org/contact/email\"\n            \"&openid.ax.value.email=foo@example.com\"\n        )\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(parsed[\"email\"], \"foo@example.com\")", "is_method": true, "class_name": "AuthTest", "function_description": "Unit test method in AuthTest verifying that the OpenID login endpoint correctly processes and returns the authenticated user's email address. It ensures email retrieval via OpenID attribute exchange functions as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10_redirect", "line_number": 357, "body": "def test_oauth10_redirect(self):\n        response = self.fetch(\"/oauth10/client/login\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\n            response.headers[\"Location\"].endswith(\n                \"/oauth1/server/authorize?oauth_token=zxcv\"\n            )\n        )\n        # the cookie is base64('zxcv')|base64('1234')\n        self.assertTrue(\n            '_oauth_request_token=\"enhjdg==|MTIzNA==\"'\n            in response.headers[\"Set-Cookie\"],\n            response.headers[\"Set-Cookie\"],\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Tests that the OAuth 1.0 login endpoint correctly redirects to the authorization URL and sets the expected request token cookie. It ensures proper OAuth flow initiation in authentication processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10_get_user", "line_number": 372, "body": "def test_oauth10_get_user(self):\n        response = self.fetch(\n            \"/oauth10/client/login?oauth_token=zxcv\",\n            headers={\"Cookie\": \"_oauth_request_token=enhjdg==|MTIzNA==\"},\n        )\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(parsed[\"email\"], \"foo@example.com\")\n        self.assertEqual(parsed[\"access_token\"], dict(key=\"uiop\", secret=\"5678\"))", "is_method": true, "class_name": "AuthTest", "function_description": "Test method of the AuthTest class that verifies successful OAuth 1.0 login flow and correct retrieval of user email and access token information. It ensures the authentication mechanism operates as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10_request_parameters", "line_number": 382, "body": "def test_oauth10_request_parameters(self):\n        response = self.fetch(\"/oauth10/client/request_params\")\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(parsed[\"oauth_consumer_key\"], \"asdf\")\n        self.assertEqual(parsed[\"oauth_token\"], \"uiop\")\n        self.assertTrue(\"oauth_nonce\" in parsed)\n        self.assertTrue(\"oauth_signature\" in parsed)", "is_method": true, "class_name": "AuthTest", "function_description": "This test method verifies that the OAuth 1.0 request parameters are correctly set and returned by the endpoint, ensuring proper OAuth authentication handling in the AuthTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10a_redirect", "line_number": 391, "body": "def test_oauth10a_redirect(self):\n        response = self.fetch(\"/oauth10a/client/login\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\n            response.headers[\"Location\"].endswith(\n                \"/oauth1/server/authorize?oauth_token=zxcv\"\n            )\n        )\n        # the cookie is base64('zxcv')|base64('1234')\n        self.assertTrue(\n            '_oauth_request_token=\"enhjdg==|MTIzNA==\"'\n            in response.headers[\"Set-Cookie\"],\n            response.headers[\"Set-Cookie\"],\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Tests that the OAuth 1.0a login endpoint correctly issues a redirect to the authorization server and sets the expected request token cookie. It ensures proper OAuth redirect and cookie behavior during authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10a_redirect_error", "line_number": 407, "body": "def test_oauth10a_redirect_error(self):\n        with mock.patch.object(OAuth1ServerRequestTokenHandler, \"get\") as get:\n            get.side_effect = Exception(\"boom\")\n            with ExpectLog(app_log, \"Uncaught exception\"):\n                response = self.fetch(\"/oauth10a/client/login\", follow_redirects=False)\n            self.assertEqual(response.code, 500)", "is_method": true, "class_name": "AuthTest", "function_description": "Tests that the OAuth1 login handler properly returns a 500 error and logs an exception when an unexpected error occurs during the token retrieval process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10a_get_user", "line_number": 414, "body": "def test_oauth10a_get_user(self):\n        response = self.fetch(\n            \"/oauth10a/client/login?oauth_token=zxcv\",\n            headers={\"Cookie\": \"_oauth_request_token=enhjdg==|MTIzNA==\"},\n        )\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(parsed[\"email\"], \"foo@example.com\")\n        self.assertEqual(parsed[\"access_token\"], dict(key=\"uiop\", secret=\"5678\"))", "is_method": true, "class_name": "AuthTest", "function_description": "Test method in AuthTest that verifies the OAuth 1.0a user login endpoint returns correct user email and access token data, ensuring OAuth authentication works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10a_request_parameters", "line_number": 424, "body": "def test_oauth10a_request_parameters(self):\n        response = self.fetch(\"/oauth10a/client/request_params\")\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(parsed[\"oauth_consumer_key\"], \"asdf\")\n        self.assertEqual(parsed[\"oauth_token\"], \"uiop\")\n        self.assertTrue(\"oauth_nonce\" in parsed)\n        self.assertTrue(\"oauth_signature\" in parsed)", "is_method": true, "class_name": "AuthTest", "function_description": "This test method verifies that the OAuth 1.0a request parameters are correctly returned by the endpoint, ensuring required keys like consumer key, token, nonce, and signature are present and valid."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth10a_get_user_coroutine_exception", "line_number": 433, "body": "def test_oauth10a_get_user_coroutine_exception(self):\n        response = self.fetch(\n            \"/oauth10a/client/login_coroutine?oauth_token=zxcv&fail_in_get_user=true\",\n            headers={\"Cookie\": \"_oauth_request_token=enhjdg==|MTIzNA==\"},\n        )\n        self.assertEqual(response.code, 503)", "is_method": true, "class_name": "AuthTest", "function_description": "Test method in AuthTest that verifies the OAuth 1.0a login coroutine properly returns a 503 error when user retrieval fails. It ensures error handling behaves correctly during user fetching in OAuth flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_oauth2_redirect", "line_number": 440, "body": "def test_oauth2_redirect(self):\n        response = self.fetch(\"/oauth2/client/login\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\"/oauth2/server/authorize?\" in response.headers[\"Location\"])", "is_method": true, "class_name": "AuthTest", "function_description": "Tests that the OAuth2 login endpoint correctly issues a redirect to the authorization server. This helps verify OAuth2 flow integration in authentication processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_facebook_login", "line_number": 445, "body": "def test_facebook_login(self):\n        response = self.fetch(\"/facebook/client/login\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\"/facebook/server/authorize?\" in response.headers[\"Location\"])\n        response = self.fetch(\n            \"/facebook/client/login?code=1234\", follow_redirects=False\n        )\n        self.assertEqual(response.code, 200)\n        user = json_decode(response.body)\n        self.assertEqual(user[\"access_token\"], \"asdf\")\n        self.assertEqual(user[\"session_expires\"], \"3600\")", "is_method": true, "class_name": "AuthTest", "function_description": "Provides a test case verifying the Facebook login flow, ensuring correct redirects and access token retrieval for authentication handling in the AuthTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "base_twitter_redirect", "line_number": 457, "body": "def base_twitter_redirect(self, url):\n        # Same as test_oauth10a_redirect\n        response = self.fetch(url, follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\n            response.headers[\"Location\"].endswith(\n                \"/oauth1/server/authorize?oauth_token=zxcv\"\n            )\n        )\n        # the cookie is base64('zxcv')|base64('1234')\n        self.assertTrue(\n            '_oauth_request_token=\"enhjdg==|MTIzNA==\"'\n            in response.headers[\"Set-Cookie\"],\n            response.headers[\"Set-Cookie\"],\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Checks if a given URL correctly redirects to the Twitter OAuth 1.0a authorization endpoint with the expected token and sets the corresponding OAuth request token cookie. Used for validating OAuth redirect behavior in authentication tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_redirect", "line_number": 473, "body": "def test_twitter_redirect(self):\n        self.base_twitter_redirect(\"/twitter/client/login\")", "is_method": true, "class_name": "AuthTest", "function_description": "Simple test method in AuthTest that triggers a Twitter login redirect process, likely to verify correct URL redirection behavior during authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_redirect_gen_coroutine", "line_number": 476, "body": "def test_twitter_redirect_gen_coroutine(self):\n        self.base_twitter_redirect(\"/twitter/client/login_gen_coroutine\")", "is_method": true, "class_name": "AuthTest", "function_description": "This test method verifies the behavior of the Twitter login redirect coroutine by invoking a base redirect test helper with a specific URL endpoint. It supports validation of asynchronous Twitter authentication flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_authenticate_redirect", "line_number": 479, "body": "def test_twitter_authenticate_redirect(self):\n        response = self.fetch(\"/twitter/client/authenticate\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\n            response.headers[\"Location\"].endswith(\n                \"/twitter/server/authenticate?oauth_token=zxcv\"\n            ),\n            response.headers[\"Location\"],\n        )\n        # the cookie is base64('zxcv')|base64('1234')\n        self.assertTrue(\n            '_oauth_request_token=\"enhjdg==|MTIzNA==\"'\n            in response.headers[\"Set-Cookie\"],\n            response.headers[\"Set-Cookie\"],\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "This test method verifies that the Twitter authentication endpoint correctly issues a redirect to the expected URL and sets the appropriate OAuth request token cookie. It ensures the initial step of OAuth login flow functions as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_get_user", "line_number": 495, "body": "def test_twitter_get_user(self):\n        response = self.fetch(\n            \"/twitter/client/login?oauth_token=zxcv\",\n            headers={\"Cookie\": \"_oauth_request_token=enhjdg==|MTIzNA==\"},\n        )\n        response.rethrow()\n        parsed = json_decode(response.body)\n        self.assertEqual(\n            parsed,\n            {\n                u\"access_token\": {\n                    u\"key\": u\"hjkl\",\n                    u\"screen_name\": u\"foo\",\n                    u\"secret\": u\"vbnm\",\n                },\n                u\"name\": u\"Foo\",\n                u\"screen_name\": u\"foo\",\n                u\"username\": u\"foo\",\n            },\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Unit test method in AuthTest that verifies Twitter user login response correctness by validating access token details and user information. It ensures expected authentication data is properly returned from the Twitter client login endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_show_user", "line_number": 516, "body": "def test_twitter_show_user(self):\n        response = self.fetch(\"/twitter/client/show_user?name=somebody\")\n        response.rethrow()\n        self.assertEqual(\n            json_decode(response.body), {\"name\": \"Somebody\", \"screen_name\": \"somebody\"}\n        )", "is_method": true, "class_name": "AuthTest", "function_description": "Tests the Twitter user information retrieval endpoint by verifying it returns expected user data for a given username. It supports validating authentication and response correctness in the AuthTest suite."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_twitter_show_user_error", "line_number": 523, "body": "def test_twitter_show_user_error(self):\n        response = self.fetch(\"/twitter/client/show_user?name=error\")\n        self.assertEqual(response.code, 500)\n        self.assertEqual(response.body, b\"error from twitter request\")", "is_method": true, "class_name": "AuthTest", "function_description": "Unit test method in the AuthTest class that verifies the Twitter user display endpoint returns a 500 error and specific error message when an invalid username is requested. It ensures proper error handling in Twitter client integration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "initialize", "line_number": 530, "body": "def initialize(self, test):\n        self.test = test\n        self._OAUTH_REDIRECT_URI = test.get_url(\"/client/login\")\n        self._OAUTH_AUTHORIZE_URL = test.get_url(\"/google/oauth2/authorize\")\n        self._OAUTH_ACCESS_TOKEN_URL = test.get_url(\"/google/oauth2/token\")", "is_method": true, "class_name": "GoogleLoginHandler", "function_description": "Initializes OAuth-related URLs using a test environment for handling Google login authentication within the GoogleLoginHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 537, "body": "def get(self):\n        code = self.get_argument(\"code\", None)\n        if code is not None:\n            # retrieve authenticate google user\n            access = yield self.get_authenticated_user(self._OAUTH_REDIRECT_URI, code)\n            user = yield self.oauth2_request(\n                self.test.get_url(\"/google/oauth2/userinfo\"),\n                access_token=access[\"access_token\"],\n            )\n            # return the user and access token as json\n            user[\"access_token\"] = access[\"access_token\"]\n            self.write(user)\n        else:\n            self.authorize_redirect(\n                redirect_uri=self._OAUTH_REDIRECT_URI,\n                client_id=self.settings[\"google_oauth\"][\"key\"],\n                client_secret=self.settings[\"google_oauth\"][\"secret\"],\n                scope=[\"profile\", \"email\"],\n                response_type=\"code\",\n                extra_params={\"prompt\": \"select_account\"},\n            )", "is_method": true, "class_name": "GoogleLoginHandler", "function_description": "Handles Google OAuth login by either redirecting to Google's authorization page or processing the returned code to authenticate the user and respond with user info and access token in JSON format."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 561, "body": "def get(self):\n        # issue a fake auth code and redirect to redirect_uri\n        code = \"fake-authorization-code\"\n        self.redirect(url_concat(self.get_argument(\"redirect_uri\"), dict(code=code)))", "is_method": true, "class_name": "GoogleOAuth2AuthorizeHandler", "function_description": "Simulates OAuth2 authorization by issuing a fake authorization code and redirecting the user to the provided redirect URI. This method is useful for testing or mocking OAuth2 authorization flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "post", "line_number": 568, "body": "def post(self):\n        assert self.get_argument(\"code\") == \"fake-authorization-code\"\n        # issue a fake token\n        self.finish(\n            {\"access_token\": \"fake-access-token\", \"expires_in\": \"never-expires\"}\n        )", "is_method": true, "class_name": "GoogleOAuth2TokenHandler", "function_description": "Method of GoogleOAuth2TokenHandler that simulates an OAuth2 token exchange by validating a fixed authorization code and returning a mock access token for testing or development purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get", "line_number": 577, "body": "def get(self):\n        assert self.get_argument(\"access_token\") == \"fake-access-token\"\n        # return a fake user\n        self.finish({\"name\": \"Foo\", \"email\": \"foo@example.com\"})", "is_method": true, "class_name": "GoogleOAuth2UserinfoHandler", "function_description": "Simulates retrieving user information by validating a fixed access token and returning a predefined fake user profile, useful for testing OAuth2 userinfo endpoints without real authentication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "get_app", "line_number": 584, "body": "def get_app(self):\n        return Application(\n            [\n                # test endpoints\n                (\"/client/login\", GoogleLoginHandler, dict(test=self)),\n                # simulated google authorization server endpoints\n                (\"/google/oauth2/authorize\", GoogleOAuth2AuthorizeHandler),\n                (\"/google/oauth2/token\", GoogleOAuth2TokenHandler),\n                (\"/google/oauth2/userinfo\", GoogleOAuth2UserinfoHandler),\n            ],\n            google_oauth={\n                \"key\": \"fake_google_client_id\",\n                \"secret\": \"fake_google_client_secret\",\n            },\n        )", "is_method": true, "class_name": "GoogleOAuth2Test", "function_description": "Constructs and returns a test web application configured with simulated Google OAuth2 endpoints for login, authorization, token exchange, and user info retrieval, facilitating OAuth2 flow testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/auth_test.py", "function": "test_google_login", "line_number": 600, "body": "def test_google_login(self):\n        response = self.fetch(\"/client/login\")\n        self.assertDictEqual(\n            {\n                u\"name\": u\"Foo\",\n                u\"email\": u\"foo@example.com\",\n                u\"access_token\": u\"fake-access-token\",\n            },\n            json_decode(response.body),\n        )", "is_method": true, "class_name": "GoogleOAuth2Test", "function_description": "Test method verifying that the Google login endpoint returns the expected user information and access token, ensuring correct OAuth2 authentication flow in the GoogleOAuth2Test class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_two_arg_exception", "line_number": 28, "body": "def test_two_arg_exception(self):\n        # This test would fail on python 3 if raise_exc_info were simply\n        # a three-argument raise statement, because TwoArgException\n        # doesn't have a \"copy constructor\"\n        class TwoArgException(Exception):\n            def __init__(self, a, b):\n                super().__init__()\n                self.a, self.b = a, b\n\n        try:\n            raise TwoArgException(1, 2)\n        except TwoArgException:\n            exc_info = sys.exc_info()\n        try:\n            raise_exc_info(exc_info)\n            self.fail(\"didn't get expected exception\")\n        except TwoArgException as e:\n            self.assertIs(e, exc_info[1])", "is_method": true, "class_name": "RaiseExcInfoTest", "function_description": "Tests that the raise_exc_info function correctly re-raises an exception using its exception info tuple, ensuring compatibility with exceptions that accept two arguments during initialization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "configurable_base", "line_number": 50, "body": "def configurable_base(cls):\n        return TestConfigurable", "is_method": true, "class_name": "TestConfigurable", "function_description": "Returns the TestConfigurable class regardless of the input, potentially serving as a base class reference for configuration or testing purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "configurable_default", "line_number": 54, "body": "def configurable_default(cls):\n        return TestConfig1", "is_method": true, "class_name": "TestConfigurable", "function_description": "Returns the default configuration class used by the TestConfigurable class. This function provides a baseline configuration for tests requiring a standard setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "initialize", "line_number": 59, "body": "def initialize(self, pos_arg=None, a=None):\n        self.a = a\n        self.pos_arg = pos_arg", "is_method": true, "class_name": "TestConfig1", "function_description": "Sets or updates the attributes `a` and `pos_arg` of the TestConfig1 instance, allowing initialization or modification of these parameters. It serves to configure the instance with optional values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "initialize", "line_number": 65, "body": "def initialize(self, pos_arg=None, b=None):\n        self.b = b\n        self.pos_arg = pos_arg", "is_method": true, "class_name": "TestConfig2", "function_description": "Initializes an instance of TestConfig2 by setting optional positional and keyword attributes. This function provides basic configuration setup for an object\u2019s state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "configurable_base", "line_number": 73, "body": "def configurable_base(cls):\n        return TestConfig3", "is_method": true, "class_name": "TestConfig3", "function_description": "Returns the TestConfig3 class, likely used to specify or override the base configuration class in a testing context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "configurable_default", "line_number": 77, "body": "def configurable_default(cls):\n        return TestConfig3A", "is_method": true, "class_name": "TestConfig3", "function_description": "Returns a default configuration class for use in testing setups, providing a standard baseline configuration when none is specified."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "initialize", "line_number": 82, "body": "def initialize(self, a=None):\n        self.a = a", "is_method": true, "class_name": "TestConfig3A", "function_description": "Initializer method for the TestConfig3A class that sets the attribute 'a' to a given value or None. It provides basic configuration setup upon object creation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "initialize", "line_number": 87, "body": "def initialize(self, b=None):\n        self.b = b", "is_method": true, "class_name": "TestConfig3B", "function_description": "Simple setter method of the TestConfig3B class that assigns an optional parameter to an instance attribute, supporting configuration initialization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "setUp", "line_number": 92, "body": "def setUp(self):\n        self.saved = TestConfigurable._save_configuration()\n        self.saved3 = TestConfig3._save_configuration()", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Sets up test environment by saving current configurations from TestConfigurable and TestConfig3 classes for later restoration during tests in the ConfigurableTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "tearDown", "line_number": 96, "body": "def tearDown(self):\n        TestConfigurable._restore_configuration(self.saved)\n        TestConfig3._restore_configuration(self.saved3)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Resets configurations to their original states after a test completes, ensuring isolation and consistency across tests in the ConfigurableTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "checkSubclasses", "line_number": 100, "body": "def checkSubclasses(self):\n        # no matter how the class is configured, it should always be\n        # possible to instantiate the subclasses directly\n        self.assertIsInstance(TestConfig1(), TestConfig1)\n        self.assertIsInstance(TestConfig2(), TestConfig2)\n\n        obj = TestConfig1(a=1)\n        self.assertEqual(obj.a, 1)\n        obj2 = TestConfig2(b=2)\n        self.assertEqual(obj2.b, 2)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests that subclasses can be instantiated correctly with or without configuration, verifying their instance types and attribute assignments. It ensures subclass initialization behaves as expected regardless of configuration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_default", "line_number": 111, "body": "def test_default(self):\n        # In these tests we combine a typing.cast to satisfy mypy with\n        # a runtime type-assertion. Without the cast, mypy would only\n        # let us access attributes of the base class.\n        obj = cast(TestConfig1, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig1)\n        self.assertIs(obj.a, None)\n\n        obj = cast(TestConfig1, TestConfigurable(a=1))\n        self.assertIsInstance(obj, TestConfig1)\n        self.assertEqual(obj.a, 1)\n\n        self.checkSubclasses()", "is_method": true, "class_name": "ConfigurableTest", "function_description": "This test method verifies default attribute values and type correctness of configurable objects, ensuring they properly instantiate and behave as expected within the class hierarchy. It supports validating subclass behaviors in configuration testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_class", "line_number": 125, "body": "def test_config_class(self):\n        TestConfigurable.configure(TestConfig2)\n        obj = cast(TestConfig2, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertIs(obj.b, None)\n\n        obj = cast(TestConfig2, TestConfigurable(b=2))\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertEqual(obj.b, 2)\n\n        self.checkSubclasses()", "is_method": true, "class_name": "ConfigurableTest", "function_description": "This test method verifies that the ConfigurableTest class correctly applies the TestConfig2 configuration, ensuring proper instantiation, attribute initialization, and subclass relationships. It validates configuration functionality through assertions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_str", "line_number": 137, "body": "def test_config_str(self):\n        TestConfigurable.configure(\"tornado.test.util_test.TestConfig2\")\n        obj = cast(TestConfig2, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertIs(obj.b, None)\n\n        obj = cast(TestConfig2, TestConfigurable(b=2))\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertEqual(obj.b, 2)\n\n        self.checkSubclasses()", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests that ConfigurableTest correctly configures and instantiates objects of a specified class with optional parameters. It verifies instance types and initialization values to ensure proper subclass behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_args", "line_number": 149, "body": "def test_config_args(self):\n        TestConfigurable.configure(None, a=3)\n        obj = cast(TestConfig1, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig1)\n        self.assertEqual(obj.a, 3)\n\n        obj = cast(TestConfig1, TestConfigurable(42, a=4))\n        self.assertIsInstance(obj, TestConfig1)\n        self.assertEqual(obj.a, 4)\n        self.assertEqual(obj.pos_arg, 42)\n\n        self.checkSubclasses()\n        # args bound in configure don't apply when using the subclass directly\n        obj = TestConfig1()\n        self.assertIs(obj.a, None)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests whether ConfigurableTest correctly applies configuration arguments and subclass instantiation, verifying that parameter binding affects dynamically configured instances but not direct subclass usage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_class_args", "line_number": 165, "body": "def test_config_class_args(self):\n        TestConfigurable.configure(TestConfig2, b=5)\n        obj = cast(TestConfig2, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertEqual(obj.b, 5)\n\n        obj = cast(TestConfig2, TestConfigurable(42, b=6))\n        self.assertIsInstance(obj, TestConfig2)\n        self.assertEqual(obj.b, 6)\n        self.assertEqual(obj.pos_arg, 42)\n\n        self.checkSubclasses()\n        # args bound in configure don't apply when using the subclass directly\n        obj = TestConfig2()\n        self.assertIs(obj.b, None)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests that the ConfigurableTest class can correctly configure and instantiate a configurable subclass with specific arguments, validating argument binding behavior and subclass integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_multi_level", "line_number": 181, "body": "def test_config_multi_level(self):\n        TestConfigurable.configure(TestConfig3, a=1)\n        obj = cast(TestConfig3A, TestConfigurable())\n        self.assertIsInstance(obj, TestConfig3A)\n        self.assertEqual(obj.a, 1)\n\n        TestConfigurable.configure(TestConfig3)\n        TestConfig3.configure(TestConfig3B, b=2)\n        obj2 = cast(TestConfig3B, TestConfigurable())\n        self.assertIsInstance(obj2, TestConfig3B)\n        self.assertEqual(obj2.b, 2)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests the ConfigurableTest class's multi-level configuration ability by verifying that configurations cascade correctly and instances reflect expected subclasses and attribute values after configuration changes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_config_inner_level", "line_number": 193, "body": "def test_config_inner_level(self):\n        # The inner level can be used even when the outer level\n        # doesn't point to it.\n        obj = TestConfig3()\n        self.assertIsInstance(obj, TestConfig3A)\n\n        TestConfig3.configure(TestConfig3B)\n        obj = TestConfig3()\n        self.assertIsInstance(obj, TestConfig3B)\n\n        # Configuring the base doesn't configure the inner.\n        obj2 = TestConfigurable()\n        self.assertIsInstance(obj2, TestConfig1)\n        TestConfigurable.configure(TestConfig2)\n\n        obj3 = TestConfigurable()\n        self.assertIsInstance(obj3, TestConfig2)\n\n        obj = TestConfig3()\n        self.assertIsInstance(obj, TestConfig3B)", "is_method": true, "class_name": "ConfigurableTest", "function_description": "Tests various configuration scenarios within the ConfigurableTest class, verifying object instantiation respects dynamic class-level configurations and the impact of configuring base versus inner levels. It ensures configuration changes propagate correctly in test objects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_unicode_escapes", "line_number": 216, "body": "def test_unicode_escapes(self):\n        self.assertEqual(utf8(u\"\\u00e9\"), b\"\\xc3\\xa9\")", "is_method": true, "class_name": "UnicodeLiteralTest", "function_description": "Test method in UnicodeLiteralTest that verifies correct UTF-8 encoding of a Unicode escape sequence to ensure proper byte representation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_no_inherit_future", "line_number": 224, "body": "def test_no_inherit_future(self):\n        # This file has from __future__ import print_function...\n        f = StringIO()\n        print(\"hello\", file=f)\n        # ...but the template doesn't\n        exec_in('print >> f, \"world\"', dict(f=f))\n        self.assertEqual(f.getvalue(), \"hello\\nworld\\n\")", "is_method": true, "class_name": "ExecInTest", "function_description": "This test method verifies that code executed with exec_in respects local future imports without inheriting them, ensuring separate future feature behavior during dynamic execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "setUp", "line_number": 234, "body": "def setUp(self):\n        def function(x, y, callback=None, z=None):\n            pass\n\n        self.replacer = ArgReplacer(function, \"callback\")", "is_method": true, "class_name": "ArgReplacerTest", "function_description": "Setup method for ArgReplacerTest that initializes an ArgReplacer instance targeting the 'callback' argument of a sample function."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_omitted", "line_number": 240, "body": "def test_omitted(self):\n        args = (1, 2)\n        kwargs = dict()  # type: Dict[str, Any]\n        self.assertIs(self.replacer.get_old_value(args, kwargs), None)\n        self.assertEqual(\n            self.replacer.replace(\"new\", args, kwargs),\n            (None, (1, 2), dict(callback=\"new\")),\n        )", "is_method": true, "class_name": "ArgReplacerTest", "function_description": "Unit test method in ArgReplacerTest that verifies behavior when no matching argument is found, ensuring the replacer returns None and updates keyword arguments appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_position", "line_number": 249, "body": "def test_position(self):\n        args = (1, 2, \"old\", 3)\n        kwargs = dict()  # type: Dict[str, Any]\n        self.assertEqual(self.replacer.get_old_value(args, kwargs), \"old\")\n        self.assertEqual(\n            self.replacer.replace(\"new\", args, kwargs),\n            (\"old\", [1, 2, \"new\", 3], dict()),\n        )", "is_method": true, "class_name": "ArgReplacerTest", "function_description": "This test method verifies that the ArgReplacer correctly retrieves and replaces a specific positional argument value within given arguments, ensuring its argument substitution behavior functions as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_keyword", "line_number": 258, "body": "def test_keyword(self):\n        args = (1,)\n        kwargs = dict(y=2, callback=\"old\", z=3)\n        self.assertEqual(self.replacer.get_old_value(args, kwargs), \"old\")\n        self.assertEqual(\n            self.replacer.replace(\"new\", args, kwargs),\n            (\"old\", (1,), dict(y=2, callback=\"new\", z=3)),\n        )", "is_method": true, "class_name": "ArgReplacerTest", "function_description": "Unit test method validating that the argument replacer correctly retrieves and updates a specific keyword argument within given positional and keyword arguments. It ensures accurate replacement and retrieval of the \"callback\" parameter value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_timedelta_to_seconds", "line_number": 269, "body": "def test_timedelta_to_seconds(self):\n        time_delta = datetime.timedelta(hours=1)\n        self.assertEqual(timedelta_to_seconds(time_delta), 3600.0)", "is_method": true, "class_name": "TimedeltaToSecondsTest", "function_description": "Unit test method in TimedeltaToSecondsTest that verifies the timedelta_to_seconds function correctly converts a one-hour timedelta into its equivalent number of seconds."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_import_member", "line_number": 275, "body": "def test_import_member(self):\n        self.assertIs(import_object(\"tornado.escape.utf8\"), utf8)", "is_method": true, "class_name": "ImportObjectTest", "function_description": "Unit test method of ImportObjectTest that verifies importing a specific member by its string path returns the expected object, ensuring correct dynamic import functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_import_member_unicode", "line_number": 278, "body": "def test_import_member_unicode(self):\n        self.assertIs(import_object(u\"tornado.escape.utf8\"), utf8)", "is_method": true, "class_name": "ImportObjectTest", "function_description": "Unit test method in ImportObjectTest that verifies importing a module member by its Unicode string path correctly returns the expected object. It ensures Unicode string handling works for dynamic imports."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_import_module", "line_number": 281, "body": "def test_import_module(self):\n        self.assertIs(import_object(\"tornado.escape\"), tornado.escape)", "is_method": true, "class_name": "ImportObjectTest", "function_description": "Tests whether the import_object function correctly imports a specified module, validating its dynamic import capability."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_import_module_unicode", "line_number": 284, "body": "def test_import_module_unicode(self):\n        # The internal implementation of __import__ differs depending on\n        # whether the thing being imported is a module or not.\n        # This variant requires a byte string in python 2.\n        self.assertIs(import_object(u\"tornado.escape\"), tornado.escape)", "is_method": true, "class_name": "ImportObjectTest", "function_description": "Tests that the import_object function correctly imports a module using a Unicode string as its name, ensuring compatibility with string types during module importation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_re_unescape", "line_number": 292, "body": "def test_re_unescape(self):\n        test_strings = (\"/favicon.ico\", \"index.html\", \"Hello, World!\", \"!$@#%;\")\n        for string in test_strings:\n            self.assertEqual(string, re_unescape(re.escape(string)))", "is_method": true, "class_name": "ReUnescapeTest", "function_description": "This test method verifies that re_unescape correctly reverses the escaping of special characters in strings, ensuring the original strings are accurately restored after escaping. It is used for validating escaping and unescaping consistency."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_re_unescape_raises_error_on_invalid_input", "line_number": 297, "body": "def test_re_unescape_raises_error_on_invalid_input(self):\n        with self.assertRaises(ValueError):\n            re_unescape(\"\\\\d\")\n        with self.assertRaises(ValueError):\n            re_unescape(\"\\\\b\")\n        with self.assertRaises(ValueError):\n            re_unescape(\"\\\\Z\")", "is_method": true, "class_name": "ReUnescapeTest", "function_description": "Tests that the re_unescape function correctly raises ValueError when given invalid escape sequences. It ensures input validation by verifying error handling for improper regex escapes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util_test.py", "function": "test_basic", "line_number": 307, "body": "def test_basic(self):\n        self.assertFalse(is_finalizing())", "is_method": true, "class_name": "IsFinalizingTest", "function_description": "Unit test method in IsFinalizingTest that verifies the is_finalizing function correctly returns False in a basic scenario, ensuring expected behavior during test finalization checking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "get_new_ioloop", "line_number": 28, "body": "def get_new_ioloop(self):\n        io_loop = AsyncIOLoop()\n        return io_loop", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Creates and returns a new instance of an asynchronous I/O loop. This method provides a fresh event loop for asynchronous operations within the AsyncIOLoopTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_callback", "line_number": 32, "body": "def test_asyncio_callback(self):\n        # Basic test that the asyncio loop is set up correctly.\n        asyncio.get_event_loop().call_soon(self.stop)\n        self.wait()", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Basic test method in AsyncIOLoopTest that verifies the asyncio event loop can schedule a callback and correctly handle loop stopping and waiting. It ensures the event loop setup works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_future", "line_number": 38, "body": "def test_asyncio_future(self):\n        # Test that we can yield an asyncio future from a tornado coroutine.\n        # Without 'yield from', we must wrap coroutines in ensure_future,\n        # which was introduced during Python 3.4, deprecating the prior \"async\".\n        if hasattr(asyncio, \"ensure_future\"):\n            ensure_future = asyncio.ensure_future\n        else:\n            # async is a reserved word in Python 3.7\n            ensure_future = getattr(asyncio, \"async\")\n\n        x = yield ensure_future(\n            asyncio.get_event_loop().run_in_executor(None, lambda: 42)\n        )\n        self.assertEqual(x, 42)", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Core test method of AsyncIOLoopTest that verifies the integration of asyncio futures with Tornado coroutines by ensuring correct execution and result retrieval from an asynchronous task wrapped into a future."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_yield_from", "line_number": 54, "body": "def test_asyncio_yield_from(self):\n        @gen.coroutine\n        def f():\n            event_loop = asyncio.get_event_loop()\n            x = yield from event_loop.run_in_executor(None, lambda: 42)\n            return x\n\n        result = yield f()\n        self.assertEqual(result, 42)", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Tests asynchronous execution by running a synchronous function in an executor and verifying the correct result is yielded using asyncio's event loop. This ensures proper coroutine integration with futures in async code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_adapter", "line_number": 64, "body": "def test_asyncio_adapter(self):\n        # This test demonstrates that when using the asyncio coroutine\n        # runner (i.e. run_until_complete), the to_asyncio_future\n        # adapter is needed. No adapter is needed in the other direction,\n        # as demonstrated by other tests in the package.\n        @gen.coroutine\n        def tornado_coroutine():\n            yield gen.moment\n            raise gen.Return(42)\n\n        async def native_coroutine_without_adapter():\n            return await tornado_coroutine()\n\n        async def native_coroutine_with_adapter():\n            return await to_asyncio_future(tornado_coroutine())\n\n        # Use the adapter, but two degrees from the tornado coroutine.\n        async def native_coroutine_with_adapter2():\n            return await to_asyncio_future(native_coroutine_without_adapter())\n\n        # Tornado supports native coroutines both with and without adapters\n        self.assertEqual(self.io_loop.run_sync(native_coroutine_without_adapter), 42)\n        self.assertEqual(self.io_loop.run_sync(native_coroutine_with_adapter), 42)\n        self.assertEqual(self.io_loop.run_sync(native_coroutine_with_adapter2), 42)\n\n        # Asyncio only supports coroutines that yield asyncio-compatible\n        # Futures (which our Future is since 5.0).\n        self.assertEqual(\n            asyncio.get_event_loop().run_until_complete(\n                native_coroutine_without_adapter()\n            ),\n            42,\n        )\n        self.assertEqual(\n            asyncio.get_event_loop().run_until_complete(\n                native_coroutine_with_adapter()\n            ),\n            42,\n        )\n        self.assertEqual(\n            asyncio.get_event_loop().run_until_complete(\n                native_coroutine_with_adapter2()\n            ),\n            42,\n        )", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Test method of AsyncIOLoopTest that verifies the interoperability between Tornado and asyncio coroutines, highlighting the need for an adapter to run Tornado coroutines with asyncio's event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "setUp", "line_number": 112, "body": "def setUp(self):\n        # Trigger a cleanup of the mapping so we start with a clean slate.\n        AsyncIOLoop().close()\n        # If we don't clean up after ourselves other tests may fail on\n        # py34.\n        self.orig_policy = asyncio.get_event_loop_policy()\n        asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())", "is_method": true, "class_name": "LeakTest", "function_description": "Setup method in LeakTest that resets the asynchronous event loop environment to a clean state before each test, ensuring no interference from previous tests on event loop policies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "tearDown", "line_number": 120, "body": "def tearDown(self):\n        asyncio.get_event_loop().close()\n        asyncio.set_event_loop_policy(self.orig_policy)", "is_method": true, "class_name": "LeakTest", "function_description": "Cleans up asynchronous event loop resources by closing the current loop and restoring the original event loop policy, ensuring the testing environment is properly reset after each leak test."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_ioloop_close_leak", "line_number": 124, "body": "def test_ioloop_close_leak(self):\n        orig_count = len(IOLoop._ioloop_for_asyncio)\n        for i in range(10):\n            # Create and close an AsyncIOLoop using Tornado interfaces.\n            loop = AsyncIOLoop()\n            loop.close()\n        new_count = len(IOLoop._ioloop_for_asyncio) - orig_count\n        self.assertEqual(new_count, 0)", "is_method": true, "class_name": "LeakTest", "function_description": "Test method in LeakTest that verifies no resource leaks occur when repeatedly creating and closing AsyncIOLoop instances, ensuring proper cleanup of asynchronous event loops."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_close_leak", "line_number": 133, "body": "def test_asyncio_close_leak(self):\n        orig_count = len(IOLoop._ioloop_for_asyncio)\n        for i in range(10):\n            # Create and close an AsyncIOMainLoop using asyncio interfaces.\n            loop = asyncio.new_event_loop()\n            loop.call_soon(IOLoop.current)\n            loop.call_soon(loop.stop)\n            loop.run_forever()\n            loop.close()\n        new_count = len(IOLoop._ioloop_for_asyncio) - orig_count\n        # Because the cleanup is run on new loop creation, we have one\n        # dangling entry in the map (but only one).\n        self.assertEqual(new_count, 1)", "is_method": true, "class_name": "LeakTest", "function_description": "This method tests for resource leaks in asyncio event loops by repeatedly creating and closing them, ensuring only a single expected reference remains. It helps verify proper cleanup of asyncio loop instances within the LeakTest class context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "setUp", "line_number": 149, "body": "def setUp(self):\n        self.orig_policy = asyncio.get_event_loop_policy()\n        self.executor = ThreadPoolExecutor(1)", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Setup method that initializes the test by saving the current asyncio event loop policy and creating a single-worker thread pool executor for use in test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "tearDown", "line_number": 153, "body": "def tearDown(self):\n        asyncio.set_event_loop_policy(self.orig_policy)\n        self.executor.shutdown()", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Resets the asyncio event loop policy to its original state and shuts down the executor, ensuring a clean environment after tests run. This method helps maintain test isolation and resource cleanup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "get_event_loop_on_thread", "line_number": 157, "body": "def get_event_loop_on_thread(self):\n        def get_and_close_event_loop():\n            \"\"\"Get the event loop. Close it if one is returned.\n\n            Returns the (closed) event loop. This is a silly thing\n            to do and leaves the thread in a broken state, but it's\n            enough for this test. Closing the loop avoids resource\n            leak warnings.\n            \"\"\"\n            loop = asyncio.get_event_loop()\n            loop.close()\n            return loop\n\n        future = self.executor.submit(get_and_close_event_loop)\n        return future.result()", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Provides a test utility that retrieves and closes an asyncio event loop on a separate thread to avoid resource leaks, enabling controlled event loop handling within threaded test environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "run_policy_test", "line_number": 173, "body": "def run_policy_test(self, accessor, expected_type):\n        # With the default policy, non-main threads don't get an event\n        # loop.\n        self.assertRaises(\n            (RuntimeError, AssertionError), self.executor.submit(accessor).result\n        )\n        # Set the policy and we can get a loop.\n        asyncio.set_event_loop_policy(AnyThreadEventLoopPolicy())\n        self.assertIsInstance(self.executor.submit(accessor).result(), expected_type)\n        # Clean up to silence leak warnings. Always use asyncio since\n        # IOLoop doesn't (currently) close the underlying loop.\n        self.executor.submit(lambda: asyncio.get_event_loop().close()).result()", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Utility method in AnyThreadEventLoopPolicyTest that verifies the event loop policy allows event loops in non-main threads, ensuring correct loop retrieval and cleanup during asynchronous execution tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_asyncio_accessor", "line_number": 186, "body": "def test_asyncio_accessor(self):\n        self.run_policy_test(asyncio.get_event_loop, asyncio.AbstractEventLoop)", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Tests that the asyncio event loop accessor returns an instance of the expected AbstractEventLoop type, validating event loop policy behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "test_tornado_accessor", "line_number": 189, "body": "def test_tornado_accessor(self):\n        self.run_policy_test(IOLoop.current, IOLoop)", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Tests that the Tornado IOLoop accessor returns the correct current event loop instance using a specific event loop policy. It ensures integration between the event loop policy and Tornado's IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "f", "line_number": 56, "body": "def f():\n            event_loop = asyncio.get_event_loop()\n            x = yield from event_loop.run_in_executor(None, lambda: 42)\n            return x", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Provides an asynchronous method to run a blocking operation in a separate thread, returning its result within an asyncio event loop for concurrency support."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "tornado_coroutine", "line_number": 70, "body": "def tornado_coroutine():\n            yield gen.moment\n            raise gen.Return(42)", "is_method": true, "class_name": "AsyncIOLoopTest", "function_description": "Returns the integer 42 asynchronously after yielding control once. It demonstrates a simple Tornado coroutine for asynchronous execution in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/asyncio_test.py", "function": "get_and_close_event_loop", "line_number": 158, "body": "def get_and_close_event_loop():\n            \"\"\"Get the event loop. Close it if one is returned.\n\n            Returns the (closed) event loop. This is a silly thing\n            to do and leaves the thread in a broken state, but it's\n            enough for this test. Closing the loop avoids resource\n            leak warnings.\n            \"\"\"\n            loop = asyncio.get_event_loop()\n            loop.close()\n            return loop", "is_method": true, "class_name": "AnyThreadEventLoopPolicyTest", "function_description": "Utility function that obtains the current asyncio event loop, closes it to avoid resource leaks, and returns the closed loop, primarily used for testing scenarios involving event loop management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util.py", "function": "_detect_ipv6", "line_number": 42, "body": "def _detect_ipv6():\n    if not socket.has_ipv6:\n        # socket.has_ipv6 check reports whether ipv6 was present at compile\n        # time. It's usually true even when ipv6 doesn't work for other reasons.\n        return False\n    sock = None\n    try:\n        sock = socket.socket(socket.AF_INET6)\n        sock.bind((\"::1\", 0))\n    except socket.error:\n        return False\n    finally:\n        if sock is not None:\n            sock.close()\n    return True", "is_method": false, "function_description": "Internal utility function that checks if the current system supports IPv6 by attempting to bind an IPv6 socket. It enables code paths to conditionally use IPv6 features based on actual runtime availability."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util.py", "function": "refusing_port", "line_number": 62, "body": "def refusing_port():\n    \"\"\"Returns a local port number that will refuse all connections.\n\n    Return value is (cleanup_func, port); the cleanup function\n    must be called to free the port to be reused.\n    \"\"\"\n    # On travis-ci, port numbers are reassigned frequently. To avoid\n    # collisions with other tests, we use an open client-side socket's\n    # ephemeral port number to ensure that nothing can listen on that\n    # port.\n    server_socket, port = bind_unused_port()\n    server_socket.setblocking(True)\n    client_socket = socket.socket()\n    client_socket.connect((\"127.0.0.1\", port))\n    conn, client_addr = server_socket.accept()\n    conn.close()\n    server_socket.close()\n    return (client_socket.close, client_addr[1])", "is_method": false, "function_description": "Provides a local port number that refuses all incoming connections, along with a cleanup function to release the port. Useful for testing scenarios needing guaranteed connection refusal without port conflicts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util.py", "function": "exec_test", "line_number": 82, "body": "def exec_test(caller_globals, caller_locals, s):\n    \"\"\"Execute ``s`` in a given context and return the result namespace.\n\n    Used to define functions for tests in particular python\n    versions that would be syntax errors in older versions.\n    \"\"\"\n    # Flatten the real global and local namespace into our fake\n    # globals: it's all global from the perspective of code defined\n    # in s.\n    global_namespace = dict(caller_globals, **caller_locals)  # type: ignore\n    local_namespace = {}  # type: typing.Dict[str, typing.Any]\n    exec(textwrap.dedent(s), global_namespace, local_namespace)\n    return local_namespace", "is_method": false, "function_description": "Utility function that executes a code string in specified global and local contexts, returning the resulting namespace. It enables defining version-specific test functions without syntax errors in earlier Python versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util.py", "function": "subTest", "line_number": 97, "body": "def subTest(test, *args, **kwargs):\n    \"\"\"Compatibility shim for unittest.TestCase.subTest.\n\n    Usage: ``with tornado.test.util.subTest(self, x=x):``\n    \"\"\"\n    try:\n        subTest = test.subTest  # py34+\n    except AttributeError:\n        subTest = contextlib.contextmanager(lambda *a, **kw: (yield))\n    return subTest(*args, **kwargs)", "is_method": false, "function_description": "Provides a compatibility wrapper for unittest's subTest context manager, enabling consistent subtest handling across Python versions. It allows code to use subTest features even if the native method is unavailable."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/util.py", "function": "ignore_deprecation", "line_number": 110, "body": "def ignore_deprecation():\n    \"\"\"Context manager to ignore deprecation warnings.\"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", DeprecationWarning)\n        yield", "is_method": false, "function_description": "Context manager that temporarily suppresses DeprecationWarning messages, allowing code to execute without interruption from such warnings during its block."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "set_environ", "line_number": 17, "body": "def set_environ(name, value):\n    old_value = os.environ.get(name)\n    os.environ[name] = value\n\n    try:\n        yield\n    finally:\n        if old_value is None:\n            del os.environ[name]\n        else:\n            os.environ[name] = old_value", "is_method": false, "function_description": "Function that temporarily sets an environment variable to a specified value within a context, restoring its previous state afterward. It is useful for running code with modified environment settings without permanent changes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_wait_timeout", "line_number": 31, "body": "def test_wait_timeout(self):\n        time = self.io_loop.time\n\n        # Accept default 5-second timeout, no error\n        self.io_loop.add_timeout(time() + 0.01, self.stop)\n        self.wait()\n\n        # Timeout passed to wait()\n        self.io_loop.add_timeout(time() + 1, self.stop)\n        with self.assertRaises(self.failureException):\n            self.wait(timeout=0.01)\n\n        # Timeout set with environment variable\n        self.io_loop.add_timeout(time() + 1, self.stop)\n        with set_environ(\"ASYNC_TEST_TIMEOUT\", \"0.01\"):\n            with self.assertRaises(self.failureException):\n                self.wait()", "is_method": true, "class_name": "AsyncTestCaseTest", "function_description": "Tests that the asynchronous wait method enforces timeout behavior correctly, including default, explicit, and environment variable\u2013based timeouts, ensuring timeout exceptions are raised as expected during asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_subsequent_wait_calls", "line_number": 49, "body": "def test_subsequent_wait_calls(self):\n        \"\"\"\n        This test makes sure that a second call to wait()\n        clears the first timeout.\n        \"\"\"\n        # The first wait ends with time left on the clock\n        self.io_loop.add_timeout(self.io_loop.time() + 0.00, self.stop)\n        self.wait(timeout=0.1)\n        # The second wait has enough time for itself but would fail if the\n        # first wait's deadline were still in effect.\n        self.io_loop.add_timeout(self.io_loop.time() + 0.2, self.stop)\n        self.wait(timeout=0.4)", "is_method": true, "class_name": "AsyncTestCaseTest", "function_description": "Tests that multiple consecutive wait() calls correctly reset timeouts, ensuring each wait operates with its own independent timeout without interference from prior calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "tearDown", "line_number": 64, "body": "def tearDown(self):\n        super().tearDown()\n        # Trigger a gc to make warnings more deterministic.\n        gc.collect()", "is_method": true, "class_name": "LeakTest", "function_description": "Performs cleanup after test execution by running superclass teardown logic and forcing garbage collection to ensure more consistent detection of resource leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_leaked_coroutine", "line_number": 69, "body": "def test_leaked_coroutine(self):\n        # This test verifies that \"leaked\" coroutines are shut down\n        # without triggering warnings like \"task was destroyed but it\n        # is pending\". If this test were to fail, it would fail\n        # because runtests.py detected unexpected output to stderr.\n        event = Event()\n\n        async def callback():\n            try:\n                await event.wait()\n            except asyncio.CancelledError:\n                pass\n\n        self.io_loop.add_callback(callback)\n        self.io_loop.add_callback(self.stop)\n        self.wait()", "is_method": true, "class_name": "LeakTest", "function_description": "Core method of the LeakTest class that verifies leaked coroutines are properly shut down without producing warning messages, ensuring clean asynchronous task management during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "setUp", "line_number": 88, "body": "def setUp(self):\n        super().setUp()\n        # Bind a second port.\n        sock, port = bind_unused_port()\n        app = Application()\n        server = HTTPServer(app, **self.get_httpserver_options())\n        server.add_socket(sock)\n        self.second_port = port\n        self.second_server = server", "is_method": true, "class_name": "AsyncHTTPTestCaseTest", "function_description": "Sets up a secondary HTTP server and binds it to an unused port for testing in the AsyncHTTPTestCaseTest class, enabling tests that require multiple server instances or ports."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "get_app", "line_number": 98, "body": "def get_app(self):\n        return Application()", "is_method": true, "class_name": "AsyncHTTPTestCaseTest", "function_description": "Returns a new instance of the Application class, providing the test framework with the application to run or test asynchronously."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_fetch_segment", "line_number": 101, "body": "def test_fetch_segment(self):\n        path = \"/path\"\n        response = self.fetch(path)\n        self.assertEqual(response.request.url, self.get_url(path))", "is_method": true, "class_name": "AsyncHTTPTestCaseTest", "function_description": "Core test method in AsyncHTTPTestCaseTest that verifies fetching a specific URL path returns a response with the expected request URL, ensuring correct request routing in asynchronous HTTP tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_fetch_full_http_url", "line_number": 106, "body": "def test_fetch_full_http_url(self):\n        # Ensure that self.fetch() recognizes absolute urls and does\n        # not transform them into references to our main test server.\n        path = \"http://localhost:%d/path\" % self.second_port\n\n        response = self.fetch(path)\n        self.assertEqual(response.request.url, path)", "is_method": true, "class_name": "AsyncHTTPTestCaseTest", "function_description": "Tests that the fetch method correctly handles and retrieves content from absolute HTTP URLs without rewriting them to the local test server, ensuring accurate URL resolution in asynchronous HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "tearDown", "line_number": 114, "body": "def tearDown(self):\n        self.second_server.stop()\n        super().tearDown()", "is_method": true, "class_name": "AsyncHTTPTestCaseTest", "function_description": "Cleans up resources by stopping the secondary server and performing standard teardown operations after each asynchronous HTTP test case. This ensures test isolation and proper resource release."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_undecorated_generator", "line_number": 120, "body": "def test_undecorated_generator(self):\n        class Test(AsyncTestCase):\n            def test_gen(self):\n                yield\n\n        test = Test(\"test_gen\")\n        result = unittest.TestResult()\n        test.run(result)\n        self.assertEqual(len(result.errors), 1)\n        self.assertIn(\"should be decorated\", result.errors[0][1])", "is_method": true, "class_name": "AsyncTestCaseWrapperTest", "function_description": "Tests that a generator method without proper decoration in an AsyncTestCase triggers an error, ensuring asynchronous test cases enforce correct coroutine usage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_undecorated_coroutine", "line_number": 135, "body": "def test_undecorated_coroutine(self):\n        class Test(AsyncTestCase):\n            async def test_coro(self):\n                pass\n\n        test = Test(\"test_coro\")\n        result = unittest.TestResult()\n\n        # Silence \"RuntimeWarning: coroutine 'test_coro' was never awaited\".\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            test.run(result)\n\n        self.assertEqual(len(result.errors), 1)\n        self.assertIn(\"should be decorated\", result.errors[0][1])", "is_method": true, "class_name": "AsyncTestCaseWrapperTest", "function_description": "Tests that an asynchronous coroutine method without the required decorator triggers an appropriate error during test execution, ensuring proper coroutine test compliance in AsyncTestCaseWrapperTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_undecorated_generator_with_skip", "line_number": 151, "body": "def test_undecorated_generator_with_skip(self):\n        class Test(AsyncTestCase):\n            @unittest.skip(\"don't run this\")\n            def test_gen(self):\n                yield\n\n        test = Test(\"test_gen\")\n        result = unittest.TestResult()\n        test.run(result)\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.skipped), 1)", "is_method": true, "class_name": "AsyncTestCaseWrapperTest", "function_description": "Tests that a skipped generator-based test method is correctly recognized as skipped without errors in an asynchronous test case. It verifies proper handling of skipped tests within AsyncTestCase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_other_return", "line_number": 163, "body": "def test_other_return(self):\n        class Test(AsyncTestCase):\n            def test_other_return(self):\n                return 42\n\n        test = Test(\"test_other_return\")\n        result = unittest.TestResult()\n        test.run(result)\n        self.assertEqual(len(result.errors), 1)\n        self.assertIn(\"Return value from test method ignored\", result.errors[0][1])", "is_method": true, "class_name": "AsyncTestCaseWrapperTest", "function_description": "This test method verifies that an AsyncTestCase test method returning a value produces an error indicating such return values are ignored. It ensures proper error reporting for unsupported test method behaviors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_set_up_tear_down", "line_number": 176, "body": "def test_set_up_tear_down(self):\n        \"\"\"\n        This test makes sure that AsyncTestCase calls super methods for\n        setUp and tearDown.\n\n        InheritBoth is a subclass of both AsyncTestCase and\n        SetUpTearDown, with the ordering so that the super of\n        AsyncTestCase will be SetUpTearDown.\n        \"\"\"\n        events = []\n        result = unittest.TestResult()\n\n        class SetUpTearDown(unittest.TestCase):\n            def setUp(self):\n                events.append(\"setUp\")\n\n            def tearDown(self):\n                events.append(\"tearDown\")\n\n        class InheritBoth(AsyncTestCase, SetUpTearDown):\n            def test(self):\n                events.append(\"test\")\n\n        InheritBoth(\"test\").run(result)\n        expected = [\"setUp\", \"test\", \"tearDown\"]\n        self.assertEqual(expected, events)", "is_method": true, "class_name": "SetUpTearDownTest", "function_description": "Test method in SetUpTearDownTest that verifies proper calling order of setUp and tearDown across multiple inheritance in async test cases. It ensures test lifecycle methods from both AsyncTestCase and a secondary class are executed correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_tear_down_releases_app_and_http_server", "line_number": 205, "body": "def test_tear_down_releases_app_and_http_server(self):\n        result = unittest.TestResult()\n\n        class SetUpTearDown(AsyncHTTPTestCase):\n            def get_app(self):\n                return Application()\n\n            def test(self):\n                self.assertTrue(hasattr(self, \"_app\"))\n                self.assertTrue(hasattr(self, \"http_server\"))\n\n        test = SetUpTearDown(\"test\")\n        test.run(result)\n        self.assertFalse(hasattr(test, \"_app\"))\n        self.assertFalse(hasattr(test, \"http_server\"))", "is_method": true, "class_name": "AsyncHTTPTestCaseSetUpTearDownTest", "function_description": "This test method verifies that the AsyncHTTPTestCase correctly releases its application and HTTP server resources after test execution, ensuring proper cleanup of these objects. It supports reliable resource management in asynchronous HTTP testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "setUp", "line_number": 223, "body": "def setUp(self):\n        super().setUp()\n        self.finished = False", "is_method": true, "class_name": "GenTest", "function_description": "Sets up the initial state before a test runs by calling the parent setup and initializing a completion flag. This method prepares the test environment for execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "tearDown", "line_number": 227, "body": "def tearDown(self):\n        self.assertTrue(self.finished)\n        super().tearDown()", "is_method": true, "class_name": "GenTest", "function_description": "Finalization method of the GenTest class that asserts test completion before performing standard teardown operations. It ensures tests conclude properly prior to resource cleanup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_sync", "line_number": 232, "body": "def test_sync(self):\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Sets the finished status to True, indicating completion. Used to mark synchronous test completion within the GenTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_async", "line_number": 236, "body": "def test_async(self):\n        yield gen.moment\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "This method yields control momentarily in asynchronous operations and marks the test as finished, supporting asynchronous flow control in the GenTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_timeout", "line_number": 240, "body": "def test_timeout(self):\n        # Set a short timeout and exceed it.\n        @gen_test(timeout=0.1)\n        def test(self):\n            yield gen.sleep(1)\n\n        # This can't use assertRaises because we need to inspect the\n        # exc_info triple (and not just the exception object)\n        try:\n            test(self)\n            self.fail(\"did not get expected exception\")\n        except ioloop.TimeoutError:\n            # The stack trace should blame the add_timeout line, not just\n            # unrelated IOLoop/testing internals.\n            self.assertIn(\"gen.sleep(1)\", traceback.format_exc())\n\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Utility method in GenTest verifying that a coroutine correctly raises a timeout error when exceeding a specified duration, ensuring timeout exceptions provide relevant stack trace information."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_no_timeout", "line_number": 258, "body": "def test_no_timeout(self):\n        # A test that does not exceed its timeout should succeed.\n        @gen_test(timeout=1)\n        def test(self):\n            yield gen.sleep(0.1)\n\n        test(self)\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "A test method within GenTest that verifies a coroutine completes successfully without exceeding a specified timeout, ensuring that tasks finishing promptly pass timeout constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_timeout_environment_variable", "line_number": 267, "body": "def test_timeout_environment_variable(self):\n        @gen_test(timeout=0.5)\n        def test_long_timeout(self):\n            yield gen.sleep(0.25)\n\n        # Uses provided timeout of 0.5 seconds, doesn't time out.\n        with set_environ(\"ASYNC_TEST_TIMEOUT\", \"0.1\"):\n            test_long_timeout(self)\n\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "This function tests that the asynchronous test decorator respects the environment variable for timeout settings, verifying that a test completes within the specified timeout duration. It ensures environment-based configuration correctly influences test timeouts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_no_timeout_environment_variable", "line_number": 278, "body": "def test_no_timeout_environment_variable(self):\n        @gen_test(timeout=0.01)\n        def test_short_timeout(self):\n            yield gen.sleep(1)\n\n        # Uses environment-variable timeout of 0.1, times out.\n        with set_environ(\"ASYNC_TEST_TIMEOUT\", \"0.1\"):\n            with self.assertRaises(ioloop.TimeoutError):\n                test_short_timeout(self)\n\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Tests that an asynchronous function respects a timeout specified by an environment variable, ensuring the configured timeout triggers correctly during execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_with_method_args", "line_number": 290, "body": "def test_with_method_args(self):\n        @gen_test\n        def test_with_args(self, *args):\n            self.assertEqual(args, (\"test\",))\n            yield gen.moment\n\n        test_with_args(self, \"test\")\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Utility method in GenTest that defines and runs a temporary test to verify argument passing in a decorated asynchronous test function."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_with_method_kwargs", "line_number": 299, "body": "def test_with_method_kwargs(self):\n        @gen_test\n        def test_with_kwargs(self, **kwargs):\n            self.assertDictEqual(kwargs, {\"test\": \"test\"})\n            yield gen.moment\n\n        test_with_kwargs(self, test=\"test\")\n        self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Method in GenTest that demonstrates running a test function with keyword arguments, verifying their passing and correctness within an asynchronous test context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_native_coroutine", "line_number": 308, "body": "def test_native_coroutine(self):\n        @gen_test\n        async def test(self):\n            self.finished = True\n\n        test(self)", "is_method": true, "class_name": "GenTest", "function_description": "Provides a test method wrapper that runs an asynchronous coroutine using a specific test decorator to mark completion within the GenTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_native_coroutine_timeout", "line_number": 315, "body": "def test_native_coroutine_timeout(self):\n        # Set a short timeout and exceed it.\n        @gen_test(timeout=0.1)\n        async def test(self):\n            await gen.sleep(1)\n\n        try:\n            test(self)\n            self.fail(\"did not get expected exception\")\n        except ioloop.TimeoutError:\n            self.finished = True", "is_method": true, "class_name": "GenTest", "function_description": "Tests that a native asynchronous coroutine correctly raises a timeout exception when execution exceeds a specified short timeout period. This function ensures timeout handling works as expected in asynchronous test scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "get_new_ioloop", "line_number": 329, "body": "def get_new_ioloop(self):\n        # Use the current loop instead of creating a new one here.\n        return ioloop.IOLoop.current()", "is_method": true, "class_name": "GetNewIOLoopTest", "function_description": "Returns the current asynchronous IOLoop instance instead of creating a new one, facilitating event loop reuse in asynchronous operations within the GetNewIOLoopTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "setUp", "line_number": 333, "body": "def setUp(self):\n        # This simulates the effect of an asyncio test harness like\n        # pytest-asyncio.\n        self.orig_loop = asyncio.get_event_loop()\n        self.new_loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(self.new_loop)\n        super().setUp()", "is_method": true, "class_name": "GetNewIOLoopTest", "function_description": "Sets up a new asyncio event loop for testing by replacing the existing loop, ensuring isolated asynchronous test execution in the GetNewIOLoopTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "tearDown", "line_number": 341, "body": "def tearDown(self):\n        super().tearDown()\n        # AsyncTestCase must not affect the existing asyncio loop.\n        self.assertFalse(asyncio.get_event_loop().is_closed())\n        asyncio.set_event_loop(self.orig_loop)\n        self.new_loop.close()", "is_method": true, "class_name": "GetNewIOLoopTest", "function_description": "Cleans up and restores the original asyncio event loop after a test case, ensuring test isolation without closing the global event loop prematurely."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_loop", "line_number": 348, "body": "def test_loop(self):\n        self.assertIs(self.io_loop.asyncio_loop, self.new_loop)", "is_method": true, "class_name": "GetNewIOLoopTest", "function_description": "Test method that verifies whether the asyncio event loop in io_loop matches the expected new_loop instance within the GetNewIOLoopTest class, ensuring correct loop assignment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test", "line_number": 243, "body": "def test(self):\n            yield gen.sleep(1)", "is_method": true, "class_name": "GenTest", "function_description": "Pauses execution within a coroutine for one second, enabling asynchronous wait functionality useful in event-driven or concurrent programming contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test", "line_number": 261, "body": "def test(self):\n            yield gen.sleep(0.1)", "is_method": true, "class_name": "GenTest", "function_description": "Yields a brief asynchronous pause, useful for simulating delay or waiting in generator-based coroutines within the GenTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_long_timeout", "line_number": 269, "body": "def test_long_timeout(self):\n            yield gen.sleep(0.25)", "is_method": true, "class_name": "GenTest", "function_description": "Generates a coroutine that pauses execution for 0.25 seconds, useful for testing asynchronous timeout handling or delays within asynchronous tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_short_timeout", "line_number": 280, "body": "def test_short_timeout(self):\n            yield gen.sleep(1)", "is_method": true, "class_name": "GenTest", "function_description": "Generates a coroutine that pauses execution for one second, useful for testing asynchronous timeout behavior in the GenTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_with_args", "line_number": 292, "body": "def test_with_args(self, *args):\n            self.assertEqual(args, (\"test\",))\n            yield gen.moment", "is_method": true, "class_name": "GenTest", "function_description": "Method in GenTest that verifies if passed arguments exactly match (\"test\",) and yields a generator moment, typically used for testing asynchronous operations with specific input validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_with_kwargs", "line_number": 301, "body": "def test_with_kwargs(self, **kwargs):\n            self.assertDictEqual(kwargs, {\"test\": \"test\"})\n            yield gen.moment", "is_method": true, "class_name": "GenTest", "function_description": "Core method of the GenTest class that verifies if given keyword arguments match a specific dictionary and then yields a generator moment, potentially used for testing generator behavior with expected input parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test_other_return", "line_number": 165, "body": "def test_other_return(self):\n                return 42", "is_method": true, "class_name": "Test", "function_description": "This test method simply returns the constant integer 42, potentially serving as a placeholder or simple verification in testing contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "setUp", "line_number": 189, "body": "def setUp(self):\n                events.append(\"setUp\")", "is_method": true, "class_name": "SetUpTearDown", "function_description": "Marks the initialization phase in test setup by appending a \"setUp\" event, typically used to prepare conditions before executing test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "tearDown", "line_number": 192, "body": "def tearDown(self):\n                events.append(\"tearDown\")", "is_method": true, "class_name": "SetUpTearDown", "function_description": "Simple method in SetUpTearDown that records a tear-down event, typically used for cleanup actions after tests or operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test", "line_number": 196, "body": "def test(self):\n                events.append(\"test\")", "is_method": true, "class_name": "InheritBoth", "function_description": "Method that appends the string \"test\" to the events list, likely for tracking or logging test-related occurrences within the InheritBoth class context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "get_app", "line_number": 209, "body": "def get_app(self):\n                return Application()", "is_method": true, "class_name": "SetUpTearDown", "function_description": "Returns a new instance of the Application class, providing access to the app object for setup or teardown operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/testing_test.py", "function": "test", "line_number": 212, "body": "def test(self):\n                self.assertTrue(hasattr(self, \"_app\"))\n                self.assertTrue(hasattr(self, \"http_server\"))", "is_method": true, "class_name": "SetUpTearDown", "function_description": "Method in SetUpTearDown class that verifies the presence of essential test attributes _app and http_server, ensuring the test environment is properly initialized before execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_return_sequence", "line_number": 29, "body": "def test_add_callback_return_sequence(self):\n        # A callback returning {} or [] shouldn't spin the CPU, see Issue #1803.\n        self.calls = 0\n\n        loop = self.io_loop\n        test = self\n        old_add_callback = loop.add_callback\n\n        def add_callback(self, callback, *args, **kwargs):\n            test.calls += 1\n            old_add_callback(callback, *args, **kwargs)\n\n        loop.add_callback = types.MethodType(add_callback, loop)  # type: ignore\n        loop.add_callback(lambda: {})  # type: ignore\n        loop.add_callback(lambda: [])  # type: ignore\n        loop.add_timeout(datetime.timedelta(milliseconds=50), loop.stop)\n        loop.start()\n        self.assertLess(self.calls, 10)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that adding callbacks which return empty collections does not cause excessive CPU usage or repeated callbacks in the TestIOLoop, ensuring efficient event loop behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_wakeup", "line_number": 49, "body": "def test_add_callback_wakeup(self):\n        # Make sure that add_callback from inside a running IOLoop\n        # wakes up the IOLoop immediately instead of waiting for a timeout.\n        def callback():\n            self.called = True\n            self.stop()\n\n        def schedule_callback():\n            self.called = False\n            self.io_loop.add_callback(callback)\n            # Store away the time so we can check if we woke up immediately\n            self.start_time = time.time()\n\n        self.io_loop.add_timeout(self.io_loop.time(), schedule_callback)\n        self.wait()\n        self.assertAlmostEqual(time.time(), self.start_time, places=2)\n        self.assertTrue(self.called)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Test method verifying that adding a callback within a running IOLoop immediately wakes the loop without delay, ensuring responsive asynchronous event handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_wakeup_other_thread", "line_number": 68, "body": "def test_add_callback_wakeup_other_thread(self):\n        def target():\n            # sleep a bit to let the ioloop go into its poll loop\n            time.sleep(0.01)\n            self.stop_time = time.time()\n            self.io_loop.add_callback(self.stop)\n\n        thread = threading.Thread(target=target)\n        self.io_loop.add_callback(thread.start)\n        self.wait()\n        delta = time.time() - self.stop_time\n        self.assertLess(delta, 0.1)\n        thread.join()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the I/O loop correctly wakes up and executes a callback from a different thread within a short time, verifying thread-safe callback handling in concurrent environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_timeout_timedelta", "line_number": 82, "body": "def test_add_timeout_timedelta(self):\n        self.io_loop.add_timeout(datetime.timedelta(microseconds=1), self.stop)\n        self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the IOLoop correctly schedules a callback after a very short timedelta, verifying timeout functionality. This method is useful for ensuring timing and callback mechanisms in asynchronous I/O loops work as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_multiple_add", "line_number": 86, "body": "def test_multiple_add(self):\n        sock, port = bind_unused_port()\n        try:\n            self.io_loop.add_handler(\n                sock.fileno(), lambda fd, events: None, IOLoop.READ\n            )\n            # Attempting to add the same handler twice fails\n            # (with a platform-dependent exception)\n            self.assertRaises(\n                Exception,\n                self.io_loop.add_handler,\n                sock.fileno(),\n                lambda fd, events: None,\n                IOLoop.READ,\n            )\n        finally:\n            self.io_loop.remove_handler(sock.fileno())\n            sock.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that adding the same I/O handler twice to the event loop raises an exception, ensuring handler uniqueness and proper error handling in the IOLoop class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_remove_without_add", "line_number": 105, "body": "def test_remove_without_add(self):\n        # remove_handler should not throw an exception if called on an fd\n        # was never added.\n        sock, port = bind_unused_port()\n        try:\n            self.io_loop.remove_handler(sock.fileno())\n        finally:\n            sock.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Method in TestIOLoop that verifies removing a non-existent handler does not raise exceptions, ensuring robustness when attempting to remove unregistered file descriptors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_from_signal", "line_number": 114, "body": "def test_add_callback_from_signal(self):\n        # cheat a little bit and just run this normally, since we can't\n        # easily simulate the races that happen with real signal handlers\n        self.io_loop.add_callback_from_signal(self.stop)\n        self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that a callback can be safely scheduled from a signal handler context within the IOLoop, verifying asynchronous stop functionality under signal-simulated conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_from_signal_other_thread", "line_number": 120, "body": "def test_add_callback_from_signal_other_thread(self):\n        # Very crude test, just to make sure that we cover this case.\n        # This also happens to be the first test where we run an IOLoop in\n        # a non-main thread.\n        other_ioloop = IOLoop()\n        thread = threading.Thread(target=other_ioloop.start)\n        thread.start()\n        other_ioloop.add_callback_from_signal(other_ioloop.stop)\n        thread.join()\n        other_ioloop.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that an IOLoop running in a non-main thread can safely schedule a callback from a signal handler. It verifies cross-thread callback addition and proper loop shutdown in a multithreaded environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_callback_while_closing", "line_number": 131, "body": "def test_add_callback_while_closing(self):\n        # add_callback should not fail if it races with another thread\n        # closing the IOLoop. The callbacks are dropped silently\n        # without executing.\n        closing = threading.Event()\n\n        def target():\n            other_ioloop.add_callback(other_ioloop.stop)\n            other_ioloop.start()\n            closing.set()\n            other_ioloop.close(all_fds=True)\n\n        other_ioloop = IOLoop()\n        thread = threading.Thread(target=target)\n        thread.start()\n        closing.wait()\n        for i in range(1000):\n            other_ioloop.add_callback(lambda: None)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that adding callbacks to an IOLoop while it is closing does not raise errors, ensuring such callbacks are silently dropped to avoid race condition failures during shutdown."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_read_while_writeable", "line_number": 151, "body": "def test_read_while_writeable(self):\n        # Ensure that write events don't come in while we're waiting for\n        # a read and haven't asked for writeability. (the reverse is\n        # difficult to test for)\n        client, server = socket.socketpair()\n        try:\n\n            def handler(fd, events):\n                self.assertEqual(events, IOLoop.READ)\n                self.stop()\n\n            self.io_loop.add_handler(client.fileno(), handler, IOLoop.READ)\n            self.io_loop.add_timeout(\n                self.io_loop.time() + 0.01, functools.partial(server.send, b\"asdf\")  # type: ignore\n            )\n            self.wait()\n            self.io_loop.remove_handler(client.fileno())\n        finally:\n            client.close()\n            server.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that read events are correctly detected without mistakenly triggering write events when only readability is requested on a socket pair. It ensures proper event handling behavior in the TestIOLoop's IO event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_remove_timeout_after_fire", "line_number": 172, "body": "def test_remove_timeout_after_fire(self):\n        # It is not an error to call remove_timeout after it has run.\n        handle = self.io_loop.add_timeout(self.io_loop.time(), self.stop)\n        self.wait()\n        self.io_loop.remove_timeout(handle)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that calling remove_timeout on a timeout handle after the timeout has executed does not cause an error. It ensures correct handling of timeouts already fired within the IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_remove_timeout_cleanup", "line_number": 178, "body": "def test_remove_timeout_cleanup(self):\n        # Add and remove enough callbacks to trigger cleanup.\n        # Not a very thorough test, but it ensures that the cleanup code\n        # gets executed and doesn't blow up.  This test is only really useful\n        # on PollIOLoop subclasses, but it should run silently on any\n        # implementation.\n        for i in range(2000):\n            timeout = self.io_loop.add_timeout(self.io_loop.time() + 3600, lambda: None)\n            self.io_loop.remove_timeout(timeout)\n        # HACK: wait two IOLoop iterations for the GC to happen.\n        self.io_loop.add_callback(lambda: self.io_loop.add_callback(self.stop))\n        self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "This test method verifies that adding and removing a large number of timeouts triggers and safely executes the IOLoop's internal cleanup process without errors. It ensures stability of timeout management in asynchronous event loops."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_remove_timeout_from_timeout", "line_number": 191, "body": "def test_remove_timeout_from_timeout(self):\n        calls = [False, False]\n\n        # Schedule several callbacks and wait for them all to come due at once.\n        # t2 should be cancelled by t1, even though it is already scheduled to\n        # be run before the ioloop even looks at it.\n        now = self.io_loop.time()\n\n        def t1():\n            calls[0] = True\n            self.io_loop.remove_timeout(t2_handle)\n\n        self.io_loop.add_timeout(now + 0.01, t1)\n\n        def t2():\n            calls[1] = True\n\n        t2_handle = self.io_loop.add_timeout(now + 0.02, t2)\n        self.io_loop.add_timeout(now + 0.03, self.stop)\n        time.sleep(0.03)\n        self.wait()\n        self.assertEqual(calls, [True, False])", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that a scheduled callback can successfully cancel a subsequent timeout before it runs, ensuring the timeout removal mechanism works correctly in the IOLoop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_timeout_with_arguments", "line_number": 214, "body": "def test_timeout_with_arguments(self):\n        # This tests that all the timeout methods pass through *args correctly.\n        results = []  # type: List[int]\n        self.io_loop.add_timeout(self.io_loop.time(), results.append, 1)\n        self.io_loop.add_timeout(datetime.timedelta(seconds=0), results.append, 2)\n        self.io_loop.call_at(self.io_loop.time(), results.append, 3)\n        self.io_loop.call_later(0, results.append, 4)\n        self.io_loop.call_later(0, self.stop)\n        self.wait()\n        # The asyncio event loop does not guarantee the order of these\n        # callbacks.\n        self.assertEqual(sorted(results), [1, 2, 3, 4])", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that various timeout scheduling methods correctly pass additional arguments to their callbacks within an event loop, verifying the proper invocation of scheduled functions with parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_timeout_return", "line_number": 227, "body": "def test_add_timeout_return(self):\n        # All the timeout methods return non-None handles that can be\n        # passed to remove_timeout.\n        handle = self.io_loop.add_timeout(self.io_loop.time(), lambda: None)\n        self.assertFalse(handle is None)\n        self.io_loop.remove_timeout(handle)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the add_timeout method returns a valid handle usable for removing the scheduled timeout. This ensures correct timeout scheduling and cancellation within the I/O event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_call_at_return", "line_number": 234, "body": "def test_call_at_return(self):\n        handle = self.io_loop.call_at(self.io_loop.time(), lambda: None)\n        self.assertFalse(handle is None)\n        self.io_loop.remove_timeout(handle)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Test method in TestIOLoop that validates scheduling and cancellation of immediate callbacks within the IOLoop event loop. It ensures that a callback can be successfully registered and then removed before execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_call_later_return", "line_number": 239, "body": "def test_call_later_return(self):\n        handle = self.io_loop.call_later(0, lambda: None)\n        self.assertFalse(handle is None)\n        self.io_loop.remove_timeout(handle)", "is_method": true, "class_name": "TestIOLoop", "function_description": "This test method verifies that scheduling a zero-delay callback in the I/O loop returns a valid handle and allows proper timeout removal. It ensures the call_later function operates correctly within the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_close_file_object", "line_number": 244, "body": "def test_close_file_object(self):\n        \"\"\"When a file object is used instead of a numeric file descriptor,\n        the object should be closed (by IOLoop.close(all_fds=True),\n        not just the fd.\n        \"\"\"\n        # Use a socket since they are supported by IOLoop on all platforms.\n        # Unfortunately, sockets don't support the .closed attribute for\n        # inspecting their close status, so we must use a wrapper.\n        class SocketWrapper(object):\n            def __init__(self, sockobj):\n                self.sockobj = sockobj\n                self.closed = False\n\n            def fileno(self):\n                return self.sockobj.fileno()\n\n            def close(self):\n                self.closed = True\n                self.sockobj.close()\n\n        sockobj, port = bind_unused_port()\n        socket_wrapper = SocketWrapper(sockobj)\n        io_loop = IOLoop()\n        io_loop.add_handler(socket_wrapper, lambda fd, events: None, IOLoop.READ)\n        io_loop.close(all_fds=True)\n        self.assertTrue(socket_wrapper.closed)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that IOLoop properly closes file-like objects, not just their file descriptors, ensuring resource cleanup when using file objects such as sockets."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_handler_callback_file_object", "line_number": 271, "body": "def test_handler_callback_file_object(self):\n        \"\"\"The handler callback receives the same fd object it passed in.\"\"\"\n        server_sock, port = bind_unused_port()\n        fds = []\n\n        def handle_connection(fd, events):\n            fds.append(fd)\n            conn, addr = server_sock.accept()\n            conn.close()\n            self.stop()\n\n        self.io_loop.add_handler(server_sock, handle_connection, IOLoop.READ)\n        with contextlib.closing(socket.socket()) as client_sock:\n            client_sock.connect((\"127.0.0.1\", port))\n            self.wait()\n        self.io_loop.remove_handler(server_sock)\n        self.io_loop.add_handler(server_sock.fileno(), handle_connection, IOLoop.READ)\n        with contextlib.closing(socket.socket()) as client_sock:\n            client_sock.connect((\"127.0.0.1\", port))\n            self.wait()\n        self.assertIs(fds[0], server_sock)\n        self.assertEqual(fds[1], server_sock.fileno())\n        self.io_loop.remove_handler(server_sock.fileno())\n        server_sock.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the IOLoop's handler callback receives the exact file descriptor object or its integer file descriptor as passed when handling socket events. Useful for verifying correct fd handling in asynchronous I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_mixed_fd_fileobj", "line_number": 296, "body": "def test_mixed_fd_fileobj(self):\n        server_sock, port = bind_unused_port()\n\n        def f(fd, events):\n            pass\n\n        self.io_loop.add_handler(server_sock, f, IOLoop.READ)\n        with self.assertRaises(Exception):\n            # The exact error is unspecified - some implementations use\n            # IOError, others use ValueError.\n            self.io_loop.add_handler(server_sock.fileno(), f, IOLoop.READ)\n        self.io_loop.remove_handler(server_sock.fileno())\n        server_sock.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests the IOLoop's handling of file descriptors versus file objects by verifying that adding a handler with the same socket as both raises an error, ensuring correct differentiation and cleanup of I/O event handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_reentrant", "line_number": 310, "body": "def test_reentrant(self):\n        \"\"\"Calling start() twice should raise an error, not deadlock.\"\"\"\n        returned_from_start = [False]\n        got_exception = [False]\n\n        def callback():\n            try:\n                self.io_loop.start()\n                returned_from_start[0] = True\n            except Exception:\n                got_exception[0] = True\n            self.stop()\n\n        self.io_loop.add_callback(callback)\n        self.wait()\n        self.assertTrue(got_exception[0])\n        self.assertFalse(returned_from_start[0])", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that starting the I/O loop twice raises an exception instead of causing a deadlock, ensuring safe and correct reentrant behavior during loop execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_exception_logging", "line_number": 328, "body": "def test_exception_logging(self):\n        \"\"\"Uncaught exceptions get logged by the IOLoop.\"\"\"\n        self.io_loop.add_callback(lambda: 1 / 0)\n        self.io_loop.add_callback(self.stop)\n        with ExpectLog(app_log, \"Exception in callback\"):\n            self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that uncaught exceptions within the IOLoop callbacks are properly logged, ensuring error visibility during asynchronous operations. Useful for validating the IOLoop's exception handling and logging behavior in asynchronous tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_exception_logging_future", "line_number": 335, "body": "def test_exception_logging_future(self):\n        \"\"\"The IOLoop examines exceptions from Futures and logs them.\"\"\"\n\n        @gen.coroutine\n        def callback():\n            self.io_loop.add_callback(self.stop)\n            1 / 0\n\n        self.io_loop.add_callback(callback)\n        with ExpectLog(app_log, \"Exception in callback\"):\n            self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the IOLoop captures and logs exceptions arising from asynchronous Future callbacks, ensuring errors are properly recorded during event loop execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_exception_logging_native_coro", "line_number": 347, "body": "def test_exception_logging_native_coro(self):\n        \"\"\"The IOLoop examines exceptions from awaitables and logs them.\"\"\"\n\n        async def callback():\n            # Stop the IOLoop two iterations after raising an exception\n            # to give the exception time to be logged.\n            self.io_loop.add_callback(self.io_loop.add_callback, self.stop)\n            1 / 0\n\n        self.io_loop.add_callback(callback)\n        with ExpectLog(app_log, \"Exception in callback\"):\n            self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Test method in TestIOLoop verifying that exceptions raised in native coroutines are properly detected and logged by the IOLoop during asynchronous callback execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_spawn_callback", "line_number": 360, "body": "def test_spawn_callback(self):\n        # Both add_callback and spawn_callback run directly on the IOLoop,\n        # so their errors are logged without stopping the test.\n        self.io_loop.add_callback(lambda: 1 / 0)\n        self.io_loop.add_callback(self.stop)\n        with ExpectLog(app_log, \"Exception in callback\"):\n            self.wait()\n        # A spawned callback is run directly on the IOLoop, so it will be\n        # logged without stopping the test.\n        self.io_loop.spawn_callback(lambda: 1 / 0)\n        self.io_loop.add_callback(self.stop)\n        with ExpectLog(app_log, \"Exception in callback\"):\n            self.wait()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that callbacks and spawned callbacks on an IOLoop handle exceptions by logging errors without interrupting execution, ensuring robust async callback error handling during asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_remove_handler_from_handler", "line_number": 375, "body": "def test_remove_handler_from_handler(self):\n        # Create two sockets with simultaneous read events.\n        client, server = socket.socketpair()\n        try:\n            client.send(b\"abc\")\n            server.send(b\"abc\")\n\n            # After reading from one fd, remove the other from the IOLoop.\n            chunks = []\n\n            def handle_read(fd, events):\n                chunks.append(fd.recv(1024))\n                if fd is client:\n                    self.io_loop.remove_handler(server)\n                else:\n                    self.io_loop.remove_handler(client)\n\n            self.io_loop.add_handler(client, handle_read, self.io_loop.READ)\n            self.io_loop.add_handler(server, handle_read, self.io_loop.READ)\n            self.io_loop.call_later(0.1, self.stop)\n            self.wait()\n\n            # Only one fd was read; the other was cleanly removed.\n            self.assertEqual(chunks, [b\"abc\"])\n        finally:\n            client.close()\n            server.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Tests that the IOLoop correctly supports removing one socket handler when reading from another, ensuring handlers can be dynamically and safely removed during event processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_init_close_race", "line_number": 405, "body": "def test_init_close_race(self):\n        # Regression test for #2367\n        #\n        # Skipped on windows because of what looks like a bug in the\n        # proactor event loop when started and stopped on non-main\n        # threads.\n        def f():\n            for i in range(10):\n                loop = IOLoop()\n                loop.close()\n\n        yield gen.multi([self.io_loop.run_in_executor(None, f) for i in range(2)])", "is_method": true, "class_name": "TestIOLoop", "function_description": "This test method verifies that multiple IOLoop instances can be rapidly created and closed concurrently without race conditions, ensuring thread-safe startup and shutdown behavior. It is useful for validating the robustness of asynchronous event loop management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "setUp", "line_number": 422, "body": "def setUp(self):\n        self.io_loop = None  # type: typing.Optional[IOLoop]\n        IOLoop.clear_current()", "is_method": true, "class_name": "TestIOLoopCurrent", "function_description": "Sets up the test environment by clearing the current IOLoop and initializing the instance's IOLoop reference to None, preparing for isolated asynchronous I/O testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "tearDown", "line_number": 426, "body": "def tearDown(self):\n        if self.io_loop is not None:\n            self.io_loop.close()", "is_method": true, "class_name": "TestIOLoopCurrent", "function_description": "Cleans up the TestIOLoopCurrent instance by closing its associated I/O loop if it exists, ensuring proper resource release after test execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_default_current", "line_number": 430, "body": "def test_default_current(self):\n        self.io_loop = IOLoop()\n        # The first IOLoop with default arguments is made current.\n        self.assertIs(self.io_loop, IOLoop.current())\n        # A second IOLoop can be created but is not made current.\n        io_loop2 = IOLoop()\n        self.assertIs(self.io_loop, IOLoop.current())\n        io_loop2.close()", "is_method": true, "class_name": "TestIOLoopCurrent", "function_description": "Tests that an IOLoop instance becomes the current loop by default and that creating additional IOLoop instances does not change the current loop reference. It ensures correct management of the active IOLoop in asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_non_current", "line_number": 439, "body": "def test_non_current(self):\n        self.io_loop = IOLoop(make_current=False)\n        # The new IOLoop is not initially made current.\n        self.assertIsNone(IOLoop.current(instance=False))\n        # Starting the IOLoop makes it current, and stopping the loop\n        # makes it non-current. This process is repeatable.\n        for i in range(3):\n\n            def f():\n                self.current_io_loop = IOLoop.current()\n                assert self.io_loop is not None\n                self.io_loop.stop()\n\n            self.io_loop.add_callback(f)\n            self.io_loop.start()\n            self.assertIs(self.current_io_loop, self.io_loop)\n            # Now that the loop is stopped, it is no longer current.\n            self.assertIsNone(IOLoop.current(instance=False))", "is_method": true, "class_name": "TestIOLoopCurrent", "function_description": "Test method in TestIOLoopCurrent that verifies an IOLoop instance behaves correctly when not initially made current, ensuring start/stop cycles properly update the loop's \"current\" status."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_force_current", "line_number": 458, "body": "def test_force_current(self):\n        self.io_loop = IOLoop(make_current=True)\n        self.assertIs(self.io_loop, IOLoop.current())\n        with self.assertRaises(RuntimeError):\n            # A second make_current=True construction cannot succeed.\n            IOLoop(make_current=True)\n        # current() was not affected by the failed construction.\n        self.assertIs(self.io_loop, IOLoop.current())", "is_method": true, "class_name": "TestIOLoopCurrent", "function_description": "Tests that creating an IOLoop instance with make_current=True sets it as the current IOLoop and verifies that attempting to create a second current IOLoop raises an error without changing the current state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_clear_without_current", "line_number": 470, "body": "def test_clear_without_current(self):\n        # If there is no current IOLoop, clear_current is a no-op (but\n        # should not fail). Use a thread so we see the threading.Local\n        # in a pristine state.\n        with ThreadPoolExecutor(1) as e:\n            yield e.submit(IOLoop.clear_current)", "is_method": true, "class_name": "TestIOLoopCurrentAsync", "function_description": "Tests that calling clear_current has no effect and does not fail when no current IOLoop exists, ensuring safe cleanup in a clean thread state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_add_future_threads", "line_number": 479, "body": "def test_add_future_threads(self):\n        with futures.ThreadPoolExecutor(1) as pool:\n\n            def dummy():\n                pass\n\n            self.io_loop.add_future(\n                pool.submit(dummy), lambda future: self.stop(future)\n            )\n            future = self.wait()\n            self.assertTrue(future.done())\n            self.assertTrue(future.result() is None)", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Tests that a future submitted to a thread pool is correctly added to the IO loop and that its completion triggers a callback, verifying asynchronous execution and result handling within the event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_run_in_executor_gen", "line_number": 493, "body": "def test_run_in_executor_gen(self):\n        event1 = threading.Event()\n        event2 = threading.Event()\n\n        def sync_func(self_event, other_event):\n            self_event.set()\n            other_event.wait()\n            # Note that return value doesn't actually do anything,\n            # it is just passed through to our final assertion to\n            # make sure it is passed through properly.\n            return self_event\n\n        # Run two synchronous functions, which would deadlock if not\n        # run in parallel.\n        res = yield [\n            IOLoop.current().run_in_executor(None, sync_func, event1, event2),\n            IOLoop.current().run_in_executor(None, sync_func, event2, event1),\n        ]\n\n        self.assertEqual([event1, event2], res)", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Test method in TestIOLoopFutures that verifies running synchronous functions in parallel using an executor to avoid deadlock, ensuring correct result propagation from concurrent tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_run_in_executor_native", "line_number": 515, "body": "def test_run_in_executor_native(self):\n        event1 = threading.Event()\n        event2 = threading.Event()\n\n        def sync_func(self_event, other_event):\n            self_event.set()\n            other_event.wait()\n            return self_event\n\n        # Go through an async wrapper to ensure that the result of\n        # run_in_executor works with await and not just gen.coroutine\n        # (simply passing the underlying concurrent future would do that).\n        async def async_wrapper(self_event, other_event):\n            return await IOLoop.current().run_in_executor(\n                None, sync_func, self_event, other_event\n            )\n\n        res = yield [async_wrapper(event1, event2), async_wrapper(event2, event1)]\n\n        self.assertEqual([event1, event2], res)", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Tests that asynchronous execution via an IOLoop executor correctly runs synchronous functions in separate threads and returns their completion signals, ensuring compatibility with async/await patterns."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_set_default_executor", "line_number": 537, "body": "def test_set_default_executor(self):\n        count = [0]\n\n        class MyExecutor(futures.ThreadPoolExecutor):\n            def submit(self, func, *args):\n                count[0] += 1\n                return super().submit(func, *args)\n\n        event = threading.Event()\n\n        def sync_func():\n            event.set()\n\n        executor = MyExecutor(1)\n        loop = IOLoop.current()\n        loop.set_default_executor(executor)\n        yield loop.run_in_executor(None, sync_func)\n        self.assertEqual(1, count[0])\n        self.assertTrue(event.is_set())", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Tests that the IOLoop's default executor can be set and used properly, verifying that tasks submitted to it are executed as expected. This ensures custom executors integrate correctly with asynchronous IOLoop operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "setUp", "line_number": 559, "body": "def setUp(self):\n        self.io_loop = IOLoop()", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Initializes an IOLoop instance before each test, preparing the test environment for asynchronous operation management in the TestIOLoopRunSync class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "tearDown", "line_number": 562, "body": "def tearDown(self):\n        self.io_loop.close()", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Cleans up by closing the I/O loop after test execution, ensuring proper resource release in TestIOLoopRunSync test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_sync_result", "line_number": 565, "body": "def test_sync_result(self):\n        with self.assertRaises(gen.BadYieldError):\n            self.io_loop.run_sync(lambda: 42)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Tests that running a synchronous function returning a non-yieldable value with the IOLoop's run_sync method raises the expected BadYieldError exception."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_sync_exception", "line_number": 569, "body": "def test_sync_exception(self):\n        with self.assertRaises(ZeroDivisionError):\n            self.io_loop.run_sync(lambda: 1 / 0)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "This test method verifies that the run_sync function correctly raises a ZeroDivisionError when encountering a division by zero, ensuring proper exception handling in synchronous IO loop execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_async_result", "line_number": 573, "body": "def test_async_result(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return(42)\n\n        self.assertEqual(self.io_loop.run_sync(f), 42)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "This test method verifies that the IOLoop's run_sync function correctly executes an asynchronous coroutine, returning the expected result. It ensures synchronous handling of async operations during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_async_exception", "line_number": 581, "body": "def test_async_exception(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            1 / 0\n\n        with self.assertRaises(ZeroDivisionError):\n            self.io_loop.run_sync(f)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Tests that the IOLoop's run_sync method correctly propagates exceptions raised in asynchronous coroutines, ensuring proper error handling during synchronous execution of async code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_current", "line_number": 590, "body": "def test_current(self):\n        def f():\n            self.assertIs(IOLoop.current(), self.io_loop)\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Tests that the currently active IOLoop within the run_sync context is the expected instance, ensuring correct event loop assignment for synchronous operations in asynchronous environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_timeout", "line_number": 596, "body": "def test_timeout(self):\n        @gen.coroutine\n        def f():\n            yield gen.sleep(1)\n\n        self.assertRaises(TimeoutError, self.io_loop.run_sync, f, timeout=0.01)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Tests that the IOLoop's run_sync method correctly raises a TimeoutError when a coroutine exceeds the specified timeout limit. This verifies timeout handling for asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_native_coroutine", "line_number": 603, "body": "def test_native_coroutine(self):\n        @gen.coroutine\n        def f1():\n            yield gen.moment\n\n        async def f2():\n            await f1()\n\n        self.io_loop.run_sync(f2)", "is_method": true, "class_name": "TestIOLoopRunSync", "function_description": "Method in TestIOLoopRunSync that verifies running an asynchronous coroutine synchronously via the I/O loop, ensuring compatibility between native and Tornado-style coroutines."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "simulate_calls", "line_number": 615, "body": "def simulate_calls(self, pc, durations):\n        \"\"\"Simulate a series of calls to the PeriodicCallback.\n\n        Pass a list of call durations in seconds (negative values\n        work to simulate clock adjustments during the call, or more or\n        less equivalently, between calls). This method returns the\n        times at which each call would be made.\n        \"\"\"\n        calls = []\n        now = 1000\n        pc._next_timeout = now\n        for d in durations:\n            pc._update_next(now)\n            calls.append(pc._next_timeout)\n            now = pc._next_timeout + d\n        return calls", "is_method": true, "class_name": "TestPeriodicCallbackMath", "function_description": "Simulates call timings of a PeriodicCallback based on given durations, including handling clock adjustments, and returns the scheduled times each call would occur. Useful for testing or analyzing periodic callback behavior over variable intervals."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_basic", "line_number": 635, "body": "def test_basic(self):\n        pc = PeriodicCallback(self.dummy, 10000)\n        self.assertEqual(\n            self.simulate_calls(pc, [0] * 5), [1010, 1020, 1030, 1040, 1050]\n        )", "is_method": true, "class_name": "TestPeriodicCallbackMath", "function_description": "Tests that PeriodicCallback triggers the given callback at expected time intervals when simulated, verifying its timing functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_overrun", "line_number": 641, "body": "def test_overrun(self):\n        # If a call runs for too long, we skip entire cycles to get\n        # back on schedule.\n        call_durations = [9, 9, 10, 11, 20, 20, 35, 35, 0, 0, 0]\n        expected = [\n            1010,\n            1020,\n            1030,  # first 3 calls on schedule\n            1050,\n            1070,  # next 2 delayed one cycle\n            1100,\n            1130,  # next 2 delayed 2 cycles\n            1170,\n            1210,  # next 2 delayed 3 cycles\n            1220,\n            1230,  # then back on schedule.\n        ]\n\n        pc = PeriodicCallback(self.dummy, 10000)\n        self.assertEqual(self.simulate_calls(pc, call_durations), expected)", "is_method": true, "class_name": "TestPeriodicCallbackMath", "function_description": "Tests that a periodic callback skips cycles appropriately when execution overruns, ensuring the callback reschedules correctly to maintain timing accuracy despite delays."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_clock_backwards", "line_number": 662, "body": "def test_clock_backwards(self):\n        pc = PeriodicCallback(self.dummy, 10000)\n        # Backwards jumps are ignored, potentially resulting in a\n        # slightly slow schedule (although we assume that when\n        # time.time() and time.monotonic() are different, time.time()\n        # is getting adjusted by NTP and is therefore more accurate)\n        self.assertEqual(\n            self.simulate_calls(pc, [-2, -1, -3, -2, 0]), [1010, 1020, 1030, 1040, 1050]\n        )\n\n        # For big jumps, we should perhaps alter the schedule, but we\n        # don't currently. This trace shows that we run callbacks\n        # every 10s of time.time(), but the first and second calls are\n        # 110s of real time apart because the backwards jump is\n        # ignored.\n        self.assertEqual(self.simulate_calls(pc, [-100, 0, 0]), [1010, 1020, 1030])", "is_method": true, "class_name": "TestPeriodicCallbackMath", "function_description": "Tests that the periodic callback correctly handles backwards jumps in the clock by ignoring them, ensuring consistent scheduling despite time adjustments. Useful for verifying robustness against system time changes in scheduling logic."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_jitter", "line_number": 679, "body": "def test_jitter(self):\n        random_times = [0.5, 1, 0, 0.75]\n        expected = [1010, 1022.5, 1030, 1041.25]\n        call_durations = [0] * len(random_times)\n        pc = PeriodicCallback(self.dummy, 10000, jitter=0.5)\n\n        def mock_random():\n            return random_times.pop(0)\n\n        with mock.patch(\"random.random\", mock_random):\n            self.assertEqual(self.simulate_calls(pc, call_durations), expected)", "is_method": true, "class_name": "TestPeriodicCallbackMath", "function_description": "Tests the effect of jitter on a periodic callback's scheduled call times by simulating calls with controlled randomness to validate timing adjustments. This ensures the PeriodicCallback correctly incorporates jitter values in its scheduling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "run_python", "line_number": 693, "body": "def run_python(self, *statements):\n        stmt_list = [\n            \"from tornado.ioloop import IOLoop\",\n            \"classname = lambda x: x.__class__.__name__\",\n        ] + list(statements)\n        args = [sys.executable, \"-c\", \"; \".join(stmt_list)]\n        return native_str(subprocess.check_output(args)).strip()", "is_method": true, "class_name": "TestIOLoopConfiguration", "function_description": "This method executes given Python statements within a Tornado IOLoop context and returns the combined output as a string. It facilitates running dynamic code snippets in a subprocess environment for testing or evaluation purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_default", "line_number": 701, "body": "def test_default(self):\n        # When asyncio is available, it is used by default.\n        cls = self.run_python(\"print(classname(IOLoop.current()))\")\n        self.assertEqual(cls, \"AsyncIOMainLoop\")\n        cls = self.run_python(\"print(classname(IOLoop()))\")\n        self.assertEqual(cls, \"AsyncIOLoop\")", "is_method": true, "class_name": "TestIOLoopConfiguration", "function_description": "Tests that the default IOLoop uses asyncio implementations when available, verifying the correct loop classes are instantiated in different contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_asyncio", "line_number": 708, "body": "def test_asyncio(self):\n        cls = self.run_python(\n            'IOLoop.configure(\"tornado.platform.asyncio.AsyncIOLoop\")',\n            \"print(classname(IOLoop.current()))\",\n        )\n        self.assertEqual(cls, \"AsyncIOMainLoop\")", "is_method": true, "class_name": "TestIOLoopConfiguration", "function_description": "Tests whether configuring the IOLoop to use the asyncio platform results in the current loop being of the expected AsyncIOMainLoop class. It validates the proper integration of asyncio within the IOLoop configuration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "test_asyncio_main", "line_number": 715, "body": "def test_asyncio_main(self):\n        cls = self.run_python(\n            \"from tornado.platform.asyncio import AsyncIOMainLoop\",\n            \"AsyncIOMainLoop().install()\",\n            \"print(classname(IOLoop.current()))\",\n        )\n        self.assertEqual(cls, \"AsyncIOMainLoop\")", "is_method": true, "class_name": "TestIOLoopConfiguration", "function_description": "Test method in TestIOLoopConfiguration that verifies if AsyncIOMainLoop is correctly installed and set as the current IOLoop, ensuring proper integration of asyncio with Tornado's event loop system."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "add_callback", "line_number": 37, "body": "def add_callback(self, callback, *args, **kwargs):\n            test.calls += 1\n            old_add_callback(callback, *args, **kwargs)", "is_method": true, "class_name": "TestIOLoop", "function_description": "Adds a callback function to the I/O loop, tracking the number of calls made; useful for scheduling and monitoring asynchronous operations within the TestIOLoop context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "callback", "line_number": 52, "body": "def callback():\n            self.called = True\n            self.stop()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Sets a flag indicating the callback was invoked and stops the I/O loop. This function is useful for signaling completion and terminating the event loop during asynchronous tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "target", "line_number": 69, "body": "def target():\n            # sleep a bit to let the ioloop go into its poll loop\n            time.sleep(0.01)\n            self.stop_time = time.time()\n            self.io_loop.add_callback(self.stop)", "is_method": true, "class_name": "TestIOLoop", "function_description": "This function schedules the stopping of the I/O loop after a brief delay, allowing the loop to enter its polling state before being stopped. It facilitates controlled termination timing of the loop during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "handle_connection", "line_number": 276, "body": "def handle_connection(fd, events):\n            fds.append(fd)\n            conn, addr = server_sock.accept()\n            conn.close()\n            self.stop()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Handles a socket connection by accepting it, closing it immediately, and stopping the event loop. It manages incoming connections during I/O event handling within the TestIOLoop context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "callback", "line_number": 339, "body": "def callback():\n            self.io_loop.add_callback(self.stop)\n            1 / 0", "is_method": true, "class_name": "TestIOLoop", "function_description": "Raises an exception after scheduling the event loop to stop via a callback. This function helps test how the I/O loop handles callbacks that fail with errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "f", "line_number": 411, "body": "def f():\n            for i in range(10):\n                loop = IOLoop()\n                loop.close()", "is_method": true, "class_name": "TestIOLoop", "function_description": "Creates and immediately closes ten separate IOLoop instances in sequence. This function may be used to test or benchmark the creation and closure of event loops."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "sync_func", "line_number": 497, "body": "def sync_func(self_event, other_event):\n            self_event.set()\n            other_event.wait()\n            # Note that return value doesn't actually do anything,\n            # it is just passed through to our final assertion to\n            # make sure it is passed through properly.\n            return self_event", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Utility function that synchronizes two event objects by setting one and waiting on the other, returning the first event to support synchronization testing in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "sync_func", "line_number": 519, "body": "def sync_func(self_event, other_event):\n            self_event.set()\n            other_event.wait()\n            return self_event", "is_method": true, "class_name": "TestIOLoopFutures", "function_description": "Synchronizes two event objects by setting one event and waiting for the other to be set, facilitating coordination between concurrent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "fileno", "line_number": 257, "body": "def fileno(self):\n                return self.sockobj.fileno()", "is_method": true, "class_name": "SocketWrapper", "function_description": "Returns the underlying socket\u2019s file descriptor, allowing integration with system-level I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "close", "line_number": 260, "body": "def close(self):\n                self.closed = True\n                self.sockobj.close()", "is_method": true, "class_name": "SocketWrapper", "function_description": "Closes the underlying socket and marks the SocketWrapper instance as closed, ensuring proper cleanup of network resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/ioloop_test.py", "function": "submit", "line_number": 541, "body": "def submit(self, func, *args):\n                count[0] += 1\n                return super().submit(func, *args)", "is_method": true, "class_name": "MyExecutor", "function_description": "Overrides a submission method to track the number of tasks submitted while forwarding the execution request. It provides task counting functionality alongside executing callable tasks asynchronously."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_handle_stream_coroutine_logging", "line_number": 18, "body": "def test_handle_stream_coroutine_logging(self):\n        # handle_stream may be a coroutine and any exception in its\n        # Future will be logged.\n        class TestServer(TCPServer):\n            @gen.coroutine\n            def handle_stream(self, stream, address):\n                yield stream.read_bytes(len(b\"hello\"))\n                stream.close()\n                1 / 0\n\n        server = client = None\n        try:\n            sock, port = bind_unused_port()\n            server = TestServer()\n            server.add_socket(sock)\n            client = IOStream(socket.socket())\n            with ExpectLog(app_log, \"Exception in callback\"):\n                yield client.connect((\"localhost\", port))\n                yield client.write(b\"hello\")\n                yield client.read_until_close()\n                yield gen.moment\n        finally:\n            if server is not None:\n                server.stop()\n            if client is not None:\n                client.close()", "is_method": true, "class_name": "TCPServerTest", "function_description": "Tests that exceptions thrown within a coroutine-based stream handler in a TCP server are correctly logged during asynchronous client-server communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_handle_stream_native_coroutine", "line_number": 46, "body": "def test_handle_stream_native_coroutine(self):\n        # handle_stream may be a native coroutine.\n\n        class TestServer(TCPServer):\n            async def handle_stream(self, stream, address):\n                stream.write(b\"data\")\n                stream.close()\n\n        sock, port = bind_unused_port()\n        server = TestServer()\n        server.add_socket(sock)\n        client = IOStream(socket.socket())\n        yield client.connect((\"localhost\", port))\n        result = yield client.read_until_close()\n        self.assertEqual(result, b\"data\")\n        server.stop()\n        client.close()", "is_method": true, "class_name": "TCPServerTest", "function_description": "Tests that the TCPServer can correctly handle an asynchronous native coroutine in its stream handling method by verifying data transmission between client and server sockets."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_stop_twice", "line_number": 64, "body": "def test_stop_twice(self):\n        sock, port = bind_unused_port()\n        server = TCPServer()\n        server.add_socket(sock)\n        server.stop()\n        server.stop()", "is_method": true, "class_name": "TCPServerTest", "function_description": "Tests that stopping the TCPServer multiple times does not cause errors or unexpected behavior, ensuring robustness in server shutdown procedures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_stop_in_callback", "line_number": 72, "body": "def test_stop_in_callback(self):\n        # Issue #2069: calling server.stop() in a loop callback should not\n        # raise EBADF when the loop handles other server connection\n        # requests in the same loop iteration\n\n        class TestServer(TCPServer):\n            @gen.coroutine\n            def handle_stream(self, stream, address):\n                server.stop()  # type: ignore\n                yield stream.read_until_close()\n\n        sock, port = bind_unused_port()\n        server = TestServer()\n        server.add_socket(sock)\n        server_addr = (\"localhost\", port)\n        N = 40\n        clients = [IOStream(socket.socket()) for i in range(N)]\n        connected_clients = []\n\n        @gen.coroutine\n        def connect(c):\n            try:\n                yield c.connect(server_addr)\n            except EnvironmentError:\n                pass\n            else:\n                connected_clients.append(c)\n\n        yield [connect(c) for c in clients]\n\n        self.assertGreater(len(connected_clients), 0, \"all clients failed connecting\")\n        try:\n            if len(connected_clients) == N:\n                # Ideally we'd make the test deterministic, but we're testing\n                # for a race condition in combination with the system's TCP stack...\n                self.skipTest(\n                    \"at least one client should fail connecting \"\n                    \"for the test to be meaningful\"\n                )\n        finally:\n            for c in connected_clients:\n                c.close()", "is_method": true, "class_name": "TCPServerTest", "function_description": "Tests that stopping the TCP server within a connection handler callback does not cause errors while handling multiple simultaneous client connections. It verifies safe server shutdown behavior during ongoing connection acceptance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "run_subproc", "line_number": 125, "body": "def run_subproc(self, code):\n        proc = subprocess.Popen(\n            sys.executable, stdin=subprocess.PIPE, stdout=subprocess.PIPE\n        )\n        proc.stdin.write(utf8(code))\n        proc.stdin.close()\n        proc.wait()\n        stdout = proc.stdout.read()\n        proc.stdout.close()\n        if proc.returncode != 0:\n            raise RuntimeError(\n                \"Process returned %d. stdout=%r\" % (proc.returncode, stdout)\n            )\n        return to_unicode(stdout)", "is_method": true, "class_name": "TestMultiprocess", "function_description": "Executes given Python code in a separate subprocess, captures its output, and raises an error if the subprocess fails. This method enables isolated code execution with output retrieval for testing or sandboxing purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_single", "line_number": 140, "body": "def test_single(self):\n        # As a sanity check, run the single-process version through this test\n        # harness too.\n        code = textwrap.dedent(\n            \"\"\"\n            from tornado.ioloop import IOLoop\n            from tornado.tcpserver import TCPServer\n\n            server = TCPServer()\n            server.listen(0, address='127.0.0.1')\n            IOLoop.current().run_sync(lambda: None)\n            print('012', end='')\n        \"\"\"\n        )\n        out = self.run_subproc(code)\n        self.assertEqual(\"\".join(sorted(out)), \"012\")", "is_method": true, "class_name": "TestMultiprocess", "function_description": "Utility method in TestMultiprocess that verifies single-process code execution by running a simple TCP server and confirming expected output, ensuring the test harness works correctly in a non-multiprocess context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_simple", "line_number": 157, "body": "def test_simple(self):\n        code = textwrap.dedent(\n            \"\"\"\n            from tornado.ioloop import IOLoop\n            from tornado.process import task_id\n            from tornado.tcpserver import TCPServer\n\n            server = TCPServer()\n            server.bind(0, address='127.0.0.1')\n            server.start(3)\n            IOLoop.current().run_sync(lambda: None)\n            print(task_id(), end='')\n        \"\"\"\n        )\n        out = self.run_subproc(code)\n        self.assertEqual(\"\".join(sorted(out)), \"012\")", "is_method": true, "class_name": "TestMultiprocess", "function_description": "Unit test method in TestMultiprocess that verifies multiple TCP server processes start correctly and that their task IDs match expected values, ensuring proper multiprocessing behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "test_advanced", "line_number": 174, "body": "def test_advanced(self):\n        code = textwrap.dedent(\n            \"\"\"\n            from tornado.ioloop import IOLoop\n            from tornado.netutil import bind_sockets\n            from tornado.process import fork_processes, task_id\n            from tornado.ioloop import IOLoop\n            from tornado.tcpserver import TCPServer\n\n            sockets = bind_sockets(0, address='127.0.0.1')\n            fork_processes(3)\n            server = TCPServer()\n            server.add_sockets(sockets)\n            IOLoop.current().run_sync(lambda: None)\n            print(task_id(), end='')\n        \"\"\"\n        )\n        out = self.run_subproc(code)\n        self.assertEqual(\"\".join(sorted(out)), \"012\")", "is_method": true, "class_name": "TestMultiprocess", "function_description": "Tests multiprocessing with Tornado by forking processes, running an IOLoop server, and verifying that all forked task IDs (0, 1, 2) execute correctly. It validates correct multiprocessing behavior in asynchronous network code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "connect", "line_number": 92, "body": "def connect(c):\n            try:\n                yield c.connect(server_addr)\n            except EnvironmentError:\n                pass\n            else:\n                connected_clients.append(c)", "is_method": true, "class_name": "TCPServerTest", "function_description": "Utility method in TCPServerTest class that attempts to connect a client to a server and tracks successful connections, silently handling connection errors for robust client management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "handle_stream", "line_number": 23, "body": "def handle_stream(self, stream, address):\n                yield stream.read_bytes(len(b\"hello\"))\n                stream.close()\n                1 / 0", "is_method": true, "class_name": "TestServer", "function_description": "This function reads a fixed number of bytes from a stream, closes it, and then raises an error. It appears incomplete or used for testing error handling during stream processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/tcpserver_test.py", "function": "handle_stream", "line_number": 79, "body": "def handle_stream(self, stream, address):\n                server.stop()  # type: ignore\n                yield stream.read_until_close()", "is_method": true, "class_name": "TestServer", "function_description": "Stops the server upon handling a new stream and yields data from the stream until it is closed, facilitating continuous data reading during server operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "relpath", "line_number": 60, "body": "def relpath(*a):\n    return os.path.join(os.path.dirname(__file__), *a)", "is_method": false, "function_description": "Function that constructs a relative file system path based on the current file location and additional path components, simplifying file access within the same project or module."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app", "line_number": 71, "body": "def get_app(self):\n        self.app = Application(self.get_handlers(), **self.get_app_kwargs())\n        return self.app", "is_method": true, "class_name": "WebTestCase", "function_description": "Constructs and returns the application instance configured with specific handlers and settings, supporting test cases that require interaction with the application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 78, "body": "def get_app_kwargs(self):\n        return {}", "is_method": true, "class_name": "WebTestCase", "function_description": "Returns an empty dictionary of keyword arguments for configuring the web application, serving as a default or placeholder in the WebTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 90, "body": "def get_handlers(self):\n        return [(\"/\", self.Handler)]", "is_method": true, "class_name": "SimpleHandlerTestCase", "function_description": "Returns a list of URL patterns associated with their handler classes, providing routing information for the SimpleHandlerTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 95, "body": "def get(self):\n        self.write(\"hello\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Handles HTTP GET requests by responding with a simple \"hello\" message, providing a basic endpoint for connectivity or greeting purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_cookie", "line_number": 113, "body": "def get_cookie(self, name):\n        return self._cookies.get(name)", "is_method": true, "class_name": "CookieTestRequestHandler", "function_description": "Returns the value of a specified cookie from the handler's cookie collection, facilitating access to client-specific data within the request context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "set_cookie", "line_number": 116, "body": "def set_cookie(self, name, value, expires_days=None):\n        self._cookies[name] = value", "is_method": true, "class_name": "CookieTestRequestHandler", "function_description": "Sets a cookie with a specified name and value, optionally supporting expiration in days. This method enables simple cookie management within the CookieTestRequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_round_trip", "line_number": 122, "body": "def test_round_trip(self):\n        handler = CookieTestRequestHandler()\n        handler.set_secure_cookie(\"foo\", b\"bar\", version=1)\n        self.assertEqual(handler.get_secure_cookie(\"foo\", min_version=1), b\"bar\")", "is_method": true, "class_name": "SecureCookieV1Test", "function_description": "Test method in SecureCookieV1Test that verifies setting and retrieving a secure cookie preserves its value correctly using version 1 encoding. It ensures the cookie round-trip process functions as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_cookie_tampering_future_timestamp", "line_number": 127, "body": "def test_cookie_tampering_future_timestamp(self):\n        handler = CookieTestRequestHandler()\n        # this string base64-encodes to '12345678'\n        handler.set_secure_cookie(\"foo\", binascii.a2b_hex(b\"d76df8e7aefc\"), version=1)\n        cookie = handler._cookies[\"foo\"]\n        match = re.match(br\"12345678\\|([0-9]+)\\|([0-9a-f]+)\", cookie)\n        assert match is not None\n        timestamp = match.group(1)\n        sig = match.group(2)\n        self.assertEqual(\n            _create_signature_v1(\n                handler.application.settings[\"cookie_secret\"],\n                \"foo\",\n                \"12345678\",\n                timestamp,\n            ),\n            sig,\n        )\n        # shifting digits from payload to timestamp doesn't alter signature\n        # (this is not desirable behavior, just confirming that that's how it\n        # works)\n        self.assertEqual(\n            _create_signature_v1(\n                handler.application.settings[\"cookie_secret\"],\n                \"foo\",\n                \"1234\",\n                b\"5678\" + timestamp,\n            ),\n            sig,\n        )\n        # tamper with the cookie\n        handler._cookies[\"foo\"] = utf8(\n            \"1234|5678%s|%s\" % (to_basestring(timestamp), to_basestring(sig))\n        )\n        # it gets rejected\n        with ExpectLog(gen_log, \"Cookie timestamp in future\"):\n            self.assertTrue(handler.get_secure_cookie(\"foo\", min_version=1) is None)", "is_method": true, "class_name": "SecureCookieV1Test", "function_description": "Tests that tampering with a version 1 secure cookie\u2019s timestamp causes it to be rejected, ensuring cookie integrity by detecting future-dated modifications. It verifies the signature validation prevents unauthorized acceptance of altered cookies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_arbitrary_bytes", "line_number": 165, "body": "def test_arbitrary_bytes(self):\n        # Secure cookies accept arbitrary data (which is base64 encoded).\n        # Note that normal cookies accept only a subset of ascii.\n        handler = CookieTestRequestHandler()\n        handler.set_secure_cookie(\"foo\", b\"\\xe9\", version=1)\n        self.assertEqual(handler.get_secure_cookie(\"foo\", min_version=1), b\"\\xe9\")", "is_method": true, "class_name": "SecureCookieV1Test", "function_description": "Tests that SecureCookieV1 can store and retrieve arbitrary byte data by encoding it securely, ensuring compatibility with non-ASCII binary content in cookies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_round_trip", "line_number": 177, "body": "def test_round_trip(self):\n        handler = CookieTestRequestHandler()\n        handler.set_secure_cookie(\"foo\", b\"bar\", version=2)\n        self.assertEqual(handler.get_secure_cookie(\"foo\", min_version=2), b\"bar\")", "is_method": true, "class_name": "SecureCookieV2Test", "function_description": "Test method in SecureCookieV2Test that verifies setting and retrieving a version 2 secure cookie preserves its value, ensuring cookie integrity across storage and retrieval operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_version_roundtrip", "line_number": 182, "body": "def test_key_version_roundtrip(self):\n        handler = CookieTestRequestHandler(\n            cookie_secret=self.KEY_VERSIONS, key_version=0\n        )\n        handler.set_secure_cookie(\"foo\", b\"bar\")\n        self.assertEqual(handler.get_secure_cookie(\"foo\"), b\"bar\")", "is_method": true, "class_name": "SecureCookieV2Test", "function_description": "Test method in SecureCookieV2Test that verifies setting and retrieving a secure cookie using a specific key version functions correctly. It ensures cookie encryption and decryption consistency with versioned keys."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_version_roundtrip_differing_version", "line_number": 189, "body": "def test_key_version_roundtrip_differing_version(self):\n        handler = CookieTestRequestHandler(\n            cookie_secret=self.KEY_VERSIONS, key_version=1\n        )\n        handler.set_secure_cookie(\"foo\", b\"bar\")\n        self.assertEqual(handler.get_secure_cookie(\"foo\"), b\"bar\")", "is_method": true, "class_name": "SecureCookieV2Test", "function_description": "Tests that a secure cookie set with one key version can be correctly retrieved when using a different key version, ensuring compatibility across key versions in secure cookie handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_version_increment_version", "line_number": 196, "body": "def test_key_version_increment_version(self):\n        handler = CookieTestRequestHandler(\n            cookie_secret=self.KEY_VERSIONS, key_version=0\n        )\n        handler.set_secure_cookie(\"foo\", b\"bar\")\n        new_handler = CookieTestRequestHandler(\n            cookie_secret=self.KEY_VERSIONS, key_version=1\n        )\n        new_handler._cookies = handler._cookies\n        self.assertEqual(new_handler.get_secure_cookie(\"foo\"), b\"bar\")", "is_method": true, "class_name": "SecureCookieV2Test", "function_description": "This test method verifies that a secure cookie set with one key version can be correctly read after incrementing to the next key version, ensuring backwards compatibility during key rotation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_version_invalidate_version", "line_number": 207, "body": "def test_key_version_invalidate_version(self):\n        handler = CookieTestRequestHandler(\n            cookie_secret=self.KEY_VERSIONS, key_version=0\n        )\n        handler.set_secure_cookie(\"foo\", b\"bar\")\n        new_key_versions = self.KEY_VERSIONS.copy()\n        new_key_versions.pop(0)\n        new_handler = CookieTestRequestHandler(\n            cookie_secret=new_key_versions, key_version=1\n        )\n        new_handler._cookies = handler._cookies\n        self.assertEqual(new_handler.get_secure_cookie(\"foo\"), None)", "is_method": true, "class_name": "SecureCookieV2Test", "function_description": "Tests that a secure cookie becomes invalid when the key version used to sign it is removed, ensuring key version management properly invalidates old cookies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 224, "body": "def get_handlers(self):\n        test = self\n\n        class FinishHandler(RequestHandler):\n            @gen.coroutine\n            def get(self):\n                test.final_return = self.finish()\n                yield test.final_return\n\n            @gen.coroutine\n            def post(self):\n                self.write(\"hello,\")\n                yield self.flush()\n                test.final_return = self.finish(\"world\")\n                yield test.final_return\n\n        class RenderHandler(RequestHandler):\n            def create_template_loader(self, path):\n                return DictLoader({\"foo.html\": \"hi\"})\n\n            @gen.coroutine\n            def get(self):\n                test.final_return = self.render(\"foo.html\")\n\n        return [(\"/finish\", FinishHandler), (\"/render\", RenderHandler)]", "is_method": true, "class_name": "FinalReturnTest", "function_description": "Provides two web request handlers: one manages asynchronous finishing of HTTP requests with optional response content, and the other renders a simple template. Useful for testing asynchronous response control and template rendering in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 250, "body": "def get_app_kwargs(self):\n        return dict(template_path=\"FinalReturnTest\")", "is_method": true, "class_name": "FinalReturnTest", "function_description": "Returns a dictionary with a fixed template path configuration used by the FinalReturnTest class. This provides standard keyword arguments for consistent setup across methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_finish_method_return_future", "line_number": 253, "body": "def test_finish_method_return_future(self):\n        response = self.fetch(self.get_url(\"/finish\"))\n        self.assertEqual(response.code, 200)\n        self.assertIsInstance(self.final_return, Future)\n        self.assertTrue(self.final_return.done())\n\n        response = self.fetch(self.get_url(\"/finish\"), method=\"POST\", body=b\"\")\n        self.assertEqual(response.code, 200)\n        self.assertIsInstance(self.final_return, Future)\n        self.assertTrue(self.final_return.done())", "is_method": true, "class_name": "FinalReturnTest", "function_description": "Tests that the \"/finish\" endpoint returns a completed Future object successfully for both GET and POST requests, verifying the endpoint's correct asynchronous response handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_render_method_return_future", "line_number": 264, "body": "def test_render_method_return_future(self):\n        response = self.fetch(self.get_url(\"/render\"))\n        self.assertEqual(response.code, 200)\n        self.assertIsInstance(self.final_return, Future)", "is_method": true, "class_name": "FinalReturnTest", "function_description": "Tests that the render method returns a Future object upon fetching the \"/render\" URL, verifying asynchronous behavior and successful response status."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 271, "body": "def get_handlers(self):\n        class SetCookieHandler(RequestHandler):\n            def get(self):\n                # Try setting cookies with different argument types\n                # to ensure that everything gets encoded correctly\n                self.set_cookie(\"str\", \"asdf\")\n                self.set_cookie(\"unicode\", u\"qwer\")\n                self.set_cookie(\"bytes\", b\"zxcv\")\n\n        class GetCookieHandler(RequestHandler):\n            def get(self):\n                cookie = self.get_cookie(\"foo\", \"default\")\n                assert cookie is not None\n                self.write(cookie)\n\n        class SetCookieDomainHandler(RequestHandler):\n            def get(self):\n                # unicode domain and path arguments shouldn't break things\n                # either (see bug #285)\n                self.set_cookie(\"unicode_args\", \"blah\", domain=u\"foo.com\", path=u\"/foo\")\n\n        class SetCookieSpecialCharHandler(RequestHandler):\n            def get(self):\n                self.set_cookie(\"equals\", \"a=b\")\n                self.set_cookie(\"semicolon\", \"a;b\")\n                self.set_cookie(\"quote\", 'a\"b')\n\n        class SetCookieOverwriteHandler(RequestHandler):\n            def get(self):\n                self.set_cookie(\"a\", \"b\", domain=\"example.com\")\n                self.set_cookie(\"c\", \"d\", domain=\"example.com\")\n                # A second call with the same name clobbers the first.\n                # Attributes from the first call are not carried over.\n                self.set_cookie(\"a\", \"e\")\n\n        class SetCookieMaxAgeHandler(RequestHandler):\n            def get(self):\n                self.set_cookie(\"foo\", \"bar\", max_age=10)\n\n        class SetCookieExpiresDaysHandler(RequestHandler):\n            def get(self):\n                self.set_cookie(\"foo\", \"bar\", expires_days=10)\n\n        class SetCookieFalsyFlags(RequestHandler):\n            def get(self):\n                self.set_cookie(\"a\", \"1\", secure=True)\n                self.set_cookie(\"b\", \"1\", secure=False)\n                self.set_cookie(\"c\", \"1\", httponly=True)\n                self.set_cookie(\"d\", \"1\", httponly=False)\n\n        return [\n            (\"/set\", SetCookieHandler),\n            (\"/get\", GetCookieHandler),\n            (\"/set_domain\", SetCookieDomainHandler),\n            (\"/special_char\", SetCookieSpecialCharHandler),\n            (\"/set_overwrite\", SetCookieOverwriteHandler),\n            (\"/set_max_age\", SetCookieMaxAgeHandler),\n            (\"/set_expires_days\", SetCookieExpiresDaysHandler),\n            (\"/set_falsy_flags\", SetCookieFalsyFlags),\n        ]", "is_method": true, "class_name": "CookieTest", "function_description": "Returns a list of HTTP request handlers for testing various cookie-setting and retrieval scenarios, enabling validation of cookie encoding, domains, special characters, overwriting, expiration, and security flags."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie", "line_number": 332, "body": "def test_set_cookie(self):\n        response = self.fetch(\"/set\")\n        self.assertEqual(\n            sorted(response.headers.get_list(\"Set-Cookie\")),\n            [\"bytes=zxcv; Path=/\", \"str=asdf; Path=/\", \"unicode=qwer; Path=/\"],\n        )", "is_method": true, "class_name": "CookieTest", "function_description": "Tests that the \"/set\" endpoint correctly sets multiple cookies with expected names and values, ensuring proper cookie handling in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_cookie", "line_number": 339, "body": "def test_get_cookie(self):\n        response = self.fetch(\"/get\", headers={\"Cookie\": \"foo=bar\"})\n        self.assertEqual(response.body, b\"bar\")\n\n        response = self.fetch(\"/get\", headers={\"Cookie\": 'foo=\"bar\"'})\n        self.assertEqual(response.body, b\"bar\")\n\n        response = self.fetch(\"/get\", headers={\"Cookie\": \"/=exception;\"})\n        self.assertEqual(response.body, b\"default\")", "is_method": true, "class_name": "CookieTest", "function_description": "Tests the CookieTest class's /get endpoint to verify it correctly parses and returns cookie values, ensuring proper handling of different cookie formats and fallback behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie_domain", "line_number": 349, "body": "def test_set_cookie_domain(self):\n        response = self.fetch(\"/set_domain\")\n        self.assertEqual(\n            response.headers.get_list(\"Set-Cookie\"),\n            [\"unicode_args=blah; Domain=foo.com; Path=/foo\"],\n        )", "is_method": true, "class_name": "CookieTest", "function_description": "Test method of the CookieTest class that verifies if the cookie domain is correctly set in the HTTP response header after requesting the \"/set_domain\" endpoint. It ensures cookie domain attributes are properly handled by the server."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_cookie_special_char", "line_number": 356, "body": "def test_cookie_special_char(self):\n        response = self.fetch(\"/special_char\")\n        headers = sorted(response.headers.get_list(\"Set-Cookie\"))\n        self.assertEqual(len(headers), 3)\n        self.assertEqual(headers[0], 'equals=\"a=b\"; Path=/')\n        self.assertEqual(headers[1], 'quote=\"a\\\\\"b\"; Path=/')\n        # python 2.7 octal-escapes the semicolon; older versions leave it alone\n        self.assertTrue(\n            headers[2] in ('semicolon=\"a;b\"; Path=/', 'semicolon=\"a\\\\073b\"; Path=/'),\n            headers[2],\n        )\n\n        data = [\n            (\"foo=a=b\", \"a=b\"),\n            ('foo=\"a=b\"', \"a=b\"),\n            ('foo=\"a;b\"', '\"a'),  # even quoted, \";\" is a delimiter\n            (\"foo=a\\\\073b\", \"a\\\\073b\"),  # escapes only decoded in quotes\n            ('foo=\"a\\\\073b\"', \"a;b\"),\n            ('foo=\"a\\\\\"b\"', 'a\"b'),\n        ]\n        for header, expected in data:\n            logging.debug(\"trying %r\", header)\n            response = self.fetch(\"/get\", headers={\"Cookie\": header})\n            self.assertEqual(response.body, utf8(expected))", "is_method": true, "class_name": "CookieTest", "function_description": "Tests the handling of cookies with special characters in HTTP headers, ensuring correct parsing and setting of cookies with characters like equals, quotes, and semicolons for reliable cookie management."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie_overwrite", "line_number": 381, "body": "def test_set_cookie_overwrite(self):\n        response = self.fetch(\"/set_overwrite\")\n        headers = response.headers.get_list(\"Set-Cookie\")\n        self.assertEqual(\n            sorted(headers), [\"a=e; Path=/\", \"c=d; Domain=example.com; Path=/\"]\n        )", "is_method": true, "class_name": "CookieTest", "function_description": "Tests that setting cookies with overlapping names results in expected cookie headers, verifying correct cookie overwrite behavior in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie_max_age", "line_number": 388, "body": "def test_set_cookie_max_age(self):\n        response = self.fetch(\"/set_max_age\")\n        headers = response.headers.get_list(\"Set-Cookie\")\n        self.assertEqual(sorted(headers), [\"foo=bar; Max-Age=10; Path=/\"])", "is_method": true, "class_name": "CookieTest", "function_description": "Test method in CookieTest that verifies the \"Set-Cookie\" header correctly includes a Max-Age attribute with the expected value in HTTP responses. It ensures proper cookie expiration behavior for the \"/set_max_age\" endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie_expires_days", "line_number": 393, "body": "def test_set_cookie_expires_days(self):\n        response = self.fetch(\"/set_expires_days\")\n        header = response.headers.get(\"Set-Cookie\")\n        assert header is not None\n        match = re.match(\"foo=bar; expires=(?P<expires>.+); Path=/\", header)\n        assert match is not None\n\n        expires = datetime.datetime.utcnow() + datetime.timedelta(days=10)\n        parsed = email.utils.parsedate(match.groupdict()[\"expires\"])\n        assert parsed is not None\n        header_expires = datetime.datetime(*parsed[:6])\n        self.assertTrue(abs((expires - header_expires).total_seconds()) < 10)", "is_method": true, "class_name": "CookieTest", "function_description": "Test method in CookieTest that verifies whether the \"Set-Cookie\" header correctly sets the cookie expiration date to 10 days in the future. It ensures HTTP responses properly manage cookie expiry timing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_cookie_false_flags", "line_number": 406, "body": "def test_set_cookie_false_flags(self):\n        response = self.fetch(\"/set_falsy_flags\")\n        headers = sorted(response.headers.get_list(\"Set-Cookie\"))\n        # The secure and httponly headers are capitalized in py35 and\n        # lowercase in older versions.\n        self.assertEqual(headers[0].lower(), \"a=1; path=/; secure\")\n        self.assertEqual(headers[1].lower(), \"b=1; path=/\")\n        self.assertEqual(headers[2].lower(), \"c=1; httponly; path=/\")\n        self.assertEqual(headers[3].lower(), \"d=1; path=/\")", "is_method": true, "class_name": "CookieTest", "function_description": "Test method verifying that cookies set by a specific endpoint correctly reflect false or absent secure and httponly flags as expected in the response headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "initialize", "line_number": 418, "body": "def initialize(self, login_url):\n        self.login_url = login_url", "is_method": true, "class_name": "AuthRedirectRequestHandler", "function_description": "Sets the login URL for the AuthRedirectRequestHandler instance, establishing the destination for authentication redirection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_login_url", "line_number": 421, "body": "def get_login_url(self):\n        return self.login_url", "is_method": true, "class_name": "AuthRedirectRequestHandler", "function_description": "Returns the URL to the login page, enabling redirection for user authentication within the AuthRedirectRequestHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 425, "body": "def get(self):\n        # we'll never actually get here because the test doesn't follow redirects\n        self.send_error(500)", "is_method": true, "class_name": "AuthRedirectRequestHandler", "function_description": "Returns a 500 error if accessed via GET method, indicating redirects should not be handled by this endpoint. Primarily used to enforce redirect flow control in authentication handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 431, "body": "def get_handlers(self):\n        return [\n            (\"/relative\", AuthRedirectRequestHandler, dict(login_url=\"/login\")),\n            (\n                \"/absolute\",\n                AuthRedirectRequestHandler,\n                dict(login_url=\"http://example.com/login\"),\n            ),\n        ]", "is_method": true, "class_name": "AuthRedirectTest", "function_description": "Provides URL handler configurations with specified relative and absolute login redirect URLs, enabling testing of authentication redirection behaviors in the AuthRedirectTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_relative_auth_redirect", "line_number": 441, "body": "def test_relative_auth_redirect(self):\n        response = self.fetch(self.get_url(\"/relative\"), follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertEqual(response.headers[\"Location\"], \"/login?next=%2Frelative\")", "is_method": true, "class_name": "AuthRedirectTest", "function_description": "Test method in AuthRedirectTest that verifies an unauthorized request to a relative URL triggers a redirect to the login page with the original URL preserved in the query parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_absolute_auth_redirect", "line_number": 446, "body": "def test_absolute_auth_redirect(self):\n        response = self.fetch(self.get_url(\"/absolute\"), follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertTrue(\n            re.match(\n                r\"http://example.com/login\\?next=http%3A%2F%2F127.0.0.1%3A[0-9]+%2Fabsolute\",\n                response.headers[\"Location\"],\n            ),\n            response.headers[\"Location\"],\n        )", "is_method": true, "class_name": "AuthRedirectTest", "function_description": "Tests that accessing an absolute URL triggers a 302 redirect to the expected login page with a correctly encoded \"next\" parameter. It verifies proper authentication redirection behavior in the AuthRedirectTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 463, "body": "def get(self):\n        self.test.on_handler_waiting()\n        yield self.test.cleanup_event.wait()", "is_method": true, "class_name": "ConnectionCloseHandler", "function_description": "Provides an asynchronous wait mechanism that pauses execution until a cleanup event is triggered, signaling that connection closure handling can proceed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "on_connection_close", "line_number": 467, "body": "def on_connection_close(self):\n        self.test.on_connection_close()", "is_method": true, "class_name": "ConnectionCloseHandler", "function_description": "Delegates connection close event handling to an associated test component, providing a hook for cleanup or state update when a connection terminates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 472, "body": "def get_handlers(self):\n        self.cleanup_event = Event()\n        return [(\"/\", ConnectionCloseHandler, dict(test=self))]", "is_method": true, "class_name": "ConnectionCloseTest", "function_description": "Returns a list of handler configurations, initializing a cleanup event used for managing connection closure testing within the ConnectionCloseTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_connection_close", "line_number": 476, "body": "def test_connection_close(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n        s.connect((\"127.0.0.1\", self.get_http_port()))\n        self.stream = IOStream(s)\n        self.stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n        self.wait()\n        # Let the hanging coroutine clean up after itself\n        self.cleanup_event.set()\n        self.io_loop.run_sync(lambda: gen.sleep(0))", "is_method": true, "class_name": "ConnectionCloseTest", "function_description": "Test method in ConnectionCloseTest that establishes a socket connection, sends a simple HTTP request, and synchronizes cleanup to verify proper connection closing behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "on_handler_waiting", "line_number": 486, "body": "def on_handler_waiting(self):\n        logging.debug(\"handler waiting\")\n        self.stream.close()", "is_method": true, "class_name": "ConnectionCloseTest", "function_description": "This method in ConnectionCloseTest closes the associated stream when the handler is waiting, enabling proper cleanup or termination of the connection during wait states."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "on_connection_close", "line_number": 490, "body": "def on_connection_close(self):\n        logging.debug(\"connection closed\")\n        self.stop()", "is_method": true, "class_name": "ConnectionCloseTest", "function_description": "Method in ConnectionCloseTest that handles connection closure events by logging the closure and stopping the associated process or operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 496, "body": "def get(self, *path_args):\n        # Type checks: web.py interfaces convert argument values to\n        # unicode strings (by default, but see also decode_argument).\n        # In httpserver.py (i.e. self.request.arguments), they're left\n        # as bytes.  Keys are always native strings.\n        for key in self.request.arguments:\n            if type(key) != str:\n                raise Exception(\"incorrect type for key: %r\" % type(key))\n            for bvalue in self.request.arguments[key]:\n                if type(bvalue) != bytes:\n                    raise Exception(\"incorrect type for value: %r\" % type(bvalue))\n            for svalue in self.get_arguments(key):\n                if type(svalue) != unicode_type:\n                    raise Exception(\"incorrect type for value: %r\" % type(svalue))\n        for arg in path_args:\n            if type(arg) != unicode_type:\n                raise Exception(\"incorrect type for path arg: %r\" % type(arg))\n        self.write(\n            dict(\n                path=self.request.path,\n                path_args=path_args,\n                args=recursive_unicode(self.request.arguments),\n            )\n        )", "is_method": true, "class_name": "EchoHandler", "function_description": "Provides a GET request handler that validates and returns the request path, path arguments, and query parameters as a dictionary, ensuring correct data types in an HTTP web context. Useful for debugging or echoing back request details."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 523, "body": "def get_handlers(self):\n        return [(\"/group/(.*)\", EchoHandler), (\"/slashes/([^/]*)/([^/]*)\", EchoHandler)]", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Returns URL pattern-handler pairs that define routing rules for request handling, facilitating mapping of incoming requests to appropriate processing logic in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "fetch_json", "line_number": 526, "body": "def fetch_json(self, path):\n        return json_decode(self.fetch(path).body)", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Utility method of the RequestEncodingTest class that fetches content from a given path and returns it decoded as JSON, facilitating easy retrieval and parsing of JSON data from HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_group_question_mark", "line_number": 529, "body": "def test_group_question_mark(self):\n        # Ensure that url-encoded question marks are handled properly\n        self.assertEqual(\n            self.fetch_json(\"/group/%3F\"),\n            dict(path=\"/group/%3F\", path_args=[\"?\"], args={}),\n        )\n        self.assertEqual(\n            self.fetch_json(\"/group/%3F?%3F=%3F\"),\n            dict(path=\"/group/%3F\", path_args=[\"?\"], args={\"?\": [\"?\"]}),\n        )", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Tests that URL-encoded question marks in paths and query parameters are correctly decoded and handled by the request processing system. It ensures proper parsing of encoded characters in endpoint URLs for accurate request interpretation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_group_encoding", "line_number": 540, "body": "def test_group_encoding(self):\n        # Path components and query arguments should be decoded the same way\n        self.assertEqual(\n            self.fetch_json(\"/group/%C3%A9?arg=%C3%A9\"),\n            {\n                u\"path\": u\"/group/%C3%A9\",\n                u\"path_args\": [u\"\\u00e9\"],\n                u\"args\": {u\"arg\": [u\"\\u00e9\"]},\n            },\n        )", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Tests that URL path components and query parameters are decoded consistently into Unicode, ensuring correct interpretation of encoded characters in HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_slashes", "line_number": 551, "body": "def test_slashes(self):\n        # Slashes may be escaped to appear as a single \"directory\" in the path,\n        # but they are then unescaped when passed to the get() method.\n        self.assertEqual(\n            self.fetch_json(\"/slashes/foo/bar\"),\n            dict(path=\"/slashes/foo/bar\", path_args=[\"foo\", \"bar\"], args={}),\n        )\n        self.assertEqual(\n            self.fetch_json(\"/slashes/a%2Fb/c%2Fd\"),\n            dict(path=\"/slashes/a%2Fb/c%2Fd\", path_args=[\"a/b\", \"c/d\"], args={}),\n        )", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Tests that URL path segments with escaped slashes are correctly interpreted and unescaped into path arguments, ensuring accurate parsing of complex request paths in RequestEncodingTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_error", "line_number": 563, "body": "def test_error(self):\n        # Percent signs (encoded as %25) should not mess up printf-style\n        # messages in logs\n        with ExpectLog(gen_log, \".*Invalid unicode\"):\n            self.fetch(\"/group/?arg=%25%e9\")", "is_method": true, "class_name": "RequestEncodingTest", "function_description": "Tests that encoded percent signs in URL parameters do not disrupt logging messages and properly trigger an \"Invalid unicode\" error log during a request."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 571, "body": "def prepare(self):\n        self.errors = {}  # type: typing.Dict[str, str]\n\n        self.check_type(\"status\", self.get_status(), int)\n\n        # get_argument is an exception from the general rule of using\n        # type str for non-body data mainly for historical reasons.\n        self.check_type(\"argument\", self.get_argument(\"foo\"), unicode_type)\n        self.check_type(\"cookie_key\", list(self.cookies.keys())[0], str)\n        self.check_type(\"cookie_value\", list(self.cookies.values())[0].value, str)\n\n        # Secure cookies return bytes because they can contain arbitrary\n        # data, but regular cookies are native strings.\n        if list(self.cookies.keys()) != [\"asdf\"]:\n            raise Exception(\n                \"unexpected values for cookie keys: %r\" % self.cookies.keys()\n            )\n        self.check_type(\"get_secure_cookie\", self.get_secure_cookie(\"asdf\"), bytes)\n        self.check_type(\"get_cookie\", self.get_cookie(\"asdf\"), str)\n\n        self.check_type(\"xsrf_token\", self.xsrf_token, bytes)\n        self.check_type(\"xsrf_form_html\", self.xsrf_form_html(), str)\n\n        self.check_type(\"reverse_url\", self.reverse_url(\"typecheck\", \"foo\"), str)\n\n        self.check_type(\"request_summary\", self._request_summary(), str)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Utility method in TypeCheckHandler that validates and asserts the expected data types of various request and cookie-related attributes to ensure type correctness during request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 598, "body": "def get(self, path_component):\n        # path_component uses type unicode instead of str for consistency\n        # with get_argument()\n        self.check_type(\"path_component\", path_component, unicode_type)\n        self.write(self.errors)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Method in TypeCheckHandler that validates the type of a given path component and outputs any accumulated errors. It ensures type consistency for path inputs during request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "post", "line_number": 604, "body": "def post(self, path_component):\n        self.check_type(\"path_component\", path_component, unicode_type)\n        self.write(self.errors)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "This method validates that a given path component is of the expected Unicode type and outputs any accumulated type-related errors. It serves as a request handler utility for enforcing data type integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "check_type", "line_number": 608, "body": "def check_type(self, name, obj, expected_type):\n        actual_type = type(obj)\n        if expected_type != actual_type:\n            self.errors[name] = \"expected %s, got %s\" % (expected_type, actual_type)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Utility method of the TypeCheckHandler class that verifies if an object's type matches the expected type and records an error if there is a mismatch. Useful for enforcing type constraints and debugging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "decode_argument", "line_number": 615, "body": "def decode_argument(self, value, name=None):\n        if type(value) != bytes:\n            raise Exception(\"unexpected type for value: %r\" % type(value))\n        # use self.request.arguments directly to avoid recursion\n        if \"encoding\" in self.request.arguments:\n            return value.decode(to_unicode(self.request.arguments[\"encoding\"][0]))\n        else:\n            return value", "is_method": true, "class_name": "DecodeArgHandler", "function_description": "Handles decoding of byte arguments based on an optional encoding specified in the request, ensuring proper conversion from bytes to string for input processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 624, "body": "def get(self, arg):\n        def describe(s):\n            if type(s) == bytes:\n                return [\"bytes\", native_str(binascii.b2a_hex(s))]\n            elif type(s) == unicode_type:\n                return [\"unicode\", s]\n            raise Exception(\"unknown type\")\n\n        self.write({\"path\": describe(arg), \"query\": describe(self.get_argument(\"foo\"))})", "is_method": true, "class_name": "DecodeArgHandler", "function_description": "Method of DecodeArgHandler that extracts and writes type and value descriptions for a given argument and a specific request parameter, aiding in type inspection and debugging of input data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 636, "body": "def get(self):\n        self.render(\"linkify.html\", message=\"http://example.com\")", "is_method": true, "class_name": "LinkifyHandler", "function_description": "Renders a web page displaying a predefined URL message, serving as a simple handler for presenting link-related content in a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 641, "body": "def get(self):\n        self.render(\"page.html\", entries=[1, 2])", "is_method": true, "class_name": "UIModuleResourceHandler", "function_description": "Returns a rendered HTML page with a predefined list of entries, serving as a simple HTTP GET handler to display content in a web UI context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 646, "body": "def get(self, path):\n        self.write({\"path\": path})", "is_method": true, "class_name": "OptionalPathHandler", "function_description": "Simple handler method that responds with the given path value, typically used to echo or confirm the requested path in web request handling scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 651, "body": "def get(self):\n        self.set_header(\"x-overwrite\", \"1\")\n        self.set_header(\"X-Overwrite\", 2)\n        self.add_header(\"x-multi\", 3)\n        self.add_header(\"X-Multi\", \"4\")", "is_method": true, "class_name": "MultiHeaderHandler", "function_description": "Sets and adds multiple HTTP headers with varying cases and values, demonstrating how to handle headers that may overwrite or accumulate in the MultiHeaderHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 659, "body": "def get(self):\n        if self.get_argument(\"permanent\", None) is not None:\n            self.redirect(\"/\", permanent=bool(int(self.get_argument(\"permanent\"))))\n        elif self.get_argument(\"status\", None) is not None:\n            self.redirect(\"/\", status=int(self.get_argument(\"status\")))\n        else:\n            raise Exception(\"didn't get permanent or status arguments\")", "is_method": true, "class_name": "RedirectHandler", "function_description": "Handles HTTP GET requests by redirecting to the root URL, using either a permanent flag or a specific status code from query parameters to determine the redirect type. Raises an exception if neither parameter is provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 670, "body": "def get(self):\n        # Ensure that the flush callback is run whether or not there\n        # was any output.  The gen.Task and direct yield forms are\n        # equivalent.\n        yield self.flush()  # \"empty\" flush, but writes headers\n        yield self.flush()  # empty flush\n        self.write(\"o\")\n        yield self.flush()  # flushes the \"o\"\n        yield self.flush()  # empty flush\n        self.finish(\"k\")", "is_method": true, "class_name": "EmptyFlushCallbackHandler", "function_description": "Core method of EmptyFlushCallbackHandler that ensures a flush callback runs multiple times to write headers and data, ultimately finalizing the response. It supports reliable output flushing and response completion in asynchronous flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 683, "body": "def get(self):\n        try:\n            self.set_header(\"X-Foo\", \"foo\\r\\nX-Bar: baz\")\n            raise Exception(\"Didn't get expected exception\")\n        except ValueError as e:\n            if \"Unsafe header value\" in str(e):\n                self.finish(b\"ok\")\n            else:\n                raise", "is_method": true, "class_name": "HeaderInjectionHandler", "function_description": "Method of HeaderInjectionHandler that verifies safe HTTP header setting by detecting and handling unsafe header values to prevent header injection attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 695, "body": "def prepare(self):\n        if self.get_argument(\"source\", None) == \"query\":\n            method = self.get_query_argument\n        elif self.get_argument(\"source\", None) == \"body\":\n            method = self.get_body_argument\n        else:\n            method = self.get_argument  # type: ignore\n        self.finish(method(\"foo\", \"default\"))", "is_method": true, "class_name": "GetArgumentHandler", "function_description": "Utility method of the GetArgumentHandler class that selects and retrieves a request argument based on its specified source, then finalizes the response with the obtained or default value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 706, "body": "def prepare(self):\n        self.finish(\n            dict(\n                default=self.get_arguments(\"foo\"),\n                query=self.get_query_arguments(\"foo\"),\n                body=self.get_body_arguments(\"foo\"),\n            )\n        )", "is_method": true, "class_name": "GetArgumentsHandler", "function_description": "Method of GetArgumentsHandler that collects and returns default, query, and body arguments for the key \"foo\", consolidating different argument sources into a single response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 720, "body": "def get_app_kwargs(self):\n        loader = DictLoader(\n            {\n                \"linkify.html\": \"{% module linkify(message) %}\",\n                \"page.html\": \"\"\"\\\n<html><head></head><body>\n{% for e in entries %}\n{% module Template(\"entry.html\", entry=e) %}\n{% end %}\n</body></html>\"\"\",\n                \"entry.html\": \"\"\"\\\n{{ set_resources(embedded_css=\".entry { margin-bottom: 1em; }\",\n                 embedded_javascript=\"js_embed()\",\n                 css_files=[\"/base.css\", \"/foo.css\"],\n                 javascript_files=\"/common.js\",\n                 html_head=\"<meta>\",\n                 html_body='<script src=\"/analytics.js\"/>') }}\n<div class=\"entry\">...</div>\"\"\",\n            }\n        )\n        return dict(\n            template_loader=loader,\n            autoescape=\"xhtml_escape\",\n            cookie_secret=self.COOKIE_SECRET,\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Provides configuration parameters including HTML templates, autoescaping method, and cookie secret for initializing a WSGI web application in a test environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "tearDown", "line_number": 746, "body": "def tearDown(self):\n        super().tearDown()\n        RequestHandler._template_loaders.clear()", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Cleans up after tests by calling the parent teardown and resetting template loaders to ensure no residual state affects subsequent web tests in WSGISafeWebTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 750, "body": "def get_handlers(self):\n        urls = [\n            url(\"/typecheck/(.*)\", TypeCheckHandler, name=\"typecheck\"),\n            url(\"/decode_arg/(.*)\", DecodeArgHandler, name=\"decode_arg\"),\n            url(\"/decode_arg_kw/(?P<arg>.*)\", DecodeArgHandler),\n            url(\"/linkify\", LinkifyHandler),\n            url(\"/uimodule_resources\", UIModuleResourceHandler),\n            url(\"/optional_path/(.+)?\", OptionalPathHandler),\n            url(\"/multi_header\", MultiHeaderHandler),\n            url(\"/redirect\", RedirectHandler),\n            url(\n                \"/web_redirect_permanent\",\n                WebRedirectHandler,\n                {\"url\": \"/web_redirect_newpath\"},\n            ),\n            url(\n                \"/web_redirect\",\n                WebRedirectHandler,\n                {\"url\": \"/web_redirect_newpath\", \"permanent\": False},\n            ),\n            url(\n                \"//web_redirect_double_slash\",\n                WebRedirectHandler,\n                {\"url\": \"/web_redirect_newpath\"},\n            ),\n            url(\"/header_injection\", HeaderInjectionHandler),\n            url(\"/get_argument\", GetArgumentHandler),\n            url(\"/get_arguments\", GetArgumentsHandler),\n        ]\n        return urls", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Returns the URL routing configuration by listing all request handlers and their corresponding paths for web testing. This enables mapping HTTP requests to specific handler classes within the WSGISafeWebTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "fetch_json", "line_number": 781, "body": "def fetch_json(self, *args, **kwargs):\n        response = self.fetch(*args, **kwargs)\n        response.rethrow()\n        return json_decode(response.body)", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Utility method in WSGISafeWebTest that sends a request and returns the response body decoded as JSON, raising errors for unsuccessful responses to simplify JSON-based API testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_types", "line_number": 786, "body": "def test_types(self):\n        cookie_value = to_unicode(\n            create_signed_value(self.COOKIE_SECRET, \"asdf\", \"qwer\")\n        )\n        response = self.fetch(\n            \"/typecheck/asdf?foo=bar\", headers={\"Cookie\": \"asdf=\" + cookie_value}\n        )\n        data = json_decode(response.body)\n        self.assertEqual(data, {})\n\n        response = self.fetch(\n            \"/typecheck/asdf?foo=bar\",\n            method=\"POST\",\n            headers={\"Cookie\": \"asdf=\" + cookie_value},\n            body=\"foo=bar\",\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests the WSGISafeWebTest class's type checking endpoint by sending signed cookie requests with different HTTP methods to verify expected response behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_decode_argument", "line_number": 803, "body": "def test_decode_argument(self):\n        # These urls all decode to the same thing\n        urls = [\n            \"/decode_arg/%C3%A9?foo=%C3%A9&encoding=utf-8\",\n            \"/decode_arg/%E9?foo=%E9&encoding=latin1\",\n            \"/decode_arg_kw/%E9?foo=%E9&encoding=latin1\",\n        ]\n        for req_url in urls:\n            response = self.fetch(req_url)\n            response.rethrow()\n            data = json_decode(response.body)\n            self.assertEqual(\n                data,\n                {u\"path\": [u\"unicode\", u\"\\u00e9\"], u\"query\": [u\"unicode\", u\"\\u00e9\"]},\n            )\n\n        response = self.fetch(\"/decode_arg/%C3%A9?foo=%C3%A9\")\n        response.rethrow()\n        data = json_decode(response.body)\n        self.assertEqual(\n            data, {u\"path\": [u\"bytes\", u\"c3a9\"], u\"query\": [u\"bytes\", u\"c3a9\"]}\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests the correct decoding of URL path and query parameters under various encodings, ensuring consistent Unicode or byte representations across different input formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_decode_argument_invalid_unicode", "line_number": 826, "body": "def test_decode_argument_invalid_unicode(self):\n        # test that invalid unicode in URLs causes 400, not 500\n        with ExpectLog(gen_log, \".*Invalid unicode.*\"):\n            response = self.fetch(\"/typecheck/invalid%FF\")\n            self.assertEqual(response.code, 400)\n            response = self.fetch(\"/typecheck/invalid?foo=%FF\")\n            self.assertEqual(response.code, 400)", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Core method of WSGISafeWebTest that verifies requests with invalid Unicode in URLs correctly return HTTP 400 errors instead of server errors, ensuring robust URL decoding and error handling in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_decode_argument_plus", "line_number": 834, "body": "def test_decode_argument_plus(self):\n        # These urls are all equivalent.\n        urls = [\n            \"/decode_arg/1%20%2B%201?foo=1%20%2B%201&encoding=utf-8\",\n            \"/decode_arg/1%20+%201?foo=1+%2B+1&encoding=utf-8\",\n        ]\n        for req_url in urls:\n            response = self.fetch(req_url)\n            response.rethrow()\n            data = json_decode(response.body)\n            self.assertEqual(\n                data,\n                {u\"path\": [u\"unicode\", u\"1 + 1\"], u\"query\": [u\"unicode\", u\"1 + 1\"]},\n            )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Test method in WSGISafeWebTest that verifies correct decoding of URL arguments containing plus signs and spaces, ensuring consistent parsing of path and query parameters across URL variants."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_reverse_url", "line_number": 849, "body": "def test_reverse_url(self):\n        self.assertEqual(self.app.reverse_url(\"decode_arg\", \"foo\"), \"/decode_arg/foo\")\n        self.assertEqual(self.app.reverse_url(\"decode_arg\", 42), \"/decode_arg/42\")\n        self.assertEqual(self.app.reverse_url(\"decode_arg\", b\"\\xe9\"), \"/decode_arg/%E9\")\n        self.assertEqual(\n            self.app.reverse_url(\"decode_arg\", u\"\\u00e9\"), \"/decode_arg/%C3%A9\"\n        )\n        self.assertEqual(\n            self.app.reverse_url(\"decode_arg\", \"1 + 1\"), \"/decode_arg/1%20%2B%201\"\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Test method in WSGISafeWebTest that verifies URL reversal correctly encodes and formats various types of arguments into URL paths. It ensures the app's reverse_url function produces accurate, safe URLs from given endpoint names and parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_uimodule_unescaped", "line_number": 860, "body": "def test_uimodule_unescaped(self):\n        response = self.fetch(\"/linkify\")\n        self.assertEqual(\n            response.body, b'<a href=\"http://example.com\">http://example.com</a>'\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Test method in WSGISafeWebTest that verifies the /linkify endpoint correctly returns an unescaped HTML anchor tag linking to the specified URL. It ensures proper rendering of UI module output in the web response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_uimodule_resources", "line_number": 866, "body": "def test_uimodule_resources(self):\n        response = self.fetch(\"/uimodule_resources\")\n        self.assertEqual(\n            response.body,\n            b\"\"\"\\\n<html><head><link href=\"/base.css\" type=\"text/css\" rel=\"stylesheet\"/><link href=\"/foo.css\" type=\"text/css\" rel=\"stylesheet\"/>\n<style type=\"text/css\">\n.entry { margin-bottom: 1em; }\n</style>\n<meta>\n</head><body>\n\n\n<div class=\"entry\">...</div>\n\n\n<div class=\"entry\">...</div>\n\n<script src=\"/common.js\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n//<![CDATA[\njs_embed()\n//]]>\n</script>\n<script src=\"/analytics.js\"/>\n</body></html>\"\"\",  # noqa: E501\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that the \"/uimodule_resources\" endpoint returns the expected HTML content including stylesheets, scripts, and structure, ensuring UI module resources are correctly served in a WSGI-safe web environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_optional_path", "line_number": 894, "body": "def test_optional_path(self):\n        self.assertEqual(self.fetch_json(\"/optional_path/foo\"), {u\"path\": u\"foo\"})\n        self.assertEqual(self.fetch_json(\"/optional_path/\"), {u\"path\": None})", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Unit test method in WSGISafeWebTest that verifies correct JSON responses for URLs with and without an optional path segment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_multi_header", "line_number": 898, "body": "def test_multi_header(self):\n        response = self.fetch(\"/multi_header\")\n        self.assertEqual(response.headers[\"x-overwrite\"], \"2\")\n        self.assertEqual(response.headers.get_list(\"x-multi\"), [\"3\", \"4\"])", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that a web response correctly handles multiple headers, verifying header overwriting and retrieval of header lists. Used to ensure proper HTTP header management in WSGI web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_redirect", "line_number": 903, "body": "def test_redirect(self):\n        response = self.fetch(\"/redirect?permanent=1\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        response = self.fetch(\"/redirect?permanent=0\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        response = self.fetch(\"/redirect?status=307\", follow_redirects=False)\n        self.assertEqual(response.code, 307)", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that the application correctly issues HTTP redirects with expected status codes for various redirect scenarios. It validates permanent, temporary, and specific status code redirects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_web_redirect", "line_number": 911, "body": "def test_web_redirect(self):\n        response = self.fetch(\"/web_redirect_permanent\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/web_redirect_newpath\")\n        response = self.fetch(\"/web_redirect\", follow_redirects=False)\n        self.assertEqual(response.code, 302)\n        self.assertEqual(response.headers[\"Location\"], \"/web_redirect_newpath\")", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that specific web endpoints correctly perform HTTP permanent (301) and temporary (302) redirects to the expected new path, ensuring proper web redirect behavior in the WSGISafeWebTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_web_redirect_double_slash", "line_number": 919, "body": "def test_web_redirect_double_slash(self):\n        response = self.fetch(\"//web_redirect_double_slash\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/web_redirect_newpath\")", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that a web endpoint redirects requests with double slashes to a corrected URL with a single slash, ensuring proper HTTP 301 redirect behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_header_injection", "line_number": 924, "body": "def test_header_injection(self):\n        response = self.fetch(\"/header_injection\")\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that the /header_injection endpoint responds correctly with \"ok\", verifying safe handling of headers to prevent injection attacks in WSGI web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_argument", "line_number": 928, "body": "def test_get_argument(self):\n        response = self.fetch(\"/get_argument?foo=bar\")\n        self.assertEqual(response.body, b\"bar\")\n        response = self.fetch(\"/get_argument?foo=\")\n        self.assertEqual(response.body, b\"\")\n        response = self.fetch(\"/get_argument\")\n        self.assertEqual(response.body, b\"default\")\n\n        # Test merging of query and body arguments.\n        # In singular form, body arguments take precedence over query arguments.\n        body = urllib.parse.urlencode(dict(foo=\"hello\"))\n        response = self.fetch(\"/get_argument?foo=bar\", method=\"POST\", body=body)\n        self.assertEqual(response.body, b\"hello\")\n        # In plural methods they are merged.\n        response = self.fetch(\"/get_arguments?foo=bar\", method=\"POST\", body=body)\n        self.assertEqual(\n            json_decode(response.body),\n            dict(default=[\"bar\", \"hello\"], query=[\"bar\"], body=[\"hello\"]),\n        )", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Unit test method in WSGISafeWebTest that verifies retrieval and merging behavior of query and body arguments from HTTP requests, ensuring correct precedence and combined handling for singular and plural argument forms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_query_arguments", "line_number": 948, "body": "def test_get_query_arguments(self):\n        # send as a post so we can ensure the separation between query\n        # string and body arguments.\n        body = urllib.parse.urlencode(dict(foo=\"hello\"))\n        response = self.fetch(\n            \"/get_argument?source=query&foo=bar\", method=\"POST\", body=body\n        )\n        self.assertEqual(response.body, b\"bar\")\n        response = self.fetch(\n            \"/get_argument?source=query&foo=\", method=\"POST\", body=body\n        )\n        self.assertEqual(response.body, b\"\")\n        response = self.fetch(\"/get_argument?source=query\", method=\"POST\", body=body)\n        self.assertEqual(response.body, b\"default\")", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests retrieval of query string arguments from HTTP requests, verifying correct separation from POST body parameters and expected default value handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_body_arguments", "line_number": 963, "body": "def test_get_body_arguments(self):\n        body = urllib.parse.urlencode(dict(foo=\"bar\"))\n        response = self.fetch(\n            \"/get_argument?source=body&foo=hello\", method=\"POST\", body=body\n        )\n        self.assertEqual(response.body, b\"bar\")\n\n        body = urllib.parse.urlencode(dict(foo=\"\"))\n        response = self.fetch(\n            \"/get_argument?source=body&foo=hello\", method=\"POST\", body=body\n        )\n        self.assertEqual(response.body, b\"\")\n\n        body = urllib.parse.urlencode(dict())\n        response = self.fetch(\n            \"/get_argument?source=body&foo=hello\", method=\"POST\", body=body\n        )\n        self.assertEqual(response.body, b\"default\")", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that POST request bodies are correctly parsed to retrieve specific argument values, validating behavior with present, empty, and missing parameters in WSGISafeWebTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_no_gzip", "line_number": 982, "body": "def test_no_gzip(self):\n        response = self.fetch(\"/get_argument\")\n        self.assertNotIn(\"Accept-Encoding\", response.headers.get(\"Vary\", \"\"))\n        self.assertNotIn(\"gzip\", response.headers.get(\"Content-Encoding\", \"\"))", "is_method": true, "class_name": "WSGISafeWebTest", "function_description": "Tests that the response from a specific endpoint does not indicate gzip compression or vary based on Accept-Encoding, ensuring correct handling of HTTP headers in web testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 989, "body": "def get_handlers(self):\n        return [(\"/empty_flush\", EmptyFlushCallbackHandler)]", "is_method": true, "class_name": "NonWSGIWebTests", "function_description": "Provides a list of URL route-handler pairs for the NonWSGIWebTests class, enabling mapping of specific request paths to their corresponding request handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_empty_flush", "line_number": 992, "body": "def test_empty_flush(self):\n        response = self.fetch(\"/empty_flush\")\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "NonWSGIWebTests", "function_description": "Simple test method in NonWSGIWebTests that verifies the \"/empty_flush\" endpoint returns the expected response body \"ok\". It ensures the endpoint responds correctly without additional data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 998, "body": "def get_handlers(self):\n        class DefaultHandler(RequestHandler):\n            def get(self):\n                if self.get_argument(\"status\", None):\n                    raise HTTPError(int(self.get_argument(\"status\")))\n                1 / 0\n\n        class WriteErrorHandler(RequestHandler):\n            def get(self):\n                if self.get_argument(\"status\", None):\n                    self.send_error(int(self.get_argument(\"status\")))\n                else:\n                    1 / 0\n\n            def write_error(self, status_code, **kwargs):\n                self.set_header(\"Content-Type\", \"text/plain\")\n                if \"exc_info\" in kwargs:\n                    self.write(\"Exception: %s\" % kwargs[\"exc_info\"][0].__name__)\n                else:\n                    self.write(\"Status: %d\" % status_code)\n\n        class FailedWriteErrorHandler(RequestHandler):\n            def get(self):\n                1 / 0\n\n            def write_error(self, status_code, **kwargs):\n                raise Exception(\"exception in write_error\")\n\n        return [\n            url(\"/default\", DefaultHandler),\n            url(\"/write_error\", WriteErrorHandler),\n            url(\"/failed_write_error\", FailedWriteErrorHandler),\n        ]", "is_method": true, "class_name": "ErrorResponseTest", "function_description": "Provides a set of request handlers simulating different error response behaviors for testing how various error scenarios and custom error writing are handled in web requests. It is useful for verifying error handling logic in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_default", "line_number": 1032, "body": "def test_default(self):\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            response = self.fetch(\"/default\")\n            self.assertEqual(response.code, 500)\n            self.assertTrue(b\"500: Internal Server Error\" in response.body)\n\n            response = self.fetch(\"/default?status=503\")\n            self.assertEqual(response.code, 503)\n            self.assertTrue(b\"503: Service Unavailable\" in response.body)\n\n            response = self.fetch(\"/default?status=435\")\n            self.assertEqual(response.code, 435)\n            self.assertTrue(b\"435: Unknown\" in response.body)", "is_method": true, "class_name": "ErrorResponseTest", "function_description": "Tests that the /default endpoint correctly returns HTTP error responses with appropriate status codes and messages, verifying server error handling for known and unknown statuses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_write_error", "line_number": 1046, "body": "def test_write_error(self):\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            response = self.fetch(\"/write_error\")\n            self.assertEqual(response.code, 500)\n            self.assertEqual(b\"Exception: ZeroDivisionError\", response.body)\n\n            response = self.fetch(\"/write_error?status=503\")\n            self.assertEqual(response.code, 503)\n            self.assertEqual(b\"Status: 503\", response.body)", "is_method": true, "class_name": "ErrorResponseTest", "function_description": "This test method verifies the /write_error endpoint correctly returns specified HTTP error codes and corresponding error messages, ensuring proper error handling and response formatting in the ErrorResponseTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_failed_write_error", "line_number": 1056, "body": "def test_failed_write_error(self):\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            response = self.fetch(\"/failed_write_error\")\n            self.assertEqual(response.code, 500)\n            self.assertEqual(b\"\", response.body)", "is_method": true, "class_name": "ErrorResponseTest", "function_description": "Test method in the ErrorResponseTest class that verifies a 500 error response with an empty body and logs an uncaught exception when a write failure occurs on a specific endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1072, "body": "def get_handlers(self):\n        class StaticUrlHandler(RequestHandler):\n            def get(self, path):\n                with_v = int(self.get_argument(\"include_version\", \"1\"))\n                self.write(self.static_url(path, include_version=with_v))\n\n        class AbsoluteStaticUrlHandler(StaticUrlHandler):\n            include_host = True\n\n        class OverrideStaticUrlHandler(RequestHandler):\n            def get(self, path):\n                do_include = bool(self.get_argument(\"include_host\"))\n                self.include_host = not do_include\n\n                regular_url = self.static_url(path)\n                override_url = self.static_url(path, include_host=do_include)\n                if override_url == regular_url:\n                    return self.write(str(False))\n\n                protocol = self.request.protocol + \"://\"\n                protocol_length = len(protocol)\n                check_regular = regular_url.find(protocol, 0, protocol_length)\n                check_override = override_url.find(protocol, 0, protocol_length)\n\n                if do_include:\n                    result = check_override == 0 and check_regular == -1\n                else:\n                    result = check_override == -1 and check_regular == 0\n                self.write(str(result))\n\n        return [\n            (\"/static_url/(.*)\", StaticUrlHandler),\n            (\"/abs_static_url/(.*)\", AbsoluteStaticUrlHandler),\n            (\"/override_static_url/(.*)\", OverrideStaticUrlHandler),\n            (\"/root_static/(.*)\", StaticFileHandler, dict(path=\"/\")),\n        ]", "is_method": true, "class_name": "StaticFileTest", "function_description": "Provides a set of HTTP request handlers that generate static file URLs with optional versioning and host inclusion, supporting flexible URL retrieval for static file testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1109, "body": "def get_app_kwargs(self):\n        return dict(static_path=relpath(\"static\"))", "is_method": true, "class_name": "StaticFileTest", "function_description": "Returns a dictionary with a relative path to the static files directory, providing configuration parameters for application setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_files", "line_number": 1112, "body": "def test_static_files(self):\n        response = self.fetch(\"/robots.txt\")\n        self.assertTrue(b\"Disallow: /\" in response.body)\n\n        response = self.fetch(\"/static/robots.txt\")\n        self.assertTrue(b\"Disallow: /\" in response.body)\n        self.assertEqual(response.headers.get(\"Content-Type\"), \"text/plain\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that static files like \"robots.txt\" are correctly served with expected content and headers, ensuring proper handling of static resources in the web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_compressed_files", "line_number": 1120, "body": "def test_static_compressed_files(self):\n        response = self.fetch(\"/static/sample.xml.gz\")\n        self.assertEqual(response.headers.get(\"Content-Type\"), \"application/gzip\")\n        response = self.fetch(\"/static/sample.xml.bz2\")\n        self.assertEqual(\n            response.headers.get(\"Content-Type\"), \"application/octet-stream\"\n        )\n        # make sure the uncompressed file still has the correct type\n        response = self.fetch(\"/static/sample.xml\")\n        self.assertTrue(\n            response.headers.get(\"Content-Type\") in set((\"text/xml\", \"application/xml\"))\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that static compressed and uncompressed files are served with the correct Content-Type headers, ensuring proper MIME type handling for different file formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_url", "line_number": 1133, "body": "def test_static_url(self):\n        response = self.fetch(\"/static_url/robots.txt\")\n        self.assertEqual(response.body, b\"/static/robots.txt?v=\" + self.robots_txt_hash)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Checks that the static URL endpoint serves the correct versioned robots.txt file, validating static file handling and cache-busting mechanisms in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_absolute_static_url", "line_number": 1137, "body": "def test_absolute_static_url(self):\n        response = self.fetch(\"/abs_static_url/robots.txt\")\n        self.assertEqual(\n            response.body,\n            (utf8(self.get_url(\"/\")) + b\"static/robots.txt?v=\" + self.robots_txt_hash),\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Method in StaticFileTest that verifies the absolute URL generation for a static file returns the correctly hashed URL response as expected. It ensures static file URL integrity in web testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_relative_version_exclusion", "line_number": 1144, "body": "def test_relative_version_exclusion(self):\n        response = self.fetch(\"/static_url/robots.txt?include_version=0\")\n        self.assertEqual(response.body, b\"/static/robots.txt\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Test method in StaticFileTest that verifies the exclusion of version information in the response URL when requested. It ensures static files are served without version query parameters if specified."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_absolute_version_exclusion", "line_number": 1148, "body": "def test_absolute_version_exclusion(self):\n        response = self.fetch(\"/abs_static_url/robots.txt?include_version=0\")\n        self.assertEqual(response.body, utf8(self.get_url(\"/\") + \"static/robots.txt\"))", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a static file URL with versioning disabled correctly excludes the version parameter, ensuring the response returns the expected file path. This verifies static file serving behavior in version-exclusion scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_include_host_override", "line_number": 1152, "body": "def test_include_host_override(self):\n        self._trigger_include_host_check(False)\n        self._trigger_include_host_check(True)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Test method in StaticFileTest that verifies behavior of include host override under both enabled and disabled conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "_trigger_include_host_check", "line_number": 1156, "body": "def _trigger_include_host_check(self, include_host):\n        path = \"/override_static_url/robots.txt?include_host=%s\"\n        response = self.fetch(path % int(include_host))\n        self.assertEqual(response.body, utf8(str(True)))", "is_method": true, "class_name": "StaticFileTest", "function_description": "Private test method in StaticFileTest that verifies if the server correctly handles the 'include_host' parameter when fetching a specific static URL. It ensures the server response matches the expected boolean outcome."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_and_head", "line_number": 1161, "body": "def get_and_head(self, *args, **kwargs):\n        \"\"\"Performs a GET and HEAD request and returns the GET response.\n\n        Fails if any ``Content-*`` headers returned by the two requests\n        differ.\n        \"\"\"\n        head_response = self.fetch(*args, method=\"HEAD\", **kwargs)\n        get_response = self.fetch(*args, method=\"GET\", **kwargs)\n        content_headers = set()\n        for h in itertools.chain(head_response.headers, get_response.headers):\n            if h.startswith(\"Content-\"):\n                content_headers.add(h)\n        for h in content_headers:\n            self.assertEqual(\n                head_response.headers.get(h),\n                get_response.headers.get(h),\n                \"%s differs between GET (%s) and HEAD (%s)\"\n                % (h, head_response.headers.get(h), get_response.headers.get(h)),\n            )\n        return get_response", "is_method": true, "class_name": "StaticFileTest", "function_description": "Performs both GET and HEAD HTTP requests to the same resource and validates that all Content-* headers match, ensuring consistency between the two responses before returning the GET response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_304_if_modified_since", "line_number": 1182, "body": "def test_static_304_if_modified_since(self):\n        response1 = self.get_and_head(\"/static/robots.txt\")\n        response2 = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\"If-Modified-Since\": response1.headers[\"Last-Modified\"]},\n        )\n        self.assertEqual(response2.code, 304)\n        self.assertTrue(\"Content-Length\" not in response2.headers)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file endpoint correctly returns a 304 Not Modified status when the file has not changed since the given timestamp, ensuring efficient client-side caching behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_304_if_none_match", "line_number": 1191, "body": "def test_static_304_if_none_match(self):\n        response1 = self.get_and_head(\"/static/robots.txt\")\n        response2 = self.get_and_head(\n            \"/static/robots.txt\", headers={\"If-None-Match\": response1.headers[\"Etag\"]}\n        )\n        self.assertEqual(response2.code, 304)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file endpoint correctly returns a 304 Not Modified status when the client sends an If-None-Match header matching the file's ETag, ensuring proper cache validation behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_304_etag_modified_bug", "line_number": 1198, "body": "def test_static_304_etag_modified_bug(self):\n        response1 = self.get_and_head(\"/static/robots.txt\")\n        response2 = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\n                \"If-None-Match\": '\"MISMATCH\"',\n                \"If-Modified-Since\": response1.headers[\"Last-Modified\"],\n            },\n        )\n        self.assertEqual(response2.code, 200)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file request correctly returns a full response when ETag and If-Modified-Since headers indicate modification, ensuring no incorrect 304 Not Modified status. This verifies proper handling of caching-related headers for static files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_if_modified_since_pre_epoch", "line_number": 1209, "body": "def test_static_if_modified_since_pre_epoch(self):\n        # On windows, the functions that work with time_t do not accept\n        # negative values, and at least one client (processing.js) seems\n        # to use if-modified-since 1/1/1960 as a cache-busting technique.\n        response = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\"If-Modified-Since\": \"Fri, 01 Jan 1960 00:00:00 GMT\"},\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that the server correctly handles HTTP If-Modified-Since headers with dates before the Unix epoch, ensuring proper cache behavior for legacy or unusual client requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_if_modified_since_time_zone", "line_number": 1219, "body": "def test_static_if_modified_since_time_zone(self):\n        # Instead of the value from Last-Modified, make requests with times\n        # chosen just before and after the known modification time\n        # of the file to ensure that the right time zone is being used\n        # when parsing If-Modified-Since.\n        stat = os.stat(relpath(\"static/robots.txt\"))\n\n        response = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\"If-Modified-Since\": format_timestamp(stat.st_mtime - 1)},\n        )\n        self.assertEqual(response.code, 200)\n        response = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\"If-Modified-Since\": format_timestamp(stat.st_mtime + 1)},\n        )\n        self.assertEqual(response.code, 304)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that the server correctly handles the If-Modified-Since HTTP header with precise timestamps around a file's modification time, ensuring proper time zone parsing for static file responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_etag", "line_number": 1237, "body": "def test_static_etag(self):\n        response = self.get_and_head(\"/static/robots.txt\")\n        self.assertEqual(\n            utf8(response.headers.get(\"Etag\")), b'\"' + self.robots_txt_hash + b'\"'\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Test method in StaticFileTest that verifies the ETag header of a static file response matches the expected hash value, ensuring proper cache validation functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range", "line_number": 1243, "body": "def test_static_with_range(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=0-9\"}\n        )\n        self.assertEqual(response.code, 206)\n        self.assertEqual(response.body, b\"User-agent\")\n        self.assertEqual(\n            utf8(response.headers.get(\"Etag\")), b'\"' + self.robots_txt_hash + b'\"'\n        )\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"10\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes 0-9/26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file server correctly handles byte-range requests by verifying partial content response, headers, and content consistency for a specific file segment. Useful for ensuring HTTP range request support and accurate partial data delivery."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_full_file", "line_number": 1255, "body": "def test_static_with_range_full_file(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=0-\"}\n        )\n        # Note: Chrome refuses to play audio if it gets an HTTP 206 in response\n        # to ``Range: bytes=0-`` :(\n        self.assertEqual(response.code, 200)\n        robots_file_path = os.path.join(self.static_dir, \"robots.txt\")\n        with open(robots_file_path) as f:\n            self.assertEqual(response.body, utf8(f.read()))\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"26\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), None)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a static file with a byte-range header requesting the full file returns a complete 200 response with the correct content and headers, ensuring range request handling serves the entire file as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_full_past_end", "line_number": 1268, "body": "def test_static_with_range_full_past_end(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=0-10000000\"}\n        )\n        self.assertEqual(response.code, 200)\n        robots_file_path = os.path.join(self.static_dir, \"robots.txt\")\n        with open(robots_file_path) as f:\n            self.assertEqual(response.body, utf8(f.read()))\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"26\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), None)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Method in StaticFileTest that verifies full file content is correctly returned when a byte range request exceeds the actual file size, ensuring proper handling of Range headers and accurate response headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_partial_past_end", "line_number": 1279, "body": "def test_static_with_range_partial_past_end(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=1-10000000\"}\n        )\n        self.assertEqual(response.code, 206)\n        robots_file_path = os.path.join(self.static_dir, \"robots.txt\")\n        with open(robots_file_path) as f:\n            self.assertEqual(response.body, utf8(f.read()[1:]))\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"25\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes 1-25/26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file server correctly handles a byte-range request extending beyond the file's end, ensuring proper partial content response with accurate headers and content delivery."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_end_edge", "line_number": 1290, "body": "def test_static_with_range_end_edge(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=22-\"}\n        )\n        self.assertEqual(response.body, b\": /\\n\")\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"4\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes 22-25/26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Utility test method in StaticFileTest that verifies correct handling of HTTP byte-range requests with open-ended ranges, ensuring proper Content-Length and Content-Range headers and partial content delivery for static files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_neg_end", "line_number": 1298, "body": "def test_static_with_range_neg_end(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=-4\"}\n        )\n        self.assertEqual(response.body, b\": /\\n\")\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"4\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes 22-25/26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Unit test method in StaticFileTest that verifies correct handling of HTTP range requests with a negative end byte, ensuring partial content response and accurate headers for static file serving."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_with_range_neg_past_start", "line_number": 1306, "body": "def test_static_with_range_neg_past_start(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=-1000000\"}\n        )\n        self.assertEqual(response.code, 200)\n        robots_file_path = os.path.join(self.static_dir, \"robots.txt\")\n        with open(robots_file_path) as f:\n            self.assertEqual(response.body, utf8(f.read()))\n        self.assertEqual(response.headers.get(\"Content-Length\"), \"26\")\n        self.assertEqual(response.headers.get(\"Content-Range\"), None)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a file with a negative byte range past the file start returns the entire file content correctly, verifying proper handling of edge-case HTTP range headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_invalid_range", "line_number": 1317, "body": "def test_static_invalid_range(self):\n        response = self.get_and_head(\"/static/robots.txt\", headers={\"Range\": \"asdf\"})\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Test method in StaticFileTest that verifies the server responds with status 200 when an invalid Range header is sent for a static file request. It ensures graceful handling of malformed byte-range requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_unsatisfiable_range_zero_suffix", "line_number": 1321, "body": "def test_static_unsatisfiable_range_zero_suffix(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=-0\"}\n        )\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes */26\")\n        self.assertEqual(response.code, 416)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a zero-length suffix byte range returns a 416 status with the correct Content-Range header, ensuring proper handling of unsatisfiable range requests for static files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_unsatisfiable_range_invalid_start", "line_number": 1328, "body": "def test_static_unsatisfiable_range_invalid_start(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=26\"}\n        )\n        self.assertEqual(response.code, 416)\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes */26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a static file with an unsatisfiable byte range starting beyond the file's length returns a 416 error and the correct Content-Range header. This ensures proper handling of invalid range requests in static file responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_unsatisfiable_range_end_less_than_start", "line_number": 1335, "body": "def test_static_unsatisfiable_range_end_less_than_start(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\", headers={\"Range\": \"bytes=10-3\"}\n        )\n        self.assertEqual(response.code, 416)\n        self.assertEqual(response.headers.get(\"Content-Range\"), \"bytes */26\")", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that the server correctly responds with a 416 error when a byte range request's end value is less than its start, ensuring proper handling of invalid HTTP Range headers in static file serving."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_head", "line_number": 1342, "body": "def test_static_head(self):\n        response = self.fetch(\"/static/robots.txt\", method=\"HEAD\")\n        self.assertEqual(response.code, 200)\n        # No body was returned, but we did get the right content length.\n        self.assertEqual(response.body, b\"\")\n        self.assertEqual(response.headers[\"Content-Length\"], \"26\")\n        self.assertEqual(\n            utf8(response.headers[\"Etag\"]), b'\"' + self.robots_txt_hash + b'\"'\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file endpoint correctly handles HEAD requests by verifying the response status, headers, and that no response body is returned. This supports validation of HTTP compliance for static file serving."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_head_range", "line_number": 1352, "body": "def test_static_head_range(self):\n        response = self.fetch(\n            \"/static/robots.txt\", method=\"HEAD\", headers={\"Range\": \"bytes=1-4\"}\n        )\n        self.assertEqual(response.code, 206)\n        self.assertEqual(response.body, b\"\")\n        self.assertEqual(response.headers[\"Content-Length\"], \"4\")\n        self.assertEqual(\n            utf8(response.headers[\"Etag\"]), b'\"' + self.robots_txt_hash + b'\"'\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests HTTP HEAD requests with byte-range headers on static files, verifying correct partial content response and headers; useful for ensuring proper range request handling in static file serving."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_range_if_none_match", "line_number": 1363, "body": "def test_static_range_if_none_match(self):\n        response = self.get_and_head(\n            \"/static/robots.txt\",\n            headers={\n                \"Range\": \"bytes=1-4\",\n                \"If-None-Match\": b'\"' + self.robots_txt_hash + b'\"',\n            },\n        )\n        self.assertEqual(response.code, 304)\n        self.assertEqual(response.body, b\"\")\n        self.assertTrue(\"Content-Length\" not in response.headers)\n        self.assertEqual(\n            utf8(response.headers[\"Etag\"]), b'\"' + self.robots_txt_hash + b'\"'\n        )", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that a static file endpoint correctly returns a 304 Not Modified response for a byte range request when the If-None-Match header matches the file's ETag. This ensures proper HTTP caching behavior for partial content requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_404", "line_number": 1378, "body": "def test_static_404(self):\n        response = self.get_and_head(\"/static/blarg\")\n        self.assertEqual(response.code, 404)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that requesting a nonexistent static file returns a 404 error, ensuring proper handling of missing static resources in the StaticFileTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_path_traversal_protection", "line_number": 1382, "body": "def test_path_traversal_protection(self):\n        # curl_httpclient processes \"..\" on the client side, so we\n        # must test this with simple_httpclient.\n        self.http_client.close()\n        self.http_client = SimpleAsyncHTTPClient()\n        with ExpectLog(gen_log, \".*not in root static directory\"):\n            response = self.get_and_head(\"/static/../static_foo.txt\")\n        # Attempted path traversal should result in 403, not 200\n        # (which means the check failed and the file was served)\n        # or 404 (which means that the file didn't exist and\n        # is probably a packaging error).\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Core test method of StaticFileTest that verifies protection against path traversal attacks by ensuring requests to files outside the root static directory are correctly denied with a 403 Forbidden response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_root_static_path", "line_number": 1396, "body": "def test_root_static_path(self):\n        # Sometimes people set the StaticFileHandler's path to '/'\n        # to disable Tornado's path validation (in conjunction with\n        # their own validation in get_absolute_path). Make sure\n        # that the stricter validation in 4.2.1 doesn't break them.\n        path = os.path.join(\n            os.path.dirname(os.path.abspath(__file__)), \"static/robots.txt\"\n        )\n        response = self.get_and_head(\"/root_static\" + urllib.parse.quote(path))\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "StaticFileTest", "function_description": "Tests that serving a static file from a root-level static path works correctly without being blocked by Tornado\u2019s stricter path validation. It ensures backward compatibility for custom static file handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1409, "body": "def get_app_kwargs(self):\n        return dict(\n            static_path=relpath(\"static\"),\n            static_handler_args=dict(default_filename=\"index.html\"),\n        )", "is_method": true, "class_name": "StaticDefaultFilenameTest", "function_description": "Returns default keyword arguments configuring static file handling, including the static path and default filename for serving index.html in a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1415, "body": "def get_handlers(self):\n        return []", "is_method": true, "class_name": "StaticDefaultFilenameTest", "function_description": "Returns an empty list of handlers, indicating no handlers are defined or used in this context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_default_filename", "line_number": 1418, "body": "def test_static_default_filename(self):\n        response = self.fetch(\"/static/dir/\", follow_redirects=False)\n        self.assertEqual(response.code, 200)\n        self.assertEqual(b\"this is the index\\n\", response.body)", "is_method": true, "class_name": "StaticDefaultFilenameTest", "function_description": "Test method in StaticDefaultFilenameTest that verifies serving the default static file returns the correct HTTP status and content for a given directory URL."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_default_redirect", "line_number": 1423, "body": "def test_static_default_redirect(self):\n        response = self.fetch(\"/static/dir\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertTrue(response.headers[\"Location\"].endswith(\"/static/dir/\"))", "is_method": true, "class_name": "StaticDefaultFilenameTest", "function_description": "Tests that accessing a static directory URL without a trailing slash correctly redirects with a 301 status to the URL including the trailing slash. This ensures proper URL normalization in static file serving."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1430, "body": "def get_app_kwargs(self):\n        return dict(\n            static_path=relpath(\"static\"),\n            static_handler_args=dict(default_filename=\"index.html\"),\n        )", "is_method": true, "class_name": "StaticFileWithPathTest", "function_description": "Utility method in StaticFileWithPathTest that provides configuration arguments for serving static files, including the static file directory path and default index filename."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1436, "body": "def get_handlers(self):\n        return [(\"/foo/(.*)\", StaticFileHandler, {\"path\": relpath(\"templates/\")})]", "is_method": true, "class_name": "StaticFileWithPathTest", "function_description": "Returns a list of web request handlers mapping URL patterns to file-serving handlers with a specified directory path, enabling static file serving in a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_serve", "line_number": 1439, "body": "def test_serve(self):\n        response = self.fetch(\"/foo/utf8.html\")\n        self.assertEqual(response.body, b\"H\\xc3\\xa9llo\\n\")", "is_method": true, "class_name": "StaticFileWithPathTest", "function_description": "Test method of StaticFileWithPathTest that verifies serving a UTF-8 encoded static file returns the expected byte content. It ensures correct file retrieval and encoding handling for static file responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1445, "body": "def get_handlers(self):\n        class MyStaticFileHandler(StaticFileHandler):\n            @classmethod\n            def make_static_url(cls, settings, path):\n                version_hash = cls.get_version(settings, path)\n                extension_index = path.rindex(\".\")\n                before_version = path[:extension_index]\n                after_version = path[(extension_index + 1) :]\n                return \"/static/%s.%s.%s\" % (\n                    before_version,\n                    version_hash,\n                    after_version,\n                )\n\n            def parse_url_path(self, url_path):\n                extension_index = url_path.rindex(\".\")\n                version_index = url_path.rindex(\".\", 0, extension_index)\n                return \"%s%s\" % (url_path[:version_index], url_path[extension_index:])\n\n            @classmethod\n            def get_absolute_path(cls, settings, path):\n                return \"CustomStaticFileTest:\" + path\n\n            def validate_absolute_path(self, root, absolute_path):\n                return absolute_path\n\n            @classmethod\n            def get_content(self, path, start=None, end=None):\n                assert start is None and end is None\n                if path == \"CustomStaticFileTest:foo.txt\":\n                    return b\"bar\"\n                raise Exception(\"unexpected path %r\" % path)\n\n            def get_content_size(self):\n                if self.absolute_path == \"CustomStaticFileTest:foo.txt\":\n                    return 3\n                raise Exception(\"unexpected path %r\" % self.absolute_path)\n\n            def get_modified_time(self):\n                return None\n\n            @classmethod\n            def get_version(cls, settings, path):\n                return \"42\"\n\n        class StaticUrlHandler(RequestHandler):\n            def get(self, path):\n                self.write(self.static_url(path))\n\n        self.static_handler_class = MyStaticFileHandler\n\n        return [(\"/static_url/(.*)\", StaticUrlHandler)]", "is_method": true, "class_name": "CustomStaticFileTest", "function_description": "Provides custom static file handling with versioned URLs and fixed content for testing, enabling static file serving and URL generation within a web application environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1498, "body": "def get_app_kwargs(self):\n        return dict(static_path=\"dummy\", static_handler_class=self.static_handler_class)", "is_method": true, "class_name": "CustomStaticFileTest", "function_description": "Returns configuration parameters specifying the static file path and handler class, useful for setting up static file serving in the CustomStaticFileTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_serve", "line_number": 1501, "body": "def test_serve(self):\n        response = self.fetch(\"/static/foo.42.txt\")\n        self.assertEqual(response.body, b\"bar\")", "is_method": true, "class_name": "CustomStaticFileTest", "function_description": "Test method in CustomStaticFileTest that verifies serving a specific static file returns the expected content. It ensures static file handling behaves correctly during tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_static_url", "line_number": 1505, "body": "def test_static_url(self):\n        with ExpectLog(gen_log, \"Could not open static file\", required=False):\n            response = self.fetch(\"/static_url/foo.txt\")\n            self.assertEqual(response.body, b\"/static/foo.42.txt\")", "is_method": true, "class_name": "CustomStaticFileTest", "function_description": "Method in CustomStaticFileTest that verifies the correctness of the static file serving URL, ensuring requests to a test path return the expected static file content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1519, "body": "def get_handlers(self):\n        return [(\"/foo\", HostMatchingTest.Handler, {\"reply\": \"wildcard\"})]", "is_method": true, "class_name": "HostMatchingTest", "function_description": "Returns a list of route-handler configurations for the HostMatchingTest, specifying URL patterns, handler classes, and associated parameters for request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_host_matching", "line_number": 1522, "body": "def test_host_matching(self):\n        self.app.add_handlers(\n            \"www.example.com\", [(\"/foo\", HostMatchingTest.Handler, {\"reply\": \"[0]\"})]\n        )\n        self.app.add_handlers(\n            r\"www\\.example\\.com\", [(\"/bar\", HostMatchingTest.Handler, {\"reply\": \"[1]\"})]\n        )\n        self.app.add_handlers(\n            \"www.example.com\", [(\"/baz\", HostMatchingTest.Handler, {\"reply\": \"[2]\"})]\n        )\n        self.app.add_handlers(\n            \"www.e.*e.com\", [(\"/baz\", HostMatchingTest.Handler, {\"reply\": \"[3]\"})]\n        )\n\n        response = self.fetch(\"/foo\")\n        self.assertEqual(response.body, b\"wildcard\")\n        response = self.fetch(\"/bar\")\n        self.assertEqual(response.code, 404)\n        response = self.fetch(\"/baz\")\n        self.assertEqual(response.code, 404)\n\n        response = self.fetch(\"/foo\", headers={\"Host\": \"www.example.com\"})\n        self.assertEqual(response.body, b\"[0]\")\n        response = self.fetch(\"/bar\", headers={\"Host\": \"www.example.com\"})\n        self.assertEqual(response.body, b\"[1]\")\n        response = self.fetch(\"/baz\", headers={\"Host\": \"www.example.com\"})\n        self.assertEqual(response.body, b\"[2]\")\n        response = self.fetch(\"/baz\", headers={\"Host\": \"www.exe.com\"})\n        self.assertEqual(response.body, b\"[3]\")", "is_method": true, "class_name": "HostMatchingTest", "function_description": "Tests that URL handlers correctly match requests based on their Host header, verifying routing behavior for exact and wildcard host patterns in the HostMatchingTest application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1554, "body": "def get_handlers(self):\n        return []", "is_method": true, "class_name": "DefaultHostMatchingTest", "function_description": "Placeholder method in DefaultHostMatchingTest that returns an empty list of handlers, indicating no handlers are configured or implemented."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1557, "body": "def get_app_kwargs(self):\n        return {\"default_host\": \"www.example.com\"}", "is_method": true, "class_name": "DefaultHostMatchingTest", "function_description": "Method of DefaultHostMatchingTest that provides default configuration arguments specifying the default host as \"www.example.com\"."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_default_host_matching", "line_number": 1560, "body": "def test_default_host_matching(self):\n        self.app.add_handlers(\n            \"www.example.com\", [(\"/foo\", HostMatchingTest.Handler, {\"reply\": \"[0]\"})]\n        )\n        self.app.add_handlers(\n            r\"www\\.example\\.com\", [(\"/bar\", HostMatchingTest.Handler, {\"reply\": \"[1]\"})]\n        )\n        self.app.add_handlers(\n            \"www.test.com\", [(\"/baz\", HostMatchingTest.Handler, {\"reply\": \"[2]\"})]\n        )\n\n        response = self.fetch(\"/foo\")\n        self.assertEqual(response.body, b\"[0]\")\n        response = self.fetch(\"/bar\")\n        self.assertEqual(response.body, b\"[1]\")\n        response = self.fetch(\"/baz\")\n        self.assertEqual(response.code, 404)\n\n        response = self.fetch(\"/foo\", headers={\"X-Real-Ip\": \"127.0.0.1\"})\n        self.assertEqual(response.code, 404)\n\n        self.app.default_host = \"www.test.com\"\n\n        response = self.fetch(\"/baz\")\n        self.assertEqual(response.body, b\"[2]\")", "is_method": true, "class_name": "DefaultHostMatchingTest", "function_description": "Test method of DefaultHostMatchingTest that verifies the app's request routing based on host matching and default host fallback, ensuring correct handler responses and 404 errors for unmatched hosts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1588, "body": "def get_handlers(self):\n        class EchoHandler(RequestHandler):\n            def get(self, path):\n                self.write(path)\n\n        return [\n            (\"/str/(?P<path>.*)\", EchoHandler),\n            (u\"/unicode/(?P<path>.*)\", EchoHandler),\n        ]", "is_method": true, "class_name": "NamedURLSpecGroupsTest", "function_description": "Returns URL routing handlers that echo back the requested path as a response, supporting both string and Unicode path formats. This facilitates testing URL pattern matching and request handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_named_urlspec_groups", "line_number": 1598, "body": "def test_named_urlspec_groups(self):\n        response = self.fetch(\"/str/foo\")\n        self.assertEqual(response.body, b\"foo\")\n\n        response = self.fetch(\"/unicode/bar\")\n        self.assertEqual(response.body, b\"bar\")", "is_method": true, "class_name": "NamedURLSpecGroupsTest", "function_description": "This test method verifies that URL pattern named groups correctly capture and return path components in HTTP responses, ensuring proper URL routing behavior in the NamedURLSpecGroupsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_clear_header", "line_number": 1614, "body": "def test_clear_header(self):\n        response = self.fetch(\"/\")\n        self.assertTrue(\"h1\" not in response.headers)\n        self.assertEqual(response.headers[\"h2\"], \"bar\")", "is_method": true, "class_name": "ClearHeaderTest", "function_description": "Test method in ClearHeaderTest that verifies specific HTTP headers are present or absent in a response, ensuring correct header manipulation or clearing behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_204_headers", "line_number": 1626, "body": "def test_204_headers(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.code, 204)\n        self.assertNotIn(\"Content-Length\", response.headers)\n        self.assertNotIn(\"Transfer-Encoding\", response.headers)", "is_method": true, "class_name": "Header204Test", "function_description": "Test method in Header204Test that verifies a 204 HTTP response correctly omits Content-Length and Transfer-Encoding headers, ensuring compliance with the 204 status code requirements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_304_headers", "line_number": 1639, "body": "def test_304_headers(self):\n        response1 = self.fetch(\"/\")\n        self.assertEqual(response1.headers[\"Content-Length\"], \"5\")\n        self.assertEqual(response1.headers[\"Content-Language\"], \"en_US\")\n\n        response2 = self.fetch(\n            \"/\", headers={\"If-None-Match\": response1.headers[\"Etag\"]}\n        )\n        self.assertEqual(response2.code, 304)\n        self.assertTrue(\"Content-Length\" not in response2.headers)\n        self.assertTrue(\"Content-Language\" not in response2.headers)\n        # Not an entity header, but should not be added to 304s by chunking\n        self.assertTrue(\"Transfer-Encoding\" not in response2.headers)", "is_method": true, "class_name": "Header304Test", "function_description": "Method in Header304Test that verifies correct HTTP 304 Not Modified responses exclude specific headers, ensuring proper handling of cached resource validation in web server tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_http_client", "line_number": 1663, "body": "def get_http_client(self):\n        # simple_httpclient only: curl doesn't expose the reason string\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "StatusReasonTest", "function_description": "Returns an asynchronous HTTP client instance optimized for simple HTTP requests, specifically providing access to HTTP reason strings unlike curl-based clients."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_status", "line_number": 1667, "body": "def test_status(self):\n        response = self.fetch(\"/?code=304\")\n        self.assertEqual(response.code, 304)\n        self.assertEqual(response.reason, \"Not Modified\")\n        response = self.fetch(\"/?code=304&reason=Foo\")\n        self.assertEqual(response.code, 304)\n        self.assertEqual(response.reason, \"Foo\")\n        response = self.fetch(\"/?code=682&reason=Bar\")\n        self.assertEqual(response.code, 682)\n        self.assertEqual(response.reason, \"Bar\")\n        response = self.fetch(\"/?code=682\")\n        self.assertEqual(response.code, 682)\n        self.assertEqual(response.reason, \"Unknown\")", "is_method": true, "class_name": "StatusReasonTest", "function_description": "Tests that HTTP response codes and corresponding reason phrases are correctly handled and returned by the fetch method, ensuring accurate status representation in different scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_date_header", "line_number": 1687, "body": "def test_date_header(self):\n        response = self.fetch(\"/\")\n        parsed = email.utils.parsedate(response.headers[\"Date\"])\n        assert parsed is not None\n        header_date = datetime.datetime(*parsed[:6])\n        self.assertTrue(\n            header_date - datetime.datetime.utcnow() < datetime.timedelta(seconds=2)\n        )", "is_method": true, "class_name": "DateHeaderTest", "function_description": "Tests that the HTTP response includes a valid \"Date\" header reflecting the current time within a 2-second margin, ensuring accurate server time reporting."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_http_client", "line_number": 1702, "body": "def get_http_client(self):\n        # simple_httpclient only: curl doesn't expose the reason string\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "RaiseWithReasonTest", "function_description": "Returns an instance of SimpleAsyncHTTPClient, providing an HTTP client that supports access to reason strings unlike other clients."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_raise_with_reason", "line_number": 1706, "body": "def test_raise_with_reason(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.code, 682)\n        self.assertEqual(response.reason, \"Foo\")\n        self.assertIn(b\"682: Foo\", response.body)", "is_method": true, "class_name": "RaiseWithReasonTest", "function_description": "Test method in RaiseWithReasonTest verifying that a response raised includes a specific status code, reason message, and corresponding body content. It ensures proper error reporting behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_httperror_str", "line_number": 1712, "body": "def test_httperror_str(self):\n        self.assertEqual(str(HTTPError(682, reason=\"Foo\")), \"HTTP 682: Foo\")", "is_method": true, "class_name": "RaiseWithReasonTest", "function_description": "Unit test method in RaiseWithReasonTest that verifies the string representation of an HTTPError includes its status code and reason phrase accurately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_httperror_str_from_httputil", "line_number": 1715, "body": "def test_httperror_str_from_httputil(self):\n        self.assertEqual(str(HTTPError(682)), \"HTTP 682: Unknown\")", "is_method": true, "class_name": "RaiseWithReasonTest", "function_description": "Unit test in RaiseWithReasonTest that verifies the string representation of an HTTPError with a given status code matches the expected format."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1720, "body": "def get_handlers(self):\n        # note that if the handlers list is empty we get the default_host\n        # redirect fallback instead of a 404, so test with both an\n        # explicitly defined error handler and an implicit 404.\n        return [(\"/error\", ErrorHandler, dict(status_code=417))]", "is_method": true, "class_name": "ErrorHandlerXSRFTest", "function_description": "Returns a list of error handler configurations mapping a specific URL path to an error handler with a custom status code for testing error handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1726, "body": "def get_app_kwargs(self):\n        return dict(xsrf_cookies=True)", "is_method": true, "class_name": "ErrorHandlerXSRFTest", "function_description": "Provides application configuration parameters indicating that XSRF cookie handling should be enabled, supporting tests that require cross-site request forgery protection settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_error_xsrf", "line_number": 1729, "body": "def test_error_xsrf(self):\n        response = self.fetch(\"/error\", method=\"POST\", body=\"\")\n        self.assertEqual(response.code, 417)", "is_method": true, "class_name": "ErrorHandlerXSRFTest", "function_description": "Tests that a POST request to the \"/error\" endpoint returns an HTTP 417 status code, verifying the server's handling of cross-site request forgery (XSRF) error responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_404_xsrf", "line_number": 1733, "body": "def test_404_xsrf(self):\n        response = self.fetch(\"/404\", method=\"POST\", body=\"\")\n        self.assertEqual(response.code, 404)", "is_method": true, "class_name": "ErrorHandlerXSRFTest", "function_description": "Test method in ErrorHandlerXSRFTest that verifies a POST request to a non-existent URL returns a 404 error, ensuring proper handling of missing resources under XSRF protection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1746, "body": "def get_app_kwargs(self):\n        return dict(\n            gzip=True, static_path=os.path.join(os.path.dirname(__file__), \"static\")\n        )", "is_method": true, "class_name": "GzipTestCase", "function_description": "Returns configuration options enabling gzip compression and specifying the path to static files, intended for setting up an application environment in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "assert_compressed", "line_number": 1751, "body": "def assert_compressed(self, response):\n        # simple_httpclient renames the content-encoding header;\n        # curl_httpclient doesn't.\n        self.assertEqual(\n            response.headers.get(\n                \"Content-Encoding\", response.headers.get(\"X-Consumed-Content-Encoding\")\n            ),\n            \"gzip\",\n        )", "is_method": true, "class_name": "GzipTestCase", "function_description": "Provides a test assertion that verifies if an HTTP response is compressed using gzip by checking relevant encoding headers. Useful for validating server responses in HTTP client tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_gzip", "line_number": 1761, "body": "def test_gzip(self):\n        response = self.fetch(\"/\")\n        self.assert_compressed(response)\n        self.assertEqual(response.headers[\"Vary\"], \"Accept-Encoding\")", "is_method": true, "class_name": "GzipTestCase", "function_description": "Test method in GzipTestCase that verifies HTTP response compression and proper header settings to ensure gzip encoding is applied and correctly indicated in the response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_gzip_static", "line_number": 1766, "body": "def test_gzip_static(self):\n        # The streaming responses in StaticFileHandler have subtle\n        # interactions with the gzip output so test this case separately.\n        response = self.fetch(\"/robots.txt\")\n        self.assert_compressed(response)\n        self.assertEqual(response.headers[\"Vary\"], \"Accept-Encoding\")", "is_method": true, "class_name": "GzipTestCase", "function_description": "Tests that a static file response is correctly gzip-compressed and validates related HTTP headers, ensuring proper handling of compressed streaming responses in static file delivery."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_gzip_not_requested", "line_number": 1773, "body": "def test_gzip_not_requested(self):\n        response = self.fetch(\"/\", use_gzip=False)\n        self.assertNotIn(\"Content-Encoding\", response.headers)\n        self.assertEqual(response.headers[\"Vary\"], \"Accept-Encoding\")", "is_method": true, "class_name": "GzipTestCase", "function_description": "Tests that when gzip compression is not requested, the response does not include gzip encoding but correctly varies based on the Accept-Encoding header. It ensures proper handling of HTTP response headers related to gzip usage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_vary_already_present", "line_number": 1778, "body": "def test_vary_already_present(self):\n        response = self.fetch(\"/?vary=Accept-Language\")\n        self.assert_compressed(response)\n        self.assertEqual(\n            [s.strip() for s in response.headers[\"Vary\"].split(\",\")],\n            [\"Accept-Language\", \"Accept-Encoding\"],\n        )", "is_method": true, "class_name": "GzipTestCase", "function_description": "Tests that a response already containing a Vary header correctly includes both the original and compression-related headers after compression, ensuring proper HTTP header management in responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_vary_already_present_multiple", "line_number": 1786, "body": "def test_vary_already_present_multiple(self):\n        # Regression test for https://github.com/tornadoweb/tornado/issues/1670\n        response = self.fetch(\"/?vary=Accept-Language&vary=Cookie\")\n        self.assert_compressed(response)\n        self.assertEqual(\n            [s.strip() for s in response.headers[\"Vary\"].split(\",\")],\n            [\"Accept-Language\", \"Cookie\", \"Accept-Encoding\"],\n        )", "is_method": true, "class_name": "GzipTestCase", "function_description": "Tests that when multiple Vary headers are already present, compression is applied correctly and the Vary header includes the original headers plus \"Accept-Encoding\". This ensures proper handling of Vary headers in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 1805, "body": "def get_handlers(self):\n        return [(\"/pos/(.*)\", self.Handler), (\"/kw/(?P<path>.*)\", self.Handler)]", "is_method": true, "class_name": "PathArgsInPrepareTest", "function_description": "Returns a list of URL patterns mapped to a handler, defining routes for positional and keyword-based path arguments in test preparation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_pos", "line_number": 1808, "body": "def test_pos(self):\n        response = self.fetch(\"/pos/foo\")\n        response.rethrow()\n        data = json_decode(response.body)\n        self.assertEqual(data, {\"args\": [\"foo\"], \"kwargs\": {}})", "is_method": true, "class_name": "PathArgsInPrepareTest", "function_description": "Unit test in PathArgsInPrepareTest that verifies correct extraction of positional arguments from a URL path, ensuring the endpoint properly returns them in the expected format."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_kw", "line_number": 1814, "body": "def test_kw(self):\n        response = self.fetch(\"/kw/foo\")\n        response.rethrow()\n        data = json_decode(response.body)\n        self.assertEqual(data, {\"args\": [], \"kwargs\": {\"path\": \"foo\"}})", "is_method": true, "class_name": "PathArgsInPrepareTest", "function_description": "Test method in PathArgsInPrepareTest that verifies the response from a specific endpoint correctly returns expected empty positional arguments and path keyword argument. It ensures the endpoint's request handling and JSON response format behave as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_clear_all_cookies", "line_number": 1827, "body": "def test_clear_all_cookies(self):\n        response = self.fetch(\"/\", headers={\"Cookie\": \"foo=bar; baz=xyzzy\"})\n        set_cookies = sorted(response.headers.get_list(\"Set-Cookie\"))\n        # Python 3.5 sends 'baz=\"\";'; older versions use 'baz=;'\n        self.assertTrue(\n            set_cookies[0].startswith(\"baz=;\") or set_cookies[0].startswith('baz=\"\";')\n        )\n        self.assertTrue(\n            set_cookies[1].startswith(\"foo=;\") or set_cookies[1].startswith('foo=\"\";')\n        )", "is_method": true, "class_name": "ClearAllCookiesTest", "function_description": "Test method in ClearAllCookiesTest that verifies all cookies sent in a request are properly cleared in the response by checking the Set-Cookie headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_http_error", "line_number": 1869, "body": "def test_http_error(self):\n        # HTTPErrors are logged as warnings with no stack trace.\n        # TODO: extend ExpectLog to test this more precisely\n        with ExpectLog(gen_log, \".*no longer here\"):\n            response = self.fetch(\"/?exc=http\")\n            self.assertEqual(response.code, 410)", "is_method": true, "class_name": "ExceptionHandlerTest", "function_description": "Tests that HTTP errors trigger logged warnings without stack traces and verify the response code, ensuring appropriate error handling and logging behavior in HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_unknown_error", "line_number": 1876, "body": "def test_unknown_error(self):\n        # Unknown errors are logged as errors with a stack trace.\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            response = self.fetch(\"/?exc=zero\")\n            self.assertEqual(response.code, 500)", "is_method": true, "class_name": "ExceptionHandlerTest", "function_description": "Test method in ExceptionHandlerTest that verifies unknown exceptions produce a 500 error response and are logged with a stack trace for proper error tracking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_known_error", "line_number": 1882, "body": "def test_known_error(self):\n        # log_exception can override logging behavior, and write_error\n        # can override the response.\n        with ExpectLog(app_log, \"custom logging for PermissionError: not allowed\"):\n            response = self.fetch(\"/?exc=permission\")\n            self.assertEqual(response.code, 403)", "is_method": true, "class_name": "ExceptionHandlerTest", "function_description": "Tests that the system correctly logs a PermissionError and returns a 403 response, validating custom error handling behavior within the ExceptionHandlerTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_buggy_log_exception", "line_number": 1898, "body": "def test_buggy_log_exception(self):\n        # Something gets logged even though the application's\n        # logger is broken.\n        with ExpectLog(app_log, \".*\"):\n            self.fetch(\"/\")", "is_method": true, "class_name": "BuggyLoggingTest", "function_description": "Test method in BuggyLoggingTest that verifies logging output occurs as expected despite a broken application logger, ensuring log messages are still captured during a fetch operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1917, "body": "def get_app_kwargs(self):\n        def my_ui_method(handler, x):\n            return \"In my_ui_method(%s) with handler value %s.\" % (x, handler.value())\n\n        class MyModule(UIModule):\n            def render(self, x):\n                return \"In MyModule(%s) with handler value %s.\" % (\n                    x,\n                    typing.cast(UIMethodUIModuleTest.Handler, self.handler).value(),\n                )\n\n        loader = DictLoader(\n            {\"foo.html\": \"{{ my_ui_method(42) }} {% module MyModule(123) %}\"}\n        )\n        return dict(\n            template_loader=loader,\n            ui_methods={\"my_ui_method\": my_ui_method},\n            ui_modules={\"MyModule\": MyModule},\n        )", "is_method": true, "class_name": "UIMethodUIModuleTest", "function_description": "Provides UI-related configuration including a template loader, a custom UI method, and a UI module class for rendering dynamic content within a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "tearDown", "line_number": 1937, "body": "def tearDown(self):\n        super().tearDown()\n        # TODO: fix template loader caching so this isn't necessary.\n        RequestHandler._template_loaders.clear()", "is_method": true, "class_name": "UIMethodUIModuleTest", "function_description": "Overrides the teardown process to clear cached template loaders, ensuring a clean state between UI module tests. It supports test reliability by preventing stale template data reuse."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_ui_method", "line_number": 1942, "body": "def test_ui_method(self):\n        response = self.fetch(\"/?value=asdf\")\n        self.assertEqual(\n            response.body,\n            b\"In my_ui_method(42) with handler value asdf. \"\n            b\"In MyModule(123) with handler value asdf.\",\n        )", "is_method": true, "class_name": "UIMethodUIModuleTest", "function_description": "Test method in UIMethodUIModuleTest that verifies the UI method's response correctness for a specific query input by checking the returned message content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_catch_error", "line_number": 1960, "body": "def test_catch_error(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(\n            json_decode(response.body),\n            {\"arg_name\": \"foo\", \"log_message\": \"Missing argument foo\"},\n        )", "is_method": true, "class_name": "GetArgumentErrorTest", "function_description": "Unit test method in GetArgumentErrorTest that verifies the correct error response is returned when a required argument is missing in a request. It ensures proper error catching and messaging behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_set_properties", "line_number": 1983, "body": "def test_set_properties(self):\n        # Ensure that current_user can be assigned to normally for apps\n        # that want to forgo the lazy get_current_user property\n        response = self.fetch(\"/\")\n        self.assertEqual(response.body, b\"Hello Ben (en_US)\")", "is_method": true, "class_name": "SetLazyPropertiesTest", "function_description": "Test method in SetLazyPropertiesTest that verifies normal assignment of current_user works correctly, ensuring expected behavior when bypassing the lazy property getter in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 1991, "body": "def get_app_kwargs(self):\n        class WithoutUserModule(UIModule):\n            def render(self):\n                return \"\"\n\n        class WithUserModule(UIModule):\n            def render(self):\n                return str(self.current_user)\n\n        loader = DictLoader(\n            {\n                \"without_user.html\": \"\",\n                \"with_user.html\": \"{{ current_user }}\",\n                \"without_user_module.html\": \"{% module WithoutUserModule() %}\",\n                \"with_user_module.html\": \"{% module WithUserModule() %}\",\n            }\n        )\n        return dict(\n            template_loader=loader,\n            ui_modules={\n                \"WithUserModule\": WithUserModule,\n                \"WithoutUserModule\": WithoutUserModule,\n            },\n        )", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Returns configuration including UI templates and modules, some of which render the current user's string representation, to support rendering user-aware or user-agnostic views in testing contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "tearDown", "line_number": 2016, "body": "def tearDown(self):\n        super().tearDown()\n        RequestHandler._template_loaders.clear()", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Cleans up after a test by resetting superclass teardown procedures and clearing template loader caches, ensuring no state leakage between tests in the GetCurrentUserTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2020, "body": "def get_handlers(self):\n        class CurrentUserHandler(RequestHandler):\n            def prepare(self):\n                self.has_loaded_current_user = False\n\n            def get_current_user(self):\n                self.has_loaded_current_user = True\n                return \"\"\n\n        class WithoutUserHandler(CurrentUserHandler):\n            def get(self):\n                self.render_string(\"without_user.html\")\n                self.finish(str(self.has_loaded_current_user))\n\n        class WithUserHandler(CurrentUserHandler):\n            def get(self):\n                self.render_string(\"with_user.html\")\n                self.finish(str(self.has_loaded_current_user))\n\n        class CurrentUserModuleHandler(CurrentUserHandler):\n            def get_template_namespace(self):\n                # If RequestHandler.get_template_namespace is called, then\n                # get_current_user is evaluated. Until #820 is fixed, this\n                # is a small hack to circumvent the issue.\n                return self.ui\n\n        class WithoutUserModuleHandler(CurrentUserModuleHandler):\n            def get(self):\n                self.render_string(\"without_user_module.html\")\n                self.finish(str(self.has_loaded_current_user))\n\n        class WithUserModuleHandler(CurrentUserModuleHandler):\n            def get(self):\n                self.render_string(\"with_user_module.html\")\n                self.finish(str(self.has_loaded_current_user))\n\n        return [\n            (\"/without_user\", WithoutUserHandler),\n            (\"/with_user\", WithUserHandler),\n            (\"/without_user_module\", WithoutUserModuleHandler),\n            (\"/with_user_module\", WithUserModuleHandler),\n        ]", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Provides a collection of web request handler classes simulating different user authentication scenarios for testing, each tracking whether the current user has been loaded during request processing. Useful for verifying user retrieval behavior in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_current_user_works", "line_number": 2069, "body": "def test_get_current_user_works(self):\n        response = self.fetch(\"/with_user\")\n        self.assertEqual(response.body, b\"True\")", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Tests that the endpoint \"/with_user\" correctly identifies the current user by verifying the response body is \"True\". It ensures user retrieval functionality works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_current_user_from_ui_module_is_lazy", "line_number": 2073, "body": "def test_get_current_user_from_ui_module_is_lazy(self):\n        response = self.fetch(\"/without_user_module\")\n        self.assertEqual(response.body, b\"False\")", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Tests that fetching the current user without the user module returns a lazy or default response, verifying correct behavior when the user module is absent."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_get_current_user_from_ui_module_works", "line_number": 2077, "body": "def test_get_current_user_from_ui_module_works(self):\n        response = self.fetch(\"/with_user_module\")\n        self.assertEqual(response.body, b\"True\")", "is_method": true, "class_name": "GetCurrentUserTest", "function_description": "Test method in GetCurrentUserTest that verifies if the current user retrieval via the UI module returns a successful, expected response. It ensures integration correctness between the UI and user context handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_unimplemented_standard_methods", "line_number": 2086, "body": "def test_unimplemented_standard_methods(self):\n        for method in [\"HEAD\", \"GET\", \"DELETE\", \"OPTIONS\"]:\n            response = self.fetch(\"/\", method=method)\n            self.assertEqual(response.code, 405)\n        for method in [\"POST\", \"PUT\"]:\n            response = self.fetch(\"/\", method=method, body=b\"\")\n            self.assertEqual(response.code, 405)", "is_method": true, "class_name": "UnimplementedHTTPMethodsTest", "function_description": "Tests that standard HTTP methods are not implemented for the endpoint by verifying each method returns a 405 Method Not Allowed response code. This ensures the system properly restricts unsupported HTTP actions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_unimplemented_patch", "line_number": 2102, "body": "def test_unimplemented_patch(self):\n        # PATCH is recently standardized; Tornado supports it by default\n        # but wsgiref.validate doesn't like it.\n        response = self.fetch(\"/\", method=\"PATCH\", body=b\"\")\n        self.assertEqual(response.code, 405)", "is_method": true, "class_name": "UnimplementedNonStandardMethodsTest", "function_description": "Test method that verifies handling of unimplemented HTTP PATCH requests by ensuring the server responds with a 405 status code indicating the method is not allowed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_unimplemented_other", "line_number": 2108, "body": "def test_unimplemented_other(self):\n        response = self.fetch(\"/\", method=\"OTHER\", allow_nonstandard_methods=True)\n        self.assertEqual(response.code, 405)", "is_method": true, "class_name": "UnimplementedNonStandardMethodsTest", "function_description": "Test method in UnimplementedNonStandardMethodsTest that verifies the server correctly responds with a 405 status to unsupported HTTP methods when nonstandard methods are allowed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_standard_methods", "line_number": 2121, "body": "def test_standard_methods(self):\n        response = self.fetch(\"/\", method=\"HEAD\")\n        self.assertEqual(response.body, b\"\")\n        for method in [\"GET\", \"DELETE\", \"OPTIONS\"]:\n            response = self.fetch(\"/\", method=method)\n            self.assertEqual(response.body, utf8(method))\n        for method in [\"POST\", \"PUT\"]:\n            response = self.fetch(\"/\", method=method, body=b\"\")\n            self.assertEqual(response.body, utf8(method))", "is_method": true, "class_name": "AllHTTPMethodsTest", "function_description": "Tests standard HTTP methods by sending requests and verifying that responses return expected method names or correct empty bodies, ensuring correct handling of common HTTP verbs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_patch", "line_number": 2144, "body": "def test_patch(self):\n        response = self.fetch(\"/\", method=\"PATCH\", body=b\"\")\n        self.assertEqual(response.body, b\"patch\")", "is_method": true, "class_name": "PatchMethodTest", "function_description": "Unit test method in PatchMethodTest that verifies handling of HTTP PATCH requests by checking if a PATCH request to the root path returns the expected response body."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_other", "line_number": 2148, "body": "def test_other(self):\n        response = self.fetch(\"/\", method=\"OTHER\", allow_nonstandard_methods=True)\n        self.assertEqual(response.body, b\"other\")", "is_method": true, "class_name": "PatchMethodTest", "function_description": "Test method in PatchMethodTest that verifies handling of a non-standard HTTP method named \"OTHER\" and asserts the correct response body is returned. It ensures compatibility with uncommon HTTP request types."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_finish_in_prepare", "line_number": 2164, "body": "def test_finish_in_prepare(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.body, b\"done\")", "is_method": true, "class_name": "FinishInPrepareTest", "function_description": "Unit test method in FinishInPrepareTest verifying that accessing the root path returns a response body of \"done\", ensuring the expected output during preparation or finishing processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2170, "body": "def get_handlers(self):\n        # If there are no handlers at all a default redirect handler gets added.\n        return [(\"/foo\", RequestHandler)]", "is_method": true, "class_name": "Default404Test", "function_description": "Provides a default set of URL handlers for testing, including a fallback redirect handler when no other handlers are defined."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_404", "line_number": 2174, "body": "def test_404(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.code, 404)\n        self.assertEqual(\n            response.body,\n            b\"<html><title>404: Not Found</title>\"\n            b\"<body>404: Not Found</body></html>\",\n        )", "is_method": true, "class_name": "Default404Test", "function_description": "Test method in Default404Test that verifies the root URL returns a 404 status and the expected \"Not Found\" HTML response, ensuring correct handling of non-existent routes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2185, "body": "def get_handlers(self):\n        return [(\"/foo\", RequestHandler)]", "is_method": true, "class_name": "Custom404Test", "function_description": "Returns a list of predefined URL handlers with their associated request handler classes for routing HTTP requests within the Custom404Test context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 2188, "body": "def get_app_kwargs(self):\n        class Custom404Handler(RequestHandler):\n            def get(self):\n                self.set_status(404)\n                self.write(\"custom 404 response\")\n\n        return dict(default_handler_class=Custom404Handler)", "is_method": true, "class_name": "Custom404Test", "function_description": "Provides application configuration specifying a custom 404 error handler that returns a tailored \"custom 404 response\" message for HTTP requests not matching any route."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_404", "line_number": 2196, "body": "def test_404(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.code, 404)\n        self.assertEqual(response.body, b\"custom 404 response\")", "is_method": true, "class_name": "Custom404Test", "function_description": "Core test method in Custom404Test that verifies the root URL returns a 404 status with a specific custom message, ensuring correct handling of missing resource routes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2203, "body": "def get_handlers(self):\n        return [(\"/foo\", RequestHandler)]", "is_method": true, "class_name": "DefaultHandlerArgumentsTest", "function_description": "Returns a list of request handler mappings linking a URL path to its handler class, enabling the association of URLs with their handling logic in a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 2206, "body": "def get_app_kwargs(self):\n        return dict(\n            default_handler_class=ErrorHandler,\n            default_handler_args=dict(status_code=403),\n        )", "is_method": true, "class_name": "DefaultHandlerArgumentsTest", "function_description": "Provides default handler class and arguments, including an error handler with a 403 status code, for configuring application behavior in the DefaultHandlerArgumentsTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_403", "line_number": 2212, "body": "def test_403(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "DefaultHandlerArgumentsTest", "function_description": "This test method verifies that accessing the root URL returns a 403 Forbidden status code, ensuring proper access restriction enforcement in the DefaultHandlerArgumentsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2218, "body": "def get_handlers(self):\n        # All three are equivalent.\n        return [\n            (\"/hello1\", HelloHandler),\n            (\"/hello2\", \"tornado.test.web_test.HelloHandler\"),\n            url(\"/hello3\", \"tornado.test.web_test.HelloHandler\"),\n        ]", "is_method": true, "class_name": "HandlerByNameTest", "function_description": "This method returns a list of URL-handler pairs associating specific endpoints with their handler classes or references. It provides route mappings used for request handling in a web application or testing context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_handler_by_name", "line_number": 2226, "body": "def test_handler_by_name(self):\n        resp = self.fetch(\"/hello1\")\n        self.assertEqual(resp.body, b\"hello\")\n        resp = self.fetch(\"/hello2\")\n        self.assertEqual(resp.body, b\"hello\")\n        resp = self.fetch(\"/hello3\")\n        self.assertEqual(resp.body, b\"hello\")", "is_method": true, "class_name": "HandlerByNameTest", "function_description": "Unit test in HandlerByNameTest that verifies multiple URL endpoints correctly return the expected \"hello\" response body. It ensures consistent handler behavior for different route names."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2236, "body": "def get_handlers(self):\n        @stream_request_body\n        class StreamingBodyHandler(RequestHandler):\n            def initialize(self, test):\n                self.test = test\n\n            def prepare(self):\n                self.test.prepared.set_result(None)\n\n            def data_received(self, data):\n                self.test.data.set_result(data)\n\n            def get(self):\n                self.test.finished.set_result(None)\n                self.write({})\n\n        @stream_request_body\n        class EarlyReturnHandler(RequestHandler):\n            def prepare(self):\n                # If we finish the response in prepare, it won't continue to\n                # the (non-existent) data_received.\n                raise HTTPError(401)\n\n        @stream_request_body\n        class CloseDetectionHandler(RequestHandler):\n            def initialize(self, test):\n                self.test = test\n\n            def on_connection_close(self):\n                super().on_connection_close()\n                self.test.close_future.set_result(None)\n\n        return [\n            (\"/stream_body\", StreamingBodyHandler, dict(test=self)),\n            (\"/early_return\", EarlyReturnHandler),\n            (\"/close_detection\", CloseDetectionHandler, dict(test=self)),\n        ]", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Provides a set of HTTP request handlers for testing streaming request body behavior, including normal streaming, early termination, and connection close detection in the StreamingRequestBodyTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "connect", "line_number": 2274, "body": "def connect(self, url, connection_close):\n        # Use a raw connection so we can control the sending of data.\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n        s.connect((\"127.0.0.1\", self.get_http_port()))\n        stream = IOStream(s)\n        stream.write(b\"GET \" + url + b\" HTTP/1.1\\r\\n\")\n        if connection_close:\n            stream.write(b\"Connection: close\\r\\n\")\n        stream.write(b\"Transfer-Encoding: chunked\\r\\n\\r\\n\")\n        return stream", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Creates and returns a raw HTTP GET connection stream to a local server using chunked transfer encoding, optionally including a connection close header. It facilitates fine-grained control over streaming HTTP request data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_streaming_body", "line_number": 2286, "body": "def test_streaming_body(self):\n        self.prepared = Future()  # type: Future[None]\n        self.data = Future()  # type: Future[bytes]\n        self.finished = Future()  # type: Future[None]\n\n        stream = self.connect(b\"/stream_body\", connection_close=True)\n        yield self.prepared\n        stream.write(b\"4\\r\\nasdf\\r\\n\")\n        # Ensure the first chunk is received before we send the second.\n        data = yield self.data\n        self.assertEqual(data, b\"asdf\")\n        self.data = Future()\n        stream.write(b\"4\\r\\nqwer\\r\\n\")\n        data = yield self.data\n        self.assertEqual(data, b\"qwer\")\n        stream.write(b\"0\\r\\n\\r\\n\")\n        yield self.finished\n        data = yield stream.read_until_close()\n        # This would ideally use an HTTP1Connection to read the response.\n        self.assertTrue(data.endswith(b\"{}\"))\n        stream.close()", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Tests the correct handling and reception of streamed HTTP request bodies in a connection, verifying chunked data transmission and proper stream closure behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_early_return", "line_number": 2309, "body": "def test_early_return(self):\n        stream = self.connect(b\"/early_return\", connection_close=False)\n        data = yield stream.read_until_close()\n        self.assertTrue(data.startswith(b\"HTTP/1.1 401\"))", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Tests if the streaming response for an early return scenario begins with an HTTP 401 status, ensuring correct handling of unauthorized access in streaming request bodies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_early_return_with_data", "line_number": 2315, "body": "def test_early_return_with_data(self):\n        stream = self.connect(b\"/early_return\", connection_close=False)\n        stream.write(b\"4\\r\\nasdf\\r\\n\")\n        data = yield stream.read_until_close()\n        self.assertTrue(data.startswith(b\"HTTP/1.1 401\"))", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Tests that a streaming request correctly returns early with expected 401 response data, validating behavior when data is sent before connection closure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_close_during_upload", "line_number": 2322, "body": "def test_close_during_upload(self):\n        self.close_future = Future()  # type: Future[None]\n        stream = self.connect(b\"/close_detection\", connection_close=False)\n        stream.close()\n        yield self.close_future", "is_method": true, "class_name": "StreamingRequestBodyTest", "function_description": "Tests if a streaming connection properly handles closure during data upload, ensuring resources are correctly released and closure events are detected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "initialize", "line_number": 2335, "body": "def initialize(self, test):\n        self.test = test\n        self.method = None\n        self.methods = []", "is_method": true, "class_name": "BaseFlowControlHandler", "function_description": "Initializes the BaseFlowControlHandler instance with a test context and resets its method tracking attributes. This setup prepares the handler for managing flow control methods during execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "in_method", "line_number": 2341, "body": "def in_method(self, method):\n        if self.method is not None:\n            self.test.fail(\"entered method %s while in %s\" % (method, self.method))\n        self.method = method\n        self.methods.append(method)\n        try:\n            yield\n        finally:\n            self.method = None", "is_method": true, "class_name": "BaseFlowControlHandler", "function_description": "Tracks entry into a method to detect and fail on nested calls, ensuring only one active method context at a time within BaseFlowControlHandler. Useful for managing and validating sequential method execution flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 2352, "body": "def prepare(self):\n        # Note that asynchronous prepare() does not block data_received,\n        # so we don't use in_method here.\n        self.methods.append(\"prepare\")\n        yield gen.moment", "is_method": true, "class_name": "BaseFlowControlHandler", "function_description": "Generates a non-blocking preparation step within flow control, signaling readiness without halting data reception. It tracks its invocation for managing asynchronous flow execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "post", "line_number": 2359, "body": "def post(self):\n        with self.in_method(\"post\"):\n            yield gen.moment\n        self.write(dict(methods=self.methods))", "is_method": true, "class_name": "BaseFlowControlHandler", "function_description": "Handles HTTP POST requests by asynchronously yielding control momentarily, then responds with available HTTP methods supported by this handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_httpserver_options", "line_number": 2366, "body": "def get_httpserver_options(self):\n        # Use a small chunk size so flow control is relevant even though\n        # all the data arrives at once.\n        return dict(chunk_size=10, decompress_request=True)", "is_method": true, "class_name": "BaseStreamingRequestFlowControlTest", "function_description": "Provides HTTP server configuration options with small chunk size and request decompression to enable effective flow control testing in streaming scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_http_client", "line_number": 2371, "body": "def get_http_client(self):\n        # simple_httpclient only: curl doesn't support body_producer.\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "BaseStreamingRequestFlowControlTest", "function_description": "Returns an instance of a simple asynchronous HTTP client for making HTTP requests without body producers, supporting basic HTTP operations in the flow control testing context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_flow_control_fixed_body", "line_number": 2376, "body": "def test_flow_control_fixed_body(self: typing.Any):\n        response = self.fetch(\"/\", body=\"abcdefghijklmnopqrstuvwxyz\", method=\"POST\")\n        response.rethrow()\n        self.assertEqual(\n            json_decode(response.body),\n            dict(\n                methods=[\n                    \"prepare\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"post\",\n                ]\n            ),\n        )", "is_method": true, "class_name": "BaseStreamingRequestFlowControlTest", "function_description": "Tests whether a POST request with a fixed body triggers the expected sequence of flow control method calls in the request lifecycle. It validates that the system processes streamed request data correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_flow_control_chunked_body", "line_number": 2392, "body": "def test_flow_control_chunked_body(self: typing.Any):\n        chunks = [b\"abcd\", b\"efgh\", b\"ijkl\"]\n\n        @gen.coroutine\n        def body_producer(write):\n            for i in chunks:\n                yield write(i)\n\n        response = self.fetch(\"/\", body_producer=body_producer, method=\"POST\")\n        response.rethrow()\n        self.assertEqual(\n            json_decode(response.body),\n            dict(\n                methods=[\n                    \"prepare\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"post\",\n                ]\n            ),\n        )", "is_method": true, "class_name": "BaseStreamingRequestFlowControlTest", "function_description": "Tests the handling of a chunked request body in a streaming flow control scenario, verifying that data chunks are processed and corresponding lifecycle methods are called in the expected order."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_flow_control_compressed_body", "line_number": 2415, "body": "def test_flow_control_compressed_body(self: typing.Any):\n        bytesio = BytesIO()\n        gzip_file = gzip.GzipFile(mode=\"w\", fileobj=bytesio)\n        gzip_file.write(b\"abcdefghijklmnopqrstuvwxyz\")\n        gzip_file.close()\n        compressed_body = bytesio.getvalue()\n        response = self.fetch(\n            \"/\",\n            body=compressed_body,\n            method=\"POST\",\n            headers={\"Content-Encoding\": \"gzip\"},\n        )\n        response.rethrow()\n        self.assertEqual(\n            json_decode(response.body),\n            dict(\n                methods=[\n                    \"prepare\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"data_received\",\n                    \"post\",\n                ]\n            ),\n        )", "is_method": true, "class_name": "BaseStreamingRequestFlowControlTest", "function_description": "Tests that the system correctly handles and decompresses a gzip-compressed POST request body, verifying proper invocation sequence of the request flow control methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2445, "body": "def get_handlers(self):\n        class DecoratedFlowControlHandler(BaseFlowControlHandler):\n            @gen.coroutine\n            def data_received(self, data):\n                with self.in_method(\"data_received\"):\n                    yield gen.moment\n\n        return [(\"/\", DecoratedFlowControlHandler, dict(test=self))]", "is_method": true, "class_name": "DecoratedStreamingRequestFlowControlTest", "function_description": "Returns a list of request handlers including a decorated flow control handler that manages data reception asynchronously within a test context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2458, "body": "def get_handlers(self):\n        class NativeFlowControlHandler(BaseFlowControlHandler):\n            async def data_received(self, data):\n                with self.in_method(\"data_received\"):\n                    import asyncio\n\n                    await asyncio.sleep(0)\n\n        return [(\"/\", NativeFlowControlHandler, dict(test=self))]", "is_method": true, "class_name": "NativeStreamingRequestFlowControlTest", "function_description": "Returns a list of request handlers with an embedded flow control handler class that asynchronously processes incoming data. It supports testing native streaming flow control behavior within the NativeStreamingRequestFlowControlTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2470, "body": "def get_handlers(self):\n        test = self\n        self.server_error = None\n\n        # Manually set a content-length that doesn't match the actual content.\n        class TooHigh(RequestHandler):\n            def get(self):\n                self.set_header(\"Content-Length\", \"42\")\n                try:\n                    self.finish(\"ok\")\n                except Exception as e:\n                    test.server_error = e\n                    raise\n\n        class TooLow(RequestHandler):\n            def get(self):\n                self.set_header(\"Content-Length\", \"2\")\n                try:\n                    self.finish(\"hello\")\n                except Exception as e:\n                    test.server_error = e\n                    raise\n\n        return [(\"/high\", TooHigh), (\"/low\", TooLow)]", "is_method": true, "class_name": "IncorrectContentLengthTest", "function_description": "Provides HTTP request handlers with intentionally incorrect Content-Length headers to test server behavior when content length does not match the actual response size. Useful for validating server error handling in edge cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_content_length_too_high", "line_number": 2495, "body": "def test_content_length_too_high(self):\n        # When the content-length is too high, the connection is simply\n        # closed without completing the response.  An error is logged on\n        # the server.\n        with ExpectLog(app_log, \"(Uncaught exception|Exception in callback)\"):\n            with ExpectLog(\n                gen_log,\n                \"(Cannot send error response after headers written\"\n                \"|Failed to flush partial response)\",\n            ):\n                with self.assertRaises(HTTPClientError):\n                    self.fetch(\"/high\", raise_error=True)\n        self.assertEqual(\n            str(self.server_error), \"Tried to write 40 bytes less than Content-Length\"\n        )", "is_method": true, "class_name": "IncorrectContentLengthTest", "function_description": "Tests the server's behavior when receiving an HTTP request with an excessively high Content-Length, ensuring it closes the connection and raises an error appropriately. This validates server robustness against malformed or oversized requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_content_length_too_low", "line_number": 2511, "body": "def test_content_length_too_low(self):\n        # When the content-length is too low, the connection is closed\n        # without writing the last chunk, so the client never sees the request\n        # complete (which would be a framing error).\n        with ExpectLog(app_log, \"(Uncaught exception|Exception in callback)\"):\n            with ExpectLog(\n                gen_log,\n                \"(Cannot send error response after headers written\"\n                \"|Failed to flush partial response)\",\n            ):\n                with self.assertRaises(HTTPClientError):\n                    self.fetch(\"/low\", raise_error=True)\n        self.assertEqual(\n            str(self.server_error), \"Tried to write more data than Content-Length\"\n        )", "is_method": true, "class_name": "IncorrectContentLengthTest", "function_description": "Core test method of IncorrectContentLengthTest that verifies the server properly handles requests with an inaccurately low Content-Length by closing the connection and raising an HTTPClientError."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_client_close", "line_number": 2543, "body": "def test_client_close(self):\n        with self.assertRaises((HTTPClientError, unittest.SkipTest)):  # type: ignore\n            response = self.fetch(\"/\", raise_error=True)\n            if response.body == b\"requires HTTP/1.x\":\n                self.skipTest(\"requires HTTP/1.x\")\n            self.assertEqual(response.code, 599)", "is_method": true, "class_name": "ClientCloseTest", "function_description": "Test method validating that the client properly handles connection closure errors or conditions requiring HTTP/1.x, ensuring appropriate exceptions or test skips are triggered."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "past", "line_number": 2555, "body": "def past(self):\n        return self.present() - 86400 * 32", "is_method": true, "class_name": "SignedValueTest", "function_description": "Returns a timestamp representing 32 days before the current time provided by the present() method, useful for calculating past dates relative to the present."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "present", "line_number": 2558, "body": "def present(self):\n        return 1300000000", "is_method": true, "class_name": "SignedValueTest", "function_description": "Constant-returning method in SignedValueTest that provides a fixed numeric value, potentially for testing or benchmarking purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_known_values", "line_number": 2561, "body": "def test_known_values(self):\n        signed_v1 = create_signed_value(\n            SignedValueTest.SECRET, \"key\", \"value\", version=1, clock=self.present\n        )\n        self.assertEqual(\n            signed_v1, b\"dmFsdWU=|1300000000|31c934969f53e48164c50768b40cbd7e2daaaa4f\"\n        )\n\n        signed_v2 = create_signed_value(\n            SignedValueTest.SECRET, \"key\", \"value\", version=2, clock=self.present\n        )\n        self.assertEqual(\n            signed_v2,\n            b\"2|1:0|10:1300000000|3:key|8:dmFsdWU=|\"\n            b\"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e152\",\n        )\n\n        signed_default = create_signed_value(\n            SignedValueTest.SECRET, \"key\", \"value\", clock=self.present\n        )\n        self.assertEqual(signed_default, signed_v2)\n\n        decoded_v1 = decode_signed_value(\n            SignedValueTest.SECRET, \"key\", signed_v1, min_version=1, clock=self.present\n        )\n        self.assertEqual(decoded_v1, b\"value\")\n\n        decoded_v2 = decode_signed_value(\n            SignedValueTest.SECRET, \"key\", signed_v2, min_version=2, clock=self.present\n        )\n        self.assertEqual(decoded_v2, b\"value\")", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests that creating and decoding signed values with different versions produces expected, consistent results, ensuring the integrity and correctness of the signing mechanism in SignedValueTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_name_swap", "line_number": 2593, "body": "def test_name_swap(self):\n        signed1 = create_signed_value(\n            SignedValueTest.SECRET, \"key1\", \"value\", clock=self.present\n        )\n        signed2 = create_signed_value(\n            SignedValueTest.SECRET, \"key2\", \"value\", clock=self.present\n        )\n        # Try decoding each string with the other's \"name\"\n        decoded1 = decode_signed_value(\n            SignedValueTest.SECRET, \"key2\", signed1, clock=self.present\n        )\n        self.assertIs(decoded1, None)\n        decoded2 = decode_signed_value(\n            SignedValueTest.SECRET, \"key1\", signed2, clock=self.present\n        )\n        self.assertIs(decoded2, None)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests that signed values created with one key name cannot be decoded with a different key name, ensuring name-based tampering protection in the SignedValueTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_expired", "line_number": 2610, "body": "def test_expired(self):\n        signed = create_signed_value(\n            SignedValueTest.SECRET, \"key1\", \"value\", clock=self.past\n        )\n        decoded_past = decode_signed_value(\n            SignedValueTest.SECRET, \"key1\", signed, clock=self.past\n        )\n        self.assertEqual(decoded_past, b\"value\")\n        decoded_present = decode_signed_value(\n            SignedValueTest.SECRET, \"key1\", signed, clock=self.present\n        )\n        self.assertIs(decoded_present, None)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests that a signed value is correctly decoded before expiration and correctly invalidated after expiration, ensuring the time-based validity of signed data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_payload_tampering", "line_number": 2623, "body": "def test_payload_tampering(self):\n        # These cookies are variants of the one in test_known_values.\n        sig = \"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e152\"\n\n        def validate(prefix):\n            return b\"value\" == decode_signed_value(\n                SignedValueTest.SECRET, \"key\", prefix + sig, clock=self.present\n            )\n\n        self.assertTrue(validate(\"2|1:0|10:1300000000|3:key|8:dmFsdWU=|\"))\n        # Change key version\n        self.assertFalse(validate(\"2|1:1|10:1300000000|3:key|8:dmFsdWU=|\"))\n        # length mismatch (field too short)\n        self.assertFalse(validate(\"2|1:0|10:130000000|3:key|8:dmFsdWU=|\"))\n        # length mismatch (field too long)\n        self.assertFalse(validate(\"2|1:0|10:1300000000|3:keey|8:dmFsdWU=|\"))", "is_method": true, "class_name": "SignedValueTest", "function_description": "Test method in SignedValueTest that verifies detection of tampered or invalid signed cookie payloads by validating signature integrity and structure, ensuring security of signed values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_signature_tampering", "line_number": 2640, "body": "def test_signature_tampering(self):\n        prefix = \"2|1:0|10:1300000000|3:key|8:dmFsdWU=|\"\n\n        def validate(sig):\n            return b\"value\" == decode_signed_value(\n                SignedValueTest.SECRET, \"key\", prefix + sig, clock=self.present\n            )\n\n        self.assertTrue(\n            validate(\"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e152\")\n        )\n        # All zeros\n        self.assertFalse(validate(\"0\" * 32))\n        # Change one character\n        self.assertFalse(\n            validate(\"4d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e152\")\n        )\n        # Change another character\n        self.assertFalse(\n            validate(\"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e153\")\n        )\n        # Truncate\n        self.assertFalse(\n            validate(\"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e15\")\n        )\n        # Lengthen\n        self.assertFalse(\n            validate(\n                \"3d4e60b996ff9c5d5788e333a0cba6f238a22c6c0f94788870e1a9ecd482e1538\"\n            )\n        )", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests the integrity of signed values by verifying that valid signatures pass and various tampered or malformed signatures fail, ensuring cryptographic signature validation correctness within SignedValueTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_non_ascii", "line_number": 2672, "body": "def test_non_ascii(self):\n        value = b\"\\xe9\"\n        signed = create_signed_value(\n            SignedValueTest.SECRET, \"key\", value, clock=self.present\n        )\n        decoded = decode_signed_value(\n            SignedValueTest.SECRET, \"key\", signed, clock=self.present\n        )\n        self.assertEqual(value, decoded)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Test method in SignedValueTest that verifies non-ASCII byte values can be correctly signed and decoded, ensuring data integrity during encoding and decoding processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_versioning_read_write_default_key", "line_number": 2682, "body": "def test_key_versioning_read_write_default_key(self):\n        value = b\"\\xe9\"\n        signed = create_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", value, clock=self.present, key_version=0\n        )\n        decoded = decode_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", signed, clock=self.present\n        )\n        self.assertEqual(value, decoded)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests that a signed value created with a specific key version can be correctly decoded using the default key, verifying the integrity of key versioning in signed value handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_versioning_read_write_non_default_key", "line_number": 2692, "body": "def test_key_versioning_read_write_non_default_key(self):\n        value = b\"\\xe9\"\n        signed = create_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", value, clock=self.present, key_version=1\n        )\n        decoded = decode_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", signed, clock=self.present\n        )\n        self.assertEqual(value, decoded)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Test method in SignedValueTest that verifies reading and writing a signed value using a non-default key version to ensure data integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_versioning_invalid_key", "line_number": 2702, "body": "def test_key_versioning_invalid_key(self):\n        value = b\"\\xe9\"\n        signed = create_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", value, clock=self.present, key_version=0\n        )\n        newkeys = SignedValueTest.SECRET_DICT.copy()\n        newkeys.pop(0)\n        decoded = decode_signed_value(newkeys, \"key\", signed, clock=self.present)\n        self.assertEqual(None, decoded)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Tests that decoding a signed value with a missing or invalid key version correctly fails, ensuring key versioning is properly handled during signature verification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_key_version_retrieval", "line_number": 2712, "body": "def test_key_version_retrieval(self):\n        value = b\"\\xe9\"\n        signed = create_signed_value(\n            SignedValueTest.SECRET_DICT, \"key\", value, clock=self.present, key_version=1\n        )\n        key_version = get_signature_key_version(signed)\n        self.assertEqual(1, key_version)", "is_method": true, "class_name": "SignedValueTest", "function_description": "Unit test method of SignedValueTest that verifies the correct retrieval of a signature's key version from a signed value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 2733, "body": "def get_app_kwargs(self):\n        return dict(xsrf_cookies=True)", "is_method": true, "class_name": "XSRFTest", "function_description": "Provides a dictionary with settings to enable cross-site request forgery (XSRF) cookie handling, supporting request validation in testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "setUp", "line_number": 2736, "body": "def setUp(self):\n        super().setUp()\n        self.xsrf_token = self.get_token()", "is_method": true, "class_name": "XSRFTest", "function_description": "Sets up the XSRFTest environment by initializing the base configuration and retrieving an XSRF token for use in tests requiring cross-site request forgery protection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_token", "line_number": 2740, "body": "def get_token(self, old_token=None, version=None):\n        if old_token is not None:\n            headers = self.cookie_headers(old_token)\n        else:\n            headers = None\n        response = self.fetch(\n            \"/\" if version is None else (\"/?version=%d\" % version), headers=headers\n        )\n        response.rethrow()\n        return native_str(response.body)", "is_method": true, "class_name": "XSRFTest", "function_description": "Provides a cross-site request forgery (XSRF) token by fetching it from the server, optionally using an old token or specifying a version. Useful for obtaining valid tokens to secure web requests against CSRF attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "cookie_headers", "line_number": 2751, "body": "def cookie_headers(self, token=None):\n        if token is None:\n            token = self.xsrf_token\n        return {\"Cookie\": \"_xsrf=\" + token}", "is_method": true, "class_name": "XSRFTest", "function_description": "Returns a cookie header dictionary containing an XSRF token, facilitating the simulation or testing of cross-site request forgery protection in HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_fail_no_token", "line_number": 2756, "body": "def test_xsrf_fail_no_token(self):\n        with ExpectLog(gen_log, \".*'_xsrf' argument missing\"):\n            response = self.fetch(\"/\", method=\"POST\", body=b\"\")\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Core test method in XSRFTest that verifies a POST request without an XSRF token fails with a 403 error, ensuring cross-site request forgery protection is enforced."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_fail_body_no_cookie", "line_number": 2761, "body": "def test_xsrf_fail_body_no_cookie(self):\n        with ExpectLog(gen_log, \".*XSRF cookie does not match POST\"):\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                body=urllib.parse.urlencode(dict(_xsrf=self.xsrf_token)),\n            )\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Tests that a POST request without the correct XSRF cookie is rejected with a 403 error, ensuring XSRF protection enforcement in the XSRFTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_fail_argument_invalid_format", "line_number": 2770, "body": "def test_xsrf_fail_argument_invalid_format(self):\n        with ExpectLog(gen_log, \".*'_xsrf' argument has invalid format\"):\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                headers=self.cookie_headers(),\n                body=urllib.parse.urlencode(dict(_xsrf=\"3|\")),\n            )\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Tests that requests with an incorrectly formatted '_xsrf' argument are rejected with a 403 error, ensuring the XSRF protection correctly handles invalid token formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_fail_cookie_invalid_format", "line_number": 2780, "body": "def test_xsrf_fail_cookie_invalid_format(self):\n        with ExpectLog(gen_log, \".*XSRF cookie does not match POST\"):\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                headers=self.cookie_headers(token=\"3|\"),\n                body=urllib.parse.urlencode(dict(_xsrf=self.xsrf_token)),\n            )\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Test method in XSRFTest that verifies a POST request is rejected with a 403 error when the XSRF cookie has an invalid format, ensuring proper XSRF protection enforcement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_fail_cookie_no_body", "line_number": 2790, "body": "def test_xsrf_fail_cookie_no_body(self):\n        with ExpectLog(gen_log, \".*'_xsrf' argument missing\"):\n            response = self.fetch(\n                \"/\", method=\"POST\", body=b\"\", headers=self.cookie_headers()\n            )\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Tests that a POST request with a cookie but no '_xsrf' argument in the body is rejected with a 403 error, verifying cross-site request forgery protection enforcement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_success_short_token", "line_number": 2797, "body": "def test_xsrf_success_short_token(self):\n        response = self.fetch(\n            \"/\",\n            method=\"POST\",\n            body=urllib.parse.urlencode(dict(_xsrf=\"deadbeef\")),\n            headers=self.cookie_headers(token=\"deadbeef\"),\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Core test method in XSRFTest that verifies successful request handling when a short XSRF token is provided, ensuring the system correctly validates CSRF protection tokens."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_success_non_hex_token", "line_number": 2806, "body": "def test_xsrf_success_non_hex_token(self):\n        response = self.fetch(\n            \"/\",\n            method=\"POST\",\n            body=urllib.parse.urlencode(dict(_xsrf=\"xoxo\")),\n            headers=self.cookie_headers(token=\"xoxo\"),\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Test method in XSRFTest that verifies successful POST requests with a non-hexadecimal XSRF token to ensure proper cross-site request forgery protection handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_success_post_body", "line_number": 2815, "body": "def test_xsrf_success_post_body(self):\n        response = self.fetch(\n            \"/\",\n            method=\"POST\",\n            body=urllib.parse.urlencode(dict(_xsrf=self.xsrf_token)),\n            headers=self.cookie_headers(),\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Utility test method in XSRFTest that verifies successful POST requests with valid XSRF tokens to ensure CSRF protection mechanisms work correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_success_query_string", "line_number": 2824, "body": "def test_xsrf_success_query_string(self):\n        response = self.fetch(\n            \"/?\" + urllib.parse.urlencode(dict(_xsrf=self.xsrf_token)),\n            method=\"POST\",\n            body=b\"\",\n            headers=self.cookie_headers(),\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Test method in XSRFTest that verifies successful handling of a POST request with a valid XSRF token passed via query string. It ensures the server properly accepts authenticated requests using query parameter tokens."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_success_header", "line_number": 2833, "body": "def test_xsrf_success_header(self):\n        response = self.fetch(\n            \"/\",\n            method=\"POST\",\n            body=b\"\",\n            headers=dict(\n                {\"X-Xsrftoken\": self.xsrf_token},  # type: ignore\n                **self.cookie_headers()\n            ),\n        )\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Test method in XSRFTest that verifies successful POST requests include the correct XSRF header and receive a 200 OK response, ensuring protection against cross-site request forgery attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_distinct_tokens", "line_number": 2845, "body": "def test_distinct_tokens(self):\n        # Every request gets a distinct token.\n        NUM_TOKENS = 10\n        tokens = set()\n        for i in range(NUM_TOKENS):\n            tokens.add(self.get_token())\n        self.assertEqual(len(tokens), NUM_TOKENS)", "is_method": true, "class_name": "XSRFTest", "function_description": "Core test method of the XSRFTest class that verifies unique tokens are generated for multiple requests, ensuring that each token is distinct to prevent cross-site request forgery attacks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_cross_user", "line_number": 2853, "body": "def test_cross_user(self):\n        token2 = self.get_token()\n        # Each token can be used to authenticate its own request.\n        for token in (self.xsrf_token, token2):\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                body=urllib.parse.urlencode(dict(_xsrf=token)),\n                headers=self.cookie_headers(token),\n            )\n            self.assertEqual(response.code, 200)\n        # Sending one in the cookie and the other in the body is not allowed.\n        for cookie_token, body_token in (\n            (self.xsrf_token, token2),\n            (token2, self.xsrf_token),\n        ):\n            with ExpectLog(gen_log, \".*XSRF cookie does not match POST\"):\n                response = self.fetch(\n                    \"/\",\n                    method=\"POST\",\n                    body=urllib.parse.urlencode(dict(_xsrf=body_token)),\n                    headers=self.cookie_headers(cookie_token),\n                )\n            self.assertEqual(response.code, 403)", "is_method": true, "class_name": "XSRFTest", "function_description": "Core test method of the XSRFTest class that verifies correct and incorrect usage of cross-site request forgery tokens, ensuring proper authentication and rejection of mismatched token scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_refresh_token", "line_number": 2878, "body": "def test_refresh_token(self):\n        token = self.xsrf_token\n        tokens_seen = set([token])\n        # A user's token is stable over time.  Refreshing the page in one tab\n        # might update the cookie while an older tab still has the old cookie\n        # in its DOM.  Simulate this scenario by passing a constant token\n        # in the body and re-querying for the token.\n        for i in range(5):\n            token = self.get_token(token)\n            # Tokens are encoded uniquely each time\n            tokens_seen.add(token)\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                body=urllib.parse.urlencode(dict(_xsrf=self.xsrf_token)),\n                headers=self.cookie_headers(token),\n            )\n            self.assertEqual(response.code, 200)\n        self.assertEqual(len(tokens_seen), 6)", "is_method": true, "class_name": "XSRFTest", "function_description": "Tests the stability and uniqueness of XSRF tokens over multiple refreshes, ensuring token updates remain valid and distinct while verifying server acceptance of reused tokens in concurrent sessions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_versioning", "line_number": 2898, "body": "def test_versioning(self):\n        # Version 1 still produces distinct tokens per request.\n        self.assertNotEqual(self.get_token(version=1), self.get_token(version=1))\n\n        # Refreshed v1 tokens are all identical.\n        v1_token = self.get_token(version=1)\n        for i in range(5):\n            self.assertEqual(self.get_token(v1_token, version=1), v1_token)\n\n        # Upgrade to a v2 version of the same token\n        v2_token = self.get_token(v1_token)\n        self.assertNotEqual(v1_token, v2_token)\n        # Each v1 token can map to many v2 tokens.\n        self.assertNotEqual(v2_token, self.get_token(v1_token))\n\n        # The tokens are cross-compatible.\n        for cookie_token, body_token in ((v1_token, v2_token), (v2_token, v1_token)):\n            response = self.fetch(\n                \"/\",\n                method=\"POST\",\n                body=urllib.parse.urlencode(dict(_xsrf=body_token)),\n                headers=self.cookie_headers(cookie_token),\n            )\n            self.assertEqual(response.code, 200)", "is_method": true, "class_name": "XSRFTest", "function_description": "Test method in XSRFTest that verifies cross-version compatibility, uniqueness, and refresh behavior of XSRF tokens to ensure secure and consistent token handling across different token versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_app_kwargs", "line_number": 2929, "body": "def get_app_kwargs(self):\n        return dict(\n            xsrf_cookies=True, xsrf_cookie_kwargs=dict(httponly=True, expires_days=2)\n        )", "is_method": true, "class_name": "XSRFCookieKwargsTest", "function_description": "Provides configuration parameters enabling XSRF cookie protection with specific HTTP-only and expiration settings, supporting secure web application setups within the XSRFCookieKwargsTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_xsrf_httponly", "line_number": 2934, "body": "def test_xsrf_httponly(self):\n        response = self.fetch(\"/\")\n        self.assertIn(\"httponly;\", response.headers[\"Set-Cookie\"].lower())\n        self.assertIn(\"expires=\", response.headers[\"Set-Cookie\"].lower())\n        header = response.headers.get(\"Set-Cookie\")\n        assert header is not None\n        match = re.match(\".*; expires=(?P<expires>.+);.*\", header)\n        assert match is not None\n\n        expires = datetime.datetime.utcnow() + datetime.timedelta(days=2)\n        parsed = email.utils.parsedate(match.groupdict()[\"expires\"])\n        assert parsed is not None\n        header_expires = datetime.datetime(*parsed[:6])\n        self.assertTrue(abs((expires - header_expires).total_seconds()) < 10)", "is_method": true, "class_name": "XSRFCookieKwargsTest", "function_description": "Tests that the HTTP-only XSRF cookie is properly set with an expiration date roughly two days in the future, ensuring secure and timely cookie handling in responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_finish_exception", "line_number": 2961, "body": "def test_finish_exception(self):\n        for u in [\"/\", \"/?finish_value=1\"]:\n            response = self.fetch(u)\n            self.assertEqual(response.code, 401)\n            self.assertEqual(\n                'Basic realm=\"something\"', response.headers.get(\"WWW-Authenticate\")\n            )\n            self.assertEqual(b\"authentication required\", response.body)", "is_method": true, "class_name": "FinishExceptionTest", "function_description": "Test method of the FinishExceptionTest class that verifies accessing specific URLs triggers a 401 authentication response with the correct headers and message. It ensures proper enforcement of authentication requirements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 2972, "body": "def get_handlers(self):\n        class RemoveSlashHandler(RequestHandler):\n            @removeslash\n            def get(self):\n                pass\n\n        class AddSlashHandler(RequestHandler):\n            @addslash\n            def get(self):\n                pass\n\n        return [(\"/removeslash/\", RemoveSlashHandler), (\"/addslash\", AddSlashHandler)]", "is_method": true, "class_name": "DecoratorTest", "function_description": "Returns URL route-handler pairs where one handler removes trailing slashes and the other adds them, facilitating consistent URL formatting in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_removeslash", "line_number": 2985, "body": "def test_removeslash(self):\n        response = self.fetch(\"/removeslash/\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/removeslash\")\n\n        response = self.fetch(\"/removeslash/?foo=bar\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/removeslash?foo=bar\")", "is_method": true, "class_name": "DecoratorTest", "function_description": "This test method verifies that URLs ending with a trailing slash are correctly redirected to their non-trailing slash versions while preserving query parameters, ensuring proper URL normalization behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_addslash", "line_number": 2994, "body": "def test_addslash(self):\n        response = self.fetch(\"/addslash\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/addslash/\")\n\n        response = self.fetch(\"/addslash?foo=bar\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/addslash/?foo=bar\")", "is_method": true, "class_name": "DecoratorTest", "function_description": "Tests that requests to a URL missing a trailing slash are correctly redirected with a 301 status to the slash-appended URL, preserving any query parameters. This ensures consistent URL formatting and SEO-friendly redirects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 3005, "body": "def get_handlers(self):\n        class EtagHandler(RequestHandler):\n            def get(self, computed_etag):\n                self.write(computed_etag)\n\n            def compute_etag(self):\n                return self._write_buffer[0]\n\n        return [(\"/etag/(.*)\", EtagHandler)]", "is_method": true, "class_name": "CacheTest", "function_description": "Provides HTTP request handlers for ETag processing, enabling retrieval of computed ETag values via GET requests within a web application framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_wildcard_etag", "line_number": 3015, "body": "def test_wildcard_etag(self):\n        computed_etag = '\"xyzzy\"'\n        etags = \"*\"\n        self._test_etag(computed_etag, etags, 304)", "is_method": true, "class_name": "CacheTest", "function_description": "Tests the handling of wildcard etag values by verifying correct response status when a computed etag matches the wildcard pattern."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_strong_etag_match", "line_number": 3020, "body": "def test_strong_etag_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy\"'\n        self._test_etag(computed_etag, etags, 304)", "is_method": true, "class_name": "CacheTest", "function_description": "Method in CacheTest that verifies the behavior of matching strong ETags, ensuring a 304 Not Modified response is correctly triggered when ETags match."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_multiple_strong_etag_match", "line_number": 3025, "body": "def test_multiple_strong_etag_match(self):\n        computed_etag = '\"xyzzy1\"'\n        etags = '\"xyzzy1\", \"xyzzy2\"'\n        self._test_etag(computed_etag, etags, 304)", "is_method": true, "class_name": "CacheTest", "function_description": "Tests whether the system correctly recognizes a matching strong ETag from multiple ETag values and returns the appropriate HTTP 304 status code. This function helps verify HTTP cache validation behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_strong_etag_not_match", "line_number": 3030, "body": "def test_strong_etag_not_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy1\"'\n        self._test_etag(computed_etag, etags, 200)", "is_method": true, "class_name": "CacheTest", "function_description": "Test method in CacheTest that verifies behavior when a computed ETag does not match the provided ETag, ensuring the system responds with the expected status code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_multiple_strong_etag_not_match", "line_number": 3035, "body": "def test_multiple_strong_etag_not_match(self):\n        computed_etag = '\"xyzzy\"'\n        etags = '\"xyzzy1\", \"xyzzy2\"'\n        self._test_etag(computed_etag, etags, 200)", "is_method": true, "class_name": "CacheTest", "function_description": "Tests that a response with a computed ETag not matching any of multiple provided ETags returns a 200 status, verifying correct handling of ETag comparisons in caching mechanisms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_weak_etag_match", "line_number": 3040, "body": "def test_weak_etag_match(self):\n        computed_etag = '\"xyzzy1\"'\n        etags = 'W/\"xyzzy1\"'\n        self._test_etag(computed_etag, etags, 304)", "is_method": true, "class_name": "CacheTest", "function_description": "Tests whether a weak ETag value correctly matches a computed ETag, verifying cache validation behavior that results in a 304 Not Modified response. This function supports cache consistency checks in HTTP-related implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_multiple_weak_etag_match", "line_number": 3045, "body": "def test_multiple_weak_etag_match(self):\n        computed_etag = '\"xyzzy2\"'\n        etags = 'W/\"xyzzy1\", W/\"xyzzy2\"'\n        self._test_etag(computed_etag, etags, 304)", "is_method": true, "class_name": "CacheTest", "function_description": "Tests whether the system correctly handles a weak ETag matching scenario by verifying that a computed ETag matches one among multiple weak ETags, expecting a 304 Not Modified response. This ensures proper HTTP caching behavior in the CacheTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_weak_etag_not_match", "line_number": 3050, "body": "def test_weak_etag_not_match(self):\n        computed_etag = '\"xyzzy2\"'\n        etags = 'W/\"xyzzy1\"'\n        self._test_etag(computed_etag, etags, 200)", "is_method": true, "class_name": "CacheTest", "function_description": "Utility test method in CacheTest that verifies proper handling of weak ETag mismatches by asserting the expected HTTP response code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_multiple_weak_etag_not_match", "line_number": 3055, "body": "def test_multiple_weak_etag_not_match(self):\n        computed_etag = '\"xyzzy3\"'\n        etags = 'W/\"xyzzy1\", W/\"xyzzy2\"'\n        self._test_etag(computed_etag, etags, 200)", "is_method": true, "class_name": "CacheTest", "function_description": "Utility test method in CacheTest verifying that a computed ETag not matching multiple weak client ETags results in a successful (200) response code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "_test_etag", "line_number": 3060, "body": "def _test_etag(self, computed_etag, etags, status_code):\n        response = self.fetch(\n            \"/etag/\" + computed_etag, headers={\"If-None-Match\": etags}\n        )\n        self.assertEqual(response.code, status_code)", "is_method": true, "class_name": "CacheTest", "function_description": "Core utility method of the CacheTest class that verifies server response status codes based on provided ETag headers to test HTTP caching behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_missing_remote_ip", "line_number": 3076, "body": "def test_missing_remote_ip(self):\n        resp = self.fetch(\"/\")\n        self.assertEqual(resp.body, b\"GET / (None)\")", "is_method": true, "class_name": "RequestSummaryTest", "function_description": "Tests that a request without a remote IP address returns the expected response, validating correct handling of missing client IPs in request summaries."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_copy", "line_number": 3082, "body": "def test_copy(self):\n        e = HTTPError(403, reason=\"Go away\")\n        e2 = copy.copy(e)\n        self.assertIsNot(e, e2)\n        self.assertEqual(e.status_code, e2.status_code)\n        self.assertEqual(e.reason, e2.reason)", "is_method": true, "class_name": "HTTPErrorTest", "function_description": "Unit test method of HTTPErrorTest that verifies copying an HTTPError instance preserves its status code and reason, while creating a distinct object."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_listen", "line_number": 3091, "body": "def test_listen(self):\n        app = Application([])\n        server = app.listen(0, address=\"127.0.0.1\")\n        server.stop()", "is_method": true, "class_name": "ApplicationTest", "function_description": "Test method in ApplicationTest that verifies the Application class can start and stop a server listening on a specified address and port without errors. It ensures basic server lifecycle functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_reverse", "line_number": 3098, "body": "def test_reverse(self):\n        self.assertEqual(\"/favicon.ico\", url(r\"/favicon\\.ico\", None).reverse())\n        self.assertEqual(\"/favicon.ico\", url(r\"^/favicon\\.ico$\", None).reverse())", "is_method": true, "class_name": "URLSpecReverseTest", "function_description": "This test method verifies that URL patterns correctly generate their corresponding string URLs when reversed, ensuring URL routing definitions produce expected paths. It is useful for validating URL pattern accuracy in routing tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_non_reversible", "line_number": 3102, "body": "def test_non_reversible(self):\n        # URLSpecs are non-reversible if they include non-constant\n        # regex features outside capturing groups. Currently, this is\n        # only strictly enforced for backslash-escaped character\n        # classes.\n        paths = [r\"^/api/v\\d+/foo/(\\w+)$\"]\n        for path in paths:\n            # A URLSpec can still be created even if it cannot be reversed.\n            url_spec = url(path, None)\n            try:\n                result = url_spec.reverse()\n                self.fail(\n                    \"did not get expected exception when reversing %s. \"\n                    \"result: %s\" % (path, result)\n                )\n            except ValueError:\n                pass", "is_method": true, "class_name": "URLSpecReverseTest", "function_description": "Tests that URL patterns containing non-reversible regex features correctly raise an exception when attempting to reverse their URLs. It ensures that non-reversible URLSpecs are identified and handled as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_reverse_arguments", "line_number": 3120, "body": "def test_reverse_arguments(self):\n        self.assertEqual(\n            \"/api/v1/foo/bar\", url(r\"^/api/v1/foo/(\\w+)$\", None).reverse(\"bar\")\n        )\n        self.assertEqual(\n            \"/api.v1/foo/5/icon.png\",\n            url(r\"/api\\.v1/foo/([0-9]+)/icon\\.png\", None).reverse(5),\n        )", "is_method": true, "class_name": "URLSpecReverseTest", "function_description": "Unit test method in URLSpecReverseTest that verifies correct URL path reconstruction from pattern arguments, ensuring accurate reversal of URL patterns with dynamic segments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_handlers", "line_number": 3131, "body": "def get_handlers(self):\n        return [\n            (\"/src\", WebRedirectHandler, {\"url\": \"/dst\"}),\n            (\"/src2\", WebRedirectHandler, {\"url\": \"/dst2?foo=bar\"}),\n            (r\"/(.*?)/(.*?)/(.*)\", WebRedirectHandler, {\"url\": \"/{1}/{0}/{2}\"}),\n        ]", "is_method": true, "class_name": "RedirectHandlerTest", "function_description": "Returns a list of URL patterns mapped to redirect handlers with target URLs, enabling testing of URL redirection logic with specific and parameterized routes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_basic_redirect", "line_number": 3138, "body": "def test_basic_redirect(self):\n        response = self.fetch(\"/src\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/dst\")", "is_method": true, "class_name": "RedirectHandlerTest", "function_description": "Tests that a request to \"/src\" responds with a 301 redirect pointing to \"/dst\", verifying the basic redirect behavior in the RedirectHandlerTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_redirect_with_argument", "line_number": 3143, "body": "def test_redirect_with_argument(self):\n        response = self.fetch(\"/src?foo=bar\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/dst?foo=bar\")", "is_method": true, "class_name": "RedirectHandlerTest", "function_description": "Unit test method in RedirectHandlerTest that verifies a URL redirect preserves query parameters and returns the correct HTTP 301 status code. It ensures redirects handle arguments correctly without following redirects automatically."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_redirect_with_appending_argument", "line_number": 3148, "body": "def test_redirect_with_appending_argument(self):\n        response = self.fetch(\"/src2?foo2=bar2\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/dst2?foo=bar&foo2=bar2\")", "is_method": true, "class_name": "RedirectHandlerTest", "function_description": "Unit test method in RedirectHandlerTest that verifies redirection appends query parameters correctly and returns a 301 status. It ensures the redirect location includes both original and appended arguments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "test_redirect_pattern", "line_number": 3153, "body": "def test_redirect_pattern(self):\n        response = self.fetch(\"/a/b/c\", follow_redirects=False)\n        self.assertEqual(response.code, 301)\n        self.assertEqual(response.headers[\"Location\"], \"/b/a/c\")", "is_method": true, "class_name": "RedirectHandlerTest", "function_description": "Test method verifying that a specific URL redirect pattern returns a 301 response with the expected location header, ensuring correct redirect behavior in the RedirectHandlerTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "describe", "line_number": 625, "body": "def describe(s):\n            if type(s) == bytes:\n                return [\"bytes\", native_str(binascii.b2a_hex(s))]\n            elif type(s) == unicode_type:\n                return [\"unicode\", s]\n            raise Exception(\"unknown type\")", "is_method": true, "class_name": "DecodeArgHandler", "function_description": "Utility method in DecodeArgHandler that identifies if input is bytes or Unicode, returning its type and a hex string for bytes; useful for handling and describing argument data types consistently."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "initialize", "line_number": 1513, "body": "def initialize(self, reply):\n            self.reply = reply", "is_method": true, "class_name": "Handler", "function_description": "Sets the reply attribute of the Handler instance to a given value, facilitating response management within the handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1516, "body": "def get(self):\n            self.write(self.reply)", "is_method": true, "class_name": "Handler", "function_description": "Handles HTTP GET requests by sending a predefined response stored in the handler\u2019s reply attribute. It serves as a simple response mechanism within a web request handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1608, "body": "def get(self):\n            self.set_header(\"h1\", \"foo\")\n            self.set_header(\"h2\", \"bar\")\n            self.clear_header(\"h1\")\n            self.clear_header(\"nonexistent\")", "is_method": true, "class_name": "Handler", "function_description": "Method in the Handler class that demonstrates setting and clearing HTTP headers, likely serving to manage or test header manipulation within a request-response cycle."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1622, "body": "def get(self):\n            self.set_status(204)\n            self.finish()", "is_method": true, "class_name": "Handler", "function_description": "Simple HTTP GET handler that responds with a 204 No Content status, indicating a successful request without returning any content. It can be used to acknowledge requests where no response body is needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1635, "body": "def get(self):\n            self.set_header(\"Content-Language\", \"en_US\")\n            self.write(\"hello\")", "is_method": true, "class_name": "Handler", "function_description": "Simple HTTP GET handler method that sets the response language to English and returns a greeting message. It provides a basic response mechanism for web requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1656, "body": "def get(self):\n            reason = self.request.arguments.get(\"reason\", [])\n            self.set_status(\n                int(self.get_argument(\"code\")),\n                reason=to_unicode(reason[0]) if reason else None,\n            )", "is_method": true, "class_name": "Handler", "function_description": "Sets the HTTP response status code and optional reason phrase based on request arguments, enabling customized client responses in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1684, "body": "def get(self):\n            self.write(\"hello\")", "is_method": true, "class_name": "Handler", "function_description": "Simple handler method that responds with a fixed greeting message, typically used to confirm server responsiveness or as a basic endpoint in a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1699, "body": "def get(self):\n            raise HTTPError(682, reason=\"Foo\")", "is_method": true, "class_name": "Handler", "function_description": "This Handler class method always raises a specific HTTP error with code 682 and reason \"Foo\". It provides a controlled way to signal a defined error condition during GET requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1740, "body": "def get(self):\n            for v in self.get_arguments(\"vary\"):\n                self.add_header(\"Vary\", v)\n            # Must write at least MIN_LENGTH bytes to activate compression.\n            self.write(\"hello world\" + (\"!\" * GZipContentEncoding.MIN_LENGTH))", "is_method": true, "class_name": "Handler", "function_description": "Handles HTTP GET requests by adding \"Vary\" headers from query parameters and writing a response that triggers compression based on a minimum length threshold. Useful for serving compressed content with customizable caching behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 1798, "body": "def prepare(self):\n            self.write(dict(args=self.path_args, kwargs=self.path_kwargs))", "is_method": true, "class_name": "Handler", "function_description": "Prepares and sends a response containing the handler's path arguments and keyword arguments. This function facilitates communication of request parameters within the Handler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1801, "body": "def get(self, path):\n            assert path == \"foo\"\n            self.finish()", "is_method": true, "class_name": "Handler", "function_description": "Handles a GET request for the specific path \"foo\" and completes the response without returning data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1823, "body": "def get(self):\n            self.clear_all_cookies()\n            self.write(\"ok\")", "is_method": true, "class_name": "Handler", "function_description": "Clears all cookies for the current session and responds with a simple confirmation message. This method is useful for resetting session state in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1845, "body": "def get(self):\n            exc = self.get_argument(\"exc\")\n            if exc == \"http\":\n                raise HTTPError(410, \"no longer here\")\n            elif exc == \"zero\":\n                1 / 0\n            elif exc == \"permission\":\n                raise PermissionError(\"not allowed\")", "is_method": true, "class_name": "Handler", "function_description": "Handles GET requests by raising specific exceptions based on a request argument, useful for testing error handling and response behaviors in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "write_error", "line_number": 1854, "body": "def write_error(self, status_code, **kwargs):\n            if \"exc_info\" in kwargs:\n                typ, value, tb = kwargs[\"exc_info\"]\n                if isinstance(value, PermissionError):\n                    self.set_status(403)\n                    self.write(\"PermissionError\")\n                    return\n            RequestHandler.write_error(self, status_code, **kwargs)", "is_method": true, "class_name": "Handler", "function_description": "Handles HTTP error responses by customizing the status and message specifically for permission errors; otherwise, delegates error handling to the standard method. Useful for providing clearer client feedback on authorization issues."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "log_exception", "line_number": 1863, "body": "def log_exception(self, typ, value, tb):\n            if isinstance(value, PermissionError):\n                app_log.warning(\"custom logging for PermissionError: %s\", value.args[0])\n            else:\n                RequestHandler.log_exception(self, typ, value, tb)", "is_method": true, "class_name": "Handler", "function_description": "Utility method in the Handler class that logs exceptions, providing custom handling for PermissionError while delegating all other exceptions to the standard logging mechanism. It enhances error tracking with specialized logging behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1911, "body": "def get(self):\n            self.render(\"foo.html\")", "is_method": true, "class_name": "Handler", "function_description": "Handles an HTTP GET request by rendering and returning the \"foo.html\" webpage. This method supports serving a specific webpage in a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "value", "line_number": 1914, "body": "def value(self):\n            return self.get_argument(\"value\")", "is_method": true, "class_name": "Handler", "function_description": "Returns the value of the \"value\" argument from the current request, providing easy access to this parameter within the Handler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "my_ui_method", "line_number": 1918, "body": "def my_ui_method(handler, x):\n            return \"In my_ui_method(%s) with handler value %s.\" % (x, handler.value())", "is_method": true, "class_name": "UIMethodUIModuleTest", "function_description": "This function formats and returns a descriptive string combining an input value and a property from a handler object. It provides a simple utility for generating informative status messages integrating handler state and input data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1953, "body": "def get(self):\n            try:\n                self.get_argument(\"foo\")\n                self.write({})\n            except MissingArgumentError as e:\n                self.write({\"arg_name\": e.arg_name, \"log_message\": e.log_message})", "is_method": true, "class_name": "Handler", "function_description": "Handles a GET request by attempting to retrieve the \"foo\" argument, responding with an empty dictionary if present or an error detail dictionary if the argument is missing. This method supports request validation and error reporting in a web handler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 1970, "body": "def prepare(self):\n            self.current_user = \"Ben\"\n            self.locale = locale.get(\"en_US\")", "is_method": true, "class_name": "Handler", "function_description": "Sets up initial user and locale settings for the Handler instance, establishing default context for subsequent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1980, "body": "def get(self):\n            self.write(\"Hello %s (%s)\" % (self.current_user, self.locale.code))", "is_method": true, "class_name": "Handler", "function_description": "Returns a greeting message including the current user's name and their locale code. This method can be used to personalize responses based on user and locale information."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "other", "line_number": 2097, "body": "def other(self):\n            # Even though this method exists, it won't get called automatically\n            # because it is not in SUPPORTED_METHODS.\n            self.write(\"other\")", "is_method": true, "class_name": "Handler", "function_description": "This method sends a fixed response \"other\" but is not automatically invoked due to class constraints, serving as an unused or auxiliary handler within the Handler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "method", "line_number": 2115, "body": "def method(self):\n            assert self.request.method is not None\n            self.write(self.request.method)", "is_method": true, "class_name": "Handler", "function_description": "Outputs the HTTP request method used in the current Handler instance, ensuring the method is present before responding. Useful for confirming or debugging the type of HTTP request received."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "patch", "line_number": 2138, "body": "def patch(self):\n            self.write(\"patch\")", "is_method": true, "class_name": "Handler", "function_description": "Simple HTTP handler method that responds to PATCH requests by returning the string \"patch\"."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "other", "line_number": 2141, "body": "def other(self):\n            self.write(\"other\")", "is_method": true, "class_name": "Handler", "function_description": "Simple utility method of the Handler class that outputs the string \"other\" as a response, likely serving as a basic placeholder or route handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 2155, "body": "def prepare(self):\n            self.finish(\"done\")", "is_method": true, "class_name": "Handler", "function_description": "Simple method in Handler that finalizes processing by signaling completion with a fixed \"done\" message."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2158, "body": "def get(self):\n            # It's difficult to assert for certain that a method did not\n            # or will not be called in an asynchronous context, but this\n            # will be logged noisily if it is reached.\n            raise Exception(\"should not reach this method\")", "is_method": true, "class_name": "Handler", "function_description": "Method in Handler class that intentionally raises an exception to signal it should never be called, typically serving as a guard against improper use or asynchronous invocation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2530, "body": "def get(self):\n            if self.request.version.startswith(\"HTTP/1\"):\n                # Simulate a connection closed by the client during\n                # request processing.  The client will see an error, but the\n                # server should respond gracefully (without logging errors\n                # because we were unable to write out as many bytes as\n                # Content-Length said we would)\n                self.request.connection.stream.close()  # type: ignore\n                self.write(\"hello\")\n            else:\n                # TODO: add a HTTP2-compatible version of this test.\n                self.write(\"requires HTTP/1.x\")", "is_method": true, "class_name": "Handler", "function_description": "Handles GET HTTP requests by closing the connection mid-response for HTTP/1.x clients to simulate client disconnection, or responds with a message requiring HTTP/1.x for other versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "validate", "line_number": 2627, "body": "def validate(prefix):\n            return b\"value\" == decode_signed_value(\n                SignedValueTest.SECRET, \"key\", prefix + sig, clock=self.present\n            )", "is_method": true, "class_name": "SignedValueTest", "function_description": "Validates whether a decoded signed value with a given prefix matches the expected byte string, ensuring data integrity and authenticity in the SignedValueTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "validate", "line_number": 2643, "body": "def validate(sig):\n            return b\"value\" == decode_signed_value(\n                SignedValueTest.SECRET, \"key\", prefix + sig, clock=self.present\n            )", "is_method": true, "class_name": "SignedValueTest", "function_description": "Validates a signed value by decoding and comparing it against an expected constant, ensuring the signature's integrity and authenticity within the SignedValueTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2723, "body": "def get(self):\n            version = int(self.get_argument(\"version\", \"2\"))\n            # This would be a bad idea in a real app, but in this test\n            # it's fine.\n            self.settings[\"xsrf_cookie_version\"] = version\n            self.write(self.xsrf_token)", "is_method": true, "class_name": "Handler", "function_description": "Handles HTTP GET requests by setting an XSRF cookie version based on a query parameter and returning the corresponding XSRF token."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "post", "line_number": 2730, "body": "def post(self):\n            self.write(\"ok\")", "is_method": true, "class_name": "Handler", "function_description": "Simple HTTP POST request handler method that responds with a fixed \"ok\" message, useful as a basic endpoint health check or acknowledgment in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2926, "body": "def get(self):\n            self.write(self.xsrf_token)", "is_method": true, "class_name": "Handler", "function_description": "Returns the current cross-site request forgery (XSRF) token to the client. This method supports security by providing the client with a token to validate future requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2952, "body": "def get(self):\n            self.set_status(401)\n            self.set_header(\"WWW-Authenticate\", 'Basic realm=\"something\"')\n            if self.get_argument(\"finish_value\", \"\"):\n                raise Finish(\"authentication required\")\n            else:\n                self.write(\"authentication required\")\n                raise Finish()", "is_method": true, "class_name": "Handler", "function_description": "Handler method that enforces HTTP Basic authentication by responding with a 401 status and appropriate headers, optionally signaling an authentication failure to terminate request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 3069, "body": "def get(self):\n            # remote_ip is optional, although it's set by\n            # both HTTPServer and WSGIAdapter.\n            # Clobber it to make sure it doesn't break logging.\n            self.request.remote_ip = None\n            self.finish(self._request_summary())", "is_method": true, "class_name": "Handler", "function_description": "Handles an HTTP GET request by clearing the remote IP attribute and returning a summary of the request. It provides a standardized response for GET requests, useful in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 229, "body": "def get(self):\n                test.final_return = self.finish()\n                yield test.final_return", "is_method": true, "class_name": "FinishHandler", "function_description": "Core method of the FinishHandler class that executes a finishing process and yields its result, allowing other functions to obtain the final output of that process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "post", "line_number": 234, "body": "def post(self):\n                self.write(\"hello,\")\n                yield self.flush()\n                test.final_return = self.finish(\"world\")\n                yield test.final_return", "is_method": true, "class_name": "FinishHandler", "function_description": "This method sends a partial response \"hello,\" immediately and then completes the response with \"world\". It manages asynchronous response writing and finalization in an HTTP request handler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "create_template_loader", "line_number": 241, "body": "def create_template_loader(self, path):\n                return DictLoader({\"foo.html\": \"hi\"})", "is_method": true, "class_name": "RenderHandler", "function_description": "Returns a simple template loader that serves predefined templates from a dictionary, facilitating quick template loading within the RenderHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 245, "body": "def get(self):\n                test.final_return = self.render(\"foo.html\")", "is_method": true, "class_name": "RenderHandler", "function_description": "Handles HTTP GET requests by rendering and returning the \"foo.html\" template, serving as a response in a web application context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 273, "body": "def get(self):\n                # Try setting cookies with different argument types\n                # to ensure that everything gets encoded correctly\n                self.set_cookie(\"str\", \"asdf\")\n                self.set_cookie(\"unicode\", u\"qwer\")\n                self.set_cookie(\"bytes\", b\"zxcv\")", "is_method": true, "class_name": "SetCookieHandler", "function_description": "Sets cookies with various data types to verify proper encoding and handling, ensuring robust cookie support across different input formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 281, "body": "def get(self):\n                cookie = self.get_cookie(\"foo\", \"default\")\n                assert cookie is not None\n                self.write(cookie)", "is_method": true, "class_name": "GetCookieHandler", "function_description": "Returns the value of the \"foo\" cookie from the request, defaulting to \"default\" if absent, and outputs it in the response. This method provides a simple way to access and return a specific cookie's value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 287, "body": "def get(self):\n                # unicode domain and path arguments shouldn't break things\n                # either (see bug #285)\n                self.set_cookie(\"unicode_args\", \"blah\", domain=u\"foo.com\", path=u\"/foo\")", "is_method": true, "class_name": "SetCookieDomainHandler", "function_description": "Sets a cookie with predefined unicode domain and path values to ensure proper handling of such arguments in HTTP responses. This method primarily tests cookie setting robustness with internationalized domain attributes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 293, "body": "def get(self):\n                self.set_cookie(\"equals\", \"a=b\")\n                self.set_cookie(\"semicolon\", \"a;b\")\n                self.set_cookie(\"quote\", 'a\"b')", "is_method": true, "class_name": "SetCookieSpecialCharHandler", "function_description": "Method of SetCookieSpecialCharHandler that sets cookies containing special characters, demonstrating handling of equals, semicolon, and quote symbols in cookie values. It can be used to verify or manage special character encoding in cookies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 299, "body": "def get(self):\n                self.set_cookie(\"a\", \"b\", domain=\"example.com\")\n                self.set_cookie(\"c\", \"d\", domain=\"example.com\")\n                # A second call with the same name clobbers the first.\n                # Attributes from the first call are not carried over.\n                self.set_cookie(\"a\", \"e\")", "is_method": true, "class_name": "SetCookieOverwriteHandler", "function_description": "Sets multiple cookies on the response, demonstrating that resetting a cookie with the same name overwrites the previous one without preserving prior attributes. This helps manage and update HTTP cookies effectively."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 307, "body": "def get(self):\n                self.set_cookie(\"foo\", \"bar\", max_age=10)", "is_method": true, "class_name": "SetCookieMaxAgeHandler", "function_description": "Sets a cookie named \"foo\" with value \"bar\" that expires after 10 seconds when handling a GET request. This method provides a simple demonstration of setting cookie max age in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 311, "body": "def get(self):\n                self.set_cookie(\"foo\", \"bar\", expires_days=10)", "is_method": true, "class_name": "SetCookieExpiresDaysHandler", "function_description": "Sets a cookie named \"foo\" with value \"bar\" that expires in 10 days. Useful for adding cookies with a defined lifespan in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 315, "body": "def get(self):\n                self.set_cookie(\"a\", \"1\", secure=True)\n                self.set_cookie(\"b\", \"1\", secure=False)\n                self.set_cookie(\"c\", \"1\", httponly=True)\n                self.set_cookie(\"d\", \"1\", httponly=False)", "is_method": true, "class_name": "SetCookieFalsyFlags", "function_description": "Sets multiple cookies with varied secure and httponly flags to demonstrate or test cookie attribute behaviors in HTTP responses. This method provides a way to handle cookie flag configurations in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1000, "body": "def get(self):\n                if self.get_argument(\"status\", None):\n                    raise HTTPError(int(self.get_argument(\"status\")))\n                1 / 0", "is_method": true, "class_name": "DefaultHandler", "function_description": "Method in DefaultHandler that triggers an HTTP error based on a given status argument or raises a division error if no status is provided, primarily for testing error handling behaviors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1006, "body": "def get(self):\n                if self.get_argument(\"status\", None):\n                    self.send_error(int(self.get_argument(\"status\")))\n                else:\n                    1 / 0", "is_method": true, "class_name": "WriteErrorHandler", "function_description": "Handles an HTTP GET request by sending a specified error status if provided, or triggering a server error if not, supporting custom error responses in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "write_error", "line_number": 1012, "body": "def write_error(self, status_code, **kwargs):\n                self.set_header(\"Content-Type\", \"text/plain\")\n                if \"exc_info\" in kwargs:\n                    self.write(\"Exception: %s\" % kwargs[\"exc_info\"][0].__name__)\n                else:\n                    self.write(\"Status: %d\" % status_code)", "is_method": true, "class_name": "WriteErrorHandler", "function_description": "Core utility of WriteErrorHandler that outputs a plain-text error message based on the status code or exception info, facilitating standardized error responses in HTTP handling contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "write_error", "line_number": 1023, "body": "def write_error(self, status_code, **kwargs):\n                raise Exception(\"exception in write_error\")", "is_method": true, "class_name": "FailedWriteErrorHandler", "function_description": "Raises a generic exception to indicate a failure occurred during a write error handling process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1074, "body": "def get(self, path):\n                with_v = int(self.get_argument(\"include_version\", \"1\"))\n                self.write(self.static_url(path, include_version=with_v))", "is_method": true, "class_name": "StaticUrlHandler", "function_description": "Method of StaticUrlHandler that returns a static URL for a given path, optionally including a version parameter based on a query argument for cache control or resource versioning."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1082, "body": "def get(self, path):\n                do_include = bool(self.get_argument(\"include_host\"))\n                self.include_host = not do_include\n\n                regular_url = self.static_url(path)\n                override_url = self.static_url(path, include_host=do_include)\n                if override_url == regular_url:\n                    return self.write(str(False))\n\n                protocol = self.request.protocol + \"://\"\n                protocol_length = len(protocol)\n                check_regular = regular_url.find(protocol, 0, protocol_length)\n                check_override = override_url.find(protocol, 0, protocol_length)\n\n                if do_include:\n                    result = check_override == 0 and check_regular == -1\n                else:\n                    result = check_override == -1 and check_regular == 0\n                self.write(str(result))", "is_method": true, "class_name": "OverrideStaticUrlHandler", "function_description": "Checks if the static URL for a given path differs when including the host, indicating whether an override URL with the host is distinct from the regular one. Useful for verifying URL variations based on host inclusion settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "make_static_url", "line_number": 1448, "body": "def make_static_url(cls, settings, path):\n                version_hash = cls.get_version(settings, path)\n                extension_index = path.rindex(\".\")\n                before_version = path[:extension_index]\n                after_version = path[(extension_index + 1) :]\n                return \"/static/%s.%s.%s\" % (\n                    before_version,\n                    version_hash,\n                    after_version,\n                )", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Generates a versioned URL for a static file by inserting a version hash into its pathname, ensuring clients receive the correct cached file. Useful for cache busting in web applications serving static assets."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "parse_url_path", "line_number": 1459, "body": "def parse_url_path(self, url_path):\n                extension_index = url_path.rindex(\".\")\n                version_index = url_path.rindex(\".\", 0, extension_index)\n                return \"%s%s\" % (url_path[:version_index], url_path[extension_index:])", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Method of MyStaticFileHandler that extracts the base file path by removing versioning information between the last two dots in a URL path, useful for resolving and serving static files without version suffixes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_absolute_path", "line_number": 1465, "body": "def get_absolute_path(cls, settings, path):\n                return \"CustomStaticFileTest:\" + path", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Returns a custom absolute file path by prefixing the given path, providing a simplified way to generate static file paths within the MyStaticFileHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "validate_absolute_path", "line_number": 1468, "body": "def validate_absolute_path(self, root, absolute_path):\n                return absolute_path", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "This method returns the given absolute path without modifications, potentially serving as a placeholder for path validation within the MyStaticFileHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_content", "line_number": 1472, "body": "def get_content(self, path, start=None, end=None):\n                assert start is None and end is None\n                if path == \"CustomStaticFileTest:foo.txt\":\n                    return b\"bar\"\n                raise Exception(\"unexpected path %r\" % path)", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Returns fixed content for a specific test file path; raises an exception for any other path requests. This method provides a controlled static file response useful for testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_content_size", "line_number": 1478, "body": "def get_content_size(self):\n                if self.absolute_path == \"CustomStaticFileTest:foo.txt\":\n                    return 3\n                raise Exception(\"unexpected path %r\" % self.absolute_path)", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Returns the content size for a specific static file path, supporting fixed-size retrieval for that file and raising an error for unexpected paths."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_modified_time", "line_number": 1483, "body": "def get_modified_time(self):\n                return None", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Returns None as a placeholder for retrieving the last modified time of a static file; currently not implemented in MyStaticFileHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_version", "line_number": 1487, "body": "def get_version(cls, settings, path):\n                return \"42\"", "is_method": true, "class_name": "MyStaticFileHandler", "function_description": "Returns a fixed version string \"42\" regardless of input, providing a simple versioning service for static file handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1491, "body": "def get(self, path):\n                self.write(self.static_url(path))", "is_method": true, "class_name": "StaticUrlHandler", "function_description": "Simple handler method in StaticUrlHandler that responds to a GET request by returning the full static URL for a given resource path."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 1590, "body": "def get(self, path):\n                self.write(path)", "is_method": true, "class_name": "EchoHandler", "function_description": "Simple request handler method that responds by echoing back the requested path, useful for verifying routing or debugging URL paths in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "render", "line_number": 1922, "body": "def render(self, x):\n                return \"In MyModule(%s) with handler value %s.\" % (\n                    x,\n                    typing.cast(UIMethodUIModuleTest.Handler, self.handler).value(),\n                )", "is_method": true, "class_name": "MyModule", "function_description": "Returns a formatted string describing the given input alongside the current handler's value within the MyModule instance. It provides a simple way to represent module state related to the handler and an input parameter."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "render", "line_number": 1997, "body": "def render(self):\n                return str(self.current_user)", "is_method": true, "class_name": "WithUserModule", "function_description": "Returns the string representation of the current user managed by the WithUserModule class. This method provides a simple way to display or log user information."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 2022, "body": "def prepare(self):\n                self.has_loaded_current_user = False", "is_method": true, "class_name": "CurrentUserHandler", "function_description": "Resets the handler's state by marking that the current user data has not been loaded yet, preparing for fresh user information retrieval or processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_current_user", "line_number": 2025, "body": "def get_current_user(self):\n                self.has_loaded_current_user = True\n                return \"\"", "is_method": true, "class_name": "CurrentUserHandler", "function_description": "Returns an empty string while marking that the current user data has been loaded."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2030, "body": "def get(self):\n                self.render_string(\"without_user.html\")\n                self.finish(str(self.has_loaded_current_user))", "is_method": true, "class_name": "WithoutUserHandler", "function_description": "Renders a specified HTML template and returns the loading status of the current user. This function supports responses in scenarios where user authentication might not be required or available."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2035, "body": "def get(self):\n                self.render_string(\"with_user.html\")\n                self.finish(str(self.has_loaded_current_user))", "is_method": true, "class_name": "WithUserHandler", "function_description": "Renders a HTML template and returns a string indicating whether the current user data has finished loading. This method provides a simple user load status check via a web response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get_template_namespace", "line_number": 2040, "body": "def get_template_namespace(self):\n                # If RequestHandler.get_template_namespace is called, then\n                # get_current_user is evaluated. Until #820 is fixed, this\n                # is a small hack to circumvent the issue.\n                return self.ui", "is_method": true, "class_name": "CurrentUserModuleHandler", "function_description": "Returns the UI namespace for template rendering, serving as a workaround to avoid evaluating the current user during template context setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2047, "body": "def get(self):\n                self.render_string(\"without_user_module.html\")\n                self.finish(str(self.has_loaded_current_user))", "is_method": true, "class_name": "WithoutUserModuleHandler", "function_description": "Renders a specific HTML page and responds with the status indicating whether the current user data has been loaded, supporting web request handling in user-related workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2052, "body": "def get(self):\n                self.render_string(\"with_user_module.html\")\n                self.finish(str(self.has_loaded_current_user))", "is_method": true, "class_name": "WithUserModuleHandler", "function_description": "Renders a specific HTML template and responds with the loaded user status, providing a simple interface to check if the current user data is available."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2190, "body": "def get(self):\n                self.set_status(404)\n                self.write(\"custom 404 response\")", "is_method": true, "class_name": "Custom404Handler", "function_description": "Core handler method of Custom404Handler that sets the HTTP response status to 404 and writes a custom message, providing a tailored response for not found errors in a web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 2242, "body": "def prepare(self):\n                self.test.prepared.set_result(None)", "is_method": true, "class_name": "StreamingBodyHandler", "function_description": "Triggers the completion of a preparation event, signaling that a required setup step has finished in the StreamingBodyHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "data_received", "line_number": 2245, "body": "def data_received(self, data):\n                self.test.data.set_result(data)", "is_method": true, "class_name": "StreamingBodyHandler", "function_description": "Method in StreamingBodyHandler that captures incoming data chunks and delivers them to a designated future or promise for further processing or testing purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2248, "body": "def get(self):\n                self.test.finished.set_result(None)\n                self.write({})", "is_method": true, "class_name": "StreamingBodyHandler", "function_description": "Completes a streaming operation by signaling its end and sending an empty response. Useful for indicating that no more data will be sent in a streaming context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "prepare", "line_number": 2254, "body": "def prepare(self):\n                # If we finish the response in prepare, it won't continue to\n                # the (non-existent) data_received.\n                raise HTTPError(401)", "is_method": true, "class_name": "EarlyReturnHandler", "function_description": "This method immediately terminates processing by raising an HTTP 401 error, preventing further data handling. It ensures early response completion, typically for unauthorized access cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "on_connection_close", "line_number": 2264, "body": "def on_connection_close(self):\n                super().on_connection_close()\n                self.test.close_future.set_result(None)", "is_method": true, "class_name": "CloseDetectionHandler", "function_description": "Handles cleanup and signaling when a connection closes, ensuring any awaiting processes tied to the closure are properly notified."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "data_received", "line_number": 2448, "body": "def data_received(self, data):\n                with self.in_method(\"data_received\"):\n                    yield gen.moment", "is_method": true, "class_name": "DecoratedFlowControlHandler", "function_description": "This method placeholder in DecoratedFlowControlHandler is intended to handle incoming data events asynchronously but currently does not process data and yields control momentarily."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2476, "body": "def get(self):\n                self.set_header(\"Content-Length\", \"42\")\n                try:\n                    self.finish(\"ok\")\n                except Exception as e:\n                    test.server_error = e\n                    raise", "is_method": true, "class_name": "TooHigh", "function_description": "Method in TooHigh class that sets a fixed Content-Length header and attempts to complete an HTTP response with \"ok\", while capturing and re-raising any exceptions during this process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 2485, "body": "def get(self):\n                self.set_header(\"Content-Length\", \"2\")\n                try:\n                    self.finish(\"hello\")\n                except Exception as e:\n                    test.server_error = e\n                    raise", "is_method": true, "class_name": "TooLow", "function_description": "Method of the TooLow class that sends a simple \"hello\" response with a fixed content length, handling exceptions by recording server errors for diagnostic purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "get", "line_number": 3007, "body": "def get(self, computed_etag):\n                self.write(computed_etag)", "is_method": true, "class_name": "EtagHandler", "function_description": "Utility method in EtagHandler that outputs the provided computed ETag value, typically used for HTTP caching and resource validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/web_test.py", "function": "compute_etag", "line_number": 3010, "body": "def compute_etag(self):\n                return self._write_buffer[0]", "is_method": true, "class_name": "EtagHandler", "function_description": "Returns the current ETag value from the internal write buffer. This method provides a way to access the resource's version identifier for cache validation or change detection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/autoreload_test.py", "function": "setUp", "line_number": 12, "body": "def setUp(self):\n        self.path = mkdtemp()", "is_method": true, "class_name": "AutoreloadTest", "function_description": "Setup method for AutoreloadTest that creates a temporary directory path for test use, ensuring isolated filesystem environment during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/autoreload_test.py", "function": "tearDown", "line_number": 15, "body": "def tearDown(self):\n        try:\n            shutil.rmtree(self.path)\n        except OSError:\n            # Windows disallows deleting files that are in use by\n            # another process, and even though we've waited for our\n            # child process below, it appears that its lock on these\n            # files is not guaranteed to be released by this point.\n            # Sleep and try again (once).\n            time.sleep(1)\n            shutil.rmtree(self.path)", "is_method": true, "class_name": "AutoreloadTest", "function_description": "Cleans up by deleting the specified directory after a test, retrying once on failure to handle file locks typically encountered on Windows systems."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/autoreload_test.py", "function": "test_reload_module", "line_number": 27, "body": "def test_reload_module(self):\n        main = \"\"\"\\\nimport os\nimport sys\n\nfrom tornado import autoreload\n\n# This import will fail if path is not set up correctly\nimport testapp\n\nprint('Starting')\nif 'TESTAPP_STARTED' not in os.environ:\n    os.environ['TESTAPP_STARTED'] = '1'\n    sys.stdout.flush()\n    autoreload._reload()\n\"\"\"\n\n        # Create temporary test application\n        os.mkdir(os.path.join(self.path, \"testapp\"))\n        open(os.path.join(self.path, \"testapp/__init__.py\"), \"w\").close()\n        with open(os.path.join(self.path, \"testapp/__main__.py\"), \"w\") as f:\n            f.write(main)\n\n        # Make sure the tornado module under test is available to the test\n        # application\n        pythonpath = os.getcwd()\n        if \"PYTHONPATH\" in os.environ:\n            pythonpath += os.pathsep + os.environ[\"PYTHONPATH\"]\n\n        p = Popen(\n            [sys.executable, \"-m\", \"testapp\"],\n            stdout=subprocess.PIPE,\n            cwd=self.path,\n            env=dict(os.environ, PYTHONPATH=pythonpath),\n            universal_newlines=True,\n        )\n        out = p.communicate()[0]\n        self.assertEqual(out, \"Starting\\nStarting\\n\")", "is_method": true, "class_name": "AutoreloadTest", "function_description": "Method of the AutoreloadTest class that verifies automatic module reloading works by running a temporary test application and confirming it restarts as expected. It ensures autoreload triggers correctly during app execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/autoreload_test.py", "function": "test_reload_wrapper_preservation", "line_number": 66, "body": "def test_reload_wrapper_preservation(self):\n        # This test verifies that when `python -m tornado.autoreload`\n        # is used on an application that also has an internal\n        # autoreload, the reload wrapper is preserved on restart.\n        main = \"\"\"\\\nimport os\nimport sys\n\n# This import will fail if path is not set up correctly\nimport testapp\n\nif 'tornado.autoreload' not in sys.modules:\n    raise Exception('started without autoreload wrapper')\n\nimport tornado.autoreload\n\nprint('Starting')\nsys.stdout.flush()\nif 'TESTAPP_STARTED' not in os.environ:\n    os.environ['TESTAPP_STARTED'] = '1'\n    # Simulate an internal autoreload (one not caused\n    # by the wrapper).\n    tornado.autoreload._reload()\nelse:\n    # Exit directly so autoreload doesn't catch it.\n    os._exit(0)\n\"\"\"\n\n        # Create temporary test application\n        os.mkdir(os.path.join(self.path, \"testapp\"))\n        init_file = os.path.join(self.path, \"testapp\", \"__init__.py\")\n        open(init_file, \"w\").close()\n        main_file = os.path.join(self.path, \"testapp\", \"__main__.py\")\n        with open(main_file, \"w\") as f:\n            f.write(main)\n\n        # Make sure the tornado module under test is available to the test\n        # application\n        pythonpath = os.getcwd()\n        if \"PYTHONPATH\" in os.environ:\n            pythonpath += os.pathsep + os.environ[\"PYTHONPATH\"]\n\n        autoreload_proc = Popen(\n            [sys.executable, \"-m\", \"tornado.autoreload\", \"-m\", \"testapp\"],\n            stdout=subprocess.PIPE,\n            cwd=self.path,\n            env=dict(os.environ, PYTHONPATH=pythonpath),\n            universal_newlines=True,\n        )\n\n        # This timeout needs to be fairly generous for pypy due to jit\n        # warmup costs.\n        for i in range(40):\n            if autoreload_proc.poll() is not None:\n                break\n            time.sleep(0.1)\n        else:\n            autoreload_proc.kill()\n            raise Exception(\"subprocess failed to terminate\")\n\n        out = autoreload_proc.communicate()[0]\n        self.assertEqual(out, \"Starting\\n\" * 2)", "is_method": true, "class_name": "AutoreloadTest", "function_description": "Function test_reload_wrapper_preservation validates that the Tornado autoreload wrapper persists correctly during application restarts when internal autoreloads occur. It ensures reliable autoreload behavior in applications using Tornado's reload mechanism."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_server_ssl_options", "line_number": 42, "body": "def _server_ssl_options():\n    return dict(\n        certfile=os.path.join(os.path.dirname(__file__), \"test.crt\"),\n        keyfile=os.path.join(os.path.dirname(__file__), \"test.key\"),\n    )", "is_method": false, "function_description": "This function provides SSL configuration options specifying the certificate and key file paths, supporting secure server communication setups that require TLS encryption."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "get", "line_number": 50, "body": "def get(self):\n        self.write(\"Hello\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Simple method of the HelloHandler class that responds to GET requests by sending a \"Hello\" message, typically used to confirm the server is reachable or operational."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "get_app", "line_number": 58, "body": "def get_app(self):\n        return Application([(\"/\", HelloHandler)])", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Returns a web application instance configured with a default route handler, providing the base application setup for web request handling within the TestIOStreamWebMixin context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_connection_closed", "line_number": 61, "body": "def test_connection_closed(self: typing.Any):\n        # When a server sends a response and then closes the connection,\n        # the client must be allowed to read the data before the IOStream\n        # closes itself.  Epoll reports closed connections with a separate\n        # EPOLLRDHUP event delivered at the same time as the read event,\n        # while kqueue reports them as a second read/write event with an EOF\n        # flag.\n        response = self.fetch(\"/\", headers={\"Connection\": \"close\"})\n        response.rethrow()", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Tests that a client can correctly receive and process a server response before the connection closes, ensuring proper handling of connection closure events in asynchronous IO streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_close", "line_number": 72, "body": "def test_read_until_close(self: typing.Any):\n        stream = self._make_client_iostream()\n        yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n\n        data = yield stream.read_until_close()\n        self.assertTrue(data.startswith(b\"HTTP/1.1 200\"))\n        self.assertTrue(data.endswith(b\"Hello\"))", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "TestIOStreamWebMixin method that verifies reading from a client IO stream until it closes, ensuring the server response starts with a valid HTTP status and ends with expected content. Useful for testing HTTP communication over streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_zero_bytes", "line_number": 82, "body": "def test_read_zero_bytes(self: typing.Any):\n        self.stream = self._make_client_iostream()\n        yield self.stream.connect((\"127.0.0.1\", self.get_http_port()))\n        self.stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n\n        # normal read\n        data = yield self.stream.read_bytes(9)\n        self.assertEqual(data, b\"HTTP/1.1 \")\n\n        # zero bytes\n        data = yield self.stream.read_bytes(0)\n        self.assertEqual(data, b\"\")\n\n        # another normal read\n        data = yield self.stream.read_bytes(3)\n        self.assertEqual(data, b\"200\")\n\n        self.stream.close()", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Tests that reading zero bytes from an IO stream returns an empty result without affecting subsequent reads, ensuring correct stream read behavior for zero-length read operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_write_while_connecting", "line_number": 102, "body": "def test_write_while_connecting(self: typing.Any):\n        stream = self._make_client_iostream()\n        connect_fut = stream.connect((\"127.0.0.1\", self.get_http_port()))\n        # unlike the previous tests, try to write before the connection\n        # is complete.\n        write_fut = stream.write(b\"GET / HTTP/1.0\\r\\nConnection: close\\r\\n\\r\\n\")\n        self.assertFalse(connect_fut.done())\n\n        # connect will always complete before write.\n        it = gen.WaitIterator(connect_fut, write_fut)\n        resolved_order = []\n        while not it.done():\n            yield it.next()\n            resolved_order.append(it.current_future)\n        self.assertEqual(resolved_order, [connect_fut, write_fut])\n\n        data = yield stream.read_until_close()\n        self.assertTrue(data.endswith(b\"Hello\"))\n\n        stream.close()", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Tests the ability of a client IO stream to handle writes initiated before the connection is fully established, verifying correct operation order and response retrieval. It validates asynchronous connection and data handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_interface", "line_number": 124, "body": "def test_future_interface(self: typing.Any):\n        \"\"\"Basic test of IOStream's ability to return Futures.\"\"\"\n        stream = self._make_client_iostream()\n        connect_result = yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        self.assertIs(connect_result, stream)\n        yield stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n        first_line = yield stream.read_until(b\"\\r\\n\")\n        self.assertEqual(first_line, b\"HTTP/1.1 200 OK\\r\\n\")\n        # callback=None is equivalent to no callback.\n        header_data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n        headers = HTTPHeaders.parse(header_data.decode(\"latin1\"))\n        content_length = int(headers[\"Content-Length\"])\n        body = yield stream.read_bytes(content_length)\n        self.assertEqual(body, b\"Hello\")\n        stream.close()", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Core test method in TestIOStreamWebMixin that verifies IOStream's asynchronous interface correctly handles connection, writing, reading HTTP response headers and body using Futures."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_close_while_reading", "line_number": 141, "body": "def test_future_close_while_reading(self: typing.Any):\n        stream = self._make_client_iostream()\n        yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        yield stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n        with self.assertRaises(StreamClosedError):\n            yield stream.read_bytes(1024 * 1024)\n        stream.close()", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Tests that the client IO stream raises a StreamClosedError if it is closed while reading data, ensuring proper error handling during asynchronous HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_read_until_close", "line_number": 150, "body": "def test_future_read_until_close(self: typing.Any):\n        # Ensure that the data comes through before the StreamClosedError.\n        stream = self._make_client_iostream()\n        yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        yield stream.write(b\"GET / HTTP/1.0\\r\\nConnection: close\\r\\n\\r\\n\")\n        yield stream.read_until(b\"\\r\\n\\r\\n\")\n        body = yield stream.read_until_close()\n        self.assertEqual(body, b\"Hello\")\n\n        # Nothing else to read; the error comes immediately without waiting\n        # for yield.\n        with self.assertRaises(StreamClosedError):\n            stream.read_bytes(1)", "is_method": true, "class_name": "TestIOStreamWebMixin", "function_description": "Tests that a client IO stream correctly reads data until closure and raises an error if reading is attempted after the stream closes. It ensures proper handling of streamed HTTP responses in asynchronous contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "iostream_pair", "line_number": 172, "body": "def iostream_pair(self, **kwargs):\n        \"\"\"Like make_iostream_pair, but called by ``async with``.\n\n        In py37 this becomes simpler with contextlib.asynccontextmanager.\n        \"\"\"\n\n        class IOStreamPairContext:\n            def __init__(self, test, kwargs):\n                self.test = test\n                self.kwargs = kwargs\n\n            async def __aenter__(self):\n                self.pair = await self.test.make_iostream_pair(**self.kwargs)\n                return self.pair\n\n            async def __aexit__(self, typ, value, tb):\n                for s in self.pair:\n                    s.close()\n\n        return IOStreamPairContext(self, kwargs)", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Provides an asynchronous context manager that creates and manages a paired IO stream for use within an async with block, ensuring proper setup and cleanup of the streams during testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_write_zero_bytes", "line_number": 194, "body": "def test_write_zero_bytes(self):\n        # Attempting to write zero bytes should run the callback without\n        # going into an infinite loop.\n        rs, ws = yield self.make_iostream_pair()\n        yield ws.write(b\"\")\n        ws.close()\n        rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests that writing zero bytes triggers the write callback correctly without causing an infinite loop, ensuring proper handling of empty write operations in stream I/O."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_delayed_close_callback", "line_number": 203, "body": "def test_future_delayed_close_callback(self: typing.Any):\n        # Same as test_delayed_close_callback, but with the future interface.\n        rs, ws = yield self.make_iostream_pair()\n\n        try:\n            ws.write(b\"12\")\n            chunks = []\n            chunks.append((yield rs.read_bytes(1)))\n            ws.close()\n            chunks.append((yield rs.read_bytes(1)))\n            self.assertEqual(chunks, [b\"1\", b\"2\"])\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Test method in TestReadWriteMixin that verifies correct reading of bytes from a stream using a future-based asynchronous interface, ensuring data is received fully before closure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_close_buffered_data", "line_number": 219, "body": "def test_close_buffered_data(self: typing.Any):\n        # Similar to the previous test, but with data stored in the OS's\n        # socket buffers instead of the IOStream's read buffer.  Out-of-band\n        # close notifications must be delayed until all data has been\n        # drained into the IOStream buffer. (epoll used to use out-of-band\n        # close events with EPOLLRDHUP, but no longer)\n        #\n        # This depends on the read_chunk_size being smaller than the\n        # OS socket buffer, so make it small.\n        rs, ws = yield self.make_iostream_pair(read_chunk_size=256)\n        try:\n            ws.write(b\"A\" * 512)\n            data = yield rs.read_bytes(256)\n            self.assertEqual(b\"A\" * 256, data)\n            ws.close()\n            # Allow the close to propagate to the `rs` side of the\n            # connection.  Using add_callback instead of add_timeout\n            # doesn't seem to work, even with multiple iterations\n            yield gen.sleep(0.01)\n            data = yield rs.read_bytes(256)\n            self.assertEqual(b\"A\" * 256, data)\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Test method validating that socket-buffered data is fully read before a close notification propagates, ensuring proper handling of out-of-band close events in asynchronous IO stream operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_close_after_close", "line_number": 245, "body": "def test_read_until_close_after_close(self: typing.Any):\n        # Similar to test_delayed_close_callback, but read_until_close takes\n        # a separate code path so test it separately.\n        rs, ws = yield self.make_iostream_pair()\n        try:\n            ws.write(b\"1234\")\n            # Read one byte to make sure the client has received the data.\n            # It won't run the close callback as long as there is more buffered\n            # data that could satisfy a later read.\n            data = yield rs.read_bytes(1)\n            ws.close()\n            self.assertEqual(data, b\"1\")\n            data = yield rs.read_until_close()\n            self.assertEqual(data, b\"234\")\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Provides a test to verify that reading from a stream using read_until_close correctly returns all remaining data after the stream is closed. It ensures proper handling of buffered data and closure in asynchronous I/O streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_large_read_until", "line_number": 264, "body": "def test_large_read_until(self: typing.Any):\n        # Performance test: read_until used to have a quadratic component\n        # so a read_until of 4MB would take 8 seconds; now it takes 0.25\n        # seconds.\n        rs, ws = yield self.make_iostream_pair()\n        try:\n            # This test fails on pypy with ssl.  I think it's because\n            # pypy's gc defeats moves objects, breaking the\n            # \"frozen write buffer\" assumption.\n            if (\n                isinstance(rs, SSLIOStream)\n                and platform.python_implementation() == \"PyPy\"\n            ):\n                raise unittest.SkipTest(\"pypy gc causes problems with openssl\")\n            NUM_KB = 4096\n            for i in range(NUM_KB):\n                ws.write(b\"A\" * 1024)\n            ws.write(b\"\\r\\n\")\n            data = yield rs.read_until(b\"\\r\\n\")\n            self.assertEqual(len(data), NUM_KB * 1024 + 2)\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests the performance and correctness of reading a large amount of data until a delimiter, ensuring the read_until method handles large buffers efficiently without performance degradation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_close_callback_with_pending_read", "line_number": 327, "body": "def test_close_callback_with_pending_read(self: typing.Any):\n        # Regression test for a bug that was introduced in 2.3\n        # where the IOStream._close_callback would never be called\n        # if there were pending reads.\n        OK = b\"OK\\r\\n\"\n        rs, ws = yield self.make_iostream_pair()\n        event = Event()\n        rs.set_close_callback(event.set)\n        try:\n            ws.write(OK)\n            res = yield rs.read_until(b\"\\r\\n\")\n            self.assertEqual(res, OK)\n\n            ws.close()\n            rs.read_until(b\"\\r\\n\")\n            # If _close_callback (self.stop) is not called,\n            # an AssertionError: Async operation timed out after 5 seconds\n            # will be raised.\n            yield event.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that the IOStream's close callback is invoked correctly even with pending read operations, ensuring proper cleanup and preventing timeouts during asynchronous I/O shutdown."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_close_callback", "line_number": 351, "body": "def test_future_close_callback(self: typing.Any):\n        # Regression test for interaction between the Future read interfaces\n        # and IOStream._maybe_add_error_listener.\n        rs, ws = yield self.make_iostream_pair()\n        closed = [False]\n        cond = Condition()\n\n        def close_callback():\n            closed[0] = True\n            cond.notify()\n\n        rs.set_close_callback(close_callback)\n        try:\n            ws.write(b\"a\")\n            res = yield rs.read_bytes(1)\n            self.assertEqual(res, b\"a\")\n            self.assertFalse(closed[0])\n            ws.close()\n            yield cond.wait()\n            self.assertTrue(closed[0])\n        finally:\n            rs.close()\n            ws.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that a close callback is properly triggered when a write-end closes, ensuring correct interaction between future read operations and IO stream error listeners. It supports reliable asynchronous stream handling in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_write_memoryview", "line_number": 376, "body": "def test_write_memoryview(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        try:\n            fut = rs.read_bytes(4)\n            ws.write(memoryview(b\"hello\"))\n            data = yield fut\n            self.assertEqual(data, b\"hell\")\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests the ability to write data using a memoryview and read a specific number of bytes, verifying correct data transmission between paired I/O streams. Useful for ensuring memory-efficient byte-level I/O operations work as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_bytes_partial", "line_number": 388, "body": "def test_read_bytes_partial(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        try:\n            # Ask for more than is available with partial=True\n            fut = rs.read_bytes(50, partial=True)\n            ws.write(b\"hello\")\n            data = yield fut\n            self.assertEqual(data, b\"hello\")\n\n            # Ask for less than what is available; num_bytes is still\n            # respected.\n            fut = rs.read_bytes(3, partial=True)\n            ws.write(b\"world\")\n            data = yield fut\n            self.assertEqual(data, b\"wor\")\n\n            # Partial reads won't return an empty string, but read_bytes(0)\n            # will.\n            data = yield rs.read_bytes(0, partial=True)\n            self.assertEqual(data, b\"\")\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests partial byte-reading behavior from a stream, confirming it returns available data without waiting for the full requested amount. Useful for validating non-blocking or incremental data reads in I/O stream implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_max_bytes", "line_number": 413, "body": "def test_read_until_max_bytes(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Extra room under the limit\n            fut = rs.read_until(b\"def\", max_bytes=50)\n            ws.write(b\"abcdef\")\n            data = yield fut\n            self.assertEqual(data, b\"abcdef\")\n\n            # Just enough space\n            fut = rs.read_until(b\"def\", max_bytes=6)\n            ws.write(b\"abcdef\")\n            data = yield fut\n            self.assertEqual(data, b\"abcdef\")\n\n            # Not enough space, but we don't know it until all we can do is\n            # log a warning and close the connection.\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                fut = rs.read_until(b\"def\", max_bytes=5)\n                ws.write(b\"123456\")\n                yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests that reading from a stream until a specified delimiter respects a maximum byte limit, verifying correct behavior when data fits within, exactly matches, or exceeds that limit."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_max_bytes_inline", "line_number": 441, "body": "def test_read_until_max_bytes_inline(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Similar to the error case in the previous test, but the\n            # ws writes first so rs reads are satisfied\n            # inline.  For consistency with the out-of-line case, we\n            # do not raise the error synchronously.\n            ws.write(b\"123456\")\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                with self.assertRaises(StreamClosedError):\n                    yield rs.read_until(b\"def\", max_bytes=5)\n            yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that reading from a stream halts with an error if the desired delimiter isn't found within a given byte limit. It ensures proper handling of unsatisfiable read requests with inline writes in asynchronous streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_max_bytes_ignores_extra", "line_number": 460, "body": "def test_read_until_max_bytes_ignores_extra(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Even though data that matches arrives the same packet that\n            # puts us over the limit, we fail the request because it was not\n            # found within the limit.\n            ws.write(b\"abcdef\")\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                rs.read_until(b\"def\", max_bytes=5)\n                yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Provides a test that verifies reading until a delimiter respects a maximum byte limit by failing if the delimiter isn't found within that limit, ensuring correct behavior for constrained reads in stream handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_regex_max_bytes", "line_number": 477, "body": "def test_read_until_regex_max_bytes(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Extra room under the limit\n            fut = rs.read_until_regex(b\"def\", max_bytes=50)\n            ws.write(b\"abcdef\")\n            data = yield fut\n            self.assertEqual(data, b\"abcdef\")\n\n            # Just enough space\n            fut = rs.read_until_regex(b\"def\", max_bytes=6)\n            ws.write(b\"abcdef\")\n            data = yield fut\n            self.assertEqual(data, b\"abcdef\")\n\n            # Not enough space, but we don't know it until all we can do is\n            # log a warning and close the connection.\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                rs.read_until_regex(b\"def\", max_bytes=5)\n                ws.write(b\"123456\")\n                yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that reading from a stream with a regex pattern respects the max_bytes limit, correctly returns data when possible, and properly handles cases where the limit is exceeded by closing the connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_regex_max_bytes_inline", "line_number": 505, "body": "def test_read_until_regex_max_bytes_inline(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Similar to the error case in the previous test, but the\n            # ws writes first so rs reads are satisfied\n            # inline.  For consistency with the out-of-line case, we\n            # do not raise the error synchronously.\n            ws.write(b\"123456\")\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                rs.read_until_regex(b\"def\", max_bytes=5)\n                yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests reading from a stream until a regex pattern or max byte limit is reached, verifying that an unsatisfiable read triggers the expected behavior without raising synchronous errors. Useful for ensuring correct stream read handling in async I/O."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_regex_max_bytes_ignores_extra", "line_number": 523, "body": "def test_read_until_regex_max_bytes_ignores_extra(self):\n        rs, ws = yield self.make_iostream_pair()\n        closed = Event()\n        rs.set_close_callback(closed.set)\n        try:\n            # Even though data that matches arrives the same packet that\n            # puts us over the limit, we fail the request because it was not\n            # found within the limit.\n            ws.write(b\"abcdef\")\n            with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n                rs.read_until_regex(b\"def\", max_bytes=5)\n                yield closed.wait()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that reading from a stream with a regex delimiter and a maximum byte limit correctly fails if the matching data exceeds that limit, ensuring read constraints are properly enforced during asynchronous I/O operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_small_reads_from_large_buffer", "line_number": 540, "body": "def test_small_reads_from_large_buffer(self: typing.Any):\n        # 10KB buffer size, 100KB available to read.\n        # Read 1KB at a time and make sure that the buffer is not eagerly\n        # filled.\n        rs, ws = yield self.make_iostream_pair(max_buffer_size=10 * 1024)\n        try:\n            ws.write(b\"a\" * 1024 * 100)\n            for i in range(100):\n                data = yield rs.read_bytes(1024)\n                self.assertEqual(data, b\"a\" * 1024)\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "This test method verifies that reading small chunks from a stream with a limited buffer size correctly yields expected data without premature buffer filling. It ensures reliable byte-by-byte reading behavior in stream IO operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_flow_control", "line_number": 570, "body": "def test_flow_control(self):\n        MB = 1024 * 1024\n        rs, ws = yield self.make_iostream_pair(max_buffer_size=5 * MB)\n        try:\n            # Client writes more than the rs will accept.\n            ws.write(b\"a\" * 10 * MB)\n            # The rs pauses while reading.\n            yield rs.read_bytes(MB)\n            yield gen.sleep(0.1)\n            # The ws's writes have been blocked; the rs can\n            # continue to read gradually.\n            for i in range(9):\n                yield rs.read_bytes(MB)\n        finally:\n            rs.close()\n            ws.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Tests flow control behavior between paired input/output streams, ensuring write operations are properly paused and resumed based on read buffer capacity, which is essential for managing backpressure in asynchronous IO communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_into_partial", "line_number": 630, "body": "def test_read_into_partial(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n\n        try:\n            # Partial read\n            buf = bytearray(10)\n            fut = rs.read_into(buf, partial=True)\n            ws.write(b\"hello\")\n            data = yield fut\n            self.assertFalse(rs.reading())\n            self.assertEqual(data, 5)\n            self.assertEqual(bytes(buf), b\"hello\\0\\0\\0\\0\\0\")\n\n            # Full read despite partial=True\n            ws.write(b\"world!1234567890\")\n            data = yield rs.read_into(buf, partial=True)\n            self.assertEqual(data, 10)\n            self.assertEqual(bytes(buf), b\"world!1234\")\n\n            # Existing buffer can satisfy read immediately\n            data = yield rs.read_into(buf, partial=True)\n            self.assertEqual(data, 6)\n            self.assertEqual(bytes(buf), b\"5678901234\")\n\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Core test method of TestReadWriteMixin that verifies partial and full reads into a buffer using an I/O stream pair, ensuring correct data transfer and buffer handling during asynchronous reads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_into_zero_bytes", "line_number": 659, "body": "def test_read_into_zero_bytes(self: typing.Any):\n        rs, ws = yield self.make_iostream_pair()\n        try:\n            buf = bytearray()\n            fut = rs.read_into(buf)\n            self.assertEqual(fut.result(), 0)\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Unit test method that verifies reading zero bytes into a buffer returns zero, ensuring correct behavior of the associated stream read_into method."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_many_mixed_reads", "line_number": 670, "body": "def test_many_mixed_reads(self):\n        # Stress buffer handling when going back and forth between\n        # read_bytes() (using an internal buffer) and read_into()\n        # (using a user-allocated buffer).\n        r = random.Random(42)\n        nbytes = 1000000\n        rs, ws = yield self.make_iostream_pair()\n\n        produce_hash = hashlib.sha1()\n        consume_hash = hashlib.sha1()\n\n        @gen.coroutine\n        def produce():\n            remaining = nbytes\n            while remaining > 0:\n                size = r.randint(1, min(1000, remaining))\n                data = os.urandom(size)\n                produce_hash.update(data)\n                yield ws.write(data)\n                remaining -= size\n            assert remaining == 0\n\n        @gen.coroutine\n        def consume():\n            remaining = nbytes\n            while remaining > 0:\n                if r.random() > 0.5:\n                    # read_bytes()\n                    size = r.randint(1, min(1000, remaining))\n                    data = yield rs.read_bytes(size)\n                    consume_hash.update(data)\n                    remaining -= size\n                else:\n                    # read_into()\n                    size = r.randint(1, min(1000, remaining))\n                    buf = bytearray(size)\n                    n = yield rs.read_into(buf)\n                    assert n == size\n                    consume_hash.update(buf)\n                    remaining -= size\n            assert remaining == 0\n\n        try:\n            yield [produce(), consume()]\n            assert produce_hash.hexdigest() == consume_hash.hexdigest()\n        finally:\n            ws.close()\n            rs.close()", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "TestReadWriteMixin method that stress-tests combined use of read_bytes and read_into methods on a stream, verifying data integrity through consistent hashing during mixed random-sized read operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "make_iostream_pair", "line_number": 728, "body": "def make_iostream_pair(self: typing.Any, **kwargs):\n        listener, port = bind_unused_port()\n        server_stream_fut = Future()  # type: Future[IOStream]\n\n        def accept_callback(connection, address):\n            server_stream_fut.set_result(\n                self._make_server_iostream(connection, **kwargs)\n            )\n\n        netutil.add_accept_handler(listener, accept_callback)\n        client_stream = self._make_client_iostream(socket.socket(), **kwargs)\n        connect_fut = client_stream.connect((\"127.0.0.1\", port))\n        server_stream, client_stream = yield [server_stream_fut, connect_fut]\n        self.io_loop.remove_handler(listener.fileno())\n        listener.close()\n        raise gen.Return((server_stream, client_stream))", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Provides a pair of interconnected IOStream objects for testing network communication by creating a local server-client stream connection on an unused port. Useful for simulating and validating asynchronous IO stream behaviors in networked environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_connection_refused", "line_number": 746, "body": "def test_connection_refused(self: typing.Any):\n        # When a connection is refused, the connect callback should not\n        # be run.  (The kqueue IOLoop used to behave differently from the\n        # epoll IOLoop in this respect)\n        cleanup_func, port = refusing_port()\n        self.addCleanup(cleanup_func)\n        stream = IOStream(socket.socket())\n\n        stream.set_close_callback(self.stop)\n        # log messages vary by platform and ioloop implementation\n        with ExpectLog(gen_log, \".*\", required=False):\n            with self.assertRaises(StreamClosedError):\n                yield stream.connect((\"127.0.0.1\", port))\n\n        self.assertTrue(isinstance(stream.error, ConnectionRefusedError), stream.error)", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Tests that the IOStream properly handles connection refusal by ensuring the connection callback is not executed and the appropriate error is raised and recorded. It validates stream behavior under a refused connection scenario."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_gaierror", "line_number": 763, "body": "def test_gaierror(self: typing.Any):\n        # Test that IOStream sets its exc_info on getaddrinfo error.\n        # It's difficult to reliably trigger a getaddrinfo error;\n        # some resolvers own't even return errors for malformed names,\n        # so we mock it instead. If IOStream changes to call a Resolver\n        # before sock.connect, the mock target will need to change too.\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n        stream = IOStream(s)\n        stream.set_close_callback(self.stop)\n        with mock.patch(\n            \"socket.socket.connect\", side_effect=socket.gaierror(errno.EIO, \"boom\")\n        ):\n            with self.assertRaises(StreamClosedError):\n                yield stream.connect((\"localhost\", 80))\n            self.assertTrue(isinstance(stream.error, socket.gaierror))", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Tests that the IOStream properly captures and handles a getaddrinfo socket error during connection attempts, ensuring appropriate error state and closure behavior. This validates robust error management in network connection operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_read_until_close_with_error", "line_number": 780, "body": "def test_read_until_close_with_error(self: typing.Any):\n        server, client = yield self.make_iostream_pair()\n        try:\n            with mock.patch(\n                \"tornado.iostream.BaseIOStream._try_inline_read\",\n                side_effect=IOError(\"boom\"),\n            ):\n                with self.assertRaisesRegexp(IOError, \"boom\"):\n                    client.read_until_close()\n        finally:\n            server.close()\n            client.close()", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "This test method verifies that the client stream raises an IOError with the correct message when a read operation encounters an error. It ensures proper error handling during asynchronous stream reads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_inline_read_error", "line_number": 796, "body": "def test_inline_read_error(self: typing.Any):\n        # An error on an inline read is raised without logging (on the\n        # assumption that it will eventually be noticed or logged further\n        # up the stack).\n        #\n        # This test is posix-only because windows os.close() doesn't work\n        # on socket FDs, but we can't close the socket object normally\n        # because we won't get the error we want if the socket knows\n        # it's closed.\n        #\n        # This test is also disabled when the\n        # AddThreadSelectorEventLoop is used, because a race between\n        # this thread closing the socket and the selector thread\n        # calling the select system call can make this test flaky.\n        # This event loop implementation is normally only used on\n        # windows, making this check redundant with skipIfNonUnix, but\n        # we sometimes enable it on other platforms for testing.\n        io_loop = IOLoop.current()\n        if isinstance(io_loop.selector_loop, AddThreadSelectorEventLoop):\n            self.skipTest(\"AddThreadSelectorEventLoop not supported\")\n        server, client = yield self.make_iostream_pair()\n        try:\n            os.close(server.socket.fileno())\n            with self.assertRaises(socket.error):\n                server.read_bytes(1)\n        finally:\n            server.close()\n            client.close()", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Tests that an inline read error is correctly raised without logging on POSIX systems, ensuring robust error handling in asynchronous I/O stream operations. It helps verify socket behavior under specific edge conditions in TestIOStreamMixin."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_async_read_error_logging", "line_number": 827, "body": "def test_async_read_error_logging(self):\n        # Socket errors on asynchronous reads should be logged (but only\n        # once).\n        server, client = yield self.make_iostream_pair()\n        closed = Event()\n        server.set_close_callback(closed.set)\n        try:\n            # Start a read that will be fulfilled asynchronously.\n            server.read_bytes(1)\n            client.write(b\"a\")\n            # Stub out read_from_fd to make it fail.\n\n            def fake_read_from_fd():\n                os.close(server.socket.fileno())\n                server.__class__.read_from_fd(server)\n\n            server.read_from_fd = fake_read_from_fd\n            # This log message is from _handle_read (not read_from_fd).\n            with ExpectLog(gen_log, \"error on read\"):\n                yield closed.wait()\n        finally:\n            server.close()\n            client.close()", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Tests that asynchronous read errors on a socket are logged exactly once, ensuring proper error reporting during asynchronous IO operations in the TestIOStreamMixin context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_future_write", "line_number": 852, "body": "def test_future_write(self):\n        \"\"\"\n        Test that write() Futures are never orphaned.\n        \"\"\"\n        # Run concurrent writers that will write enough bytes so as to\n        # clog the socket buffer and accumulate bytes in our write buffer.\n        m, n = 5000, 1000\n        nproducers = 10\n        total_bytes = m * n * nproducers\n        server, client = yield self.make_iostream_pair(max_buffer_size=total_bytes)\n\n        @gen.coroutine\n        def produce():\n            data = b\"x\" * m\n            for i in range(n):\n                yield server.write(data)\n\n        @gen.coroutine\n        def consume():\n            nread = 0\n            while nread < total_bytes:\n                res = yield client.read_bytes(m)\n                nread += len(res)\n\n        try:\n            yield [produce() for i in range(nproducers)] + [consume()]\n        finally:\n            server.close()\n            client.close()", "is_method": true, "class_name": "TestIOStreamMixin", "function_description": "Provides a test method that verifies concurrent write operations produce Futures that complete properly without being lost or orphaned, ensuring reliable asynchronous I/O behavior in socket communication scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_client_iostream", "line_number": 884, "body": "def _make_client_iostream(self):\n        return IOStream(socket.socket())", "is_method": true, "class_name": "TestIOStreamWebHTTP", "function_description": "Creates and returns a new IOStream object using a fresh socket. This function provides a basic client stream setup for network communication in the TestIOStreamWebHTTP context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_client_iostream", "line_number": 889, "body": "def _make_client_iostream(self):\n        return SSLIOStream(socket.socket(), ssl_options=dict(cert_reqs=ssl.CERT_NONE))", "is_method": true, "class_name": "TestIOStreamWebHTTPS", "function_description": "Private method in TestIOStreamWebHTTPS that creates a non-verifying SSL IO stream client for secure socket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_server_iostream", "line_number": 894, "body": "def _make_server_iostream(self, connection, **kwargs):\n        return IOStream(connection, **kwargs)", "is_method": true, "class_name": "TestIOStream", "function_description": "Private method in TestIOStream that creates and returns a new IOStream instance wrapping a given connection, facilitating asynchronous input/output operations over that connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_client_iostream", "line_number": 897, "body": "def _make_client_iostream(self, connection, **kwargs):\n        return IOStream(connection, **kwargs)", "is_method": true, "class_name": "TestIOStream", "function_description": "Private helper method of the TestIOStream class that creates and returns an IOStream object wrapping a given connection, facilitating stream-based input/output operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_server_iostream", "line_number": 902, "body": "def _make_server_iostream(self, connection, **kwargs):\n        connection = ssl.wrap_socket(\n            connection,\n            server_side=True,\n            do_handshake_on_connect=False,\n            **_server_ssl_options()\n        )\n        return SSLIOStream(connection, **kwargs)", "is_method": true, "class_name": "TestIOStreamSSL", "function_description": "Creates an SSL-wrapped server-side IO stream from a raw connection, enabling secure asynchronous communication in server applications. This method provides SSL configuration and handshake control tailored for server streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_client_iostream", "line_number": 911, "body": "def _make_client_iostream(self, connection, **kwargs):\n        return SSLIOStream(\n            connection, ssl_options=dict(cert_reqs=ssl.CERT_NONE), **kwargs\n        )", "is_method": true, "class_name": "TestIOStreamSSL", "function_description": "Private method of TestIOStreamSSL that creates an SSLIOStream client connection with no certificate verification, facilitating secure communication setup in testing or controlled environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_server_iostream", "line_number": 921, "body": "def _make_server_iostream(self, connection, **kwargs):\n        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n        context.load_cert_chain(\n            os.path.join(os.path.dirname(__file__), \"test.crt\"),\n            os.path.join(os.path.dirname(__file__), \"test.key\"),\n        )\n        connection = ssl_wrap_socket(\n            connection, context, server_side=True, do_handshake_on_connect=False\n        )\n        return SSLIOStream(connection, **kwargs)", "is_method": true, "class_name": "TestIOStreamSSLContext", "function_description": "Creates and returns an SSL-enabled IOStream for a server connection using test certificates, facilitating secure communication in test environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "_make_client_iostream", "line_number": 932, "body": "def _make_client_iostream(self, connection, **kwargs):\n        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n        return SSLIOStream(connection, ssl_options=context, **kwargs)", "is_method": true, "class_name": "TestIOStreamSSLContext", "function_description": "Creates and returns an SSL-wrapped client IO stream using a specific SSL context for secure communication. This method supports establishing encrypted connections in network clients."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "setUp", "line_number": 938, "body": "def setUp(self):\n        try:\n            super().setUp()\n            self.listener, self.port = bind_unused_port()\n            self.server_stream = None\n            self.server_accepted = Future()  # type: Future[None]\n            netutil.add_accept_handler(self.listener, self.accept)\n            self.client_stream = IOStream(\n                socket.socket()\n            )  # type: typing.Optional[IOStream]\n            self.io_loop.add_future(\n                self.client_stream.connect((\"127.0.0.1\", self.port)), self.stop\n            )\n            self.wait()\n            self.io_loop.add_future(self.server_accepted, self.stop)\n            self.wait()\n        except Exception as e:\n            print(e)\n            raise", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Sets up the test environment by opening a server socket, preparing client and server streams, and establishing a connection for testing TLS over IO streams. It initializes asynchronous handlers to manage connection events during tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "tearDown", "line_number": 958, "body": "def tearDown(self):\n        if self.server_stream is not None:\n            self.server_stream.close()\n        if self.client_stream is not None:\n            self.client_stream.close()\n        self.io_loop.remove_handler(self.listener.fileno())\n        self.listener.close()\n        super().tearDown()", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Cleans up network streams and listener resources after tests in TestIOStreamStartTLS, ensuring proper closure and removal from the event loop. It finalizes the test environment for reliable teardown."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "accept", "line_number": 967, "body": "def accept(self, connection, address):\n        if self.server_stream is not None:\n            self.fail(\"should only get one connection\")\n        self.server_stream = IOStream(connection)\n        self.server_accepted.set_result(None)", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Handles and accepts a single incoming connection, initializing an IOStream for communication and signaling that the server has accepted the connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "client_send_line", "line_number": 974, "body": "def client_send_line(self, line):\n        assert self.client_stream is not None\n        self.client_stream.write(line)\n        assert self.server_stream is not None\n        recv_line = yield self.server_stream.read_until(b\"\\r\\n\")\n        self.assertEqual(line, recv_line)", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Method of TestIOStreamStartTLS that sends a line to the client stream and verifies the server stream receives the same line, facilitating communication testing between client and server streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "server_send_line", "line_number": 982, "body": "def server_send_line(self, line):\n        assert self.server_stream is not None\n        self.server_stream.write(line)\n        assert self.client_stream is not None\n        recv_line = yield self.client_stream.read_until(b\"\\r\\n\")\n        self.assertEqual(line, recv_line)", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Method of TestIOStreamStartTLS that sends a line through the server stream and verifies the client stream receives the exact same line, supporting communication integrity tests in asynchronous I/O stream environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "client_start_tls", "line_number": 989, "body": "def client_start_tls(self, ssl_options=None, server_hostname=None):\n        assert self.client_stream is not None\n        client_stream = self.client_stream\n        self.client_stream = None\n        return client_stream.start_tls(False, ssl_options, server_hostname)", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Provides a client-side method to initiate a TLS handshake on an existing stream, upgrading the connection to a secure encrypted channel using optional SSL settings and server hostname information."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "server_start_tls", "line_number": 995, "body": "def server_start_tls(self, ssl_options=None):\n        assert self.server_stream is not None\n        server_stream = self.server_stream\n        self.server_stream = None\n        return server_stream.start_tls(True, ssl_options)", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Enables transitioning an existing server stream to use TLS encryption, optionally with specified SSL options, to secure communication within the TestIOStreamStartTLS context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_start_tls_smtp", "line_number": 1002, "body": "def test_start_tls_smtp(self):\n        # This flow is simplified from RFC 3207 section 5.\n        # We don't really need all of this, but it helps to make sure\n        # that after realistic back-and-forth traffic the buffers end up\n        # in a sane state.\n        yield self.server_send_line(b\"220 mail.example.com ready\\r\\n\")\n        yield self.client_send_line(b\"EHLO mail.example.com\\r\\n\")\n        yield self.server_send_line(b\"250-mail.example.com welcome\\r\\n\")\n        yield self.server_send_line(b\"250 STARTTLS\\r\\n\")\n        yield self.client_send_line(b\"STARTTLS\\r\\n\")\n        yield self.server_send_line(b\"220 Go ahead\\r\\n\")\n        client_future = self.client_start_tls(dict(cert_reqs=ssl.CERT_NONE))\n        server_future = self.server_start_tls(_server_ssl_options())\n        self.client_stream = yield client_future\n        self.server_stream = yield server_future\n        self.assertTrue(isinstance(self.client_stream, SSLIOStream))\n        self.assertTrue(isinstance(self.server_stream, SSLIOStream))\n        yield self.client_send_line(b\"EHLO mail.example.com\\r\\n\")\n        yield self.server_send_line(b\"250 mail.example.com welcome\\r\\n\")", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Simulates and verifies the SMTP STARTTLS handshake process, ensuring that client and server streams correctly transition to secure SSL/TLS connections during email communication testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_handshake_fail", "line_number": 1023, "body": "def test_handshake_fail(self):\n        server_future = self.server_start_tls(_server_ssl_options())\n        # Certificates are verified with the default configuration.\n        with ExpectLog(gen_log, \"SSL Error\"):\n            client_future = self.client_start_tls(server_hostname=\"localhost\")\n            with self.assertRaises(ssl.SSLError):\n                yield client_future\n            with self.assertRaises((ssl.SSLError, socket.error)):\n                yield server_future", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Tests that the TLS handshake fails as expected when using default certificate verification, ensuring proper error handling for SSL errors during client-server TLS negotiation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_check_hostname", "line_number": 1034, "body": "def test_check_hostname(self):\n        # Test that server_hostname parameter to start_tls is being used.\n        # The check_hostname functionality is only available in python 2.7 and\n        # up and in python 3.4 and up.\n        server_future = self.server_start_tls(_server_ssl_options())\n        with ExpectLog(gen_log, \"SSL Error\"):\n            client_future = self.client_start_tls(\n                ssl.create_default_context(), server_hostname=\"127.0.0.1\"\n            )\n            with self.assertRaises(ssl.SSLError):\n                # The client fails to connect with an SSL error.\n                yield client_future\n            with self.assertRaises(Exception):\n                # The server fails to connect, but the exact error is unspecified.\n                yield server_future", "is_method": true, "class_name": "TestIOStreamStartTLS", "function_description": "Tests that the server_hostname parameter in start_tls is correctly used, verifying SSL hostname checking by expecting SSL errors during client-server TLS handshake failures. Useful for validating TLS connection security checks in asynchronous I/O streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "connect_to_server", "line_number": 1053, "body": "def connect_to_server(self, server_cls):\n        server = client = None\n        try:\n            sock, port = bind_unused_port()\n            server = server_cls(ssl_options=_server_ssl_options())\n            server.add_socket(sock)\n\n            ssl_ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n            ssl_ctx.check_hostname = False\n            ssl_ctx.verify_mode = ssl.CERT_NONE\n            # These tests fail with ConnectionAbortedErrors with TLS\n            # 1.3 on windows python 3.7.4 (which includes an upgrade\n            # to openssl 1.1.c. Other platforms might be affected with\n            # newer openssl too). Disable it until we figure out\n            # what's up.\n            ssl_ctx.options |= getattr(ssl, \"OP_NO_TLSv1_3\", 0)\n            client = SSLIOStream(socket.socket(), ssl_options=ssl_ctx)\n            yield client.connect((\"127.0.0.1\", port))\n            self.assertIsNotNone(client.socket.cipher())\n        finally:\n            if server is not None:\n                server.stop()\n            if client is not None:\n                client.close()", "is_method": true, "class_name": "WaitForHandshakeTest", "function_description": "Establishes a secure SSL connection to a locally bound server for testing handshake functionality and ensures the client successfully negotiates an encryption cipher. It handles setup and teardown of server and client resources within the test."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_wait_for_handshake_future", "line_number": 1079, "body": "def test_wait_for_handshake_future(self):\n        test = self\n        handshake_future = Future()  # type: Future[None]\n\n        class TestServer(TCPServer):\n            def handle_stream(self, stream, address):\n                test.assertIsNone(stream.socket.cipher())\n                test.io_loop.spawn_callback(self.handle_connection, stream)\n\n            @gen.coroutine\n            def handle_connection(self, stream):\n                yield stream.wait_for_handshake()\n                handshake_future.set_result(None)\n\n        yield self.connect_to_server(TestServer)\n        yield handshake_future", "is_method": true, "class_name": "WaitForHandshakeTest", "function_description": "Tests that a server properly waits for a TLS handshake to complete before proceeding, verifying asynchronous handshake handling in a TCP server context. This ensures secure connection establishment is correctly awaited."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_wait_for_handshake_already_waiting_error", "line_number": 1097, "body": "def test_wait_for_handshake_already_waiting_error(self):\n        test = self\n        handshake_future = Future()  # type: Future[None]\n\n        class TestServer(TCPServer):\n            @gen.coroutine\n            def handle_stream(self, stream, address):\n                fut = stream.wait_for_handshake()\n                test.assertRaises(RuntimeError, stream.wait_for_handshake)\n                yield fut\n\n                handshake_future.set_result(None)\n\n        yield self.connect_to_server(TestServer)\n        yield handshake_future", "is_method": true, "class_name": "WaitForHandshakeTest", "function_description": "Tests that calling wait_for_handshake on a stream while a handshake is already pending raises a RuntimeError, ensuring proper handshake state management in the connection handling process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_wait_for_handshake_already_connected", "line_number": 1114, "body": "def test_wait_for_handshake_already_connected(self):\n        handshake_future = Future()  # type: Future[None]\n\n        class TestServer(TCPServer):\n            @gen.coroutine\n            def handle_stream(self, stream, address):\n                yield stream.wait_for_handshake()\n                yield stream.wait_for_handshake()\n                handshake_future.set_result(None)\n\n        yield self.connect_to_server(TestServer)\n        yield handshake_future", "is_method": true, "class_name": "WaitForHandshakeTest", "function_description": "Tests that a TCP server correctly recognizes an already completed handshake and does not block when wait_for_handshake is called multiple times on the same connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "make_iostream_pair", "line_number": 1131, "body": "def make_iostream_pair(self, **kwargs):\n        r, w = os.pipe()\n\n        return PipeIOStream(r, **kwargs), PipeIOStream(w, **kwargs)", "is_method": true, "class_name": "TestPipeIOStream", "function_description": "Creates and returns a connected pair of PipeIOStream objects representing the read and write ends of an OS pipe, enabling inter-process communication through stream interfaces."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_pipe_iostream", "line_number": 1137, "body": "def test_pipe_iostream(self):\n        rs, ws = yield self.make_iostream_pair()\n\n        ws.write(b\"hel\")\n        ws.write(b\"lo world\")\n\n        data = yield rs.read_until(b\" \")\n        self.assertEqual(data, b\"hello \")\n\n        data = yield rs.read_bytes(3)\n        self.assertEqual(data, b\"wor\")\n\n        ws.close()\n\n        data = yield rs.read_until_close()\n        self.assertEqual(data, b\"ld\")\n\n        rs.close()", "is_method": true, "class_name": "TestPipeIOStream", "function_description": "Test method of TestPipeIOStream that verifies reading and writing behavior of paired IO streams, ensuring correct data transmission and reading until specified bytes, delimiters, and stream closure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_pipe_iostream_big_write", "line_number": 1157, "body": "def test_pipe_iostream_big_write(self):\n        rs, ws = yield self.make_iostream_pair()\n\n        NUM_BYTES = 1048576\n\n        # Write 1MB of data, which should fill the buffer\n        ws.write(b\"1\" * NUM_BYTES)\n\n        data = yield rs.read_bytes(NUM_BYTES)\n        self.assertEqual(data, b\"1\" * NUM_BYTES)\n\n        ws.close()\n        rs.close()", "is_method": true, "class_name": "TestPipeIOStream", "function_description": "This test method verifies that a pipe-based IO stream can correctly write and read large data buffers, ensuring data integrity and proper stream closure for high-volume data transfers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "setUp", "line_number": 1177, "body": "def setUp(self):\n        self.random = random.Random(42)", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Initializes a consistent pseudo-random number generator for the TestStreamBuffer class to ensure reproducible test results."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "to_bytes", "line_number": 1180, "body": "def to_bytes(self, b):\n        if isinstance(b, (bytes, bytearray)):\n            return bytes(b)\n        elif isinstance(b, memoryview):\n            return b.tobytes()  # For py2\n        else:\n            raise TypeError(b)", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Converts various byte-like objects into immutable bytes, ensuring consistent byte representation from inputs such as bytes, bytearrays, or memoryviews. This utility aids in handling different binary data types uniformly within the TestStreamBuffer class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "make_streambuffer", "line_number": 1188, "body": "def make_streambuffer(self, large_buf_threshold=10):\n        buf = _StreamBuffer()\n        assert buf._large_buf_threshold\n        buf._large_buf_threshold = large_buf_threshold\n        return buf", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Creates and returns a new _StreamBuffer instance with a configurable threshold for large buffer handling, enabling customized stream buffering behavior within the TestStreamBuffer context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "check_peek", "line_number": 1194, "body": "def check_peek(self, buf, expected):\n        size = 1\n        while size < 2 * len(expected):\n            got = self.to_bytes(buf.peek(size))\n            self.assertTrue(got)  # Not empty\n            self.assertLessEqual(len(got), size)\n            self.assertTrue(expected.startswith(got), (expected, got))\n            size = (size * 3 + 1) // 2", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Utility method in TestStreamBuffer that incrementally verifies the peeked contents of a buffer match the expected prefix, ensuring the buffer's peek operation returns progressively larger valid data slices."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "check_append_all_then_skip_all", "line_number": 1203, "body": "def check_append_all_then_skip_all(self, buf, objs, input_type):\n        self.assertEqual(len(buf), 0)\n\n        expected = b\"\"\n\n        for o in objs:\n            expected += o\n            buf.append(input_type(o))\n            self.assertEqual(len(buf), len(expected))\n            self.check_peek(buf, expected)\n\n        while expected:\n            n = self.random.randrange(1, len(expected) + 1)\n            expected = expected[n:]\n            buf.advance(n)\n            self.assertEqual(len(buf), len(expected))\n            self.check_peek(buf, expected)\n\n        self.assertEqual(len(buf), 0)", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Method in TestStreamBuffer that verifies appending multiple items and then sequentially skipping them updates the buffer length and content as expected, ensuring correct buffer behavior under varied operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_small", "line_number": 1223, "body": "def test_small(self):\n        objs = [b\"12\", b\"345\", b\"67\", b\"89a\", b\"bcde\", b\"fgh\", b\"ijklmn\"]\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, bytes)\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, bytearray)\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, memoryview)\n\n        # Test internal algorithm\n        buf = self.make_streambuffer(10)\n        for i in range(9):\n            buf.append(b\"x\")\n        self.assertEqual(len(buf._buffers), 1)\n        for i in range(9):\n            buf.append(b\"x\")\n        self.assertEqual(len(buf._buffers), 2)\n        buf.advance(10)\n        self.assertEqual(len(buf._buffers), 1)\n        buf.advance(8)\n        self.assertEqual(len(buf._buffers), 0)\n        self.assertEqual(len(buf), 0)", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Tests various behaviors of the TestStreamBuffer class, including appending and skipping byte-like objects and verifying internal buffer management and state after operations. It ensures correct buffer handling for different input types and edge cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "test_large", "line_number": 1249, "body": "def test_large(self):\n        objs = [\n            b\"12\" * 5,\n            b\"345\" * 2,\n            b\"67\" * 20,\n            b\"89a\" * 12,\n            b\"bcde\" * 1,\n            b\"fgh\" * 7,\n            b\"ijklmn\" * 2,\n        ]\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, bytes)\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, bytearray)\n\n        buf = self.make_streambuffer()\n        self.check_append_all_then_skip_all(buf, objs, memoryview)\n\n        # Test internal algorithm\n        buf = self.make_streambuffer(10)\n        for i in range(3):\n            buf.append(b\"x\" * 11)\n        self.assertEqual(len(buf._buffers), 3)\n        buf.append(b\"y\")\n        self.assertEqual(len(buf._buffers), 4)\n        buf.append(b\"z\")\n        self.assertEqual(len(buf._buffers), 4)\n        buf.advance(33)\n        self.assertEqual(len(buf._buffers), 1)\n        buf.advance(2)\n        self.assertEqual(len(buf._buffers), 0)\n        self.assertEqual(len(buf), 0)", "is_method": true, "class_name": "TestStreamBuffer", "function_description": "Tests the behavior and internal buffer management of a stream buffer by appending various byte-like objects, advancing the buffer, and verifying buffer resizing and data skipping functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "sleep_some", "line_number": 591, "body": "def sleep_some():\n            self.io_loop.run_sync(lambda: gen.sleep(0.05))", "is_method": true, "class_name": "TestReadWriteMixin", "function_description": "Pauses execution briefly within the IO loop to allow asynchronous operations to proceed, facilitating controlled timing in test scenarios involving read/write processes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "handle_stream", "line_number": 1084, "body": "def handle_stream(self, stream, address):\n                test.assertIsNone(stream.socket.cipher())\n                test.io_loop.spawn_callback(self.handle_connection, stream)", "is_method": true, "class_name": "TestServer", "function_description": "Handles an incoming stream by verifying its security cipher is None and asynchronously initiating connection processing within the test server environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/iostream_test.py", "function": "handle_stream", "line_number": 1103, "body": "def handle_stream(self, stream, address):\n                fut = stream.wait_for_handshake()\n                test.assertRaises(RuntimeError, stream.wait_for_handshake)\n                yield fut\n\n                handshake_future.set_result(None)", "is_method": true, "class_name": "TestServer", "function_description": "Handles a network stream's handshake process, ensuring only one handshake occurs and raising an error on subsequent attempts. Used to manage connection initialization in server tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "get_http_client", "line_number": 21, "body": "def get_http_client(self):\n        client = CurlAsyncHTTPClient(defaults=dict(allow_ipv6=False))\n        # make sure AsyncHTTPClient magic doesn't give us the wrong class\n        self.assertTrue(isinstance(client, CurlAsyncHTTPClient))\n        return client", "is_method": true, "class_name": "CurlHTTPClientCommonTestCase", "function_description": "Returns an instance of CurlAsyncHTTPClient with IPv6 disabled, ensuring the correct client class is instantiated for asynchronous HTTP operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "initialize", "line_number": 29, "body": "def initialize(self, username, password):\n        self.username = username\n        self.password = password", "is_method": true, "class_name": "DigestAuthHandler", "function_description": "Initializes the DigestAuthHandler with a username and password for managing HTTP Digest Authentication credentials."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "get", "line_number": 33, "body": "def get(self):\n        realm = \"test\"\n        opaque = \"asdf\"\n        # Real implementations would use a random nonce.\n        nonce = \"1234\"\n\n        auth_header = self.request.headers.get(\"Authorization\", None)\n        if auth_header is not None:\n            auth_mode, params = auth_header.split(\" \", 1)\n            assert auth_mode == \"Digest\"\n            param_dict = {}\n            for pair in params.split(\",\"):\n                k, v = pair.strip().split(\"=\", 1)\n                if v[0] == '\"' and v[-1] == '\"':\n                    v = v[1:-1]\n                param_dict[k] = v\n            assert param_dict[\"realm\"] == realm\n            assert param_dict[\"opaque\"] == opaque\n            assert param_dict[\"nonce\"] == nonce\n            assert param_dict[\"username\"] == self.username\n            assert param_dict[\"uri\"] == self.request.path\n            h1 = md5(\n                utf8(\"%s:%s:%s\" % (self.username, realm, self.password))\n            ).hexdigest()\n            h2 = md5(\n                utf8(\"%s:%s\" % (self.request.method, self.request.path))\n            ).hexdigest()\n            digest = md5(utf8(\"%s:%s:%s\" % (h1, nonce, h2))).hexdigest()\n            if digest == param_dict[\"response\"]:\n                self.write(\"ok\")\n            else:\n                self.write(\"fail\")\n        else:\n            self.set_status(401)\n            self.set_header(\n                \"WWW-Authenticate\",\n                'Digest realm=\"%s\", nonce=\"%s\", opaque=\"%s\"' % (realm, nonce, opaque),\n            )", "is_method": true, "class_name": "DigestAuthHandler", "function_description": "Handles HTTP Digest Authentication by validating the Authorization header against expected credentials and issues a 401 challenge if authentication is missing or invalid. It provides basic Digest Auth verification for protected resources."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "get", "line_number": 74, "body": "def get(self):\n        self.set_status(200, \"Custom reason\")", "is_method": true, "class_name": "CustomReasonHandler", "function_description": "Sets an HTTP response status with a custom status code and reason phrase, allowing tailored response messages in HTTP handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "get", "line_number": 79, "body": "def get(self):\n        self.set_status(400, \"Custom reason\")", "is_method": true, "class_name": "CustomFailReasonHandler", "function_description": "Sets the HTTP response status to 400 with a custom reason phrase, allowing tailored error messages in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "setUp", "line_number": 85, "body": "def setUp(self):\n        super().setUp()\n        self.http_client = self.create_client()", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Sets up the test environment by initializing an HTTP client instance for use in subsequent test methods within the CurlHTTPClientTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "get_app", "line_number": 89, "body": "def get_app(self):\n        return Application(\n            [\n                (\"/digest\", DigestAuthHandler, {\"username\": \"foo\", \"password\": \"bar\"}),\n                (\n                    \"/digest_non_ascii\",\n                    DigestAuthHandler,\n                    {\"username\": \"foo\", \"password\": \"bar\u30e6\u00a3\"},\n                ),\n                (\"/custom_reason\", CustomReasonHandler),\n                (\"/custom_fail_reason\", CustomFailReasonHandler),\n            ]\n        )", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Provides a Tornado application configured with multiple HTTP handlers for testing different authentication and response scenarios in CurlHTTPClientTestCase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "create_client", "line_number": 103, "body": "def create_client(self, **kwargs):\n        return CurlAsyncHTTPClient(\n            force_instance=True, defaults=dict(allow_ipv6=False), **kwargs\n        )", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Creates and returns a configured CurlAsyncHTTPClient instance with IPv6 disabled by default for testing HTTP client behavior in asynchronous curl-based environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "test_digest_auth", "line_number": 108, "body": "def test_digest_auth(self):\n        response = self.fetch(\n            \"/digest\", auth_mode=\"digest\", auth_username=\"foo\", auth_password=\"bar\"\n        )\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Test method in CurlHTTPClientTestCase that verifies digest authentication by sending a request with digest credentials and asserting a successful response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "test_custom_reason", "line_number": 114, "body": "def test_custom_reason(self):\n        response = self.fetch(\"/custom_reason\")\n        self.assertEqual(response.reason, \"Custom reason\")", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Tests that the HTTP client correctly returns a custom reason phrase from the server response, validating proper handling of non-standard HTTP status reasons."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "test_fail_custom_reason", "line_number": 118, "body": "def test_fail_custom_reason(self):\n        response = self.fetch(\"/custom_fail_reason\")\n        self.assertEqual(str(response.error), \"HTTP 400: Custom reason\")", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Tests that a failing HTTP response correctly returns a custom error reason message, verifying error handling in the CurlHTTPClientTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/curl_httpclient_test.py", "function": "test_digest_auth_non_ascii", "line_number": 122, "body": "def test_digest_auth_non_ascii(self):\n        response = self.fetch(\n            \"/digest_non_ascii\",\n            auth_mode=\"digest\",\n            auth_username=\"foo\",\n            auth_password=\"bar\u30e6\u00a3\",\n        )\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "CurlHTTPClientTestCase", "function_description": "Test method in CurlHTTPClientTestCase that verifies digest authentication handles non-ASCII characters in the password correctly and returns the expected successful response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/import_test.py", "function": "test_import_everything", "line_number": 50, "body": "def test_import_everything(self):\n        # Test that all Tornado modules can be imported without side effects,\n        # specifically without initializing the default asyncio event loop.\n        # Since we can't tell which modules may have already beein imported\n        # in our process, do it in a subprocess for a clean slate.\n        proc = subprocess.Popen([sys.executable], stdin=subprocess.PIPE)\n        proc.communicate(_import_everything)\n        self.assertEqual(proc.returncode, 0)", "is_method": true, "class_name": "ImportTest", "function_description": "Core test method of the ImportTest class that verifies all Tornado modules import cleanly without triggering side effects, especially the default asyncio event loop initialization. It ensures module imports are safe in isolated subprocess environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/import_test.py", "function": "test_import_aliases", "line_number": 59, "body": "def test_import_aliases(self):\n        # Ensure we don't delete formerly-documented aliases accidentally.\n        import tornado.ioloop\n        import tornado.gen\n        import tornado.util\n\n        self.assertIs(tornado.ioloop.TimeoutError, tornado.util.TimeoutError)\n        self.assertIs(tornado.gen.TimeoutError, tornado.util.TimeoutError)", "is_method": true, "class_name": "ImportTest", "function_description": "Tests that various Tornado modules correctly reference the same TimeoutError alias, ensuring backward compatibility and preventing accidental removal of these documented aliases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "form_data_args", "line_number": 28, "body": "def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n\n    mypy insists on type annotations for dict literals, so this lets us avoid\n    the verbose types throughout this test.\n    \"\"\"\n    return {}, {}", "is_method": false, "function_description": "Utility function that returns two empty dictionaries typed for multipart form data parsing, simplifying type annotations in testing contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_no_query_params", "line_number": 38, "body": "def test_url_concat_no_query_params(self):\n        url = url_concat(\"https://localhost/path\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?y=y&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Tests that url_concat correctly appends multiple query parameters to a URL without existing query parameters, ensuring proper URL construction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_encode_args", "line_number": 42, "body": "def test_url_concat_encode_args(self):\n        url = url_concat(\"https://localhost/path\", [(\"y\", \"/y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?y=%2Fy&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Test method verifying that URL parameter encoding and concatenation works correctly, ensuring special characters in query arguments are properly encoded in the resulting URL."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_trailing_q", "line_number": 46, "body": "def test_url_concat_trailing_q(self):\n        url = url_concat(\"https://localhost/path?\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?y=y&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Test method in TestUrlConcat class that verifies url_concat correctly appends query parameters to a URL ending with a question mark."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_q_with_no_trailing_amp", "line_number": 50, "body": "def test_url_concat_q_with_no_trailing_amp(self):\n        url = url_concat(\"https://localhost/path?x\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?x=&y=y&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Test method in TestUrlConcat verifying that url_concat correctly appends query parameters even when the base URL's query string lacks a trailing ampersand."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_trailing_amp", "line_number": 54, "body": "def test_url_concat_trailing_amp(self):\n        url = url_concat(\"https://localhost/path?x&\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?x=&y=y&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "A test method validating that the url_concat function correctly appends query parameters to URLs ending with a trailing ampersand, ensuring proper URL construction in edge cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_mult_params", "line_number": 58, "body": "def test_url_concat_mult_params(self):\n        url = url_concat(\"https://localhost/path?a=1&b=2\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?a=1&b=2&y=y&z=z\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Unit test method of TestUrlConcat that verifies appending multiple query parameters to an existing URL preserves and correctly concatenates all parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_no_params", "line_number": 62, "body": "def test_url_concat_no_params(self):\n        url = url_concat(\"https://localhost/path?r=1&t=2\", [])\n        self.assertEqual(url, \"https://localhost/path?r=1&t=2\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Test method for TestUrlConcat that verifies url_concat returns the original URL unchanged when no additional parameters are provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_none_params", "line_number": 66, "body": "def test_url_concat_none_params(self):\n        url = url_concat(\"https://localhost/path?r=1&t=2\", None)\n        self.assertEqual(url, \"https://localhost/path?r=1&t=2\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "This test method verifies that concatenating a URL with None parameters returns the original URL unchanged, ensuring the url_concat function handles None inputs gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_with_frag", "line_number": 70, "body": "def test_url_concat_with_frag(self):\n        url = url_concat(\"https://localhost/path#tab\", [(\"y\", \"y\")])\n        self.assertEqual(url, \"https://localhost/path?y=y#tab\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Test method in the TestUrlConcat class that verifies url_concat correctly appends query parameters to URLs containing fragments. It ensures query strings are inserted before the URL fragment identifier."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_multi_same_params", "line_number": 74, "body": "def test_url_concat_multi_same_params(self):\n        url = url_concat(\"https://localhost/path\", [(\"y\", \"y1\"), (\"y\", \"y2\")])\n        self.assertEqual(url, \"https://localhost/path?y=y1&y=y2\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Unit test method for TestUrlConcat that verifies url_concat correctly appends multiple query parameters with the same name to a base URL."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_multi_same_query_params", "line_number": 78, "body": "def test_url_concat_multi_same_query_params(self):\n        url = url_concat(\"https://localhost/path?r=1&r=2\", [(\"y\", \"y\")])\n        self.assertEqual(url, \"https://localhost/path?r=1&r=2&y=y\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "Tests that the url_concat function correctly appends additional query parameters to a URL already containing duplicate parameters with the same name. This ensures proper handling of multiple identical query keys during URL construction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_url_concat_dict_params", "line_number": 82, "body": "def test_url_concat_dict_params(self):\n        url = url_concat(\"https://localhost/path\", dict(y=\"y\"))\n        self.assertEqual(url, \"https://localhost/path?y=y\")", "is_method": true, "class_name": "TestUrlConcat", "function_description": "This test method verifies that the url_concat function correctly appends query parameters from a dictionary to a base URL. It ensures proper URL construction with dictionary-based parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_parsing", "line_number": 88, "body": "def test_parsing(self):\n        qsstring = \"a=1&b=2&a=3\"\n        qs = urllib.parse.parse_qs(qsstring)\n        qsl = list(qs_to_qsl(qs))\n        self.assertIn((\"a\", \"1\"), qsl)\n        self.assertIn((\"a\", \"3\"), qsl)\n        self.assertIn((\"b\", \"2\"), qsl)", "is_method": true, "class_name": "QsParseTest", "function_description": "Test method in QsParseTest that verifies correct parsing of query strings into key-value pairs, ensuring multiple values for the same key are handled properly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_file_upload", "line_number": 98, "body": "def test_file_upload(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b\"1234\", data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], \"ab.txt\")\n        self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Unit test method in MultipartFormDataTest that verifies correct parsing of multipart form data for file uploads, ensuring the filename and file content are accurately extracted."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_unquoted_names", "line_number": 113, "body": "def test_unquoted_names(self):\n        # quotes are optional unless special characters are present\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=files; filename=ab.txt\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b\"1234\", data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], \"ab.txt\")\n        self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Tests that multipart form data with unquoted field names and filenames parses correctly, validating file metadata and content extraction."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_special_filenames", "line_number": 129, "body": "def test_special_filenames(self):\n        filenames = [\n            \"a;b.txt\",\n            'a\"b.txt',\n            'a\";b.txt',\n            'a;\"b.txt',\n            'a\";\";.txt',\n            'a\\\\\"b.txt',\n            \"a\\\\b.txt\",\n        ]\n        for filename in filenames:\n            logging.debug(\"trying filename %r\", filename)\n            str_data = \"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"%s\"\n\nFoo\n--1234--\"\"\" % filename.replace(\n                \"\\\\\", \"\\\\\\\\\"\n            ).replace(\n                '\"', '\\\\\"'\n            )\n            data = utf8(str_data.replace(\"\\n\", \"\\r\\n\"))\n            args, files = form_data_args()\n            parse_multipart_form_data(b\"1234\", data, args, files)\n            file = files[\"files\"][0]\n            self.assertEqual(file[\"filename\"], filename)\n            self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Tests that multipart form data parsing correctly handles various filenames with special characters, ensuring filenames and file contents are accurately extracted in form submissions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_non_ascii_filename", "line_number": 158, "body": "def test_non_ascii_filename(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"; filename*=UTF-8''%C3%A1b.txt\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b\"1234\", data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], u\"\u00e1b.txt\")\n        self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Tests multipart form data parsing to verify that filenames with non-ASCII UTF-8 characters are correctly decoded and file contents are properly extracted. It ensures accurate handling of internationalized filenames in form submissions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_boundary_starts_and_ends_with_quotes", "line_number": 173, "body": "def test_boundary_starts_and_ends_with_quotes(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b'\"1234\"', data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], \"ab.txt\")\n        self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Test method in MultipartFormDataTest that verifies multipart form data parsing correctly handles boundaries enclosed in quotes, ensuring files are properly extracted with accurate filenames and content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_missing_headers", "line_number": 188, "body": "def test_missing_headers(self):\n        data = b\"\"\"\\\n--1234\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        with ExpectLog(gen_log, \"multipart/form-data missing headers\"):\n            parse_multipart_form_data(b\"1234\", data, args, files)\n        self.assertEqual(files, {})", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Tests that multipart/form-data parsing handles parts missing headers gracefully, ensuring no files are incorrectly extracted from malformed data inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_invalid_content_disposition", "line_number": 201, "body": "def test_invalid_content_disposition(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: invalid; name=\"files\"; filename=\"ab.txt\"\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        with ExpectLog(gen_log, \"Invalid multipart/form-data\"):\n            parse_multipart_form_data(b\"1234\", data, args, files)\n        self.assertEqual(files, {})", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Unit test in MultipartFormDataTest that verifies multipart parser handles invalid Content-Disposition headers by ensuring no files are extracted and an appropriate log message is generated."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_line_does_not_end_with_correct_line_break", "line_number": 215, "body": "def test_line_does_not_end_with_correct_line_break(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"\n\nFoo--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        with ExpectLog(gen_log, \"Invalid multipart/form-data\"):\n            parse_multipart_form_data(b\"1234\", data, args, files)\n        self.assertEqual(files, {})", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Unit test in MultipartFormDataTest class verifying that multipart/form-data parser correctly detects and rejects improperly terminated input without the correct line break sequence."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_content_disposition_header_without_name_parameter", "line_number": 228, "body": "def test_content_disposition_header_without_name_parameter(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; filename=\"ab.txt\"\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        with ExpectLog(gen_log, \"multipart/form-data value missing name\"):\n            parse_multipart_form_data(b\"1234\", data, args, files)\n        self.assertEqual(files, {})", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Test method in MultipartFormDataTest that verifies multipart form-data parsing logs a warning and omits files when the Content-Disposition header lacks a 'name' parameter."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_data_after_final_boundary", "line_number": 242, "body": "def test_data_after_final_boundary(self):\n        # The spec requires that data after the final boundary be ignored.\n        # http://www.w3.org/Protocols/rfc1341/7_2_Multipart.html\n        # In practice, some libraries include an extra CRLF after the boundary.\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"\n\nFoo\n--1234--\n\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b\"1234\", data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], \"ab.txt\")\n        self.assertEqual(file[\"body\"], b\"Foo\")", "is_method": true, "class_name": "MultipartFormDataTest", "function_description": "Unit test method in MultipartFormDataTest that verifies multipart form data parsing correctly ignores any data appearing after the final boundary, ensuring compliance with the multipart data specification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_multi_line", "line_number": 263, "body": "def test_multi_line(self):\n        # Lines beginning with whitespace are appended to the previous line\n        # with any leading whitespace replaced by a single space.\n        # Note that while multi-line headers are a part of the HTTP spec,\n        # their use is strongly discouraged.\n        data = \"\"\"\\\nFoo: bar\n baz\nAsdf: qwer\n\\tzxcv\nFoo: even\n     more\n     lines\n\"\"\".replace(\n            \"\\n\", \"\\r\\n\"\n        )\n        headers = HTTPHeaders.parse(data)\n        self.assertEqual(headers[\"asdf\"], \"qwer zxcv\")\n        self.assertEqual(headers.get_list(\"asdf\"), [\"qwer zxcv\"])\n        self.assertEqual(headers[\"Foo\"], \"bar baz,even more lines\")\n        self.assertEqual(headers.get_list(\"foo\"), [\"bar baz\", \"even more lines\"])\n        self.assertEqual(\n            sorted(list(headers.get_all())),\n            [(\"Asdf\", \"qwer zxcv\"), (\"Foo\", \"bar baz\"), (\"Foo\", \"even more lines\")],\n        )", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Tests that the HTTPHeaders class correctly parses and consolidates multi-line HTTP header values, ensuring proper handling of continuation lines and case-insensitive retrieval of header entries."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_malformed_continuation", "line_number": 289, "body": "def test_malformed_continuation(self):\n        # If the first line starts with whitespace, it's a\n        # continuation line with nothing to continue, so reject it\n        # (with a proper error).\n        data = \" Foo: bar\"\n        self.assertRaises(HTTPInputError, HTTPHeaders.parse, data)", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Test method in HTTPHeadersTest that verifies malformed header lines starting with whitespace cause parsing to fail with an HTTPInputError, ensuring header format validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_unicode_newlines", "line_number": 296, "body": "def test_unicode_newlines(self):\n        # Ensure that only \\r\\n is recognized as a header separator, and not\n        # the other newline-like unicode characters.\n        # Characters that are likely to be problematic can be found in\n        # http://unicode.org/standard/reports/tr13/tr13-5.html\n        # and cpython's unicodeobject.c (which defines the implementation\n        # of unicode_type.splitlines(), and uses a different list than TR13).\n        newlines = [\n            u\"\\u001b\",  # VERTICAL TAB\n            u\"\\u001c\",  # FILE SEPARATOR\n            u\"\\u001d\",  # GROUP SEPARATOR\n            u\"\\u001e\",  # RECORD SEPARATOR\n            u\"\\u0085\",  # NEXT LINE\n            u\"\\u2028\",  # LINE SEPARATOR\n            u\"\\u2029\",  # PARAGRAPH SEPARATOR\n        ]\n        for newline in newlines:\n            # Try the utf8 and latin1 representations of each newline\n            for encoding in [\"utf8\", \"latin1\"]:\n                try:\n                    try:\n                        encoded = newline.encode(encoding)\n                    except UnicodeEncodeError:\n                        # Some chars cannot be represented in latin1\n                        continue\n                    data = b\"Cookie: foo=\" + encoded + b\"bar\"\n                    # parse() wants a native_str, so decode through latin1\n                    # in the same way the real parser does.\n                    headers = HTTPHeaders.parse(native_str(data.decode(\"latin1\")))\n                    expected = [\n                        (\n                            \"Cookie\",\n                            \"foo=\" + native_str(encoded.decode(\"latin1\")) + \"bar\",\n                        )\n                    ]\n                    self.assertEqual(expected, list(headers.get_all()))\n                except Exception:\n                    gen_log.warning(\"failed while trying %r in %s\", newline, encoding)\n                    raise", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Test method of HTTPHeadersTest that verifies only the CRLF sequence (\\r\\n) is treated as a valid header separator, ensuring other Unicode newline-like characters do not split HTTP headers incorrectly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_optional_cr", "line_number": 336, "body": "def test_optional_cr(self):\n        # Both CRLF and LF should be accepted as separators. CR should not be\n        # part of the data when followed by LF, but it is a normal char\n        # otherwise (or should bare CR be an error?)\n        headers = HTTPHeaders.parse(\"CRLF: crlf\\r\\nLF: lf\\nCR: cr\\rMore: more\\r\\n\")\n        self.assertEqual(\n            sorted(headers.get_all()),\n            [(\"Cr\", \"cr\\rMore: more\"), (\"Crlf\", \"crlf\"), (\"Lf\", \"lf\")],\n        )", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Unit test method in HTTPHeadersTest that verifies the parsing of HTTP headers correctly handles different line break formats, ensuring CRLF and LF are accepted while standalone CR is treated as part of the header value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_copy", "line_number": 346, "body": "def test_copy(self):\n        all_pairs = [(\"A\", \"1\"), (\"A\", \"2\"), (\"B\", \"c\")]\n        h1 = HTTPHeaders()\n        for k, v in all_pairs:\n            h1.add(k, v)\n        h2 = h1.copy()\n        h3 = copy.copy(h1)\n        h4 = copy.deepcopy(h1)\n        for headers in [h1, h2, h3, h4]:\n            # All the copies are identical, no matter how they were\n            # constructed.\n            self.assertEqual(list(sorted(headers.get_all())), all_pairs)\n        for headers in [h2, h3, h4]:\n            # Neither the dict or its member lists are reused.\n            self.assertIsNot(headers, h1)\n            self.assertIsNot(headers.get_list(\"A\"), h1.get_list(\"A\"))", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Tests that copying an HTTPHeaders instance, by shallow or deep copy methods, produces independent duplicates with identical contents. Ensures copies do not share internal data structures with the original."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_pickle_roundtrip", "line_number": 363, "body": "def test_pickle_roundtrip(self):\n        headers = HTTPHeaders()\n        headers.add(\"Set-Cookie\", \"a=b\")\n        headers.add(\"Set-Cookie\", \"c=d\")\n        headers.add(\"Content-Type\", \"text/html\")\n        pickled = pickle.dumps(headers)\n        unpickled = pickle.loads(pickled)\n        self.assertEqual(sorted(headers.get_all()), sorted(unpickled.get_all()))\n        self.assertEqual(sorted(headers.items()), sorted(unpickled.items()))", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Tests that HTTPHeaders objects can be serialized and deserialized with pickle without losing header data, ensuring data consistency across pickle roundtrips."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_setdefault", "line_number": 373, "body": "def test_setdefault(self):\n        headers = HTTPHeaders()\n        headers[\"foo\"] = \"bar\"\n        # If a value is present, setdefault returns it without changes.\n        self.assertEqual(headers.setdefault(\"foo\", \"baz\"), \"bar\")\n        self.assertEqual(headers[\"foo\"], \"bar\")\n        # If a value is not present, setdefault sets it for future use.\n        self.assertEqual(headers.setdefault(\"quux\", \"xyzzy\"), \"xyzzy\")\n        self.assertEqual(headers[\"quux\"], \"xyzzy\")\n        self.assertEqual(sorted(headers.get_all()), [(\"Foo\", \"bar\"), (\"Quux\", \"xyzzy\")])", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "This test method verifies that the HTTPHeaders class's setdefault function returns existing values unchanged and sets new default values when keys don't exist. It ensures correct behavior for managing HTTP header entries."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_string", "line_number": 384, "body": "def test_string(self):\n        headers = HTTPHeaders()\n        headers.add(\"Foo\", \"1\")\n        headers.add(\"Foo\", \"2\")\n        headers.add(\"Foo\", \"3\")\n        headers2 = HTTPHeaders.parse(str(headers))\n        self.assertEqual(headers, headers2)", "is_method": true, "class_name": "HTTPHeadersTest", "function_description": "Unit test method in HTTPHeadersTest that verifies adding multiple headers and correctly parsing them back preserves the header collection's integrity and equivalence."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "check", "line_number": 398, "body": "def check(self, value):\n        self.assertEqual(format_timestamp(value), self.EXPECTED)", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Method in FormatTimestampTest that verifies if the format_timestamp function correctly converts a given value to the expected timestamp string. It serves as a test assertion to ensure formatting consistency."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_unix_time_float", "line_number": 401, "body": "def test_unix_time_float(self):\n        self.check(self.TIMESTAMP)", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Test method of the FormatTimestampTest class that validates the handling or formatting of a floating-point Unix timestamp. It ensures correct processing of timestamp values in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_unix_time_int", "line_number": 404, "body": "def test_unix_time_int(self):\n        self.check(int(self.TIMESTAMP))", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Test method in FormatTimestampTest class that verifies handling of Unix timestamps represented as integers. It ensures the system processes integer-format timestamps correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_struct_time", "line_number": 407, "body": "def test_struct_time(self):\n        self.check(time.gmtime(self.TIMESTAMP))", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Test method in FormatTimestampTest that verifies correct formatting or handling of structured time generated from a timestamp. It ensures time.gmtime produces expected results for given timestamps."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_time_tuple", "line_number": 410, "body": "def test_time_tuple(self):\n        tup = tuple(time.gmtime(self.TIMESTAMP))\n        self.assertEqual(9, len(tup))\n        self.check(tup)", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Verifies that converting a timestamp to a UTC time tuple produces a tuple of the expected length and valid content. This test ensures correct formatting and integrity of time tuple representations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_datetime", "line_number": 415, "body": "def test_datetime(self):\n        self.check(datetime.datetime.utcfromtimestamp(self.TIMESTAMP))", "is_method": true, "class_name": "FormatTimestampTest", "function_description": "Test method that verifies correct formatting or handling of a UTC datetime derived from a specific timestamp value. It ensures the datetime conversion behaves as expected within the FormatTimestampTest class context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_default_constructor", "line_number": 422, "body": "def test_default_constructor(self):\n        # All parameters are formally optional, but uri is required\n        # (and has been for some time).  This test ensures that no\n        # more required parameters slip in.\n        HTTPServerRequest(uri=\"/\")", "is_method": true, "class_name": "HTTPServerRequestTest", "function_description": "Test method in HTTPServerRequestTest that verifies the HTTPServerRequest constructor requires only the uri parameter, ensuring no unintended required parameters are added."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_body_is_a_byte_string", "line_number": 428, "body": "def test_body_is_a_byte_string(self):\n        requets = HTTPServerRequest(uri=\"/\")\n        self.assertIsInstance(requets.body, bytes)", "is_method": true, "class_name": "HTTPServerRequestTest", "function_description": "Unit test in HTTPServerRequestTest verifying that the HTTPServerRequest's body attribute is returned as a byte string."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_repr_does_not_contain_headers", "line_number": 432, "body": "def test_repr_does_not_contain_headers(self):\n        request = HTTPServerRequest(\n            uri=\"/\", headers=HTTPHeaders({\"Canary\": [\"Coal Mine\"]})\n        )\n        self.assertTrue(\"Canary\" not in repr(request))", "is_method": true, "class_name": "HTTPServerRequestTest", "function_description": "Tests that the string representation of an HTTPServerRequest instance does not include its headers, ensuring sensitive header information is not exposed in debug output."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_parse_request_start_line", "line_number": 444, "body": "def test_parse_request_start_line(self):\n        start_line = \" \".join([self.METHOD, self.PATH, self.VERSION])\n        parsed_start_line = parse_request_start_line(start_line)\n        self.assertEqual(parsed_start_line.method, self.METHOD)\n        self.assertEqual(parsed_start_line.path, self.PATH)\n        self.assertEqual(parsed_start_line.version, self.VERSION)", "is_method": true, "class_name": "ParseRequestStartLineTest", "function_description": "Tests that the parse_request_start_line function correctly parses HTTP request start lines into their method, path, and version components. It ensures proper extraction of these key elements for HTTP request processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_python_cookies", "line_number": 455, "body": "def test_python_cookies(self):\n        \"\"\"\n        Test cases copied from Python's Lib/test/test_http_cookies.py\n        \"\"\"\n        self.assertEqual(\n            parse_cookie(\"chips=ahoy; vienna=finger\"),\n            {\"chips\": \"ahoy\", \"vienna\": \"finger\"},\n        )\n        # Here parse_cookie() differs from Python's cookie parsing in that it\n        # treats all semicolons as delimiters, even within quotes.\n        self.assertEqual(\n            parse_cookie('keebler=\"E=mc2; L=\\\\\"Loves\\\\\"; fudge=\\\\012;\"'),\n            {\"keebler\": '\"E=mc2', \"L\": '\\\\\"Loves\\\\\"', \"fudge\": \"\\\\012\", \"\": '\"'},\n        )\n        # Illegal cookies that have an '=' char in an unquoted value.\n        self.assertEqual(parse_cookie(\"keebler=E=mc2\"), {\"keebler\": \"E=mc2\"})\n        # Cookies with ':' character in their name.\n        self.assertEqual(\n            parse_cookie(\"key:term=value:term\"), {\"key:term\": \"value:term\"}\n        )\n        # Cookies with '[' and ']'.\n        self.assertEqual(\n            parse_cookie(\"a=b; c=[; d=r; f=h\"), {\"a\": \"b\", \"c\": \"[\", \"d\": \"r\", \"f\": \"h\"}\n        )", "is_method": true, "class_name": "ParseCookieTest", "function_description": "Unit test method in ParseCookieTest that verifies the parse_cookie function handles various cookie string formats correctly, ensuring robust parsing of cookie key-value pairs under different scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_cookie_edgecases", "line_number": 480, "body": "def test_cookie_edgecases(self):\n        # Cookies that RFC6265 allows.\n        self.assertEqual(\n            parse_cookie(\"a=b; Domain=example.com\"), {\"a\": \"b\", \"Domain\": \"example.com\"}\n        )\n        # parse_cookie() has historically kept only the last cookie with the\n        # same name.\n        self.assertEqual(parse_cookie(\"a=b; h=i; a=c\"), {\"a\": \"c\", \"h\": \"i\"})", "is_method": true, "class_name": "ParseCookieTest", "function_description": "Test method of ParseCookieTest that verifies correct parsing of cookie strings, including handling of RFC6265-compliant cookies and keeping only the last occurrence of duplicate cookie names."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httputil_test.py", "function": "test_invalid_cookies", "line_number": 489, "body": "def test_invalid_cookies(self):\n        \"\"\"\n        Cookie strings that go against RFC6265 but browsers will send if set\n        via document.cookie.\n        \"\"\"\n        # Chunks without an equals sign appear as unnamed values per\n        # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n        self.assertIn(\n            \"django_language\",\n            parse_cookie(\"abc=def; unnamed; django_language=en\").keys(),\n        )\n        # Even a double quote may be an unamed value.\n        self.assertEqual(parse_cookie('a=b; \"; c=d'), {\"a\": \"b\", \"\": '\"', \"c\": \"d\"})\n        # Spaces in names and values, and an equals sign in values.\n        self.assertEqual(\n            parse_cookie(\"a b c=d e = f; gh=i\"), {\"a b c\": \"d e = f\", \"gh\": \"i\"}\n        )\n        # More characters the spec forbids.\n        self.assertEqual(\n            parse_cookie('a   b,c<>@:/[]?{}=d  \"  =e,f g'),\n            {\"a   b,c<>@:/[]?{}\": 'd  \"  =e,f g'},\n        )\n        # Unicode characters. The spec only allows ASCII.\n        self.assertEqual(\n            parse_cookie(\"saint=Andr\u00e9 Bessette\"),\n            {\"saint\": native_str(\"Andr\u00e9 Bessette\")},\n        )\n        # Browsers don't send extra whitespace or semicolons in Cookie headers,\n        # but parse_cookie() should parse whitespace the same way\n        # document.cookie parses whitespace.\n        self.assertEqual(\n            parse_cookie(\"  =  b  ;  ;  =  ;   c  =  ;  \"), {\"\": \"b\", \"c\": \"\"}\n        )", "is_method": true, "class_name": "ParseCookieTest", "function_description": "Tests the parse_cookie function's handling of malformed or non-standard cookie strings, ensuring robust parsing of invalid or unconventional cookies that browsers might still send despite violating RFC6265."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "ignore_bytes_warning", "line_number": 33, "body": "def ignore_bytes_warning():\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=BytesWarning)\n        yield", "is_method": false, "function_description": "Context manager that suppresses BytesWarning warnings within its scope, allowing code to run without these warnings interrupting execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "setUp", "line_number": 46, "body": "def setUp(self):\n        self.formatter = LogFormatter(color=False)\n        # Fake color support.  We can't guarantee anything about the $TERM\n        # variable when the tests are run, so just patch in some values\n        # for testing.  (testing with color off fails to expose some potential\n        # encoding issues from the control characters)\n        self.formatter._colors = {logging.ERROR: u\"\\u0001\"}\n        self.formatter._normal = u\"\\u0002\"\n        # construct a Logger directly to bypass getLogger's caching\n        self.logger = logging.Logger(\"LogFormatterTest\")\n        self.logger.propagate = False\n        self.tempdir = tempfile.mkdtemp()\n        self.filename = os.path.join(self.tempdir, \"log.out\")\n        self.handler = self.make_handler(self.filename)\n        self.handler.setFormatter(self.formatter)\n        self.logger.addHandler(self.handler)", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Sets up the test environment by initializing a LogFormatter instance, a logger, and a file handler to capture log outputs, enabling controlled and isolated testing of log formatting behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "tearDown", "line_number": 63, "body": "def tearDown(self):\n        self.handler.close()\n        os.unlink(self.filename)\n        os.rmdir(self.tempdir)", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Cleanup method that closes log handlers and removes temporary files and directories used during testing to ensure no residual data remains after each test run."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "make_handler", "line_number": 68, "body": "def make_handler(self, filename):\n        # Base case: default setup without explicit encoding.\n        # In python 2, supports arbitrary byte strings and unicode objects\n        # that contain only ascii.  In python 3, supports ascii-only unicode\n        # strings (but byte strings will be repr'd automatically).\n        return logging.FileHandler(filename)", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Provides a logging handler that writes log records to a specified file, supporting compatible encoding behavior across Python versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "get_output", "line_number": 75, "body": "def get_output(self):\n        with open(self.filename, \"rb\") as f:\n            line = f.read().strip()\n            m = LogFormatterTest.LINE_RE.match(line)\n            if m:\n                return m.group(1)\n            else:\n                raise Exception(\"output didn't match regex: %r\" % line)", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Retrieves and returns the formatted log output from a file by matching it against a predefined pattern, raising an error if the output format is invalid."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_basic_logging", "line_number": 84, "body": "def test_basic_logging(self):\n        self.logger.error(\"foo\")\n        self.assertEqual(self.get_output(), b\"foo\")", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Test method in LogFormatterTest that verifies basic error logging outputs the expected message."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_bytes_logging", "line_number": 88, "body": "def test_bytes_logging(self):\n        with ignore_bytes_warning():\n            # This will be \"\\xe9\" on python 2 or \"b'\\xe9'\" on python 3\n            self.logger.error(b\"\\xe9\")\n            self.assertEqual(self.get_output(), utf8(repr(b\"\\xe9\")))", "is_method": true, "class_name": "LogFormatterTest", "function_description": "This test method verifies that logging byte strings correctly handles encoding warnings and outputs the expected UTF-8 representation, ensuring byte data is properly logged without errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_utf8_logging", "line_number": 94, "body": "def test_utf8_logging(self):\n        with ignore_bytes_warning():\n            self.logger.error(u\"\\u00e9\".encode(\"utf8\"))\n        if issubclass(bytes, basestring_type):\n            # on python 2, utf8 byte strings (and by extension ascii byte\n            # strings) are passed through as-is.\n            self.assertEqual(self.get_output(), utf8(u\"\\u00e9\"))\n        else:\n            # on python 3, byte strings always get repr'd even if\n            # they're ascii-only, so this degenerates into another\n            # copy of test_bytes_logging.\n            self.assertEqual(self.get_output(), utf8(repr(utf8(u\"\\u00e9\"))))", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Tests that UTF-8 encoded byte strings are correctly logged, verifying proper handling differences between Python 2 and 3 environments. It ensures the logger outputs expected UTF-8 representations without errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_bytes_exception_logging", "line_number": 107, "body": "def test_bytes_exception_logging(self):\n        try:\n            raise Exception(b\"\\xe9\")\n        except Exception:\n            self.logger.exception(\"caught exception\")\n        # This will be \"Exception: \\xe9\" on python 2 or\n        # \"Exception: b'\\xe9'\" on python 3.\n        output = self.get_output()\n        self.assertRegexpMatches(output, br\"Exception.*\\\\xe9\")\n        # The traceback contains newlines, which should not have been escaped.\n        self.assertNotIn(br\"\\n\", output)", "is_method": true, "class_name": "LogFormatterTest", "function_description": "Tests that exceptions containing byte strings are correctly logged without escaping newline characters, ensuring proper formatting of exception messages in logs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "make_handler", "line_number": 121, "body": "def make_handler(self, filename):\n        # Adding an explicit encoding configuration allows non-ascii unicode\n        # strings in both python 2 and 3, without changing the behavior\n        # for byte strings.\n        return logging.FileHandler(filename, encoding=\"utf8\")", "is_method": true, "class_name": "UnicodeLogFormatterTest", "function_description": "Provides a logging handler configured to write log messages to a file with UTF-8 encoding, ensuring proper handling of non-ASCII Unicode strings across Python versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_unicode_logging", "line_number": 127, "body": "def test_unicode_logging(self):\n        self.logger.error(u\"\\u00e9\")\n        self.assertEqual(self.get_output(), utf8(u\"\\u00e9\"))", "is_method": true, "class_name": "UnicodeLogFormatterTest", "function_description": "Tests that the logger correctly handles and outputs Unicode characters, ensuring proper encoding during error logging in the UnicodeLogFormatterTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "setUp", "line_number": 133, "body": "def setUp(self):\n        super().setUp()\n        self.options = OptionParser()\n        define_logging_options(self.options)\n        self.logger = logging.Logger(\"tornado.test.log_test.EnablePrettyLoggingTest\")\n        self.logger.propagate = False", "is_method": true, "class_name": "EnablePrettyLoggingTest", "function_description": "Setup method in EnablePrettyLoggingTest that initializes logging options and a dedicated logger instance for controlled and isolated test logging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_log_file", "line_number": 140, "body": "def test_log_file(self):\n        tmpdir = tempfile.mkdtemp()\n        try:\n            self.options.log_file_prefix = tmpdir + \"/test_log\"\n            enable_pretty_logging(options=self.options, logger=self.logger)\n            self.assertEqual(1, len(self.logger.handlers))\n            self.logger.error(\"hello\")\n            self.logger.handlers[0].flush()\n            filenames = glob.glob(tmpdir + \"/test_log*\")\n            self.assertEqual(1, len(filenames))\n            with open(filenames[0]) as f:\n                self.assertRegexpMatches(f.read(), r\"^\\[E [^]]*\\] hello$\")\n        finally:\n            for handler in self.logger.handlers:\n                handler.flush()\n                handler.close()\n            for filename in glob.glob(tmpdir + \"/test_log*\"):\n                os.unlink(filename)\n            os.rmdir(tmpdir)", "is_method": true, "class_name": "EnablePrettyLoggingTest", "function_description": "Tests whether enabling pretty logging correctly creates a log file with a formatted error message and ensures proper handler setup and cleanup. It validates the logging output and file management for the EnablePrettyLoggingTest configuration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_log_file_with_timed_rotating", "line_number": 160, "body": "def test_log_file_with_timed_rotating(self):\n        tmpdir = tempfile.mkdtemp()\n        try:\n            self.options.log_file_prefix = tmpdir + \"/test_log\"\n            self.options.log_rotate_mode = \"time\"\n            enable_pretty_logging(options=self.options, logger=self.logger)\n            self.logger.error(\"hello\")\n            self.logger.handlers[0].flush()\n            filenames = glob.glob(tmpdir + \"/test_log*\")\n            self.assertEqual(1, len(filenames))\n            with open(filenames[0]) as f:\n                self.assertRegexpMatches(f.read(), r\"^\\[E [^]]*\\] hello$\")\n        finally:\n            for handler in self.logger.handlers:\n                handler.flush()\n                handler.close()\n            for filename in glob.glob(tmpdir + \"/test_log*\"):\n                os.unlink(filename)\n            os.rmdir(tmpdir)", "is_method": true, "class_name": "EnablePrettyLoggingTest", "function_description": "Unit test method in EnablePrettyLoggingTest that verifies logging to a time-rotated log file writes accurately formatted error messages and manages temporary log files correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_wrong_rotate_mode_value", "line_number": 180, "body": "def test_wrong_rotate_mode_value(self):\n        try:\n            self.options.log_file_prefix = \"some_path\"\n            self.options.log_rotate_mode = \"wrong_mode\"\n            self.assertRaises(\n                ValueError,\n                enable_pretty_logging,\n                options=self.options,\n                logger=self.logger,\n            )\n        finally:\n            for handler in self.logger.handlers:\n                handler.flush()\n                handler.close()", "is_method": true, "class_name": "EnablePrettyLoggingTest", "function_description": "This test method validates that enabling pretty logging with an invalid rotate mode raises a ValueError, ensuring robustness in logging configuration error handling. It supports reliable logger setup by verifying input validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "logs_present", "line_number": 199, "body": "def logs_present(self, statement, args=None):\n        # Each test may manipulate and/or parse the options and then logs\n        # a line at the 'info' level.  This level is ignored in the\n        # logging module by default, but Tornado turns it on by default\n        # so it is the easiest way to tell whether tornado's logging hooks\n        # ran.\n        IMPORT = \"from tornado.options import options, parse_command_line\"\n        LOG_INFO = 'import logging; logging.info(\"hello\")'\n        program = \";\".join([IMPORT, statement, LOG_INFO])\n        proc = subprocess.Popen(\n            [sys.executable, \"-c\", program] + (args or []),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        stdout, stderr = proc.communicate()\n        self.assertEqual(proc.returncode, 0, \"process failed: %r\" % stdout)\n        return b\"hello\" in stdout", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Checks if a given code snippet triggers Tornado's logging hooks by running it in a subprocess and verifying if an \"info\" level log output is present. Useful for testing logging behaviors in dynamic code execution contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_default", "line_number": 217, "body": "def test_default(self):\n        self.assertFalse(self.logs_present(\"pass\"))", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Unit test method in LoggingOptionTest that verifies no logs are present for a \"pass\" event, ensuring correct default logging behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_tornado_default", "line_number": 220, "body": "def test_tornado_default(self):\n        self.assertTrue(self.logs_present(\"parse_command_line()\"))", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Simple test method in LoggingOptionTest that checks whether log entries containing \"parse_command_line()\" are present, ensuring basic logging functionality works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_disable_command_line", "line_number": 223, "body": "def test_disable_command_line(self):\n        self.assertFalse(self.logs_present(\"parse_command_line()\", [\"--logging=none\"]))", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Method in LoggingOptionTest that verifies no logging occurs when the command-line option to disable logging is specified. It ensures the logging suppression functionality works correctly during command-line parsing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_disable_command_line_case_insensitive", "line_number": 226, "body": "def test_disable_command_line_case_insensitive(self):\n        self.assertFalse(self.logs_present(\"parse_command_line()\", [\"--logging=None\"]))", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Tests that logging is correctly disabled via a case-insensitive command line argument, ensuring no related logs are generated when specifying \"--logging=None\"."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_disable_code_string", "line_number": 229, "body": "def test_disable_code_string(self):\n        self.assertFalse(\n            self.logs_present('options.logging = \"none\"; parse_command_line()')\n        )", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Tests that disabling logging via a specific code string correctly prevents any logs from being recorded, ensuring the logging option functions as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_disable_code_none", "line_number": 234, "body": "def test_disable_code_none(self):\n        self.assertFalse(\n            self.logs_present(\"options.logging = None; parse_command_line()\")\n        )", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Tests that disabling logging by setting the logging option to None prevents any logs from being generated during command-line parsing. This method verifies correct log suppression behavior in the LoggingOptionTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/log_test.py", "function": "test_disable_override", "line_number": 239, "body": "def test_disable_override(self):\n        # command line trumps code defaults\n        self.assertTrue(\n            self.logs_present(\n                \"options.logging = None; parse_command_line()\", [\"--logging=info\"]\n            )\n        )", "is_method": true, "class_name": "LoggingOptionTest", "function_description": "Tests that command-line logging options override default logging settings in code, ensuring the logging configuration respects user-specified command-line arguments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "initialize", "line_number": 49, "body": "def initialize(self, close_future=None, compression_options=None):\n        self.close_future = close_future\n        self.compression_options = compression_options", "is_method": true, "class_name": "TestWebSocketHandler", "function_description": "Initialize the TestWebSocketHandler with optional parameters to manage connection closure and data compression settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_compression_options", "line_number": 53, "body": "def get_compression_options(self):\n        return self.compression_options", "is_method": true, "class_name": "TestWebSocketHandler", "function_description": "Returns the current WebSocket compression options configured for the handler, enabling other components to access compression settings for message transmission."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_close", "line_number": 56, "body": "def on_close(self):\n        if self.close_future is not None:\n            self.close_future.set_result((self.close_code, self.close_reason))", "is_method": true, "class_name": "TestWebSocketHandler", "function_description": "Handles the closure of a WebSocket connection by setting the result of a future with the close code and reason, enabling other components to react to the connection closing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 63, "body": "def on_message(self, message):\n        try:\n            yield self.write_message(message, isinstance(message, bytes))\n        except asyncio.CancelledError:\n            pass\n        except WebSocketClosedError:\n            pass", "is_method": true, "class_name": "EchoHandler", "function_description": "Core handler method of EchoHandler that sends received messages back to the sender, supporting both text and binary data while gracefully handling connection interruptions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 78, "body": "def open(self):\n        methods_to_test = [\n            functools.partial(self.write, \"This should not work\"),\n            functools.partial(self.redirect, \"http://localhost/elsewhere\"),\n            functools.partial(self.set_header, \"X-Test\", \"\"),\n            functools.partial(self.set_cookie, \"Chocolate\", \"Chip\"),\n            functools.partial(self.set_status, 503),\n            self.flush,\n            self.finish,\n        ]\n        for method in methods_to_test:\n            try:\n                # In a websocket context, many RequestHandler methods\n                # raise RuntimeErrors.\n                method()  # type: ignore\n                raise Exception(\"did not get expected exception\")\n            except RuntimeError:\n                pass\n        self.write_message(self.request.headers.get(\"X-Test\", \"\"))", "is_method": true, "class_name": "HeaderHandler", "function_description": "Method in HeaderHandler that verifies certain HTTP-related methods raise errors in a specific context and then sends a WebSocket message with a request header value. It tests method restrictions before communicating header data over a WebSocket."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "set_default_headers", "line_number": 100, "body": "def set_default_headers(self):\n        self.set_header(\"X-Extra-Response-Header\", \"Extra-Response-Value\")", "is_method": true, "class_name": "HeaderEchoHandler", "function_description": "Core method of the HeaderEchoHandler class that sets a default HTTP header for responses, enabling consistent inclusion of extra metadata in all outgoing responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "prepare", "line_number": 103, "body": "def prepare(self):\n        for k, v in self.request.headers.get_all():\n            if k.lower().startswith(\"x-test\"):\n                self.set_header(k, v)", "is_method": true, "class_name": "HeaderEchoHandler", "function_description": "Sets response headers that start with \"x-test\" by copying them from the request, enabling echoing of specific test-related headers back to the client."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get", "line_number": 110, "body": "def get(self):\n        self.write(\"ok\")", "is_method": true, "class_name": "NonWebSocketHandler", "function_description": "Simple handler method in NonWebSocketHandler that responds with a plain \"ok\" message to GET requests, often used for basic health checks or status confirmations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get", "line_number": 115, "body": "def get(self):\n        self.redirect(\"/echo\")", "is_method": true, "class_name": "RedirectHandler", "function_description": "Simple method in RedirectHandler that redirects incoming GET requests to the \"/echo\" endpoint. It serves as a basic URL redirection utility within a web request handling context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 120, "body": "def open(self):\n        self.on_close_called = False\n        self.close(1001, \"goodbye\")", "is_method": true, "class_name": "CloseReasonHandler", "function_description": "Method of CloseReasonHandler that initiates a closure process by resetting the close flag and triggering a close event with a specific code and farewell message. It provides a controlled way to begin a connection termination sequence."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "prepare", "line_number": 127, "body": "def prepare(self):\n        yield gen.moment", "is_method": true, "class_name": "AsyncPrepareHandler", "function_description": "This method yields control momentarily within asynchronous workflows, facilitating concurrency management without performing any specific preparation logic."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 130, "body": "def on_message(self, message):\n        self.write_message(message)", "is_method": true, "class_name": "AsyncPrepareHandler", "function_description": "Handles incoming messages by immediately echoing them back, facilitating real-time asynchronous communication responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 135, "body": "def open(self, arg):\n        self.write_message(arg)", "is_method": true, "class_name": "PathArgsHandler", "function_description": "Simple method in PathArgsHandler that processes an argument by passing it to a message-writing function, enabling handling or logging of input data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "initialize", "line_number": 140, "body": "def initialize(self, **kwargs):\n        super().initialize(**kwargs)\n        self.sleeping = 0", "is_method": true, "class_name": "CoroutineOnMessageHandler", "function_description": "Initializes the CoroutineOnMessageHandler instance, setting up base configurations and resetting the sleeping state. This method prepares the handler for operation by ensuring it starts in an active state."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 145, "body": "def on_message(self, message):\n        if self.sleeping > 0:\n            self.write_message(\"another coroutine is already sleeping\")\n        self.sleeping += 1\n        yield gen.sleep(0.01)\n        self.sleeping -= 1\n        self.write_message(message)", "is_method": true, "class_name": "CoroutineOnMessageHandler", "function_description": "Handles incoming messages by ensuring only one coroutine sleeps at a time, delaying briefly before responding with the message; useful for managing concurrent message processing in asynchronous environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 155, "body": "def on_message(self, message):\n        self.write_message(self.render_string(\"message.html\", message=message))", "is_method": true, "class_name": "RenderMessageHandler", "function_description": "Handles incoming messages by rendering and sending them as HTML responses, enabling dynamic message display in the RenderMessageHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "initialize", "line_number": 160, "body": "def initialize(self, **kwargs):\n        super().initialize(**kwargs)\n        self.select_subprotocol_called = False", "is_method": true, "class_name": "SubprotocolHandler", "function_description": "Resets the subprotocol selection flag during initialization, ensuring the handler starts with a clean state each time it is set up."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "select_subprotocol", "line_number": 164, "body": "def select_subprotocol(self, subprotocols):\n        if self.select_subprotocol_called:\n            raise Exception(\"select_subprotocol called twice\")\n        self.select_subprotocol_called = True\n        if \"goodproto\" in subprotocols:\n            return \"goodproto\"\n        return None", "is_method": true, "class_name": "SubprotocolHandler", "function_description": "Core method of SubprotocolHandler that selects a preferred subprotocol from a list, ensuring it is called only once. It prioritizes \"goodproto\" if available and returns None otherwise."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 172, "body": "def open(self):\n        if not self.select_subprotocol_called:\n            raise Exception(\"select_subprotocol not called\")\n        self.write_message(\"subprotocol=%s\" % self.selected_subprotocol)", "is_method": true, "class_name": "SubprotocolHandler", "function_description": "Method in SubprotocolHandler that validates subprotocol selection before initiating the communication by sending the chosen subprotocol identifier. It ensures protocol negotiation is completed prior to message exchange."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "initialize", "line_number": 179, "body": "def initialize(self, test, **kwargs):\n        super().initialize(**kwargs)\n        self.test = test\n        self.open_finished = False", "is_method": true, "class_name": "OpenCoroutineHandler", "function_description": "Initializes the OpenCoroutineHandler with a test flag and setup parameters, preparing its state for managing coroutine operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 185, "body": "def open(self):\n        yield self.test.message_sent.wait()\n        yield gen.sleep(0.010)\n        self.open_finished = True", "is_method": true, "class_name": "OpenCoroutineHandler", "function_description": "Yields control until a message is sent and a brief delay passes, then marks the opening process as finished. Used to manage asynchronous initialization or readiness signaling within coroutine operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 190, "body": "def on_message(self, message):\n        if not self.open_finished:\n            raise Exception(\"on_message called before open finished\")\n        self.write_message(\"ok\")", "is_method": true, "class_name": "OpenCoroutineHandler", "function_description": "Handles incoming messages only after the open process completes, sending an acknowledgment response. It ensures message processing occurs at the correct communication stage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 197, "body": "def open(self):\n        raise Exception(\"boom\")", "is_method": true, "class_name": "ErrorInOpenHandler", "function_description": "This method intentionally raises an exception when called, simulating an error during the open operation for testing or error-handling validation purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "open", "line_number": 208, "body": "def open(self):\n        self.set_nodelay(True)\n        self.write_message(\"hello\")", "is_method": true, "class_name": "NoDelayHandler", "function_description": "Method of the NoDelayHandler class that enables immediate message sending by disabling output buffering and sends an initial greeting message. It facilitates prompt communication setup in asynchronous message handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "ws_connect", "line_number": 215, "body": "def ws_connect(self, path, **kwargs):\n        ws = yield websocket_connect(\n            \"ws://127.0.0.1:%d%s\" % (self.get_http_port(), path), **kwargs\n        )\n        raise gen.Return(ws)", "is_method": true, "class_name": "WebSocketBaseTestCase", "function_description": "Connects to a WebSocket server at a specified path using the test case's HTTP port, providing an established WebSocket connection for testing asynchronous communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 223, "body": "def get_app(self):\n        self.close_future = Future()  # type: Future[None]\n        return Application(\n            [\n                (\"/echo\", EchoHandler, dict(close_future=self.close_future)),\n                (\"/non_ws\", NonWebSocketHandler),\n                (\"/redirect\", RedirectHandler),\n                (\"/header\", HeaderHandler, dict(close_future=self.close_future)),\n                (\n                    \"/header_echo\",\n                    HeaderEchoHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/close_reason\",\n                    CloseReasonHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/error_in_on_message\",\n                    ErrorInOnMessageHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/async_prepare\",\n                    AsyncPrepareHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/path_args/(.*)\",\n                    PathArgsHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/coroutine\",\n                    CoroutineOnMessageHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\"/render\", RenderMessageHandler, dict(close_future=self.close_future)),\n                (\n                    \"/subprotocol\",\n                    SubprotocolHandler,\n                    dict(close_future=self.close_future),\n                ),\n                (\n                    \"/open_coroutine\",\n                    OpenCoroutineHandler,\n                    dict(close_future=self.close_future, test=self),\n                ),\n                (\"/error_in_open\", ErrorInOpenHandler),\n                (\"/error_in_async_open\", ErrorInAsyncOpenHandler),\n                (\"/nodelay\", NoDelayHandler),\n            ],\n            template_loader=DictLoader({\"message.html\": \"<b>{{ message }}</b>\"}),\n        )", "is_method": true, "class_name": "WebSocketTest", "function_description": "Provides a configured web application instance with multiple WebSocket and HTTP request handlers for testing various WebSocket behaviors and scenarios. This method enables setting up a comprehensive testing environment within the WebSocketTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_http_client", "line_number": 279, "body": "def get_http_client(self):\n        # These tests require HTTP/1; force the use of SimpleAsyncHTTPClient.\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "WebSocketTest", "function_description": "Returns an HTTP client configured to use HTTP/1, specifically for testing purposes requiring SimpleAsyncHTTPClient."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "tearDown", "line_number": 283, "body": "def tearDown(self):\n        super().tearDown()\n        RequestHandler._template_loaders.clear()", "is_method": true, "class_name": "WebSocketTest", "function_description": "Cleans up test environment by invoking the superclass teardown and resetting WebSocket request template loaders to ensure no residual state affects subsequent tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_http_request", "line_number": 287, "body": "def test_http_request(self):\n        # WS server, HTTP client.\n        response = self.fetch(\"/echo\")\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method in WebSocketTest that sends an HTTP request to the /echo endpoint and verifies it returns a 400 error code, ensuring the server rejects improper HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_missing_websocket_key", "line_number": 292, "body": "def test_missing_websocket_key(self):\n        response = self.fetch(\n            \"/echo\",\n            headers={\n                \"Connection\": \"Upgrade\",\n                \"Upgrade\": \"WebSocket\",\n                \"Sec-WebSocket-Version\": \"13\",\n            },\n        )\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection request without the required security key is correctly rejected with a 400 error, ensuring protocol compliance in the WebSocketTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_bad_websocket_version", "line_number": 303, "body": "def test_bad_websocket_version(self):\n        response = self.fetch(\n            \"/echo\",\n            headers={\n                \"Connection\": \"Upgrade\",\n                \"Upgrade\": \"WebSocket\",\n                \"Sec-WebSocket-Version\": \"12\",\n            },\n        )\n        self.assertEqual(response.code, 426)", "is_method": true, "class_name": "WebSocketTest", "function_description": "This test method verifies that the server correctly rejects WebSocket upgrade requests using unsupported protocol versions by returning the appropriate error status code. It ensures compliance with WebSocket version negotiation standards."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_gen", "line_number": 315, "body": "def test_websocket_gen(self):\n        ws = yield self.ws_connect(\"/echo\")\n        yield ws.write_message(\"hello\")\n        response = yield ws.read_message()\n        self.assertEqual(response, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method of the WebSocketTest class that verifies sending and receiving messages over a WebSocket connection to an echo endpoint, ensuring message integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_callbacks", "line_number": 321, "body": "def test_websocket_callbacks(self):\n        websocket_connect(\n            \"ws://127.0.0.1:%d/echo\" % self.get_http_port(), callback=self.stop\n        )\n        ws = self.wait().result()\n        ws.write_message(\"hello\")\n        ws.read_message(self.stop)\n        response = self.wait().result()\n        self.assertEqual(response, \"hello\")\n        self.close_future.add_done_callback(lambda f: self.stop())\n        ws.close()\n        self.wait()", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests WebSocket connection callbacks by validating message sending and receiving sequences, ensuring the WebSocket server echoes messages correctly during asynchronous communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_binary_message", "line_number": 335, "body": "def test_binary_message(self):\n        ws = yield self.ws_connect(\"/echo\")\n        ws.write_message(b\"hello \\xe9\", binary=True)\n        response = yield ws.read_message()\n        self.assertEqual(response, b\"hello \\xe9\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Serves as a test method in WebSocketTest verifying that binary messages can be sent and received correctly over a WebSocket connection, ensuring proper handling of binary data transmission."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_unicode_message", "line_number": 342, "body": "def test_unicode_message(self):\n        ws = yield self.ws_connect(\"/echo\")\n        ws.write_message(u\"hello \\u00e9\")\n        response = yield ws.read_message()\n        self.assertEqual(response, u\"hello \\u00e9\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection correctly sends and receives Unicode messages, ensuring proper handling of non-ASCII characters like accented letters during communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_render_message", "line_number": 349, "body": "def test_render_message(self):\n        ws = yield self.ws_connect(\"/render\")\n        ws.write_message(\"hello\")\n        response = yield ws.read_message()\n        self.assertEqual(response, \"<b>hello</b>\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method of the WebSocketTest class that verifies the /render endpoint wraps received messages in HTML bold tags, ensuring correct message rendering via WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_error_in_on_message", "line_number": 356, "body": "def test_error_in_on_message(self):\n        ws = yield self.ws_connect(\"/error_in_on_message\")\n        ws.write_message(\"hello\")\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            response = yield ws.read_message()\n        self.assertIs(response, None)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Core test method in WebSocketTest that verifies proper handling and logging of exceptions occurring during message processing, ensuring the WebSocket connection closes gracefully after an error."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_http_fail", "line_number": 364, "body": "def test_websocket_http_fail(self):\n        with self.assertRaises(HTTPError) as cm:\n            yield self.ws_connect(\"/notfound\")\n        self.assertEqual(cm.exception.code, 404)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that attempting to connect to an invalid WebSocket endpoint correctly raises an HTTP 404 error. This ensures proper error handling for failed WebSocket HTTP requests in WebSocketTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_http_success", "line_number": 370, "body": "def test_websocket_http_success(self):\n        with self.assertRaises(WebSocketError):\n            yield self.ws_connect(\"/non_ws\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Unit test method in WebSocketTest that verifies a WebSocket connection to a non-WebSocket HTTP endpoint raises an expected WebSocketError."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_http_redirect", "line_number": 375, "body": "def test_websocket_http_redirect(self):\n        with self.assertRaises(HTTPError):\n            yield self.ws_connect(\"/redirect\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method in WebSocketTest that verifies a WebSocket connection attempt to a redirect URL raises an HTTP error, ensuring proper handling of HTTP redirects during WebSocket connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_network_fail", "line_number": 380, "body": "def test_websocket_network_fail(self):\n        sock, port = bind_unused_port()\n        sock.close()\n        with self.assertRaises(IOError):\n            with ExpectLog(gen_log, \".*\"):\n                yield websocket_connect(\n                    \"ws://127.0.0.1:%d/\" % port, connect_timeout=3600\n                )", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method of WebSocketTest that verifies the websocket_connect function raises an IOError when attempting to connect to a closed network port, ensuring proper error handling on network failure."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_close_buffered_data", "line_number": 390, "body": "def test_websocket_close_buffered_data(self):\n        ws = yield websocket_connect(\"ws://127.0.0.1:%d/echo\" % self.get_http_port())\n        ws.write_message(\"hello\")\n        ws.write_message(\"world\")\n        # Close the underlying stream.\n        ws.stream.close()", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests WebSocket behavior when closing the underlying stream while messages are buffered, ensuring proper handling of pending data during connection termination."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_headers", "line_number": 398, "body": "def test_websocket_headers(self):\n        # Ensure that arbitrary headers can be passed through websocket_connect.\n        ws = yield websocket_connect(\n            HTTPRequest(\n                \"ws://127.0.0.1:%d/header\" % self.get_http_port(),\n                headers={\"X-Test\": \"hello\"},\n            )\n        )\n        response = yield ws.read_message()\n        self.assertEqual(response, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that custom headers can be successfully sent and received through a WebSocket connection, verifying header transmission functionality in WebSocketTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_websocket_header_echo", "line_number": 410, "body": "def test_websocket_header_echo(self):\n        # Ensure that headers can be returned in the response.\n        # Specifically, that arbitrary headers passed through websocket_connect\n        # can be returned.\n        ws = yield websocket_connect(\n            HTTPRequest(\n                \"ws://127.0.0.1:%d/header_echo\" % self.get_http_port(),\n                headers={\"X-Test-Hello\": \"hello\"},\n            )\n        )\n        self.assertEqual(ws.headers.get(\"X-Test-Hello\"), \"hello\")\n        self.assertEqual(\n            ws.headers.get(\"X-Extra-Response-Header\"), \"Extra-Response-Value\"\n        )", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that custom headers sent during a WebSocket connection are correctly echoed back in the response, validating header transmission through the WebSocket handshake process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_server_close_reason", "line_number": 426, "body": "def test_server_close_reason(self):\n        ws = yield self.ws_connect(\"/close_reason\")\n        msg = yield ws.read_message()\n        # A message of None means the other side closed the connection.\n        self.assertIs(msg, None)\n        self.assertEqual(ws.close_code, 1001)\n        self.assertEqual(ws.close_reason, \"goodbye\")\n        # The on_close callback is called no matter which side closed.\n        code, reason = yield self.close_future\n        # The client echoed the close code it received to the server,\n        # so the server's close code (returned via close_future) is\n        # the same.\n        self.assertEqual(code, 1001)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that the WebSocket connection correctly handles and reports the close code and reason when the server closes the connection. It verifies proper closure detection and callback behavior for WebSocket close events."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_client_close_reason", "line_number": 441, "body": "def test_client_close_reason(self):\n        ws = yield self.ws_connect(\"/echo\")\n        ws.close(1001, \"goodbye\")\n        code, reason = yield self.close_future\n        self.assertEqual(code, 1001)\n        self.assertEqual(reason, \"goodbye\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection correctly captures the client's close code and reason, verifying proper WebSocket close event handling within the WebSocketTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_write_after_close", "line_number": 449, "body": "def test_write_after_close(self):\n        ws = yield self.ws_connect(\"/close_reason\")\n        msg = yield ws.read_message()\n        self.assertIs(msg, None)\n        with self.assertRaises(WebSocketClosedError):\n            ws.write_message(\"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that writing to a WebSocket after it has been closed raises the appropriate WebSocketClosedError, ensuring correct handling of post-closure write attempts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_async_prepare", "line_number": 457, "body": "def test_async_prepare(self):\n        # Previously, an async prepare method triggered a bug that would\n        # result in a timeout on test shutdown (and a memory leak).\n        ws = yield self.ws_connect(\"/async_prepare\")\n        ws.write_message(\"hello\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method in WebSocketTest that verifies asynchronous preparation does not cause timeouts or memory leaks by establishing a connection, sending a message, and confirming the echoed response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_path_args", "line_number": 466, "body": "def test_path_args(self):\n        ws = yield self.ws_connect(\"/path_args/hello\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Method in WebSocketTest that verifies a WebSocket connection correctly receives the expected message when connected with specific path arguments. It ensures the WebSocket endpoint responds accurately to given URL paths."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_coroutine", "line_number": 472, "body": "def test_coroutine(self):\n        ws = yield self.ws_connect(\"/coroutine\")\n        # Send both messages immediately, coroutine must process one at a time.\n        yield ws.write_message(\"hello1\")\n        yield ws.write_message(\"hello2\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello1\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello2\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket coroutine processes incoming messages sequentially by sending multiple messages and verifying their order of reception."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_check_origin_valid_no_path", "line_number": 483, "body": "def test_check_origin_valid_no_path(self):\n        port = self.get_http_port()\n\n        url = \"ws://127.0.0.1:%d/echo\" % port\n        headers = {\"Origin\": \"http://127.0.0.1:%d\" % port}\n\n        ws = yield websocket_connect(HTTPRequest(url, headers=headers))\n        ws.write_message(\"hello\")\n        response = yield ws.read_message()\n        self.assertEqual(response, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection accepts requests with a valid Origin header lacking a path, ensuring proper origin validation for connections targeting the echo endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_check_origin_valid_with_path", "line_number": 495, "body": "def test_check_origin_valid_with_path(self):\n        port = self.get_http_port()\n\n        url = \"ws://127.0.0.1:%d/echo\" % port\n        headers = {\"Origin\": \"http://127.0.0.1:%d/something\" % port}\n\n        ws = yield websocket_connect(HTTPRequest(url, headers=headers))\n        ws.write_message(\"hello\")\n        response = yield ws.read_message()\n        self.assertEqual(response, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection accepts requests with an Origin header containing a valid path, verifying correct message echo functionality for the WebSocket server."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_check_origin_invalid_partial_url", "line_number": 507, "body": "def test_check_origin_invalid_partial_url(self):\n        port = self.get_http_port()\n\n        url = \"ws://127.0.0.1:%d/echo\" % port\n        headers = {\"Origin\": \"127.0.0.1:%d\" % port}\n\n        with self.assertRaises(HTTPError) as cm:\n            yield websocket_connect(HTTPRequest(url, headers=headers))\n        self.assertEqual(cm.exception.code, 403)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection with an invalid Origin header lacking a proper URL scheme is correctly rejected with a 403 HTTP error. It ensures the server enforces strict origin validation for security."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_check_origin_invalid", "line_number": 518, "body": "def test_check_origin_invalid(self):\n        port = self.get_http_port()\n\n        url = \"ws://127.0.0.1:%d/echo\" % port\n        # Host is 127.0.0.1, which should not be accessible from some other\n        # domain\n        headers = {\"Origin\": \"http://somewhereelse.com\"}\n\n        with self.assertRaises(HTTPError) as cm:\n            yield websocket_connect(HTTPRequest(url, headers=headers))\n\n        self.assertEqual(cm.exception.code, 403)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Method of the WebSocketTest class that verifies the server correctly rejects WebSocket connections with invalid Origin headers, ensuring proper origin-based access control and security enforcement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_check_origin_invalid_subdomains", "line_number": 532, "body": "def test_check_origin_invalid_subdomains(self):\n        port = self.get_http_port()\n\n        url = \"ws://localhost:%d/echo\" % port\n        # Subdomains should be disallowed by default.  If we could pass a\n        # resolver to websocket_connect we could test sibling domains as well.\n        headers = {\"Origin\": \"http://subtenant.localhost\"}\n\n        with self.assertRaises(HTTPError) as cm:\n            yield websocket_connect(HTTPRequest(url, headers=headers))\n\n        self.assertEqual(cm.exception.code, 403)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that websocket connections with invalid subdomain origins are rejected with a 403 error, ensuring proper origin checking to prevent unauthorized cross-origin access in WebSocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_subprotocols", "line_number": 546, "body": "def test_subprotocols(self):\n        ws = yield self.ws_connect(\n            \"/subprotocol\", subprotocols=[\"badproto\", \"goodproto\"]\n        )\n        self.assertEqual(ws.selected_subprotocol, \"goodproto\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"subprotocol=goodproto\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests WebSocket connection handling of subprotocol negotiation, verifying that the server correctly selects and responds with the preferred supported subprotocol from a list of client options."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_subprotocols_not_offered", "line_number": 555, "body": "def test_subprotocols_not_offered(self):\n        ws = yield self.ws_connect(\"/subprotocol\")\n        self.assertIs(ws.selected_subprotocol, None)\n        res = yield ws.read_message()\n        self.assertEqual(res, \"subprotocol=None\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that when no WebSocket subprotocols are offered by the client, the server selects none and responds accordingly. Useful for verifying protocol negotiation behavior in WebSocket connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_open_coroutine", "line_number": 562, "body": "def test_open_coroutine(self):\n        self.message_sent = Event()\n        ws = yield self.ws_connect(\"/open_coroutine\")\n        yield ws.write_message(\"hello\")\n        self.message_sent.set()\n        res = yield ws.read_message()\n        self.assertEqual(res, \"ok\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests the WebSocket connection lifecycle by sending a message and verifying the expected response, ensuring proper open coroutine communication handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_error_in_open", "line_number": 571, "body": "def test_error_in_open(self):\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            ws = yield self.ws_connect(\"/error_in_open\")\n            res = yield ws.read_message()\n        self.assertIsNone(res)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Test method in WebSocketTest that verifies handling of exceptions during WebSocket connection opening, ensuring an error is logged and no message is received."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_error_in_async_open", "line_number": 578, "body": "def test_error_in_async_open(self):\n        with ExpectLog(app_log, \"Uncaught exception\"):\n            ws = yield self.ws_connect(\"/error_in_async_open\")\n            res = yield ws.read_message()\n        self.assertIsNone(res)", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection to \"/error_in_async_open\" correctly logs an uncaught exception and results in no message received, validating error handling during asynchronous connection opening."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_nodelay", "line_number": 585, "body": "def test_nodelay(self):\n        ws = yield self.ws_connect(\"/nodelay\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello\")", "is_method": true, "class_name": "WebSocketTest", "function_description": "Tests that a WebSocket connection to the \"/nodelay\" endpoint successfully receives an initial \"hello\" message, verifying the connection and message delivery in the WebSocketTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "initialize", "line_number": 592, "body": "def initialize(self, **kwargs):\n        super().initialize(**kwargs)\n        self.sleeping = 0", "is_method": true, "class_name": "NativeCoroutineOnMessageHandler", "function_description": "Initializes the NativeCoroutineOnMessageHandler instance, setting up its state and resetting the sleeping counter. This prepares the handler for managing coroutine behaviors upon receiving messages."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 606, "body": "def get_app(self):\n        return Application([(\"/native\", NativeCoroutineOnMessageHandler)])", "is_method": true, "class_name": "WebSocketNativeCoroutineTest", "function_description": "Returns a web application instance configured with a native coroutine message handler for the \"/native\" route, facilitating asynchronous WebSocket communication in testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_native_coroutine", "line_number": 610, "body": "def test_native_coroutine(self):\n        ws = yield self.ws_connect(\"/native\")\n        # Send both messages immediately, coroutine must process one at a time.\n        yield ws.write_message(\"hello1\")\n        yield ws.write_message(\"hello2\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello1\")\n        res = yield ws.read_message()\n        self.assertEqual(res, \"hello2\")", "is_method": true, "class_name": "WebSocketNativeCoroutineTest", "function_description": "Tests that a WebSocket coroutine correctly processes messages one at a time, ensuring ordered send and receive operations during websocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 624, "body": "def get_app(self):\n        class LimitedHandler(TestWebSocketHandler):\n            @property\n            def max_message_size(self):\n                return 1024\n\n            def on_message(self, message):\n                self.write_message(str(len(message)))\n\n        return Application(\n            [\n                (\n                    \"/echo\",\n                    EchoHandler,\n                    dict(compression_options=self.get_server_compression_options()),\n                ),\n                (\n                    \"/limited\",\n                    LimitedHandler,\n                    dict(compression_options=self.get_server_compression_options()),\n                ),\n            ]\n        )", "is_method": true, "class_name": "CompressionTestMixin", "function_description": "Provides a test application with two WebSocket handlers, including a size-limited echo handler, to facilitate testing of message compression behaviors and limits in a WebSocket server environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_message_sizes", "line_number": 658, "body": "def test_message_sizes(self: typing.Any):\n        ws = yield self.ws_connect(\n            \"/echo\", compression_options=self.get_client_compression_options()\n        )\n        # Send the same message three times so we can measure the\n        # effect of the context_takeover options.\n        for i in range(3):\n            ws.write_message(self.MESSAGE)\n            response = yield ws.read_message()\n            self.assertEqual(response, self.MESSAGE)\n        self.assertEqual(ws.protocol._message_bytes_out, len(self.MESSAGE) * 3)\n        self.assertEqual(ws.protocol._message_bytes_in, len(self.MESSAGE) * 3)\n        self.verify_wire_bytes(ws.protocol._wire_bytes_in, ws.protocol._wire_bytes_out)", "is_method": true, "class_name": "CompressionTestMixin", "function_description": "Tests that sending a message multiple times over a WebSocket with compression produces expected message sizes and consistent round-trip data transfer, verifying compression effects and data integrity during communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_size_limit", "line_number": 673, "body": "def test_size_limit(self: typing.Any):\n        ws = yield self.ws_connect(\n            \"/limited\", compression_options=self.get_client_compression_options()\n        )\n        # Small messages pass through.\n        ws.write_message(\"a\" * 128)\n        response = yield ws.read_message()\n        self.assertEqual(response, \"128\")\n        # This message is too big after decompression, but it compresses\n        # down to a size that will pass the initial checks.\n        ws.write_message(\"a\" * 2048)\n        response = yield ws.read_message()\n        self.assertIsNone(response)", "is_method": true, "class_name": "CompressionTestMixin", "function_description": "Tests that a WebSocket connection correctly enforces size limits on compressed messages, allowing small messages while rejecting oversized ones that exceed decompressed size constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "verify_wire_bytes", "line_number": 691, "body": "def verify_wire_bytes(self: typing.Any, bytes_in, bytes_out):\n        # Bytes out includes the 4-byte mask key per message.\n        self.assertEqual(bytes_out, 3 * (len(self.MESSAGE) + 6))\n        self.assertEqual(bytes_in, 3 * (len(self.MESSAGE) + 2))", "is_method": true, "class_name": "UncompressedTestMixin", "function_description": "Utility method in UncompressedTestMixin that asserts expected byte counts for input and output wire data, considering the message length and protocol-specific overhead during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_server_compression_options", "line_number": 703, "body": "def get_server_compression_options(self):\n        return {}", "is_method": true, "class_name": "ServerOnlyCompressionTest", "function_description": "Returns an empty dictionary representing the server's compression options, indicating no compression settings are provided or enabled."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_client_compression_options", "line_number": 708, "body": "def get_client_compression_options(self):\n        return {}", "is_method": true, "class_name": "ClientOnlyCompressionTest", "function_description": "Returns an empty dictionary indicating no client-side compression options are provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_server_compression_options", "line_number": 713, "body": "def get_server_compression_options(self):\n        return {}", "is_method": true, "class_name": "DefaultCompressionTest", "function_description": "Returns the available server compression options, which in this default implementation is an empty set. This function serves as a placeholder for subclasses to specify supported compression methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_client_compression_options", "line_number": 716, "body": "def get_client_compression_options(self):\n        return {}", "is_method": true, "class_name": "DefaultCompressionTest", "function_description": "Returns an empty dictionary representing compression options for a client. It provides a default or placeholder implementation in compression-related workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "verify_wire_bytes", "line_number": 719, "body": "def verify_wire_bytes(self, bytes_in, bytes_out):\n        self.assertLess(bytes_out, 3 * (len(self.MESSAGE) + 6))\n        self.assertLess(bytes_in, 3 * (len(self.MESSAGE) + 2))\n        # Bytes out includes the 4 bytes mask key per message.\n        self.assertEqual(bytes_out, bytes_in + 12)", "is_method": true, "class_name": "DefaultCompressionTest", "function_description": "Method in DefaultCompressionTest that validates transmitted byte sizes fall within expected compression bounds, ensuring output bytes correspond correctly to input plus protocol overhead."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "mask", "line_number": 750, "body": "def mask(self, mask, data):\n        return _websocket_mask_python(mask, data)", "is_method": true, "class_name": "PythonMaskFunctionTest", "function_description": "Provides a utility to apply a masking operation to data using a specified mask, facilitating WebSocket masking processes in Python."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "mask", "line_number": 756, "body": "def mask(self, mask, data):\n        return speedups.websocket_mask(mask, data)", "is_method": true, "class_name": "CythonMaskFunctionTest", "function_description": "Utility method in CythonMaskFunctionTest that applies a WebSocket mask to data, facilitating efficient data masking operations in WebSocket communication protocols."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 761, "body": "def get_app(self):\n        class PingHandler(TestWebSocketHandler):\n            def on_pong(self, data):\n                self.write_message(\"got pong\")\n\n        return Application([(\"/\", PingHandler)], websocket_ping_interval=0.01)", "is_method": true, "class_name": "ServerPeriodicPingTest", "function_description": "Provides a web application with a WebSocket handler that responds to pong messages, enabling periodic ping-pong testing of a server\u2019s WebSocket connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_server_ping", "line_number": 769, "body": "def test_server_ping(self):\n        ws = yield self.ws_connect(\"/\")\n        for i in range(3):\n            response = yield ws.read_message()\n            self.assertEqual(response, \"got pong\")", "is_method": true, "class_name": "ServerPeriodicPingTest", "function_description": "Method of ServerPeriodicPingTest that verifies the server responds with \"got pong\" to periodic ping messages, ensuring connection liveness and proper ping-pong handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 778, "body": "def get_app(self):\n        class PingHandler(TestWebSocketHandler):\n            def on_ping(self, data):\n                self.write_message(\"got ping\")\n\n        return Application([(\"/\", PingHandler)])", "is_method": true, "class_name": "ClientPeriodicPingTest", "function_description": "Provides a web application with a WebSocket handler that responds to ping messages by sending a confirmation message. Useful for testing periodic client-server connectivity via WebSocket pings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_client_ping", "line_number": 786, "body": "def test_client_ping(self):\n        ws = yield self.ws_connect(\"/\", ping_interval=0.01)\n        for i in range(3):\n            response = yield ws.read_message()\n            self.assertEqual(response, \"got ping\")", "is_method": true, "class_name": "ClientPeriodicPingTest", "function_description": "This method tests that a client properly receives ping messages at short intervals by establishing a WebSocket connection and validating expected responses. It ensures the client's responsiveness to periodic server pings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 795, "body": "def get_app(self):\n        class PingHandler(TestWebSocketHandler):\n            def on_ping(self, data):\n                self.write_message(data, binary=isinstance(data, bytes))\n\n        return Application([(\"/\", PingHandler)])", "is_method": true, "class_name": "ManualPingTest", "function_description": "Creates and returns a web application that handles WebSocket ping messages by echoing back received data, facilitating manual ping testing in WebSocket communication scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_manual_ping", "line_number": 803, "body": "def test_manual_ping(self):\n        ws = yield self.ws_connect(\"/\")\n\n        self.assertRaises(ValueError, ws.ping, \"a\" * 126)\n\n        ws.ping(\"hello\")\n        resp = yield ws.read_message()\n        # on_ping always sees bytes.\n        self.assertEqual(resp, b\"hello\")\n\n        ws.ping(b\"binary hello\")\n        resp = yield ws.read_message()\n        self.assertEqual(resp, b\"binary hello\")", "is_method": true, "class_name": "ManualPingTest", "function_description": "Test method of ManualPingTest that verifies websocket ping functionality, ensuring valid payload sizes and correct echo responses for both text and binary pings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "get_app", "line_number": 819, "body": "def get_app(self):\n        return Application([(\"/\", EchoHandler)], websocket_max_message_size=1024)", "is_method": true, "class_name": "MaxMessageSizeTest", "function_description": "Returns a Tornado web Application configured with a maximum websocket message size of 1024 bytes, useful for testing message size limits in websocket communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "test_large_message", "line_number": 823, "body": "def test_large_message(self):\n        ws = yield self.ws_connect(\"/\")\n\n        # Write a message that is allowed.\n        msg = \"a\" * 1024\n        ws.write_message(msg)\n        resp = yield ws.read_message()\n        self.assertEqual(resp, msg)\n\n        # Write a message that is too large.\n        ws.write_message(msg + \"b\")\n        resp = yield ws.read_message()\n        # A message of None means the other side closed the connection.\n        self.assertIs(resp, None)\n        self.assertEqual(ws.close_code, 1009)\n        self.assertEqual(ws.close_reason, \"message too big\")", "is_method": true, "class_name": "MaxMessageSizeTest", "function_description": "Tests if a WebSocket connection correctly handles messages at the maximum allowed size, ensuring messages within limits pass and overly large messages cause connection closure with appropriate error code and reason."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "max_message_size", "line_number": 627, "body": "def max_message_size(self):\n                return 1024", "is_method": true, "class_name": "LimitedHandler", "function_description": "Returns the maximum allowed message size, providing a fixed limit for message handling within the LimitedHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_message", "line_number": 630, "body": "def on_message(self, message):\n                self.write_message(str(len(message)))", "is_method": true, "class_name": "LimitedHandler", "function_description": "Handles incoming messages by responding with the length of the received message as a string. This method supports communication protocols that require simple acknowledgments based on message size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_pong", "line_number": 763, "body": "def on_pong(self, data):\n                self.write_message(\"got pong\")", "is_method": true, "class_name": "PingHandler", "function_description": "Handles a pong response by sending confirmation back, supporting communication keep-alive in network or websocket interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_ping", "line_number": 780, "body": "def on_ping(self, data):\n                self.write_message(\"got ping\")", "is_method": true, "class_name": "PingHandler", "function_description": "Handles incoming ping messages by responding with a confirmation message, enabling connection keep-alive or health checks in communication protocols."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/websocket_test.py", "function": "on_ping", "line_number": 797, "body": "def on_ping(self, data):\n                self.write_message(data, binary=isinstance(data, bytes))", "is_method": true, "class_name": "PingHandler", "function_description": "Handles incoming ping messages by echoing the received data back to the sender, supporting both text and binary formats. It enables connection keep-alive and responsiveness checks in the PingHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "_failing_getaddrinfo", "line_number": 61, "body": "def _failing_getaddrinfo(*args):\n    \"\"\"Dummy implementation of getaddrinfo for use in mocks\"\"\"\n    raise socket.gaierror(errno.EIO, \"mock: lookup failed\")", "is_method": false, "function_description": "This function provides a mock implementation of getaddrinfo that always raises a lookup failure error, useful for simulating socket address resolution failures in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_localhost", "line_number": 45, "body": "def test_localhost(self: typing.Any):\n        addrinfo = yield self.resolver.resolve(\"localhost\", 80, socket.AF_UNSPEC)\n        self.assertIn((socket.AF_INET, (\"127.0.0.1\", 80)), addrinfo)", "is_method": true, "class_name": "_ResolverTestMixin", "function_description": "Tests that resolving \"localhost\" returns the expected IPv4 address and port, verifying correct resolver behavior in the _ResolverTestMixin class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_bad_host", "line_number": 56, "body": "def test_bad_host(self: typing.Any):\n        with self.assertRaises(IOError):\n            yield self.resolver.resolve(\"an invalid domain\", 80, socket.AF_UNSPEC)", "is_method": true, "class_name": "_ResolverErrorTestMixin", "function_description": "Test method in _ResolverErrorTestMixin that verifies the resolver raises an IOError when attempting to resolve an invalid domain, ensuring proper error handling in DNS resolution scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 68, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = BlockingResolver()", "is_method": true, "class_name": "BlockingResolverTest", "function_description": "Set up the test environment by initializing an instance of BlockingResolver, preparing it for subsequent test methods to use."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 77, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = BlockingResolver()\n        self.real_getaddrinfo = socket.getaddrinfo\n        socket.getaddrinfo = _failing_getaddrinfo", "is_method": true, "class_name": "BlockingResolverErrorTest", "function_description": "Sets up the test environment by initializing a BlockingResolver instance and monkey-patching socket.getaddrinfo to simulate failure scenarios for testing error handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "tearDown", "line_number": 83, "body": "def tearDown(self):\n        socket.getaddrinfo = self.real_getaddrinfo\n        super().tearDown()", "is_method": true, "class_name": "BlockingResolverErrorTest", "function_description": "Restores the original DNS resolution function after tests and performs standard teardown operations, ensuring network-related test modifications do not affect subsequent tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 89, "body": "def setUp(self):\n        super().setUp()\n        mapping = {\n            (\"google.com\", 80): (\"1.2.3.4\", 80),\n            (\"google.com\", 80, socket.AF_INET): (\"1.2.3.4\", 80),\n            (\"google.com\", 80, socket.AF_INET6): (\n                \"2a02:6b8:7c:40c:c51e:495f:e23a:3\",\n                80,\n            ),\n        }\n        self.resolver = OverrideResolver(BlockingResolver(), mapping)", "is_method": true, "class_name": "OverrideResolverTest", "function_description": "Sets up the test environment by initializing an OverrideResolver with predefined hostname-to-address mappings for different socket families, supporting subsequent override resolution tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_resolve_multiaddr", "line_number": 102, "body": "def test_resolve_multiaddr(self):\n        result = yield self.resolver.resolve(\"google.com\", 80, socket.AF_INET)\n        self.assertIn((socket.AF_INET, (\"1.2.3.4\", 80)), result)\n\n        result = yield self.resolver.resolve(\"google.com\", 80, socket.AF_INET6)\n        self.assertIn(\n            (socket.AF_INET6, (\"2a02:6b8:7c:40c:c51e:495f:e23a:3\", 80, 0, 0)), result\n        )", "is_method": true, "class_name": "OverrideResolverTest", "function_description": "Tests the resolver\u2019s ability to resolve a hostname and port into IPv4 and IPv6 socket addresses, verifying correct multi-address resolution functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 114, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = ThreadedResolver()", "is_method": true, "class_name": "ThreadedResolverTest", "function_description": "SetUp method initializes the testing environment by creating an instance of ThreadedResolver, preparing the test case for further execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "tearDown", "line_number": 118, "body": "def tearDown(self):\n        self.resolver.close()\n        super().tearDown()", "is_method": true, "class_name": "ThreadedResolverTest", "function_description": "Cleans up resources by closing the resolver after each test, ensuring proper teardown in the ThreadedResolverTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 124, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = BlockingResolver()\n        self.real_getaddrinfo = socket.getaddrinfo\n        socket.getaddrinfo = _failing_getaddrinfo", "is_method": true, "class_name": "ThreadedResolverErrorTest", "function_description": "Sets up testing environment by initializing a resolver and patching the socket's address resolution function to simulate failure scenarios, aiding in the testing of error handling in network resolution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "tearDown", "line_number": 130, "body": "def tearDown(self):\n        socket.getaddrinfo = self.real_getaddrinfo\n        super().tearDown()", "is_method": true, "class_name": "ThreadedResolverErrorTest", "function_description": "Restores the original socket address resolution method after tests and ensures proper cleanup by calling the superclass teardown. It supports maintaining test isolation in network-related test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_import", "line_number": 138, "body": "def test_import(self):\n        TIMEOUT = 5\n\n        # Test for a deadlock when importing a module that runs the\n        # ThreadedResolver at import-time. See resolve_test.py for\n        # full explanation.\n        command = [sys.executable, \"-c\", \"import tornado.test.resolve_test_helper\"]\n\n        start = time.time()\n        popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT))\n        while time.time() - start < TIMEOUT:\n            return_code = popen.poll()\n            if return_code is not None:\n                self.assertEqual(0, return_code)\n                return  # Success.\n            time.sleep(0.05)\n\n        self.fail(\"import timed out\")", "is_method": true, "class_name": "ThreadedResolverImportTest", "function_description": "Tests whether importing a specific module that uses ThreadedResolver completes without deadlock within a timeout. It ensures safe, deadlock-free module import behavior under concurrency conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 169, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = CaresResolver()", "is_method": true, "class_name": "CaresResolverTest", "function_description": "Sets up the test environment by initializing a CaresResolver instance before each test in the CaresResolverTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "setUp", "line_number": 188, "body": "def setUp(self):\n        super().setUp()\n        self.resolver = TwistedResolver()", "is_method": true, "class_name": "TwistedResolverTest", "function_description": "Setup method for TwistedResolverTest that initializes the TwistedResolver instance before each test case runs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_is_valid_ip", "line_number": 194, "body": "def test_is_valid_ip(self):\n        self.assertTrue(is_valid_ip(\"127.0.0.1\"))\n        self.assertTrue(is_valid_ip(\"4.4.4.4\"))\n        self.assertTrue(is_valid_ip(\"::1\"))\n        self.assertTrue(is_valid_ip(\"2620:0:1cfe:face:b00c::3\"))\n        self.assertTrue(not is_valid_ip(\"www.google.com\"))\n        self.assertTrue(not is_valid_ip(\"localhost\"))\n        self.assertTrue(not is_valid_ip(\"4.4.4.4<\"))\n        self.assertTrue(not is_valid_ip(\" 127.0.0.1\"))\n        self.assertTrue(not is_valid_ip(\"\"))\n        self.assertTrue(not is_valid_ip(\" \"))\n        self.assertTrue(not is_valid_ip(\"\\n\"))\n        self.assertTrue(not is_valid_ip(\"\\x00\"))", "is_method": true, "class_name": "IsValidIPTest", "function_description": "Unit test method of the IsValidIPTest class that verifies the correctness of the is_valid_ip function by checking various valid and invalid IP address formats. It ensures reliable IP validation for both IPv4 and IPv6 addresses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_same_port_allocation", "line_number": 210, "body": "def test_same_port_allocation(self):\n        if \"TRAVIS\" in os.environ:\n            self.skipTest(\"dual-stack servers often have port conflicts on travis\")\n        sockets = bind_sockets(0, \"localhost\")\n        try:\n            port = sockets[0].getsockname()[1]\n            self.assertTrue(all(s.getsockname()[1] == port for s in sockets[1:]))\n        finally:\n            for sock in sockets:\n                sock.close()", "is_method": true, "class_name": "TestPortAllocation", "function_description": "Tests that multiple sockets bound to port 0 on localhost receive the same allocated port, ensuring consistent port allocation behavior unless skipped in certain environments."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/netutil_test.py", "function": "test_reuse_port", "line_number": 224, "body": "def test_reuse_port(self):\n        sockets = []  # type: List[socket.socket]\n        socket, port = bind_unused_port(reuse_port=True)\n        try:\n            sockets = bind_sockets(port, \"127.0.0.1\", reuse_port=True)\n            self.assertTrue(all(s.getsockname()[1] == port for s in sockets))\n        finally:\n            socket.close()\n            for sock in sockets:\n                sock.close()", "is_method": true, "class_name": "TestPortAllocation", "function_description": "Tests whether multiple sockets can be bound to the same port using port reuse, ensuring that the system supports binding multiple connections on one port for concurrent network operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_simple", "line_number": 13, "body": "def test_simple(self):\n        template = Template(\"Hello {{ name }}!\")\n        self.assertEqual(template.generate(name=\"Ben\"), b\"Hello Ben!\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Simple test method in the TemplateTest class that verifies whether a template correctly generates a greeting string by substituting a provided name variable."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_bytes", "line_number": 17, "body": "def test_bytes(self):\n        template = Template(\"Hello {{ name }}!\")\n        self.assertEqual(template.generate(name=utf8(\"Ben\")), b\"Hello Ben!\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test for Template class verifying it correctly generates a byte string by substituting variables into a template. It ensures proper handling of UTF-8 encoded input during template rendering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_expressions", "line_number": 21, "body": "def test_expressions(self):\n        template = Template(\"2 + 2 = {{ 2 + 2 }}\")\n        self.assertEqual(template.generate(), b\"2 + 2 = 4\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Simple test method in TemplateTest that verifies the template engine correctly evaluates and renders expressions within double curly braces."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_comment", "line_number": 25, "body": "def test_comment(self):\n        template = Template(\"Hello{# TODO i18n #} {{ name }}!\")\n        self.assertEqual(template.generate(name=utf8(\"Ben\")), b\"Hello Ben!\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test method in TemplateTest that verifies the template engine correctly renders a template string with comments and variable substitution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_include", "line_number": 29, "body": "def test_include(self):\n        loader = DictLoader(\n            {\n                \"index.html\": '{% include \"header.html\" %}\\nbody text',\n                \"header.html\": \"header text\",\n            }\n        )\n        self.assertEqual(\n            loader.load(\"index.html\").generate(), b\"header text\\nbody text\"\n        )", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that including one template within another correctly inserts the included content during template generation, ensuring the template loader handles includes as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_extends", "line_number": 40, "body": "def test_extends(self):\n        loader = DictLoader(\n            {\n                \"base.html\": \"\"\"\\\n<title>{% block title %}default title{% end %}</title>\n<body>{% block body %}default body{% end %}</body>\n\"\"\",\n                \"page.html\": \"\"\"\\\n{% extends \"base.html\" %}\n{% block title %}page title{% end %}\n{% block body %}page body{% end %}\n\"\"\",\n            }\n        )\n        self.assertEqual(\n            loader.load(\"page.html\").generate(),\n            b\"<title>page title</title>\\n<body>page body</body>\\n\",\n        )", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that a template correctly inherits from a base template and overrides its blocks, ensuring template extension and block replacement work as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_relative_load", "line_number": 59, "body": "def test_relative_load(self):\n        loader = DictLoader(\n            {\n                \"a/1.html\": \"{% include '2.html' %}\",\n                \"a/2.html\": \"{% include '../b/3.html' %}\",\n                \"b/3.html\": \"ok\",\n            }\n        )\n        self.assertEqual(loader.load(\"a/1.html\").generate(), b\"ok\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Test method in TemplateTest that verifies correct resolution of relative template includes across nested directories, ensuring the loader properly processes hierarchical template dependencies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_escaping", "line_number": 69, "body": "def test_escaping(self):\n        self.assertRaises(ParseError, lambda: Template(\"{{\"))\n        self.assertRaises(ParseError, lambda: Template(\"{%\"))\n        self.assertEqual(Template(\"{{!\").generate(), b\"{{\")\n        self.assertEqual(Template(\"{%!\").generate(), b\"{%\")\n        self.assertEqual(Template(\"{#!\").generate(), b\"{#\")\n        self.assertEqual(\n            Template(\"{{ 'expr' }} {{!jquery expr}}\").generate(),\n            b\"expr {{jquery expr}}\",\n        )", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that the Template class correctly handles syntax errors and special escaping sequences, ensuring proper parsing and output generation for templates with incomplete or escaped delimiters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_unicode_template", "line_number": 80, "body": "def test_unicode_template(self):\n        template = Template(utf8(u\"\\u00e9\"))\n        self.assertEqual(template.generate(), utf8(u\"\\u00e9\"))", "is_method": true, "class_name": "TemplateTest", "function_description": "Simple test method of the TemplateTest class that verifies a template correctly handles and generates Unicode characters. It ensures Unicode encoding consistency for template processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_unicode_literal_expression", "line_number": 84, "body": "def test_unicode_literal_expression(self):\n        # Unicode literals should be usable in templates.  Note that this\n        # test simulates unicode characters appearing directly in the\n        # template file (with utf8 encoding), i.e. \\u escapes would not\n        # be used in the template file itself.\n        template = Template(utf8(u'{{ \"\\u00e9\" }}'))\n        self.assertEqual(template.generate(), utf8(u\"\\u00e9\"))", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that unicode literal characters can be correctly processed and rendered within templates, ensuring proper handling of UTF-8 encoded unicode content in template files."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_custom_namespace", "line_number": 92, "body": "def test_custom_namespace(self):\n        loader = DictLoader(\n            {\"test.html\": \"{{ inc(5) }}\"}, namespace={\"inc\": lambda x: x + 1}\n        )\n        self.assertEqual(loader.load(\"test.html\").generate(), b\"6\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that the DictLoader correctly applies a custom namespace function during template rendering, verifying the function transforms input as expected. This ensures support for extending template logic with user-defined functions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_apply", "line_number": 98, "body": "def test_apply(self):\n        def upper(s):\n            return s.upper()\n\n        template = Template(utf8(\"{% apply upper %}foo{% end %}\"))\n        self.assertEqual(template.generate(upper=upper), b\"FOO\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that the Template class correctly applies a provided transformation function to the template content during generation. It ensures that custom filters like the uppercase function work as intended in templates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_unicode_apply", "line_number": 105, "body": "def test_unicode_apply(self):\n        def upper(s):\n            return to_unicode(s).upper()\n\n        template = Template(utf8(u\"{% apply upper %}foo \\u00e9{% end %}\"))\n        self.assertEqual(template.generate(upper=upper), utf8(u\"FOO \\u00c9\"))", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test method in TemplateTest that verifies the correct application of a Unicode-aware uppercase filter within a template rendering process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_bytes_apply", "line_number": 112, "body": "def test_bytes_apply(self):\n        def upper(s):\n            return utf8(to_unicode(s).upper())\n\n        template = Template(utf8(u\"{% apply upper %}foo \\u00e9{% end %}\"))\n        self.assertEqual(template.generate(upper=upper), utf8(u\"FOO \\u00c9\"))", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that the Template class correctly applies a custom UTF-8 string transformation filter to template content, ensuring proper handling of Unicode and byte strings during rendering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_if", "line_number": 119, "body": "def test_if(self):\n        template = Template(utf8(\"{% if x > 4 %}yes{% else %}no{% end %}\"))\n        self.assertEqual(template.generate(x=5), b\"yes\")\n        self.assertEqual(template.generate(x=3), b\"no\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Method in TemplateTest that verifies conditional rendering in templates by testing if-else logic for different variable values within the template generation process."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_if_empty_body", "line_number": 124, "body": "def test_if_empty_body(self):\n        template = Template(utf8(\"{% if True %}{% else %}{% end %}\"))\n        self.assertEqual(template.generate(), b\"\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test method in TemplateTest verifying that a template with an empty conditional body produces an empty output when rendered. It ensures correct handling of templates with no content between control flow tags."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_try", "line_number": 128, "body": "def test_try(self):\n        template = Template(\n            utf8(\n                \"\"\"{% try %}\ntry{% set y = 1/x %}\n{% except %}-except\n{% else %}-else\n{% finally %}-finally\n{% end %}\"\"\"\n            )\n        )\n        self.assertEqual(template.generate(x=1), b\"\\ntry\\n-else\\n-finally\\n\")\n        self.assertEqual(template.generate(x=0), b\"\\ntry-except\\n-finally\\n\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test method of TemplateTest that verifies correct execution and output of try-except-else-finally blocks within a template under different input conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_comment_directive", "line_number": 142, "body": "def test_comment_directive(self):\n        template = Template(utf8(\"{% comment blah blah %}foo\"))\n        self.assertEqual(template.generate(), b\"foo\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Test method in TemplateTest that verifies the template engine correctly ignores content inside comment directives during generation. It ensures comment blocks do not appear in the rendered output."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_break_continue", "line_number": 146, "body": "def test_break_continue(self):\n        template = Template(\n            utf8(\n                \"\"\"\\\n{% for i in range(10) %}\n    {% if i == 2 %}\n        {% continue %}\n    {% end %}\n    {{ i }}\n    {% if i == 6 %}\n        {% break %}\n    {% end %}\n{% end %}\"\"\"\n            )\n        )\n        result = template.generate()\n        # remove extraneous whitespace\n        result = b\"\".join(result.split())\n        self.assertEqual(result, b\"013456\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests the Template class's handling of loop control statements by verifying that break and continue keywords behave correctly within a template rendering loop. It ensures iteration control flow produces the expected output."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_break_outside_loop", "line_number": 166, "body": "def test_break_outside_loop(self):\n        try:\n            Template(utf8(\"{% break %}\"))\n            raise Exception(\"Did not get expected exception\")\n        except ParseError:\n            pass", "is_method": true, "class_name": "TemplateTest", "function_description": "Core testing method of the TemplateTest class that verifies the parser correctly raises a ParseError when a break statement appears outside a loop. It ensures template syntax validation enforces correct control flow usage."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_break_in_apply", "line_number": 173, "body": "def test_break_in_apply(self):\n        # This test verifies current behavior, although of course it would\n        # be nice if apply didn't cause seemingly unrelated breakage\n        try:\n            Template(\n                utf8(\"{% for i in [] %}{% apply foo %}{% break %}{% end %}{% end %}\")\n            )\n            raise Exception(\"Did not get expected exception\")\n        except ParseError:\n            pass", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that applying a filter inside a loop raises a parsing error when including a break statement, verifying the Template class's current error handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_no_inherit_future", "line_number": 185, "body": "def test_no_inherit_future(self):\n        # TODO(bdarnell): make a test like this for one of the future\n        # imports available in python 3. Unfortunately they're harder\n        # to use in a template than division was.\n\n        # This file has from __future__ import division...\n        self.assertEqual(1 / 2, 0.5)\n        # ...but the template doesn't\n        template = Template(\"{{ 1 / 2 }}\")\n        self.assertEqual(template.generate(), \"0\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Unit test method in TemplateTest that verifies how future import behavior in the source code does not propagate into template evaluation, ensuring template arithmetic uses default Python division semantics."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_non_ascii_name", "line_number": 196, "body": "def test_non_ascii_name(self):\n        loader = DictLoader({u\"t\\u00e9st.html\": \"hello\"})\n        self.assertEqual(loader.load(u\"t\\u00e9st.html\").generate(), b\"hello\")", "is_method": true, "class_name": "TemplateTest", "function_description": "Tests that the DictLoader correctly handles template names containing non-ASCII characters, ensuring proper loading and rendering of such templates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_expression", "line_number": 202, "body": "def test_error_line_number_expression(self):\n        loader = DictLoader(\n            {\n                \"test.html\": \"\"\"one\ntwo{{1/0}}\nthree\n        \"\"\"\n            }\n        )\n        try:\n            loader.load(\"test.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            self.assertTrue(\"# test.html:2\" in traceback.format_exc())", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that a division-by-zero error in template rendering correctly reports the error line number in the generated stack trace for accurate debugging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_directive", "line_number": 217, "body": "def test_error_line_number_directive(self):\n        loader = DictLoader(\n            {\n                \"test.html\": \"\"\"one\ntwo{%if 1/0%}\nthree{%end%}\n        \"\"\"\n            }\n        )\n        try:\n            loader.load(\"test.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            self.assertTrue(\"# test.html:2\" in traceback.format_exc())", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that a division-by-zero error during template rendering includes the correct source line number in the stack trace, ensuring accurate error reporting from template processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_module", "line_number": 232, "body": "def test_error_line_number_module(self):\n        loader = None  # type: typing.Optional[DictLoader]\n\n        def load_generate(path, **kwargs):\n            assert loader is not None\n            return loader.load(path).generate(**kwargs)\n\n        loader = DictLoader(\n            {\"base.html\": \"{% module Template('sub.html') %}\", \"sub.html\": \"{{1/0}}\"},\n            namespace={\"_tt_modules\": ObjectDict(Template=load_generate)},\n        )\n        try:\n            loader.load(\"base.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            exc_stack = traceback.format_exc()\n            self.assertTrue(\"# base.html:1\" in exc_stack)\n            self.assertTrue(\"# sub.html:1\" in exc_stack)", "is_method": true, "class_name": "StackTraceTest", "function_description": "Test method in StackTraceTest that verifies if error stack traces correctly report the line numbers and source files when exceptions occur during template generation involving module inclusion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_include", "line_number": 251, "body": "def test_error_line_number_include(self):\n        loader = DictLoader(\n            {\"base.html\": \"{% include 'sub.html' %}\", \"sub.html\": \"{{1/0}}\"}\n        )\n        try:\n            loader.load(\"base.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            self.assertTrue(\"# sub.html:1 (via base.html:1)\" in traceback.format_exc())", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that the error traceback correctly includes line numbers and file references from templates when an exception occurs during template rendering, ensuring accurate debugging information."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_extends_base_error", "line_number": 261, "body": "def test_error_line_number_extends_base_error(self):\n        loader = DictLoader(\n            {\"base.html\": \"{{1/0}}\", \"sub.html\": \"{% extends 'base.html' %}\"}\n        )\n        try:\n            loader.load(\"sub.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            exc_stack = traceback.format_exc()\n        self.assertTrue(\"# base.html:1\" in exc_stack)", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that a syntax error in a base template is correctly reported with the proper filename and line number in the traceback when loading a template that extends it. This ensures accurate error localization in template inheritance scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_error_line_number_extends_sub_error", "line_number": 272, "body": "def test_error_line_number_extends_sub_error(self):\n        loader = DictLoader(\n            {\n                \"base.html\": \"{% block 'block' %}{% end %}\",\n                \"sub.html\": \"\"\"\n{% extends 'base.html' %}\n{% block 'block' %}\n{{1/0}}\n{% end %}\n            \"\"\",\n            }\n        )\n        try:\n            loader.load(\"sub.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            self.assertTrue(\"# sub.html:4 (via base.html:1)\" in traceback.format_exc())", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that traceback line numbers correctly extend through template inheritance, ensuring errors in child templates show accurate file and line references for debugging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_multi_includes", "line_number": 290, "body": "def test_multi_includes(self):\n        loader = DictLoader(\n            {\n                \"a.html\": \"{% include 'b.html' %}\",\n                \"b.html\": \"{% include 'c.html' %}\",\n                \"c.html\": \"{{1/0}}\",\n            }\n        )\n        try:\n            loader.load(\"a.html\").generate()\n            self.fail(\"did not get expected exception\")\n        except ZeroDivisionError:\n            self.assertTrue(\n                \"# c.html:1 (via b.html:1, a.html:1)\" in traceback.format_exc()\n            )", "is_method": true, "class_name": "StackTraceTest", "function_description": "Tests that nested template includes correctly propagate errors with clear stack traces, ensuring debugging information shows the include chain when an exception occurs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_details", "line_number": 308, "body": "def test_details(self):\n        loader = DictLoader({\"foo.html\": \"\\n\\n{{\"})\n        with self.assertRaises(ParseError) as cm:\n            loader.load(\"foo.html\")\n        self.assertEqual(\"Missing end expression }} at foo.html:3\", str(cm.exception))\n        self.assertEqual(\"foo.html\", cm.exception.filename)\n        self.assertEqual(3, cm.exception.lineno)", "is_method": true, "class_name": "ParseErrorDetailTest", "function_description": "Unit test method in ParseErrorDetailTest that verifies detailed error information is correctly reported when parsing a malformed template, ensuring accurate filename and line number in parse exceptions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_custom_parse_error", "line_number": 316, "body": "def test_custom_parse_error(self):\n        # Make sure that ParseErrors remain compatible with their\n        # pre-4.3 signature.\n        self.assertEqual(\"asdf at None:0\", str(ParseError(\"asdf\")))", "is_method": true, "class_name": "ParseErrorDetailTest", "function_description": "Test method verifying that the ParseError exception retains compatibility with its legacy string representation format."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "setUp", "line_number": 323, "body": "def setUp(self):\n        self.templates = {\n            \"escaped.html\": \"{% autoescape xhtml_escape %}{{ name }}\",\n            \"unescaped.html\": \"{% autoescape None %}{{ name }}\",\n            \"default.html\": \"{{ name }}\",\n            \"include.html\": \"\"\"\\\nescaped: {% include 'escaped.html' %}\nunescaped: {% include 'unescaped.html' %}\ndefault: {% include 'default.html' %}\n\"\"\",\n            \"escaped_block.html\": \"\"\"\\\n{% autoescape xhtml_escape %}\\\n{% block name %}base: {{ name }}{% end %}\"\"\",\n            \"unescaped_block.html\": \"\"\"\\\n{% autoescape None %}\\\n{% block name %}base: {{ name }}{% end %}\"\"\",\n            # Extend a base template with different autoescape policy,\n            # with and without overriding the base's blocks\n            \"escaped_extends_unescaped.html\": \"\"\"\\\n{% autoescape xhtml_escape %}\\\n{% extends \"unescaped_block.html\" %}\"\"\",\n            \"escaped_overrides_unescaped.html\": \"\"\"\\\n{% autoescape xhtml_escape %}\\\n{% extends \"unescaped_block.html\" %}\\\n{% block name %}extended: {{ name }}{% end %}\"\"\",\n            \"unescaped_extends_escaped.html\": \"\"\"\\\n{% autoescape None %}\\\n{% extends \"escaped_block.html\" %}\"\"\",\n            \"unescaped_overrides_escaped.html\": \"\"\"\\\n{% autoescape None %}\\\n{% extends \"escaped_block.html\" %}\\\n{% block name %}extended: {{ name }}{% end %}\"\"\",\n            \"raw_expression.html\": \"\"\"\\\n{% autoescape xhtml_escape %}\\\nexpr: {{ name }}\nraw: {% raw name %}\"\"\",\n        }", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Sets up a collection of HTML template strings with various autoescaping configurations for testing template rendering behavior under different autoescape rules."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_default_off", "line_number": 361, "body": "def test_default_off(self):\n        loader = DictLoader(self.templates, autoescape=None)\n        name = \"Bobby <table>s\"\n        self.assertEqual(\n            loader.load(\"escaped.html\").generate(name=name), b\"Bobby &lt;table&gt;s\"\n        )\n        self.assertEqual(\n            loader.load(\"unescaped.html\").generate(name=name), b\"Bobby <table>s\"\n        )\n        self.assertEqual(\n            loader.load(\"default.html\").generate(name=name), b\"Bobby <table>s\"\n        )\n\n        self.assertEqual(\n            loader.load(\"include.html\").generate(name=name),\n            b\"escaped: Bobby &lt;table&gt;s\\n\"\n            b\"unescaped: Bobby <table>s\\n\"\n            b\"default: Bobby <table>s\\n\",\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "This test method verifies that template auto-escaping is disabled by default, ensuring that HTML content is only escaped in explicitly marked templates while others render raw HTML as expected. It validates proper handling of escaped and unescaped outputs in different templates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_default_on", "line_number": 381, "body": "def test_default_on(self):\n        loader = DictLoader(self.templates, autoescape=\"xhtml_escape\")\n        name = \"Bobby <table>s\"\n        self.assertEqual(\n            loader.load(\"escaped.html\").generate(name=name), b\"Bobby &lt;table&gt;s\"\n        )\n        self.assertEqual(\n            loader.load(\"unescaped.html\").generate(name=name), b\"Bobby <table>s\"\n        )\n        self.assertEqual(\n            loader.load(\"default.html\").generate(name=name), b\"Bobby &lt;table&gt;s\"\n        )\n\n        self.assertEqual(\n            loader.load(\"include.html\").generate(name=name),\n            b\"escaped: Bobby &lt;table&gt;s\\n\"\n            b\"unescaped: Bobby <table>s\\n\"\n            b\"default: Bobby &lt;table&gt;s\\n\",\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests whether the autoescape feature correctly escapes HTML characters by default in template rendering, ensuring safe and expected output for different template cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_unextended_block", "line_number": 401, "body": "def test_unextended_block(self):\n        loader = DictLoader(self.templates)\n        name = \"<script>\"\n        self.assertEqual(\n            loader.load(\"escaped_block.html\").generate(name=name),\n            b\"base: &lt;script&gt;\",\n        )\n        self.assertEqual(\n            loader.load(\"unescaped_block.html\").generate(name=name), b\"base: <script>\"\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests whether template blocks are correctly auto-escaped or rendered raw, ensuring proper HTML escaping behavior in templates with and without explicit escape control."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_extended_block", "line_number": 412, "body": "def test_extended_block(self):\n        loader = DictLoader(self.templates)\n\n        def render(name):\n            return loader.load(name).generate(name=\"<script>\")\n\n        self.assertEqual(render(\"escaped_extends_unescaped.html\"), b\"base: <script>\")\n        self.assertEqual(\n            render(\"escaped_overrides_unescaped.html\"), b\"extended: &lt;script&gt;\"\n        )\n\n        self.assertEqual(\n            render(\"unescaped_extends_escaped.html\"), b\"base: &lt;script&gt;\"\n        )\n        self.assertEqual(\n            render(\"unescaped_overrides_escaped.html\"), b\"extended: <script>\"\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests template rendering behavior with different combinations of escaped and unescaped content in extended and overridden blocks, ensuring correct HTML escaping handling in templates."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_raw_expression", "line_number": 430, "body": "def test_raw_expression(self):\n        loader = DictLoader(self.templates)\n\n        def render(name):\n            return loader.load(name).generate(name='<>&\"')\n\n        self.assertEqual(\n            render(\"raw_expression.html\"), b\"expr: &lt;&gt;&amp;&quot;\\n\" b'raw: <>&\"'\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Test method in AutoEscapeTest that verifies proper escaping of special characters in rendered templates, ensuring raw expressions remain unescaped while others are correctly HTML-escaped."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_custom_escape", "line_number": 440, "body": "def test_custom_escape(self):\n        loader = DictLoader({\"foo.py\": \"{% autoescape py_escape %}s = {{ name }}\\n\"})\n\n        def py_escape(s):\n            self.assertEqual(type(s), bytes)\n            return repr(native_str(s))\n\n        def render(template, name):\n            return loader.load(template).generate(py_escape=py_escape, name=name)\n\n        self.assertEqual(render(\"foo.py\", \"<html>\"), b\"s = '<html>'\\n\")\n        self.assertEqual(render(\"foo.py\", \"';sys.exit()\"), b\"\"\"s = \"';sys.exit()\"\\n\"\"\")\n        self.assertEqual(\n            render(\"foo.py\", [\"not a string\"]), b\"\"\"s = \"['not a string']\"\\n\"\"\"\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests a custom auto-escaping mechanism in template rendering to ensure values are safely and correctly escaped according to a user-defined escape function."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_manual_minimize_whitespace", "line_number": 456, "body": "def test_manual_minimize_whitespace(self):\n        # Whitespace including newlines is allowed within template tags\n        # and directives, and this is one way to avoid long lines while\n        # keeping extra whitespace out of the rendered output.\n        loader = DictLoader(\n            {\n                \"foo.txt\": \"\"\"\\\n{% for i in items\n  %}{% if i > 0 %}, {% end %}{#\n  #}{{i\n  }}{% end\n%}\"\"\"\n            }\n        )\n        self.assertEqual(\n            loader.load(\"foo.txt\").generate(items=range(5)), b\"0, 1, 2, 3, 4\"\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests that manually minimized whitespace within template tags and directives does not appear in the rendered output, ensuring correct handling of whitespace in template rendering."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_whitespace_by_filename", "line_number": 474, "body": "def test_whitespace_by_filename(self):\n        # Default whitespace handling depends on the template filename.\n        loader = DictLoader(\n            {\n                \"foo.html\": \"   \\n\\t\\n asdf\\t   \",\n                \"bar.js\": \" \\n\\n\\n\\t qwer     \",\n                \"baz.txt\": \"\\t    zxcv\\n\\n\",\n                \"include.html\": \"  {% include baz.txt %} \\n \",\n                \"include.txt\": \"\\t\\t{% include foo.html %}    \",\n            }\n        )\n\n        # HTML and JS files have whitespace compressed by default.\n        self.assertEqual(loader.load(\"foo.html\").generate(), b\"\\nasdf \")\n        self.assertEqual(loader.load(\"bar.js\").generate(), b\"\\nqwer \")\n        # TXT files do not.\n        self.assertEqual(loader.load(\"baz.txt\").generate(), b\"\\t    zxcv\\n\\n\")\n\n        # Each file maintains its own status even when included in\n        # a file of the other type.\n        self.assertEqual(loader.load(\"include.html\").generate(), b\" \\t    zxcv\\n\\n\\n\")\n        self.assertEqual(loader.load(\"include.txt\").generate(), b\"\\t\\t\\nasdf     \")", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests how whitespace is handled differently based on template filenames, verifying that HTML/JS compress whitespace by default while TXT files preserve it, including scenarios with nested template inclusion across file types."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_whitespace_by_loader", "line_number": 497, "body": "def test_whitespace_by_loader(self):\n        templates = {\"foo.html\": \"\\t\\tfoo\\n\\n\", \"bar.txt\": \"\\t\\tbar\\n\\n\"}\n        loader = DictLoader(templates, whitespace=\"all\")\n        self.assertEqual(loader.load(\"foo.html\").generate(), b\"\\t\\tfoo\\n\\n\")\n        self.assertEqual(loader.load(\"bar.txt\").generate(), b\"\\t\\tbar\\n\\n\")\n\n        loader = DictLoader(templates, whitespace=\"single\")\n        self.assertEqual(loader.load(\"foo.html\").generate(), b\" foo\\n\")\n        self.assertEqual(loader.load(\"bar.txt\").generate(), b\" bar\\n\")\n\n        loader = DictLoader(templates, whitespace=\"oneline\")\n        self.assertEqual(loader.load(\"foo.html\").generate(), b\" foo \")\n        self.assertEqual(loader.load(\"bar.txt\").generate(), b\" bar \")", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Tests that the DictLoader correctly handles and preserves whitespace in templates according to different whitespace modes: \"all\", \"single\", and \"oneline\". This ensures template loading respects expected formatting behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_whitespace_directive", "line_number": 511, "body": "def test_whitespace_directive(self):\n        loader = DictLoader(\n            {\n                \"foo.html\": \"\"\"\\\n{% whitespace oneline %}\n    {% for i in range(3) %}\n        {{ i }}\n    {% end %}\n{% whitespace all %}\n    pre\\tformatted\n\"\"\"\n            }\n        )\n        self.assertEqual(\n            loader.load(\"foo.html\").generate(), b\"  0  1  2  \\n    pre\\tformatted\\n\"\n        )", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Unit test in AutoEscapeTest that verifies correct handling of whitespace directives in template loading and rendering, ensuring output formatting behaves as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "setUp", "line_number": 530, "body": "def setUp(self):\n        self.loader = Loader(os.path.join(os.path.dirname(__file__), \"templates\"))", "is_method": true, "class_name": "TemplateLoaderTest", "function_description": "Sets up the test environment by initializing a Loader instance with a predefined templates directory for use in TemplateLoaderTest methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "test_utf8_in_file", "line_number": 533, "body": "def test_utf8_in_file(self):\n        tmpl = self.loader.load(\"utf8.html\")\n        result = tmpl.generate()\n        self.assertEqual(to_unicode(result).strip(), u\"H\\u00e9llo\")", "is_method": true, "class_name": "TemplateLoaderTest", "function_description": "Unit test verifying that the TemplateLoader correctly loads and generates content from a UTF-8 encoded file, ensuring proper handling of Unicode characters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "upper", "line_number": 99, "body": "def upper(s):\n            return s.upper()", "is_method": true, "class_name": "TemplateTest", "function_description": "Utility method of the TemplateTest class that converts a given string to uppercase, facilitating uniform text formatting or comparison tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "upper", "line_number": 106, "body": "def upper(s):\n            return to_unicode(s).upper()", "is_method": true, "class_name": "TemplateTest", "function_description": "Converts the input string to Unicode and returns its uppercase version. Useful for consistent case normalization in text processing within the TemplateTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "upper", "line_number": 113, "body": "def upper(s):\n            return utf8(to_unicode(s).upper())", "is_method": true, "class_name": "TemplateTest", "function_description": "Converts a given string to uppercase, ensuring it is properly encoded in UTF-8 format. This utility supports consistent text processing with Unicode handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "load_generate", "line_number": 235, "body": "def load_generate(path, **kwargs):\n            assert loader is not None\n            return loader.load(path).generate(**kwargs)", "is_method": true, "class_name": "StackTraceTest", "function_description": "Utility method of StackTraceTest that loads content from a specified path and generates output using the loaded content, allowing flexible generation with additional parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "render", "line_number": 415, "body": "def render(name):\n            return loader.load(name).generate(name=\"<script>\")", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Utility method in AutoEscapeTest that loads a resource by name and generates content with a fixed script tag, likely to test or demonstrate automatic escaping in rendered outputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "render", "line_number": 433, "body": "def render(name):\n            return loader.load(name).generate(name='<>&\"')", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Core utility of the AutoEscapeTest class that renders a loaded template by generating output with special characters to test automatic escaping behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "py_escape", "line_number": 443, "body": "def py_escape(s):\n            self.assertEqual(type(s), bytes)\n            return repr(native_str(s))", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Utility method in AutoEscapeTest that asserts the input is bytes and returns its escaped string representation, useful for verifying byte string handling in test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/template_test.py", "function": "render", "line_number": 447, "body": "def render(template, name):\n            return loader.load(template).generate(py_escape=py_escape, name=name)", "is_method": true, "class_name": "AutoEscapeTest", "function_description": "Provides a rendering service by loading a template and generating output with automatic escaping and a specified name parameter, facilitating safe template processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/http1connection_test.py", "function": "setUp", "line_number": 15, "body": "def setUp(self):\n        super().setUp()\n        self.asyncSetUp()", "is_method": true, "class_name": "HTTP1ConnectionTest", "function_description": "Sets up the test environment by running both synchronous and asynchronous initialization steps, preparing the HTTP1ConnectionTest instance for execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/http1connection_test.py", "function": "asyncSetUp", "line_number": 20, "body": "def asyncSetUp(self):\n        listener, port = bind_unused_port()\n        event = Event()\n\n        def accept_callback(conn, addr):\n            self.server_stream = IOStream(conn)\n            self.addCleanup(self.server_stream.close)\n            event.set()\n\n        add_accept_handler(listener, accept_callback)\n        self.client_stream = IOStream(socket.socket())\n        self.addCleanup(self.client_stream.close)\n        yield [self.client_stream.connect((\"127.0.0.1\", port)), event.wait()]\n        self.io_loop.remove_handler(listener)\n        listener.close()", "is_method": true, "class_name": "HTTP1ConnectionTest", "function_description": "Setup method for asynchronous test initialization that binds a server to an unused port, establishes client-server IO streams, and manages cleanup for HTTP connection testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/http1connection_test.py", "function": "test_http10_no_content_length", "line_number": 37, "body": "def test_http10_no_content_length(self):\n        # Regression test for a bug in which can_keep_alive would crash\n        # for an HTTP/1.0 (not 1.1) response with no content-length.\n        conn = HTTP1Connection(self.client_stream, True)\n        self.server_stream.write(b\"HTTP/1.0 200 Not Modified\\r\\n\\r\\nhello\")\n        self.server_stream.close()\n\n        event = Event()\n        test = self\n        body = []\n\n        class Delegate(HTTPMessageDelegate):\n            def headers_received(self, start_line, headers):\n                test.code = start_line.code\n\n            def data_received(self, data):\n                body.append(data)\n\n            def finish(self):\n                event.set()\n\n        yield conn.read_response(Delegate())\n        yield event.wait()\n        self.assertEqual(self.code, 200)\n        self.assertEqual(b\"\".join(body), b\"hello\")", "is_method": true, "class_name": "HTTP1ConnectionTest", "function_description": "Provides a regression test to verify that an HTTP/1.0 response without a Content-Length header is correctly handled without crashing, ensuring proper reading of response code and body in HTTP1Connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/http1connection_test.py", "function": "accept_callback", "line_number": 24, "body": "def accept_callback(conn, addr):\n            self.server_stream = IOStream(conn)\n            self.addCleanup(self.server_stream.close)\n            event.set()", "is_method": true, "class_name": "HTTP1ConnectionTest", "function_description": "Sets up a server stream for a new connection and signals when the connection is ready, facilitating asynchronous handling of incoming HTTP connections during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/http1connection_test.py", "function": "headers_received", "line_number": 49, "body": "def headers_received(self, start_line, headers):\n                test.code = start_line.code", "is_method": true, "class_name": "Delegate", "function_description": "This method updates a status code based on the received HTTP start line during header processing. It facilitates tracking of response status within the Delegate class when headers are received."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_http_client", "line_number": 46, "body": "def get_http_client(self):\n        client = SimpleAsyncHTTPClient(force_instance=True)\n        self.assertTrue(isinstance(client, SimpleAsyncHTTPClient))\n        return client", "is_method": true, "class_name": "SimpleHTTPClientCommonTestCase", "function_description": "Provides a SimpleAsyncHTTPClient instance, ensuring the returned object is correctly instantiated for testing HTTP client functionality within SimpleHTTPClientCommonTestCase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "initialize", "line_number": 53, "body": "def initialize(self, queue, wake_callback):\n        self.queue = queue\n        self.wake_callback = wake_callback", "is_method": true, "class_name": "TriggerHandler", "function_description": "Initializer method of the TriggerHandler class that sets up internal references to a queue and a wake-up callback function for future trigger processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 58, "body": "def get(self):\n        logging.debug(\"queuing trigger\")\n        event = Event()\n        self.queue.append(event.set)\n        if self.get_argument(\"wake\", \"true\") == \"true\":\n            self.wake_callback()\n        yield event.wait()", "is_method": true, "class_name": "TriggerHandler", "function_description": "Core method of TriggerHandler that queues an event trigger and optionally invokes a wake callback, then waits asynchronously for the event to be signaled. It enables coordinated triggering and waiting mechanisms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 68, "body": "def get(self):\n        self.stream = self.detach()\n        IOLoop.current().spawn_callback(self.write_response)", "is_method": true, "class_name": "ContentLengthHandler", "function_description": "Triggers response writing asynchronously after detaching the current stream, enabling non-blocking handling of content length in an asynchronous I/O environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "write_response", "line_number": 73, "body": "def write_response(self):\n        yield self.stream.write(\n            utf8(\n                \"HTTP/1.0 200 OK\\r\\nContent-Length: %s\\r\\n\\r\\nok\"\n                % self.get_argument(\"value\")\n            )\n        )\n        self.stream.close()", "is_method": true, "class_name": "ContentLengthHandler", "function_description": "Produces an HTTP response with a status 200 and a Content-Length header set from a request argument, then closes the stream. Useful for sending simple fixed-content HTTP replies with specified content length."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "head", "line_number": 84, "body": "def head(self):\n        self.set_header(\"Content-Length\", \"7\")", "is_method": true, "class_name": "HeadHandler", "function_description": "Sets the Content-Length header to \"7\" for an HTTP response, ensuring the response indicates a fixed body size. This method supports managing HTTP headers in the HeadHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "options", "line_number": 89, "body": "def options(self):\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.write(\"ok\")", "is_method": true, "class_name": "OptionsHandler", "function_description": "Handles HTTP OPTIONS requests by setting CORS headers and responding with a simple acknowledgment, enabling cross-origin resource sharing support in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 95, "body": "def get(self):\n        self.set_status(204)\n        self.finish()", "is_method": true, "class_name": "NoContentHandler", "function_description": "Handles HTTP GET requests by responding with a 204 No Content status, indicating a successful request with no body content. This method is useful for endpoints that acknowledge requests without returning data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "post", "line_number": 101, "body": "def post(self):\n        redirect_code = int(self.request.body)\n        assert redirect_code in (302, 303), \"unexpected body %r\" % self.request.body\n        self.set_header(\"Location\", \"/see_other_get\")\n        self.set_status(redirect_code)", "is_method": true, "class_name": "SeeOtherPostHandler", "function_description": "Handles POST requests by responding with a 302 or 303 redirect to a predefined URL, enabling HTTP redirection following the POST-Redirect-GET pattern. This facilitates safe URL redirection after form submissions or similar POST actions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 109, "body": "def get(self):\n        if self.request.body:\n            raise Exception(\"unexpected body %r\" % self.request.body)\n        self.write(\"ok\")", "is_method": true, "class_name": "SeeOtherGetHandler", "function_description": "Handler method that verifies the HTTP GET request has no body and responds with a simple \"ok\" message, ensuring correct request format for GET operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 116, "body": "def get(self):\n        self.write(self.request.headers[\"Host\"])", "is_method": true, "class_name": "HostEchoHandler", "function_description": "This method in HostEchoHandler returns the value of the \"Host\" HTTP header from the incoming request, useful for echoing or inspecting the request's target host."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 121, "body": "def get(self):\n        if self.request.version.startswith(\"HTTP/1\"):\n            # Emulate the old HTTP/1.0 behavior of returning a body with no\n            # content-length.  Tornado handles content-length at the framework\n            # level so we have to go around it.\n            stream = self.detach()\n            stream.write(b\"HTTP/1.0 200 OK\\r\\n\\r\\n\" b\"hello\")\n            stream.close()\n        else:\n            self.finish(\"HTTP/1 required\")", "is_method": true, "class_name": "NoContentLengthHandler", "function_description": "Handles HTTP GET requests by returning a response with no Content-Length header for HTTP/1.0 clients, emulating legacy behavior; otherwise, it returns an error message for unsupported HTTP versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "post", "line_number": 134, "body": "def post(self):\n        self.write(self.request.body)", "is_method": true, "class_name": "EchoPostHandler", "function_description": "Handles HTTP POST requests by echoing back the request body exactly as received. This method can be used to verify or debug incoming POST data in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "prepare", "line_number": 140, "body": "def prepare(self):\n        self.set_status(403)\n        self.finish(\"forbidden\")", "is_method": true, "class_name": "RespondInPrepareHandler", "function_description": "Method of RespondInPrepareHandler that sets an HTTP 403 Forbidden status and completes the response with a \"forbidden\" message, typically used to block unauthorized requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 149, "body": "def get_app(self: typing.Any):\n        # callable objects to finish pending /trigger requests\n        self.triggers = (\n            collections.deque()\n        )  # type: typing.Deque[typing.Callable[[], None]]\n        return Application(\n            [\n                url(\n                    \"/trigger\",\n                    TriggerHandler,\n                    dict(queue=self.triggers, wake_callback=self.stop),\n                ),\n                url(\"/chunk\", ChunkHandler),\n                url(\"/countdown/([0-9]+)\", CountdownHandler, name=\"countdown\"),\n                url(\"/hello\", HelloWorldHandler),\n                url(\"/content_length\", ContentLengthHandler),\n                url(\"/head\", HeadHandler),\n                url(\"/options\", OptionsHandler),\n                url(\"/no_content\", NoContentHandler),\n                url(\"/see_other_post\", SeeOtherPostHandler),\n                url(\"/see_other_get\", SeeOtherGetHandler),\n                url(\"/host_echo\", HostEchoHandler),\n                url(\"/no_content_length\", NoContentLengthHandler),\n                url(\"/echo_post\", EchoPostHandler),\n                url(\"/respond_in_prepare\", RespondInPrepareHandler),\n                url(\"/redirect\", RedirectHandler),\n                url(\"/user_agent\", UserAgentHandler),\n            ],\n            gzip=True,\n        )", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Returns a configured web application instance with various request handlers for testing HTTP client interactions, supporting multiple endpoints and triggers for handling different HTTP behaviors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_singleton", "line_number": 180, "body": "def test_singleton(self: typing.Any):\n        # Class \"constructor\" reuses objects on the same IOLoop\n        self.assertTrue(SimpleAsyncHTTPClient() is SimpleAsyncHTTPClient())\n        # unless force_instance is used\n        self.assertTrue(\n            SimpleAsyncHTTPClient() is not SimpleAsyncHTTPClient(force_instance=True)\n        )\n        # different IOLoops use different objects\n        with closing(IOLoop()) as io_loop2:\n\n            async def make_client():\n                await gen.sleep(0)\n                return SimpleAsyncHTTPClient()\n\n            client1 = self.io_loop.run_sync(make_client)\n            client2 = io_loop2.run_sync(make_client)\n            self.assertTrue(client1 is not client2)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Method testing if SimpleAsyncHTTPClient correctly implements a singleton pattern per IOLoop, ensuring shared instances unless explicitly forced, and distinct instances across different IOLoops."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_connection_limit", "line_number": 198, "body": "def test_connection_limit(self: typing.Any):\n        with closing(self.create_client(max_clients=2)) as client:\n            self.assertEqual(client.max_clients, 2)\n            seen = []\n            # Send 4 requests.  Two can be sent immediately, while the others\n            # will be queued\n            for i in range(4):\n\n                def cb(fut, i=i):\n                    seen.append(i)\n                    self.stop()\n\n                client.fetch(self.get_url(\"/trigger\")).add_done_callback(cb)\n            self.wait(condition=lambda: len(self.triggers) == 2)\n            self.assertEqual(len(client.queue), 2)\n\n            # Finish the first two requests and let the next two through\n            self.triggers.popleft()()\n            self.triggers.popleft()()\n            self.wait(condition=lambda: (len(self.triggers) == 2 and len(seen) == 2))\n            self.assertEqual(set(seen), set([0, 1]))\n            self.assertEqual(len(client.queue), 0)\n\n            # Finish all the pending requests\n            self.triggers.popleft()()\n            self.triggers.popleft()()\n            self.wait(condition=lambda: len(seen) == 4)\n            self.assertEqual(set(seen), set([0, 1, 2, 3]))\n            self.assertEqual(len(self.triggers), 0)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that the HTTP client enforces a maximum concurrent connection limit by queuing excess requests and processing them in order as prior requests complete. It ensures correct queuing and callback execution under constrained parallelism."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_redirect_connection_limit", "line_number": 229, "body": "def test_redirect_connection_limit(self: typing.Any):\n        # following redirects should not consume additional connections\n        with closing(self.create_client(max_clients=1)) as client:\n            response = yield client.fetch(self.get_url(\"/countdown/3\"), max_redirects=3)\n            response.rethrow()", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin ensuring that HTTP redirects do not exceed the maximum allowed client connections during request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_max_redirects", "line_number": 235, "body": "def test_max_redirects(self: typing.Any):\n        response = self.fetch(\"/countdown/5\", max_redirects=3)\n        self.assertEqual(302, response.code)\n        # We requested 5, followed three redirects for 4, 3, 2, then the last\n        # unfollowed redirect is to 1.\n        self.assertTrue(response.request.url.endswith(\"/countdown/5\"))\n        self.assertTrue(response.effective_url.endswith(\"/countdown/2\"))\n        self.assertTrue(response.headers[\"Location\"].endswith(\"/countdown/1\"))", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests that the HTTP client respects the maximum number of allowed redirects and verifies the correct response and URLs after reaching that limit. It ensures redirect handling behaves as configured during requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_header_reuse", "line_number": 244, "body": "def test_header_reuse(self: typing.Any):\n        # Apps may reuse a headers object if they are only passing in constant\n        # headers like user-agent.  The header object should not be modified.\n        headers = HTTPHeaders({\"User-Agent\": \"Foo\"})\n        self.fetch(\"/hello\", headers=headers)\n        self.assertEqual(list(headers.get_all()), [(\"User-Agent\", \"Foo\")])", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies HTTP header objects remain unchanged and reusable after making a request, ensuring consistent header behavior across multiple uses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_default_user_agent", "line_number": 251, "body": "def test_default_user_agent(self: typing.Any):\n        response = self.fetch(\"/user_agent\", method=\"GET\")\n        self.assertEqual(200, response.code)\n        self.assertEqual(response.body.decode(), \"Tornado/{}\".format(version))", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests that the HTTP client sends the correct default User-Agent header by verifying the response from a server endpoint. This ensures the client identifies itself properly during requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_see_other_redirect", "line_number": 256, "body": "def test_see_other_redirect(self: typing.Any):\n        for code in (302, 303):\n            response = self.fetch(\"/see_other_post\", method=\"POST\", body=\"%d\" % code)\n            self.assertEqual(200, response.code)\n            self.assertTrue(response.request.url.endswith(\"/see_other_post\"))\n            self.assertTrue(response.effective_url.endswith(\"/see_other_get\"))\n            # request is the original request, is a POST still\n            self.assertEqual(\"POST\", response.request.method)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that HTTP 302 and 303 status codes properly redirect POST requests while preserving the original request method and URL behaviors. It ensures correct handling of \"See Other\" redirects in client-server interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_connect_timeout", "line_number": 267, "body": "def test_connect_timeout(self: typing.Any):\n        timeout = 0.1\n\n        cleanup_event = Event()\n        test = self\n\n        class TimeoutResolver(Resolver):\n            async def resolve(self, *args, **kwargs):\n                await cleanup_event.wait()\n                # Return something valid so the test doesn't raise during shutdown.\n                return [(socket.AF_INET, (\"127.0.0.1\", test.get_http_port()))]\n\n        with closing(self.create_client(resolver=TimeoutResolver())) as client:\n            with self.assertRaises(HTTPTimeoutError):\n                yield client.fetch(\n                    self.get_url(\"/hello\"),\n                    connect_timeout=timeout,\n                    request_timeout=3600,\n                    raise_error=True,\n                )\n\n        # Let the hanging coroutine clean up after itself. We need to\n        # wait more than a single IOLoop iteration for the SSL case,\n        # which logs errors on unexpected EOF.\n        cleanup_event.set()\n        yield gen.sleep(0.2)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies the client correctly raises a timeout error when connection attempts exceed a specified timeout period. It ensures robust handling of connection timeouts during HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_request_timeout", "line_number": 295, "body": "def test_request_timeout(self: typing.Any):\n        timeout = 0.1\n        if os.name == \"nt\":\n            timeout = 0.5\n\n        with self.assertRaises(HTTPTimeoutError):\n            self.fetch(\"/trigger?wake=false\", request_timeout=timeout, raise_error=True)\n        # trigger the hanging request to let it clean up after itself\n        self.triggers.popleft()()\n        self.io_loop.run_sync(lambda: gen.sleep(0))", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies the client correctly raises a timeout error when a request exceeds the specified timeout duration. It ensures proper timeout handling behavior in HTTP requests across platforms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_ipv6", "line_number": 307, "body": "def test_ipv6(self: typing.Any):\n        [sock] = bind_sockets(0, \"::1\", family=socket.AF_INET6)\n        port = sock.getsockname()[1]\n        self.http_server.add_socket(sock)\n        url = \"%s://[::1]:%d/hello\" % (self.get_protocol(), port)\n\n        # ipv6 is currently enabled by default but can be disabled\n        with self.assertRaises(Exception):\n            self.fetch(url, allow_ipv6=False, raise_error=True)\n\n        response = self.fetch(url)\n        self.assertEqual(response.body, b\"Hello world!\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests IPv6 connectivity support of the HTTP client by binding to an IPv6 address, verifying connection behavior with IPv6 enabled and disabled, and confirming successful data retrieval over IPv6."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_multiple_content_length_accepted", "line_number": 320, "body": "def test_multiple_content_length_accepted(self: typing.Any):\n        response = self.fetch(\"/content_length?value=2,2\")\n        self.assertEqual(response.body, b\"ok\")\n        response = self.fetch(\"/content_length?value=2,%202,2\")\n        self.assertEqual(response.body, b\"ok\")\n\n        with ExpectLog(\n            gen_log, \".*Multiple unequal Content-Lengths\", level=logging.INFO\n        ):\n            with self.assertRaises(HTTPStreamClosedError):\n                self.fetch(\"/content_length?value=2,4\", raise_error=True)\n            with self.assertRaises(HTTPStreamClosedError):\n                self.fetch(\"/content_length?value=2,%202,3\", raise_error=True)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that the HTTP client correctly accepts multiple identical Content-Length headers while raising errors for multiple unequal Content-Length headers, ensuring proper handling of HTTP header compliance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_head_request", "line_number": 334, "body": "def test_head_request(self: typing.Any):\n        response = self.fetch(\"/head\", method=\"HEAD\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.headers[\"content-length\"], \"7\")\n        self.assertFalse(response.body)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies the HTTP HEAD request returns a 200 status, correct content-length header, and no response body. It ensures proper server handling of HEAD requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_options_request", "line_number": 340, "body": "def test_options_request(self: typing.Any):\n        response = self.fetch(\"/options\", method=\"OPTIONS\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.headers[\"content-length\"], \"2\")\n        self.assertEqual(response.headers[\"access-control-allow-origin\"], \"*\")\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that an OPTIONS HTTP request to the \"/options\" endpoint returns a successful response with expected headers and body content. It ensures correct handling of HTTP OPTIONS requests in the SimpleHTTPClientTestMixin context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_no_content", "line_number": 347, "body": "def test_no_content(self: typing.Any):\n        response = self.fetch(\"/no_content\")\n        self.assertEqual(response.code, 204)\n        # 204 status shouldn't have a content-length\n        #\n        # Tests with a content-length header are included below\n        # in HTTP204NoContentTestCase.\n        self.assertNotIn(\"Content-Length\", response.headers)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies a 204 No Content HTTP response has the correct status code and omits the Content-Length header. It ensures compliance with HTTP standards for no-content responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_host_header", "line_number": 356, "body": "def test_host_header(self: typing.Any):\n        host_re = re.compile(b\"^127.0.0.1:[0-9]+$\")\n        response = self.fetch(\"/host_echo\")\n        self.assertTrue(host_re.match(response.body))\n\n        url = self.get_url(\"/host_echo\").replace(\"http://\", \"http://me:secret@\")\n        response = self.fetch(url)\n        self.assertTrue(host_re.match(response.body), response.body)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests whether the HTTP client's Host header correctly reflects the request's address, ensuring proper header handling with and without embedded authentication credentials."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_connection_refused", "line_number": 365, "body": "def test_connection_refused(self: typing.Any):\n        cleanup_func, port = refusing_port()\n        self.addCleanup(cleanup_func)\n        with ExpectLog(gen_log, \".*\", required=False):\n            with self.assertRaises(socket.error) as cm:\n                self.fetch(\"http://127.0.0.1:%d/\" % port, raise_error=True)\n\n        if sys.platform != \"cygwin\":\n            # cygwin returns EPERM instead of ECONNREFUSED here\n            contains_errno = str(errno.ECONNREFUSED) in str(cm.exception)\n            if not contains_errno and hasattr(errno, \"WSAECONNREFUSED\"):\n                contains_errno = str(errno.WSAECONNREFUSED) in str(  # type: ignore\n                    cm.exception\n                )\n            self.assertTrue(contains_errno, cm.exception)\n            # This is usually \"Connection refused\".\n            # On windows, strerror is broken and returns \"Unknown error\".\n            expected_message = os.strerror(errno.ECONNREFUSED)\n            self.assertTrue(expected_message in str(cm.exception), cm.exception)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests that the HTTP client correctly raises and handles a connection refused error when unable to connect to a specified port. This ensures robust error reporting for connection failures during HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_queue_timeout", "line_number": 385, "body": "def test_queue_timeout(self: typing.Any):\n        with closing(self.create_client(max_clients=1)) as client:\n            # Wait for the trigger request to block, not complete.\n            fut1 = client.fetch(self.get_url(\"/trigger\"), request_timeout=10)\n            self.wait()\n            with self.assertRaises(HTTPTimeoutError) as cm:\n                self.io_loop.run_sync(\n                    lambda: client.fetch(\n                        self.get_url(\"/hello\"), connect_timeout=0.1, raise_error=True\n                    )\n                )\n\n            self.assertEqual(str(cm.exception), \"Timeout in request queue\")\n            self.triggers.popleft()()\n            self.io_loop.run_sync(lambda: fut1)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that the HTTP client correctly raises a timeout error when request queue limits are exceeded, ensuring proper handling of request queuing and timeout behaviors under constrained client capacity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_no_content_length", "line_number": 401, "body": "def test_no_content_length(self: typing.Any):\n        response = self.fetch(\"/no_content_length\")\n        if response.body == b\"HTTP/1 required\":\n            self.skipTest(\"requires HTTP/1.x\")\n        else:\n            self.assertEqual(b\"hello\", response.body)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests that a response from the \"/no_content_length\" endpoint correctly returns expected content or skips the test if HTTP/1.x is required. It verifies handling of responses without a Content-Length header."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "sync_body_producer", "line_number": 408, "body": "def sync_body_producer(self, write):\n        write(b\"1234\")\n        write(b\"5678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "A simple utility method that writes fixed byte sequences to a provided output function, useful for testing synchronous body streaming in HTTP client implementations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "async_body_producer", "line_number": 413, "body": "def async_body_producer(self, write):\n        yield write(b\"1234\")\n        yield gen.moment\n        yield write(b\"5678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Generates asynchronous write operations sending byte chunks sequentially, useful for simulating streaming or chunked HTTP request bodies in asynchronous HTTP client testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_sync_body_producer_chunked", "line_number": 418, "body": "def test_sync_body_producer_chunked(self: typing.Any):\n        response = self.fetch(\n            \"/echo_post\", method=\"POST\", body_producer=self.sync_body_producer\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin that verifies synchronous chunked data sending and correct response retrieval from a POST request."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_sync_body_producer_content_length", "line_number": 425, "body": "def test_sync_body_producer_content_length(self: typing.Any):\n        response = self.fetch(\n            \"/echo_post\",\n            method=\"POST\",\n            body_producer=self.sync_body_producer,\n            headers={\"Content-Length\": \"8\"},\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Method in SimpleHTTPClientTestMixin that verifies a synchronous body producer correctly sends a request body matching the specified Content-Length header. It ensures proper data transmission in HTTP POST request tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_async_body_producer_chunked", "line_number": 435, "body": "def test_async_body_producer_chunked(self: typing.Any):\n        response = self.fetch(\n            \"/echo_post\", method=\"POST\", body_producer=self.async_body_producer\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method for verifying that an asynchronous body producer correctly sends chunked POST request data and receives the expected response body in an HTTP client testing mixin."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_async_body_producer_content_length", "line_number": 442, "body": "def test_async_body_producer_content_length(self: typing.Any):\n        response = self.fetch(\n            \"/echo_post\",\n            method=\"POST\",\n            body_producer=self.async_body_producer,\n            headers={\"Content-Length\": \"8\"},\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests that an asynchronous body producer correctly sends a POST request with a specified content length and verifies the response body matches the expected data. This ensures the async body producer integration functions as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_native_body_producer_chunked", "line_number": 452, "body": "def test_native_body_producer_chunked(self: typing.Any):\n        async def body_producer(write):\n            await write(b\"1234\")\n            import asyncio\n\n            await asyncio.sleep(0)\n            await write(b\"5678\")\n\n        response = self.fetch(\"/echo_post\", method=\"POST\", body_producer=body_producer)\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests the ability to send a chunked request body asynchronously using a native body producer and verifies the server correctly assembles the chunks into a single response body. Useful for validating HTTP client chunked transfer support."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_native_body_producer_content_length", "line_number": 464, "body": "def test_native_body_producer_content_length(self: typing.Any):\n        async def body_producer(write):\n            await write(b\"1234\")\n            import asyncio\n\n            await asyncio.sleep(0)\n            await write(b\"5678\")\n\n        response = self.fetch(\n            \"/echo_post\",\n            method=\"POST\",\n            body_producer=body_producer,\n            headers={\"Content-Length\": \"8\"},\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"12345678\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method verifying that an asynchronous body producer correctly sends data with the specified Content-Length during an HTTP POST request. It ensures the client properly handles streamed request bodies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_100_continue", "line_number": 481, "body": "def test_100_continue(self: typing.Any):\n        response = self.fetch(\n            \"/echo_post\", method=\"POST\", body=b\"1234\", expect_100_continue=True\n        )\n        self.assertEqual(response.body, b\"1234\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Tests if the HTTP client correctly handles '100 Continue' responses by sending a POST request and verifying the echoed response body. This ensures proper support for expect-continue mechanism in HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_100_continue_early_response", "line_number": 487, "body": "def test_100_continue_early_response(self: typing.Any):\n        def body_producer(write):\n            raise Exception(\"should not be called\")\n\n        response = self.fetch(\n            \"/respond_in_prepare\",\n            method=\"POST\",\n            body_producer=body_producer,\n            expect_100_continue=True,\n        )\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "Test method in SimpleHTTPClientTestMixin verifying that a 100-Continue expectation triggers an early server response, preventing further request body transmission when a non-continue status is returned."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_streaming_follow_redirects", "line_number": 499, "body": "def test_streaming_follow_redirects(self: typing.Any):\n        # When following redirects, header and streaming callbacks\n        # should only be called for the final result.\n        # TODO(bdarnell): this test belongs in httpclient_test instead of\n        # simple_httpclient_test, but it fails with the version of libcurl\n        # available on travis-ci. Move it when that has been upgraded\n        # or we have a better framework to skip tests based on curl version.\n        headers = []  # type: typing.List[str]\n        chunk_bytes = []  # type: typing.List[bytes]\n        self.fetch(\n            \"/redirect?url=/hello\",\n            header_callback=headers.append,\n            streaming_callback=chunk_bytes.append,\n        )\n        chunks = list(map(to_unicode, chunk_bytes))\n        self.assertEqual(chunks, [\"Hello world!\"])\n        # Make sure we only got one set of headers.\n        num_start_lines = len([h for h in headers if h.startswith(\"HTTP/\")])\n        self.assertEqual(num_start_lines, 1)", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This test method verifies that when following HTTP redirects, header and streaming callbacks are triggered only for the final response, ensuring correct callback behavior during redirected HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "setUp", "line_number": 521, "body": "def setUp(self):\n        super().setUp()\n        self.http_client = self.create_client()", "is_method": true, "class_name": "SimpleHTTPClientTestCase", "function_description": "Sets up the test environment by initializing an HTTP client instance for use in subsequent test methods within the SimpleHTTPClientTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "create_client", "line_number": 525, "body": "def create_client(self, **kwargs):\n        return SimpleAsyncHTTPClient(force_instance=True, **kwargs)", "is_method": true, "class_name": "SimpleHTTPClientTestCase", "function_description": "Creates and returns a new instance of SimpleAsyncHTTPClient with customizable options, useful for setting up HTTP clients in test scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "setUp", "line_number": 530, "body": "def setUp(self):\n        super().setUp()\n        self.http_client = self.create_client()", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Sets up the test environment by initializing an HTTP client instance before each test method runs, supporting HTTP-related test cases within the SimpleHTTPSClientTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "create_client", "line_number": 534, "body": "def create_client(self, **kwargs):\n        return SimpleAsyncHTTPClient(\n            force_instance=True, defaults=dict(validate_cert=False), **kwargs\n        )", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Creates and returns a SimpleAsyncHTTPClient instance configured with default settings, simplifying client setup for asynchronous HTTP requests in test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_ssl_options", "line_number": 539, "body": "def test_ssl_options(self):\n        resp = self.fetch(\"/hello\", ssl_options={})\n        self.assertEqual(resp.body, b\"Hello world!\")", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Test method in SimpleHTTPSClientTestCase that verifies fetching a resource over HTTPS with default SSL options returns the expected response content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_ssl_context", "line_number": 543, "body": "def test_ssl_context(self):\n        resp = self.fetch(\"/hello\", ssl_options=ssl.SSLContext(ssl.PROTOCOL_SSLv23))\n        self.assertEqual(resp.body, b\"Hello world!\")", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Test method in SimpleHTTPSClientTestCase that verifies an HTTP fetch succeeds using a specified SSL context and checks the response body content for correctness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_ssl_options_handshake_fail", "line_number": 547, "body": "def test_ssl_options_handshake_fail(self):\n        with ExpectLog(gen_log, \"SSL Error|Uncaught exception\", required=False):\n            with self.assertRaises(ssl.SSLError):\n                self.fetch(\n                    \"/hello\",\n                    ssl_options=dict(cert_reqs=ssl.CERT_REQUIRED),\n                    raise_error=True,\n                )", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Tests that an SSL handshake failure raises an SSLError when custom SSL options require certificate validation during an HTTPS request. Useful for verifying SSL error handling in secure client-server communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_ssl_context_handshake_fail", "line_number": 556, "body": "def test_ssl_context_handshake_fail(self):\n        with ExpectLog(gen_log, \"SSL Error|Uncaught exception\"):\n            ctx = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n            ctx.verify_mode = ssl.CERT_REQUIRED\n            with self.assertRaises(ssl.SSLError):\n                self.fetch(\"/hello\", ssl_options=ctx, raise_error=True)", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Test method in SimpleHTTPSClientTestCase that verifies the client raises an SSL error when an SSL handshake fails due to required certificate verification."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_error_logging", "line_number": 563, "body": "def test_error_logging(self):\n        # No stack traces are logged for SSL errors (in this case,\n        # failure to validate the testing self-signed cert).\n        # The SSLError is exposed through ssl.SSLError.\n        with ExpectLog(gen_log, \".*\") as expect_log:\n            with self.assertRaises(ssl.SSLError):\n                self.fetch(\"/\", validate_cert=True, raise_error=True)\n        self.assertFalse(expect_log.logged_stack)", "is_method": true, "class_name": "SimpleHTTPSClientTestCase", "function_description": "Tests that SSL errors during HTTPS requests do not produce stack trace logs, ensuring clean error output when certificate validation fails in the SimpleHTTPSClientTestCase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "setUp", "line_number": 574, "body": "def setUp(self):\n        super().setUp()\n        self.saved = AsyncHTTPClient._save_configuration()", "is_method": true, "class_name": "CreateAsyncHTTPClientTestCase", "function_description": "Setup method for CreateAsyncHTTPClientTestCase that preserves the current AsyncHTTPClient configuration before tests run, ensuring test isolation and configuration restoration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "tearDown", "line_number": 578, "body": "def tearDown(self):\n        AsyncHTTPClient._restore_configuration(self.saved)\n        super().tearDown()", "is_method": true, "class_name": "CreateAsyncHTTPClientTestCase", "function_description": "Cleans up and restores the AsyncHTTPClient's configuration after a test completes, ensuring test isolation and consistent client state in asynchronous HTTP client tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_max_clients", "line_number": 582, "body": "def test_max_clients(self):\n        AsyncHTTPClient.configure(SimpleAsyncHTTPClient)\n        with closing(AsyncHTTPClient(force_instance=True)) as client:\n            self.assertEqual(client.max_clients, 10)  # type: ignore\n        with closing(AsyncHTTPClient(max_clients=11, force_instance=True)) as client:\n            self.assertEqual(client.max_clients, 11)  # type: ignore\n\n        # Now configure max_clients statically and try overriding it\n        # with each way max_clients can be passed\n        AsyncHTTPClient.configure(SimpleAsyncHTTPClient, max_clients=12)\n        with closing(AsyncHTTPClient(force_instance=True)) as client:\n            self.assertEqual(client.max_clients, 12)  # type: ignore\n        with closing(AsyncHTTPClient(max_clients=13, force_instance=True)) as client:\n            self.assertEqual(client.max_clients, 13)  # type: ignore\n        with closing(AsyncHTTPClient(max_clients=14, force_instance=True)) as client:\n            self.assertEqual(client.max_clients, 14)", "is_method": true, "class_name": "CreateAsyncHTTPClientTestCase", "function_description": "Test method in CreateAsyncHTTPClientTestCase that verifies AsyncHTTPClient correctly sets and overrides the maximum number of concurrent clients under different configuration scenarios. It ensures client limits are properly applied both statically and per instance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "respond_100", "line_number": 601, "body": "def respond_100(self, request):\n        self.http1 = request.version.startswith(\"HTTP/1.\")\n        if not self.http1:\n            request.connection.write_headers(\n                ResponseStartLine(\"\", 200, \"OK\"), HTTPHeaders()\n            )\n            request.connection.finish()\n            return\n        self.request = request\n        fut = self.request.connection.stream.write(b\"HTTP/1.1 100 CONTINUE\\r\\n\\r\\n\")\n        fut.add_done_callback(self.respond_200)", "is_method": true, "class_name": "HTTP100ContinueTestCase", "function_description": "Handles an HTTP 100 Continue request by sending the appropriate interim response for HTTP/1.x clients, then triggers a final response; for non-HTTP/1.x clients, it directly sends a 200 OK response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "respond_200", "line_number": 613, "body": "def respond_200(self, fut):\n        fut.result()\n        fut = self.request.connection.stream.write(\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 1\\r\\n\\r\\nA\"\n        )\n        fut.add_done_callback(lambda f: self.request.connection.stream.close())", "is_method": true, "class_name": "HTTP100ContinueTestCase", "function_description": "Method of HTTP100ContinueTestCase that sends a fixed HTTP 200 OK response with a single-character body and closes the connection stream afterward, typically used for testing HTTP interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 620, "body": "def get_app(self):\n        # Not a full Application, but works as an HTTPServer callback\n        return self.respond_100", "is_method": true, "class_name": "HTTP100ContinueTestCase", "function_description": "Returns a callable used as an HTTP server callback that triggers a 100 Continue response, facilitating testing of client-server HTTP interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_100_continue", "line_number": 624, "body": "def test_100_continue(self):\n        res = self.fetch(\"/\")\n        if not self.http1:\n            self.skipTest(\"requires HTTP/1.x\")\n        self.assertEqual(res.body, b\"A\")", "is_method": true, "class_name": "HTTP100ContinueTestCase", "function_description": "This test method verifies that a server correctly handles HTTP/1.x 100-continue behavior by fetching the root path and asserting the expected response body. It skips the test if the protocol is not HTTP/1.x."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "respond_204", "line_number": 632, "body": "def respond_204(self, request):\n        self.http1 = request.version.startswith(\"HTTP/1.\")\n        if not self.http1:\n            # Close the request cleanly in HTTP/2; it will be skipped anyway.\n            request.connection.write_headers(\n                ResponseStartLine(\"\", 200, \"OK\"), HTTPHeaders()\n            )\n            request.connection.finish()\n            return\n\n        # A 204 response never has a body, even if doesn't have a content-length\n        # (which would otherwise mean read-until-close).  We simulate here a\n        # server that sends no content length and does not close the connection.\n        #\n        # Tests of a 204 response with no Content-Length header are included\n        # in SimpleHTTPClientTestMixin.\n        stream = request.connection.detach()\n        stream.write(b\"HTTP/1.1 204 No content\\r\\n\")\n        if request.arguments.get(\"error\", [False])[-1]:\n            stream.write(b\"Content-Length: 5\\r\\n\")\n        else:\n            stream.write(b\"Content-Length: 0\\r\\n\")\n        stream.write(b\"\\r\\n\")\n        stream.close()", "is_method": true, "class_name": "HTTP204NoContentTestCase", "function_description": "Provides a test handler that sends an HTTP 204 No Content response, simulating different behaviors for HTTP/1.x and HTTP/2 protocols, useful for validating client handling of no-content responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 657, "body": "def get_app(self):\n        return self.respond_204", "is_method": true, "class_name": "HTTP204NoContentTestCase", "function_description": "Returns the application instance configured to respond with HTTP 204 No Content, facilitating testing of such responses in the HTTP204NoContentTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_204_no_content", "line_number": 660, "body": "def test_204_no_content(self):\n        resp = self.fetch(\"/\")\n        if not self.http1:\n            self.skipTest(\"requires HTTP/1.x\")\n        self.assertEqual(resp.code, 204)\n        self.assertEqual(resp.body, b\"\")", "is_method": true, "class_name": "HTTP204NoContentTestCase", "function_description": "Test method in HTTP204NoContentTestCase that verifies the server responds with a 204 No Content status and an empty body when accessing the root URL using HTTP/1.x protocol."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_204_invalid_content_length", "line_number": 667, "body": "def test_204_invalid_content_length(self):\n        # 204 status with non-zero content length is malformed\n        with ExpectLog(\n            gen_log, \".*Response with code 204 should not have body\", level=logging.INFO\n        ):\n            with self.assertRaises(HTTPStreamClosedError):\n                self.fetch(\"/?error=1\", raise_error=True)\n                if not self.http1:\n                    self.skipTest(\"requires HTTP/1.x\")\n                if self.http_client.configured_class != SimpleAsyncHTTPClient:\n                    self.skipTest(\"curl client accepts invalid headers\")", "is_method": true, "class_name": "HTTP204NoContentTestCase", "function_description": "Tests that a 204 No Content HTTP response correctly triggers errors or warnings when it improperly includes a non-zero content length, ensuring protocol compliance in HTTP response handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "setUp", "line_number": 681, "body": "def setUp(self):\n        super().setUp()\n        self.http_client = SimpleAsyncHTTPClient(\n            hostname_mapping={\n                \"www.example.com\": \"127.0.0.1\",\n                (\"foo.example.com\", 8000): (\"127.0.0.1\", self.get_http_port()),\n            }\n        )", "is_method": true, "class_name": "HostnameMappingTestCase", "function_description": "Sets up an HTTP client with custom hostname-to-IP mappings for testing purposes, enabling control over network requests during test execution in the HostnameMappingTestCase class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 690, "body": "def get_app(self):\n        return Application([url(\"/hello\", HelloWorldHandler)])", "is_method": true, "class_name": "HostnameMappingTestCase", "function_description": "Returns a configured Application instance with a predefined route for testing purposes, enabling HTTP request simulations within the HostnameMappingTestCase environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_hostname_mapping", "line_number": 693, "body": "def test_hostname_mapping(self):\n        response = self.fetch(\"http://www.example.com:%d/hello\" % self.get_http_port())\n        response.rethrow()\n        self.assertEqual(response.body, b\"Hello world!\")", "is_method": true, "class_name": "HostnameMappingTestCase", "function_description": "This test method verifies that a request to a mapped hostname returns the expected response, ensuring correct hostname routing and content delivery in the tested system."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_port_mapping", "line_number": 698, "body": "def test_port_mapping(self):\n        response = self.fetch(\"http://foo.example.com:8000/hello\")\n        response.rethrow()\n        self.assertEqual(response.body, b\"Hello world!\")", "is_method": true, "class_name": "HostnameMappingTestCase", "function_description": "Tests that a request to a specific hostname and port returns the expected response, validating correct URL port mapping in the system."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "setUp", "line_number": 705, "body": "def setUp(self):\n        self.cleanup_event = Event()\n        test = self\n\n        # Dummy Resolver subclass that never finishes.\n        class BadResolver(Resolver):\n            @gen.coroutine\n            def resolve(self, *args, **kwargs):\n                yield test.cleanup_event.wait()\n                # Return something valid so the test doesn't raise during cleanup.\n                return [(socket.AF_INET, (\"127.0.0.1\", test.get_http_port()))]\n\n        super().setUp()\n        self.http_client = SimpleAsyncHTTPClient(resolver=BadResolver())", "is_method": true, "class_name": "ResolveTimeoutTestCase", "function_description": "Sets up a test environment with a custom resolver that simulates unresolved DNS queries by blocking indefinitely, enabling testing of timeout handling in network requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 720, "body": "def get_app(self):\n        return Application([url(\"/hello\", HelloWorldHandler)])", "is_method": true, "class_name": "ResolveTimeoutTestCase", "function_description": "Provides a test application instance configured with a specific URL route and handler, allowing test cases to simulate and verify web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_resolve_timeout", "line_number": 723, "body": "def test_resolve_timeout(self):\n        with self.assertRaises(HTTPTimeoutError):\n            self.fetch(\"/hello\", connect_timeout=0.1, raise_error=True)\n\n        # Let the hanging coroutine clean up after itself\n        self.cleanup_event.set()\n        self.io_loop.run_sync(lambda: gen.sleep(0))", "is_method": true, "class_name": "ResolveTimeoutTestCase", "function_description": "Unit test method in ResolveTimeoutTestCase that verifies a fetch call correctly raises an HTTPTimeoutError upon connection timeout, ensuring proper timeout handling and cleanup in asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 733, "body": "def get_app(self):\n        class SmallHeaders(RequestHandler):\n            def get(self):\n                self.set_header(\"X-Filler\", \"a\" * 100)\n                self.write(\"ok\")\n\n        class LargeHeaders(RequestHandler):\n            def get(self):\n                self.set_header(\"X-Filler\", \"a\" * 1000)\n                self.write(\"ok\")\n\n        return Application([(\"/small\", SmallHeaders), (\"/large\", LargeHeaders)])", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Constructs a web application with two routes that respond with small and large custom HTTP headers, useful for testing how different header sizes are handled in requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_http_client", "line_number": 746, "body": "def get_http_client(self):\n        return SimpleAsyncHTTPClient(max_header_size=1024)", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Provides an HTTP client instance configured with a maximum header size limit of 1024 bytes, enabling controlled handling of HTTP headers for network requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_small_headers", "line_number": 749, "body": "def test_small_headers(self):\n        response = self.fetch(\"/small\")\n        response.rethrow()\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Test method in MaxHeaderSizeTest that verifies the server correctly handles small headers by asserting the response body equals \"ok\". It ensures proper processing of requests with small headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_large_headers", "line_number": 754, "body": "def test_large_headers(self):\n        with ExpectLog(gen_log, \"Unsatisfiable read\", level=logging.INFO):\n            with self.assertRaises(UnsatisfiableReadError):\n                self.fetch(\"/large\", raise_error=True)", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Test method in MaxHeaderSizeTest that verifies large header handling by ensuring a specific error is raised and logged during an unsatisfiable read operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 761, "body": "def get_app(self):\n        class SmallBody(RequestHandler):\n            def get(self):\n                self.write(\"a\" * 1024 * 64)\n\n        class LargeBody(RequestHandler):\n            def get(self):\n                self.write(\"a\" * 1024 * 100)\n\n        return Application([(\"/small\", SmallBody), (\"/large\", LargeBody)])", "is_method": true, "class_name": "MaxBodySizeTest", "function_description": "Provides a web application with two endpoints that serve responses of predefined small and large sizes, useful for testing how clients or servers handle different maximum body sizes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_http_client", "line_number": 772, "body": "def get_http_client(self):\n        return SimpleAsyncHTTPClient(max_body_size=1024 * 64)", "is_method": true, "class_name": "MaxBodySizeTest", "function_description": "Returns an HTTP client configured with a maximum request body size of 64 KB, enabling controlled handling of large HTTP payloads in asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_small_body", "line_number": 775, "body": "def test_small_body(self):\n        response = self.fetch(\"/small\")\n        response.rethrow()\n        self.assertEqual(response.body, b\"a\" * 1024 * 64)", "is_method": true, "class_name": "MaxBodySizeTest", "function_description": "Test method in MaxBodySizeTest that verifies the response body from the \"/small\" endpoint matches a specific 64KB byte pattern, ensuring correct handling of small-sized data responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_large_body", "line_number": 780, "body": "def test_large_body(self):\n        with ExpectLog(\n            gen_log,\n            \"Malformed HTTP message from None: Content-Length too long\",\n            level=logging.INFO,\n        ):\n            with self.assertRaises(HTTPStreamClosedError):\n                self.fetch(\"/large\", raise_error=True)", "is_method": true, "class_name": "MaxBodySizeTest", "function_description": "Core test method of the MaxBodySizeTest class that verifies the system correctly handles oversized HTTP request bodies by raising an error and logging a specific message about content length limits."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 791, "body": "def get_app(self):\n        class LargeBody(RequestHandler):\n            def get(self):\n                self.write(\"a\" * 1024 * 100)\n\n        return Application([(\"/large\", LargeBody)])", "is_method": true, "class_name": "MaxBufferSizeTest", "function_description": "Provides a Tornado web application with a single endpoint that responds with a large fixed-size body, useful for testing handling of large HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_http_client", "line_number": 798, "body": "def get_http_client(self):\n        # 100KB body with 64KB buffer\n        return SimpleAsyncHTTPClient(\n            max_body_size=1024 * 100, max_buffer_size=1024 * 64\n        )", "is_method": true, "class_name": "MaxBufferSizeTest", "function_description": "Provides an HTTP client configured with a 100KB maximum body size and a 64KB buffer size, suitable for testing scenarios involving network data limits and buffering constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_large_body", "line_number": 804, "body": "def test_large_body(self):\n        response = self.fetch(\"/large\")\n        response.rethrow()\n        self.assertEqual(response.body, b\"a\" * 1024 * 100)", "is_method": true, "class_name": "MaxBufferSizeTest", "function_description": "Test method in MaxBufferSizeTest that verifies handling and retrieval of a large response body of 100 KB to ensure system stability with large payloads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_app", "line_number": 811, "body": "def get_app(self):\n        class ChunkedWithContentLength(RequestHandler):\n            def get(self):\n                # Add an invalid Transfer-Encoding to the response\n                self.set_header(\"Transfer-Encoding\", \"chunked\")\n                self.write(\"Hello world\")\n\n        return Application([(\"/chunkwithcl\", ChunkedWithContentLength)])", "is_method": true, "class_name": "ChunkedWithContentLengthTest", "function_description": "Returns a web application routing requests to a handler that sets a chunked Transfer-Encoding header and responds with \"Hello world\". This is useful for testing server response behavior with chunked encoding and content length headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get_http_client", "line_number": 820, "body": "def get_http_client(self):\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "ChunkedWithContentLengthTest", "function_description": "Returns a new instance of an asynchronous HTTP client for making non-blocking HTTP requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "test_chunked_with_content_length", "line_number": 823, "body": "def test_chunked_with_content_length(self):\n        # Make sure the invalid headers are detected\n        with ExpectLog(\n            gen_log,\n            (\n                \"Malformed HTTP message from None: Response \"\n                \"with both Transfer-Encoding and Content-Length\"\n            ),\n            level=logging.INFO,\n        ):\n            with self.assertRaises(HTTPStreamClosedError):\n                self.fetch(\"/chunkwithcl\", raise_error=True)", "is_method": true, "class_name": "ChunkedWithContentLengthTest", "function_description": "Test method in ChunkedWithContentLengthTest that verifies error handling when HTTP responses incorrectly include both Transfer-Encoding and Content-Length headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "body_producer", "line_number": 488, "body": "def body_producer(write):\n            raise Exception(\"should not be called\")", "is_method": true, "class_name": "SimpleHTTPClientTestMixin", "function_description": "This function is a placeholder intended to raise an exception if invoked, indicating it should not be used to produce a request body in HTTP client tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "resolve", "line_number": 712, "body": "def resolve(self, *args, **kwargs):\n                yield test.cleanup_event.wait()\n                # Return something valid so the test doesn't raise during cleanup.\n                return [(socket.AF_INET, (\"127.0.0.1\", test.get_http_port()))]", "is_method": true, "class_name": "BadResolver", "function_description": "Provides a resolution service that yields a wait event and returns a fixed network address tuple, primarily ensuring valid cleanup behavior during testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 735, "body": "def get(self):\n                self.set_header(\"X-Filler\", \"a\" * 100)\n                self.write(\"ok\")", "is_method": true, "class_name": "SmallHeaders", "function_description": "Sets a custom HTTP header with a fixed 100-character value and responds with \"ok\". This method provides a simple way to test or include predefined headers in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 740, "body": "def get(self):\n                self.set_header(\"X-Filler\", \"a\" * 1000)\n                self.write(\"ok\")", "is_method": true, "class_name": "LargeHeaders", "function_description": "Sets a custom HTTP header with a large fixed-size value and responds with a simple confirmation message. Useful for testing handling of large headers in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 763, "body": "def get(self):\n                self.write(\"a\" * 1024 * 64)", "is_method": true, "class_name": "SmallBody", "function_description": "Method of the SmallBody class that produces a fixed 64KB string of the letter \"a\" when invoked, likely for testing or simulating a response body of specific size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 767, "body": "def get(self):\n                self.write(\"a\" * 1024 * 100)", "is_method": true, "class_name": "LargeBody", "function_description": "Provides a response that writes a large string of 100KB consisting of repeated \"a\" characters, useful for testing data transfer or handling large payloads in the LargeBody context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 793, "body": "def get(self):\n                self.write(\"a\" * 1024 * 100)", "is_method": true, "class_name": "LargeBody", "function_description": "Writes a fixed large string of 100KB size, primarily serving as a test or placeholder for output handling in the LargeBody class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/simple_httpclient_test.py", "function": "get", "line_number": 813, "body": "def get(self):\n                # Add an invalid Transfer-Encoding to the response\n                self.set_header(\"Transfer-Encoding\", \"chunked\")\n                self.write(\"Hello world\")", "is_method": true, "class_name": "ChunkedWithContentLength", "function_description": "Sets a chunked Transfer-Encoding header and writes a fixed \"Hello world\" response. Provides a simple example of sending chunked HTTP response content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "value", "line_number": 26, "body": "def value(self):\n        return self._value", "is_method": true, "class_name": "Email", "function_description": "Returns the current value stored in the Email instance, providing access to its underlying data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_parse_command_line", "line_number": 31, "body": "def test_parse_command_line(self):\n        options = OptionParser()\n        options.define(\"port\", default=80)\n        options.parse_command_line([\"main.py\", \"--port=443\"])\n        self.assertEqual(options.port, 443)", "is_method": true, "class_name": "OptionsTest", "function_description": "Test method in OptionsTest that verifies command-line option parsing correctly updates an option's value from default to a specified argument."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_parse_config_file", "line_number": 37, "body": "def test_parse_config_file(self):\n        options = OptionParser()\n        options.define(\"port\", default=80)\n        options.define(\"username\", default=\"foo\")\n        options.define(\"my_path\")\n        config_path = os.path.join(\n            os.path.dirname(os.path.abspath(__file__)), \"options_test.cfg\"\n        )\n        options.parse_config_file(config_path)\n        self.assertEqual(options.port, 443)\n        self.assertEqual(options.username, \"\u674e\u5eb7\")\n        self.assertEqual(options.my_path, config_path)", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that a configuration file is correctly parsed to set option values, validating handling of defaults and overridden settings in the OptionsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_parse_callbacks", "line_number": 50, "body": "def test_parse_callbacks(self):\n        options = OptionParser()\n        self.called = False\n\n        def callback():\n            self.called = True\n\n        options.add_parse_callback(callback)\n\n        # non-final parse doesn't run callbacks\n        options.parse_command_line([\"main.py\"], final=False)\n        self.assertFalse(self.called)\n\n        # final parse does\n        options.parse_command_line([\"main.py\"])\n        self.assertTrue(self.called)\n\n        # callbacks can be run more than once on the same options\n        # object if there are multiple final parses\n        self.called = False\n        options.parse_command_line([\"main.py\"])\n        self.assertTrue(self.called)", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that parse callbacks in the OptionsTest class are triggered only during final command-line parsing and verifies they can be invoked multiple times across final parses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_help", "line_number": 73, "body": "def test_help(self):\n        options = OptionParser()\n        try:\n            orig_stderr = sys.stderr\n            sys.stderr = StringIO()\n            with self.assertRaises(SystemExit):\n                options.parse_command_line([\"main.py\", \"--help\"])\n            usage = sys.stderr.getvalue()\n        finally:\n            sys.stderr = orig_stderr\n        self.assertIn(\"Usage:\", usage)", "is_method": true, "class_name": "OptionsTest", "function_description": "Utility method in OptionsTest that verifies the OptionParser correctly displays usage information and exits when the --help flag is provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_subcommand", "line_number": 85, "body": "def test_subcommand(self):\n        base_options = OptionParser()\n        base_options.define(\"verbose\", default=False)\n        sub_options = OptionParser()\n        sub_options.define(\"foo\", type=str)\n        rest = base_options.parse_command_line(\n            [\"main.py\", \"--verbose\", \"subcommand\", \"--foo=bar\"]\n        )\n        self.assertEqual(rest, [\"subcommand\", \"--foo=bar\"])\n        self.assertTrue(base_options.verbose)\n        rest2 = sub_options.parse_command_line(rest)\n        self.assertEqual(rest2, [])\n        self.assertEqual(sub_options.foo, \"bar\")\n\n        # the two option sets are distinct\n        try:\n            orig_stderr = sys.stderr\n            sys.stderr = StringIO()\n            with self.assertRaises(Error):\n                sub_options.parse_command_line([\"subcommand\", \"--verbose\"])\n        finally:\n            sys.stderr = orig_stderr", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that separate command-line option parsers correctly parse and isolate their respective flags, ensuring distinct option sets work independently without conflicts. It validates parsing behavior for nested or subcommand scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_setattr", "line_number": 108, "body": "def test_setattr(self):\n        options = OptionParser()\n        options.define(\"foo\", default=1, type=int)\n        options.foo = 2\n        self.assertEqual(options.foo, 2)", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that setting an attribute on an OptionParser instance correctly updates the option's value. This function validates the attribute assignment mechanism of option objects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_setattr_type_check", "line_number": 114, "body": "def test_setattr_type_check(self):\n        # setattr requires that options be the right type and doesn't\n        # parse from string formats.\n        options = OptionParser()\n        options.define(\"foo\", default=1, type=int)\n        with self.assertRaises(Error):\n            options.foo = \"2\"", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that the OptionsTest class correctly enforces type checking when setting attributes, ensuring values assigned to options match declared types and do not accept invalid string formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_setattr_with_callback", "line_number": 122, "body": "def test_setattr_with_callback(self):\n        values = []  # type: List[int]\n        options = OptionParser()\n        options.define(\"foo\", default=1, type=int, callback=values.append)\n        options.foo = 2\n        self.assertEqual(values, [2])", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that setting an option attribute triggers the associated callback function, capturing the updated value. This verifies callback execution upon attribute assignment in option parsing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "_sample_options", "line_number": 129, "body": "def _sample_options(self):\n        options = OptionParser()\n        options.define(\"a\", default=1)\n        options.define(\"b\", default=2)\n        return options", "is_method": true, "class_name": "OptionsTest", "function_description": "Creates and returns an OptionParser instance with predefined default options \"a\" and \"b\". This facilitates setting up standardized configurable parameters for testing purposes within the OptionsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_iter", "line_number": 135, "body": "def test_iter(self):\n        options = self._sample_options()\n        # OptionParsers always define 'help'.\n        self.assertEqual(set([\"a\", \"b\", \"help\"]), set(iter(options)))", "is_method": true, "class_name": "OptionsTest", "function_description": "Unit test method in OptionsTest that verifies the iterator of an options object correctly includes all defined options, ensuring proper iteration behavior over available option names."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_getitem", "line_number": 140, "body": "def test_getitem(self):\n        options = self._sample_options()\n        self.assertEqual(1, options[\"a\"])", "is_method": true, "class_name": "OptionsTest", "function_description": "Unit test method in OptionsTest that verifies accessing an option by key returns the expected value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_setitem", "line_number": 144, "body": "def test_setitem(self):\n        options = OptionParser()\n        options.define(\"foo\", default=1, type=int)\n        options[\"foo\"] = 2\n        self.assertEqual(options[\"foo\"], 2)", "is_method": true, "class_name": "OptionsTest", "function_description": "Unit test method for OptionsTest that verifies setting and retrieving option values by key in an OptionParser instance."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_items", "line_number": 150, "body": "def test_items(self):\n        options = self._sample_options()\n        # OptionParsers always define 'help'.\n        expected = [(\"a\", 1), (\"b\", 2), (\"help\", options.help)]\n        actual = sorted(options.items())\n        self.assertEqual(expected, actual)", "is_method": true, "class_name": "OptionsTest", "function_description": "Unit test method in OptionsTest that verifies the items() method returns all expected option pairs, including the default 'help' option, ensuring correct option retrieval behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_as_dict", "line_number": 157, "body": "def test_as_dict(self):\n        options = self._sample_options()\n        expected = {\"a\": 1, \"b\": 2, \"help\": options.help}\n        self.assertEqual(expected, options.as_dict())", "is_method": true, "class_name": "OptionsTest", "function_description": "Test method in OptionsTest that verifies the as_dict function correctly converts option attributes to a dictionary including a help entry. It ensures the options object\u2019s dictionary representation matches expected key-value pairs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_group_dict", "line_number": 162, "body": "def test_group_dict(self):\n        options = OptionParser()\n        options.define(\"a\", default=1)\n        options.define(\"b\", group=\"b_group\", default=2)\n\n        frame = sys._getframe(0)\n        this_file = frame.f_code.co_filename\n        self.assertEqual(set([\"b_group\", \"\", this_file]), options.groups())\n\n        b_group_dict = options.group_dict(\"b_group\")\n        self.assertEqual({\"b\": 2}, b_group_dict)\n\n        self.assertEqual({}, options.group_dict(\"nonexistent\"))", "is_method": true, "class_name": "OptionsTest", "function_description": "Utility test method in OptionsTest that verifies grouping and retrieval of option defaults by group, ensuring correct handling of defined and undefined option groups."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_mock_patch", "line_number": 176, "body": "def test_mock_patch(self):\n        # ensure that our setattr hooks don't interfere with mock.patch\n        options = OptionParser()\n        options.define(\"foo\", default=1)\n        options.parse_command_line([\"main.py\", \"--foo=2\"])\n        self.assertEqual(options.foo, 2)\n\n        with mock.patch.object(options.mockable(), \"foo\", 3):\n            self.assertEqual(options.foo, 3)\n        self.assertEqual(options.foo, 2)\n\n        # Try nested patches mixed with explicit sets\n        with mock.patch.object(options.mockable(), \"foo\", 4):\n            self.assertEqual(options.foo, 4)\n            options.foo = 5\n            self.assertEqual(options.foo, 5)\n            with mock.patch.object(options.mockable(), \"foo\", 6):\n                self.assertEqual(options.foo, 6)\n            self.assertEqual(options.foo, 5)\n        self.assertEqual(options.foo, 2)", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that patching attributes with mock.patch works correctly alongside the OptionParser's set and get mechanisms, ensuring mocked values temporarily override options without permanent changes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "_define_options", "line_number": 197, "body": "def _define_options(self):\n        options = OptionParser()\n        options.define(\"str\", type=str)\n        options.define(\"basestring\", type=basestring_type)\n        options.define(\"int\", type=int)\n        options.define(\"float\", type=float)\n        options.define(\"datetime\", type=datetime.datetime)\n        options.define(\"timedelta\", type=datetime.timedelta)\n        options.define(\"email\", type=Email)\n        options.define(\"list-of-int\", type=int, multiple=True)\n        return options", "is_method": true, "class_name": "OptionsTest", "function_description": "This method sets up and returns a collection of predefined typed options for command-line parsing. It enables consistent and reusable option definitions across the OptionsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "_check_options_values", "line_number": 209, "body": "def _check_options_values(self, options):\n        self.assertEqual(options.str, \"asdf\")\n        self.assertEqual(options.basestring, \"qwer\")\n        self.assertEqual(options.int, 42)\n        self.assertEqual(options.float, 1.5)\n        self.assertEqual(options.datetime, datetime.datetime(2013, 4, 28, 5, 16))\n        self.assertEqual(options.timedelta, datetime.timedelta(seconds=45))\n        self.assertEqual(options.email.value, \"tornado@web.com\")\n        self.assertTrue(isinstance(options.email, Email))\n        self.assertEqual(options.list_of_int, [1, 2, 3])", "is_method": true, "class_name": "OptionsTest", "function_description": "Internal test method in OptionsTest that verifies specific option attributes have expected values and types, ensuring option parsing or assignment correctness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_types", "line_number": 220, "body": "def test_types(self):\n        options = self._define_options()\n        options.parse_command_line(\n            [\n                \"main.py\",\n                \"--str=asdf\",\n                \"--basestring=qwer\",\n                \"--int=42\",\n                \"--float=1.5\",\n                \"--datetime=2013-04-28 05:16\",\n                \"--timedelta=45s\",\n                \"--email=tornado@web.com\",\n                \"--list-of-int=1,2,3\",\n            ]\n        )\n        self._check_options_values(options)", "is_method": true, "class_name": "OptionsTest", "function_description": "Service method in OptionsTest that verifies correct parsing and value assignment of command line options across various data types, ensuring the options system handles diverse input formats properly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_types_with_conf_file", "line_number": 237, "body": "def test_types_with_conf_file(self):\n        for config_file_name in (\n            \"options_test_types.cfg\",\n            \"options_test_types_str.cfg\",\n        ):\n            options = self._define_options()\n            options.parse_config_file(\n                os.path.join(os.path.dirname(__file__), config_file_name)\n            )\n            self._check_options_values(options)", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that configuration files are correctly parsed and their option values properly validated, ensuring type handling in the OptionsTest class works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_multiple_string", "line_number": 248, "body": "def test_multiple_string(self):\n        options = OptionParser()\n        options.define(\"foo\", type=str, multiple=True)\n        options.parse_command_line([\"main.py\", \"--foo=a,b,c\"])\n        self.assertEqual(options.foo, [\"a\", \"b\", \"c\"])", "is_method": true, "class_name": "OptionsTest", "function_description": "Test method verifying that the OptionsTest class correctly parses and stores multiple string values passed as a single comma-separated command-line option."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_multiple_int", "line_number": 254, "body": "def test_multiple_int(self):\n        options = OptionParser()\n        options.define(\"foo\", type=int, multiple=True)\n        options.parse_command_line([\"main.py\", \"--foo=1,3,5:7\"])\n        self.assertEqual(options.foo, [1, 3, 5, 6, 7])", "is_method": true, "class_name": "OptionsTest", "function_description": "Test method in OptionsTest that verifies parsing multiple integer values from a command line argument into a list, ensuring correct handling of ranges and individual integers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_error_redefine", "line_number": 260, "body": "def test_error_redefine(self):\n        options = OptionParser()\n        options.define(\"foo\")\n        with self.assertRaises(Error) as cm:\n            options.define(\"foo\")\n        self.assertRegexpMatches(str(cm.exception), \"Option.*foo.*already defined\")", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that redefining an existing option in OptionParser raises an appropriate error, ensuring option names remain unique. This method verifies correct error handling for duplicate option definitions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_error_redefine_underscore", "line_number": 267, "body": "def test_error_redefine_underscore(self):\n        # Ensure that the dash/underscore normalization doesn't\n        # interfere with the redefinition error.\n        tests = [\n            (\"foo-bar\", \"foo-bar\"),\n            (\"foo_bar\", \"foo_bar\"),\n            (\"foo-bar\", \"foo_bar\"),\n            (\"foo_bar\", \"foo-bar\"),\n        ]\n        for a, b in tests:\n            with subTest(self, a=a, b=b):\n                options = OptionParser()\n                options.define(a)\n                with self.assertRaises(Error) as cm:\n                    options.define(b)\n                self.assertRegexpMatches(\n                    str(cm.exception), \"Option.*foo.bar.*already defined\"\n                )", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that redefining options with dash/underscore variations raises an error, ensuring consistent detection of duplicate option names despite normalization differences."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_dash_underscore_cli", "line_number": 286, "body": "def test_dash_underscore_cli(self):\n        # Dashes and underscores should be interchangeable.\n        for defined_name in [\"foo-bar\", \"foo_bar\"]:\n            for flag in [\"--foo-bar=a\", \"--foo_bar=a\"]:\n                options = OptionParser()\n                options.define(defined_name)\n                options.parse_command_line([\"main.py\", flag])\n                # Attr-style access always uses underscores.\n                self.assertEqual(options.foo_bar, \"a\")\n                # Dict-style access allows both.\n                self.assertEqual(options[\"foo-bar\"], \"a\")\n                self.assertEqual(options[\"foo_bar\"], \"a\")", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that option names with dashes and underscores are treated equivalently in command-line parsing, ensuring flexible access via both attribute and dictionary styles."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_dash_underscore_file", "line_number": 299, "body": "def test_dash_underscore_file(self):\n        # No matter how an option was defined, it can be set with underscores\n        # in a config file.\n        for defined_name in [\"foo-bar\", \"foo_bar\"]:\n            options = OptionParser()\n            options.define(defined_name)\n            options.parse_config_file(\n                os.path.join(os.path.dirname(__file__), \"options_test.cfg\")\n            )\n            self.assertEqual(options.foo_bar, \"a\")", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that option names defined with dashes or underscores can be set interchangeably using underscores in configuration files, ensuring flexible option parsing in the OptionsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "test_dash_underscore_introspection", "line_number": 310, "body": "def test_dash_underscore_introspection(self):\n        # Original names are preserved in introspection APIs.\n        options = OptionParser()\n        options.define(\"with-dash\", group=\"g\")\n        options.define(\"with_underscore\", group=\"g\")\n        all_options = [\"help\", \"with-dash\", \"with_underscore\"]\n        self.assertEqual(sorted(options), all_options)\n        self.assertEqual(sorted(k for (k, v) in options.items()), all_options)\n        self.assertEqual(sorted(options.as_dict().keys()), all_options)\n\n        self.assertEqual(\n            sorted(options.group_dict(\"g\")), [\"with-dash\", \"with_underscore\"]\n        )\n\n        # --help shows CLI-style names with dashes.\n        buf = StringIO()\n        options.print_help(buf)\n        self.assertIn(\"--with-dash\", buf.getvalue())\n        self.assertIn(\"--with-underscore\", buf.getvalue())", "is_method": true, "class_name": "OptionsTest", "function_description": "Tests that option names with dashes and underscores are correctly preserved and displayed in introspection and help outputs, ensuring consistent handling of CLI-style option naming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/options_test.py", "function": "callback", "line_number": 54, "body": "def callback():\n            self.called = True", "is_method": true, "class_name": "OptionsTest", "function_description": "Sets a flag indicating that the callback has been invoked. This function can be used to track or confirm that a specific event or operation has occurred."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/wsgi_test.py", "function": "wsgi_app", "line_number": 9, "body": "def wsgi_app(self, environ, start_response):\n        status = \"200 OK\"\n        response_headers = [(\"Content-Type\", \"text/plain\")]\n        start_response(status, response_headers)\n        return [b\"Hello world!\"]", "is_method": true, "class_name": "WSGIContainerTest", "function_description": "Returns a simple WSGI application response that always outputs \"Hello world!\" with a 200 OK status, useful for testing WSGI server handling and pipeline integration."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/wsgi_test.py", "function": "get_app", "line_number": 15, "body": "def get_app(self):\n        return WSGIContainer(validator(self.wsgi_app))", "is_method": true, "class_name": "WSGIContainerTest", "function_description": "Returns a WSGIContainer wrapping the WSGI app with validation applied, facilitating testing of WSGI applications within a controlled environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/wsgi_test.py", "function": "test_simple", "line_number": 18, "body": "def test_simple(self):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.body, b\"Hello world!\")", "is_method": true, "class_name": "WSGIContainerTest", "function_description": "Simple test method in WSGIContainerTest that verifies the root URL returns the expected \"Hello world!\" response body, ensuring basic server response correctness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 37, "body": "def get(self):\n        name = self.get_argument(\"name\", \"world\")\n        self.set_header(\"Content-Type\", \"text/plain\")\n        self.finish(\"Hello %s!\" % name)", "is_method": true, "class_name": "HelloWorldHandler", "function_description": "Handles HTTP GET requests by responding with a personalized plain-text greeting message based on a provided or default name parameter."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "post", "line_number": 44, "body": "def post(self):\n        self.finish(\n            \"Post arg1: %s, arg2: %s\"\n            % (self.get_argument(\"arg1\"), self.get_argument(\"arg2\"))\n        )", "is_method": true, "class_name": "PostHandler", "function_description": "Handles an HTTP POST request by retrieving specific arguments and returning them as a formatted response string. It provides a simple way to echo received POST parameters back to the client."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "put", "line_number": 52, "body": "def put(self):\n        self.write(\"Put body: \")\n        self.write(self.request.body)", "is_method": true, "class_name": "PutHandler", "function_description": "Simple handler method in PutHandler that outputs the raw body content of an HTTP PUT request, useful for debugging or logging incoming data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "prepare", "line_number": 58, "body": "def prepare(self):\n        self.write(\"redirects can have bodies too\")\n        self.redirect(\n            self.get_argument(\"url\"), status=int(self.get_argument(\"status\", \"302\"))\n        )", "is_method": true, "class_name": "RedirectHandler", "function_description": "Method of RedirectHandler that sends a customizable HTTP redirect response, optionally including a message body and allowing callers to specify the target URL and status code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "prepare", "line_number": 66, "body": "def prepare(self):\n        # For testing error handling of a redirect with no location header.\n        self.set_status(301)\n        self.finish()", "is_method": true, "class_name": "RedirectWithoutLocationHandler", "function_description": "Method in RedirectWithoutLocationHandler that sets a 301 redirect status and immediately finishes the response without specifying a location header, primarily for testing error handling of such redirects."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 74, "body": "def get(self):\n        self.write(\"asdf\")\n        self.flush()\n        # Wait a bit to ensure the chunks are sent and received separately.\n        yield gen.sleep(0.01)\n        self.write(\"qwer\")", "is_method": true, "class_name": "ChunkHandler", "function_description": "Sends a sequence of chunked responses to the client with a short delay between them, enabling streaming of partial data for asynchronous processing or progressive loading scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 83, "body": "def get(self):\n        self.finish(self.request.headers[\"Authorization\"])", "is_method": true, "class_name": "AuthHandler", "function_description": "Returns the value of the Authorization header from the current HTTP request, typically used to access authentication credentials."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 88, "body": "def get(self, count):\n        count = int(count)\n        if count > 0:\n            self.redirect(self.reverse_url(\"countdown\", count - 1))\n        else:\n            self.write(\"Zero\")", "is_method": true, "class_name": "CountdownHandler", "function_description": "Handles a countdown by redirecting to itself with a decremented count until zero, where it outputs \"Zero\". It supports iterative URL-based counting flows in web request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "post", "line_number": 97, "body": "def post(self):\n        self.write(self.request.body)", "is_method": true, "class_name": "EchoPostHandler", "function_description": "Simple HTTP POST handler that echoes back the received request body, useful for testing or debugging POST requests in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 102, "body": "def get(self):\n        self.write(self.request.headers.get(\"User-Agent\", \"User agent not set\"))", "is_method": true, "class_name": "UserAgentHandler", "function_description": "Returns the User-Agent string from the incoming HTTP request headers, providing information about the client software making the request. This can be used for client identification or logging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 107, "body": "def get(self):\n        self.set_status(304)\n        self.set_header(\"Content-Length\", 42)", "is_method": true, "class_name": "ContentLength304Handler", "function_description": "Sets an HTTP 304 status with a fixed Content-Length header, useful for signaling that content is unchanged without sending a response body."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "patch", "line_number": 118, "body": "def patch(self):\n        \"Return the request payload - so we can check it is being kept\"\n        self.write(self.request.body)", "is_method": true, "class_name": "PatchHandler", "function_description": "Returns the raw payload of a patch request by echoing the request body, enabling validation or inspection of the data sent in patch operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "method", "line_number": 126, "body": "def method(self):\n        assert self.request.method is not None\n        self.write(self.request.method)", "is_method": true, "class_name": "AllMethodsHandler", "function_description": "Returns the HTTP method of the current request as a response, providing a simple way to confirm or expose the request method received by the AllMethodsHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 134, "body": "def get(self):\n        # Use get_arguments for keys to get strings, but\n        # request.arguments for values to get bytes.\n        for k, v in zip(self.get_arguments(\"k\"), self.request.arguments[\"v\"]):\n            self.set_header(k, v)", "is_method": true, "class_name": "SetHeaderHandler", "function_description": "Sets multiple HTTP headers on the response using keys and corresponding byte values from request parameters. Useful for dynamically configuring response headers in web handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get", "line_number": 142, "body": "def get(self):\n        # set Content-Encoding manually to avoid automatic gzip encoding\n        self.set_header(\"Content-Type\", \"text/plain\")\n        self.set_header(\"Content-Encoding\", \"gzip\")\n        # Triggering the potential bug seems to depend on input length.\n        # This length is taken from the bad-response example reported in\n        # https://github.com/tornadoweb/tornado/pull/2875 (uncompressed).\n        body = \"\".join(\"Hello World {}\\n\".format(i) for i in range(9000))[:149051]\n        body = gzip.compress(body.encode(), compresslevel=6) + b\"\\00\"\n        self.write(body)", "is_method": true, "class_name": "InvalidGzipHandler", "function_description": "Provides an HTTP GET handler that returns a manually gzip-compressed plain text response with specific content length to demonstrate or test behavior related to invalid gzip encoding in responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get_app", "line_number": 160, "body": "def get_app(self):\n        return Application(\n            [\n                url(\"/hello\", HelloWorldHandler),\n                url(\"/post\", PostHandler),\n                url(\"/put\", PutHandler),\n                url(\"/redirect\", RedirectHandler),\n                url(\"/redirect_without_location\", RedirectWithoutLocationHandler),\n                url(\"/chunk\", ChunkHandler),\n                url(\"/auth\", AuthHandler),\n                url(\"/countdown/([0-9]+)\", CountdownHandler, name=\"countdown\"),\n                url(\"/echopost\", EchoPostHandler),\n                url(\"/user_agent\", UserAgentHandler),\n                url(\"/304_with_content_length\", ContentLength304Handler),\n                url(\"/all_methods\", AllMethodsHandler),\n                url(\"/patch\", PatchHandler),\n                url(\"/set_header\", SetHeaderHandler),\n                url(\"/invalid_gzip\", InvalidGzipHandler),\n            ],\n            gzip=True,\n        )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Returns a configured web application instance with multiple predefined URL routes and handlers, enabling HTTP request handling for diverse endpoints and methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_patch_receives_payload", "line_number": 182, "body": "def test_patch_receives_payload(self):\n        body = b\"some patch data\"\n        response = self.fetch(\"/patch\", method=\"PATCH\", body=body)\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.body, body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies a PATCH request correctly receives and echoes the sent payload, ensuring proper request handling and response integrity."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_hello_world", "line_number": 189, "body": "def test_hello_world(self):\n        response = self.fetch(\"/hello\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.headers[\"Content-Type\"], \"text/plain\")\n        self.assertEqual(response.body, b\"Hello world!\")\n        assert response.request_time is not None\n        self.assertEqual(int(response.request_time), 0)\n\n        response = self.fetch(\"/hello?name=Ben\")\n        self.assertEqual(response.body, b\"Hello Ben!\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client correctly handles the \"/hello\" endpoint, verifying response status, content type, body content, and request timing for default and personalized greeting requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_streaming_callback", "line_number": 200, "body": "def test_streaming_callback(self):\n        # streaming_callback is also tested in test_chunked\n        chunks = []  # type: typing.List[bytes]\n        response = self.fetch(\"/hello\", streaming_callback=chunks.append)\n        # with streaming_callback, data goes to the callback and not response.body\n        self.assertEqual(chunks, [b\"Hello world!\"])\n        self.assertFalse(response.body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that an HTTP client's streaming callback correctly receives response data chunks in real-time, ensuring data is handled via the callback instead of the full response body. Useful for validating streaming response handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_post", "line_number": 208, "body": "def test_post(self):\n        response = self.fetch(\"/post\", method=\"POST\", body=\"arg1=foo&arg2=bar\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.body, b\"Post arg1: foo, arg2: bar\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that a POST request to \"/post\" returns a 200 status and the expected response body, verifying correct handling of POST data in HTTPClientCommonTestCase."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_chunked", "line_number": 213, "body": "def test_chunked(self):\n        response = self.fetch(\"/chunk\")\n        self.assertEqual(response.body, b\"asdfqwer\")\n\n        chunks = []  # type: typing.List[bytes]\n        response = self.fetch(\"/chunk\", streaming_callback=chunks.append)\n        self.assertEqual(chunks, [b\"asdf\", b\"qwer\"])\n        self.assertFalse(response.body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies correct handling of chunked HTTP responses by comparing full-body and streaming callback results."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_chunked_close", "line_number": 222, "body": "def test_chunked_close(self):\n        # test case in which chunks spread read-callback processing\n        # over several ioloop iterations, but the connection is already closed.\n        sock, port = bind_unused_port()\n        with closing(sock):\n\n            @gen.coroutine\n            def accept_callback(conn, address):\n                # fake an HTTP server using chunked encoding where the final chunks\n                # and connection close all happen at once\n                stream = IOStream(conn)\n                request_data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n                if b\"HTTP/1.\" not in request_data:\n                    self.skipTest(\"requires HTTP/1.x\")\n                yield stream.write(\n                    b\"\"\"\\\nHTTP/1.1 200 OK\nTransfer-Encoding: chunked\n\n1\n1\n1\n2\n0\n\n\"\"\".replace(\n                        b\"\\n\", b\"\\r\\n\"\n                    )\n                )\n                stream.close()\n\n            netutil.add_accept_handler(sock, accept_callback)  # type: ignore\n            resp = self.fetch(\"http://127.0.0.1:%d/\" % port)\n            resp.rethrow()\n            self.assertEqual(resp.body, b\"12\")\n            self.io_loop.remove_handler(sock.fileno())", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests the handling of HTTP chunked encoding where all chunks and connection close occur simultaneously, ensuring correct response decoding even when the connection closes across multiple event loop iterations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_basic_auth", "line_number": 259, "body": "def test_basic_auth(self):\n        # This test data appears in section 2 of RFC 7617.\n        self.assertEqual(\n            self.fetch(\n                \"/auth\", auth_username=\"Aladdin\", auth_password=\"open sesame\"\n            ).body,\n            b\"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\",\n        )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies correct handling of Basic Authentication by ensuring the encoded credentials match the expected RFC 7617 example."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_basic_auth_explicit_mode", "line_number": 268, "body": "def test_basic_auth_explicit_mode(self):\n        self.assertEqual(\n            self.fetch(\n                \"/auth\",\n                auth_username=\"Aladdin\",\n                auth_password=\"open sesame\",\n                auth_mode=\"basic\",\n            ).body,\n            b\"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\",\n        )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client correctly sends explicit basic authentication headers when provided with username and password credentials. This ensures authentication mechanisms function as expected in explicit mode."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_basic_auth_unicode", "line_number": 279, "body": "def test_basic_auth_unicode(self):\n        # This test data appears in section 2.1 of RFC 7617.\n        self.assertEqual(\n            self.fetch(\"/auth\", auth_username=\"test\", auth_password=\"123\u00a3\").body,\n            b\"Basic dGVzdDoxMjPCow==\",\n        )\n\n        # The standard mandates NFC. Give it a decomposed username\n        # and ensure it is normalized to composed form.\n        username = unicodedata.normalize(\"NFD\", u\"jos\u00e9\")\n        self.assertEqual(\n            self.fetch(\"/auth\", auth_username=username, auth_password=\"s\u0259cr\u0259t\").body,\n            b\"Basic am9zw6k6c8mZY3LJmXQ=\",\n        )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP basic authentication correctly handles Unicode usernames and passwords, including normalization of decomposed Unicode characters as mandated by RFC 7617."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_unsupported_auth_mode", "line_number": 294, "body": "def test_unsupported_auth_mode(self):\n        # curl and simple clients handle errors a bit differently; the\n        # important thing is that they don't fall back to basic auth\n        # on an unknown mode.\n        with ExpectLog(gen_log, \"uncaught exception\", required=False):\n            with self.assertRaises((ValueError, HTTPError)):  # type: ignore\n                self.fetch(\n                    \"/auth\",\n                    auth_username=\"Aladdin\",\n                    auth_password=\"open sesame\",\n                    auth_mode=\"asdf\",\n                    raise_error=True,\n                )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies an error is raised when an unsupported authentication mode is used, ensuring clients do not default to basic auth on unknown modes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_follow_redirect", "line_number": 308, "body": "def test_follow_redirect(self):\n        response = self.fetch(\"/countdown/2\", follow_redirects=False)\n        self.assertEqual(302, response.code)\n        self.assertTrue(response.headers[\"Location\"].endswith(\"/countdown/1\"))\n\n        response = self.fetch(\"/countdown/2\")\n        self.assertEqual(200, response.code)\n        self.assertTrue(response.effective_url.endswith(\"/countdown/0\"))\n        self.assertEqual(b\"Zero\", response.body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "This test method verifies the HTTP client's ability to handle redirects correctly, both when disabled and enabled, ensuring proper status codes and final response content are returned. It supports validating redirect behavior in client-server interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_redirect_without_location", "line_number": 318, "body": "def test_redirect_without_location(self):\n        response = self.fetch(\"/redirect_without_location\", follow_redirects=True)\n        # If there is no location header, the redirect response should\n        # just be returned as-is. (This should arguably raise an\n        # error, but libcurl doesn't treat this as an error, so we\n        # don't either).\n        self.assertEqual(301, response.code)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies client behavior when a redirect response lacks a Location header, ensuring the response is returned unchanged instead of raising an error."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_redirect_put_with_body", "line_number": 326, "body": "def test_redirect_put_with_body(self):\n        response = self.fetch(\n            \"/redirect?url=/put&status=307\", method=\"PUT\", body=\"hello\"\n        )\n        self.assertEqual(response.body, b\"Put body: hello\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "This test method verifies that an HTTP PUT request with a body correctly follows a 307 redirect and sends the body to the redirected URL. It ensures the client preserves the request method and body during redirection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_redirect_put_without_body", "line_number": 332, "body": "def test_redirect_put_without_body(self):\n        # This \"without body\" edge case is similar to what happens with body_producer.\n        response = self.fetch(\n            \"/redirect?url=/put&status=307\",\n            method=\"PUT\",\n            allow_nonstandard_methods=True,\n        )\n        self.assertEqual(response.body, b\"Put body: \")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies a PUT request with a redirect and no body correctly receives an expected empty body response. It ensures proper handling of edge-case HTTP redirects without request content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_method_after_redirect", "line_number": 341, "body": "def test_method_after_redirect(self):\n        # Legacy redirect codes (301, 302) convert POST requests to GET.\n        for status in [301, 302, 303]:\n            url = \"/redirect?url=/all_methods&status=%d\" % status\n            resp = self.fetch(url, method=\"POST\", body=b\"\")\n            self.assertEqual(b\"GET\", resp.body)\n\n            # Other methods are left alone, except for 303 redirect, depending on client\n            for method in [\"GET\", \"OPTIONS\", \"PUT\", \"DELETE\"]:\n                resp = self.fetch(url, method=method, allow_nonstandard_methods=True)\n                if status in [301, 302]:\n                    self.assertEqual(utf8(method), resp.body)\n                else:\n                    self.assertIn(resp.body, [utf8(method), b\"GET\"])\n\n            # HEAD is different so check it separately.\n            resp = self.fetch(url, method=\"HEAD\")\n            self.assertEqual(200, resp.code)\n            self.assertEqual(b\"\", resp.body)\n\n        # Newer redirects always preserve the original method.\n        for status in [307, 308]:\n            url = \"/redirect?url=/all_methods&status=307\"\n            for method in [\"GET\", \"OPTIONS\", \"POST\", \"PUT\", \"DELETE\"]:\n                resp = self.fetch(url, method=method, allow_nonstandard_methods=True)\n                self.assertEqual(method, to_unicode(resp.body))\n            resp = self.fetch(url, method=\"HEAD\")\n            self.assertEqual(200, resp.code)\n            self.assertEqual(b\"\", resp.body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "This test method verifies HTTP redirect behavior, ensuring legacy redirects change POST to GET while newer codes preserve the original method, validating HTTP client compliance across various request types."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_credentials_in_url", "line_number": 371, "body": "def test_credentials_in_url(self):\n        url = self.get_url(\"/auth\").replace(\"http://\", \"http://me:secret@\")\n        response = self.fetch(url)\n        self.assertEqual(b\"Basic \" + base64.b64encode(b\"me:secret\"), response.body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method verifying that credentials embedded in a URL are correctly extracted and used for authentication by the HTTP client."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_body_encoding", "line_number": 376, "body": "def test_body_encoding(self):\n        unicode_body = u\"\\xe9\"\n        byte_body = binascii.a2b_hex(b\"e9\")\n\n        # unicode string in body gets converted to utf8\n        response = self.fetch(\n            \"/echopost\",\n            method=\"POST\",\n            body=unicode_body,\n            headers={\"Content-Type\": \"application/blah\"},\n        )\n        self.assertEqual(response.headers[\"Content-Length\"], \"2\")\n        self.assertEqual(response.body, utf8(unicode_body))\n\n        # byte strings pass through directly\n        response = self.fetch(\n            \"/echopost\",\n            method=\"POST\",\n            body=byte_body,\n            headers={\"Content-Type\": \"application/blah\"},\n        )\n        self.assertEqual(response.headers[\"Content-Length\"], \"1\")\n        self.assertEqual(response.body, byte_body)\n\n        # Mixing unicode in headers and byte string bodies shouldn't\n        # break anything\n        response = self.fetch(\n            \"/echopost\",\n            method=\"POST\",\n            body=byte_body,\n            headers={\"Content-Type\": \"application/blah\"},\n            user_agent=u\"foo\",\n        )\n        self.assertEqual(response.headers[\"Content-Length\"], \"1\")\n        self.assertEqual(response.body, byte_body)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method verifying that HTTP POST request bodies are correctly encoded, ensuring unicode strings convert to UTF-8 and byte strings pass through unchanged, preserving proper Content-Length headers under various conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_types", "line_number": 412, "body": "def test_types(self):\n        response = self.fetch(\"/hello\")\n        self.assertEqual(type(response.body), bytes)\n        self.assertEqual(type(response.headers[\"Content-Type\"]), str)\n        self.assertEqual(type(response.code), int)\n        self.assertEqual(type(response.effective_url), str)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client response components have expected data types, ensuring response body is bytes, headers are strings, and status code is an integer. This aids in validating HTTP client behavior during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_gzip", "line_number": 419, "body": "def test_gzip(self):\n        # All the tests in this file should be using gzip, but this test\n        # ensures that it is in fact getting compressed, and also tests\n        # the httpclient's decompress=False option.\n        # Setting Accept-Encoding manually bypasses the client's\n        # decompression so we can see the raw data.\n        response = self.fetch(\n            \"/chunk\", decompress_response=False, headers={\"Accept-Encoding\": \"gzip\"}\n        )\n        self.assertEqual(response.headers[\"Content-Encoding\"], \"gzip\")\n        self.assertNotEqual(response.body, b\"asdfqwer\")\n        # Our test data gets bigger when gzipped.  Oops.  :)\n        # Chunked encoding bypasses the MIN_LENGTH check.\n        self.assertEqual(len(response.body), 34)\n        f = gzip.GzipFile(mode=\"r\", fileobj=response.buffer)\n        self.assertEqual(f.read(), b\"asdfqwer\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP client properly handles gzip compression and optionally disables automatic decompression, verifying raw compressed data integrity and correct header settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_invalid_gzip", "line_number": 436, "body": "def test_invalid_gzip(self):\n        # test if client hangs on tricky invalid gzip\n        # curl/simple httpclient have different behavior (exception, logging)\n        with ExpectLog(\n            app_log, \"(Uncaught exception|Exception in callback)\", required=False\n        ):\n            try:\n                response = self.fetch(\"/invalid_gzip\")\n                self.assertEqual(response.code, 200)\n                self.assertEqual(response.body[:14], b\"Hello World 0\\n\")\n            except HTTPError:\n                pass", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests the HTTP client\u2019s handling of invalid gzip responses, verifying it processes or properly handles errors without hanging. Useful for ensuring robustness against malformed compressed content in HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_header_callback", "line_number": 449, "body": "def test_header_callback(self):\n        first_line = []\n        headers = {}\n        chunks = []\n\n        def header_callback(header_line):\n            if header_line.startswith(\"HTTP/1.1 101\"):\n                # Upgrading to HTTP/2\n                pass\n            elif header_line.startswith(\"HTTP/\"):\n                first_line.append(header_line)\n            elif header_line != \"\\r\\n\":\n                k, v = header_line.split(\":\", 1)\n                headers[k.lower()] = v.strip()\n\n        def streaming_callback(chunk):\n            # All header callbacks are run before any streaming callbacks,\n            # so the header data is available to process the data as it\n            # comes in.\n            self.assertEqual(headers[\"content-type\"], \"text/html; charset=UTF-8\")\n            chunks.append(chunk)\n\n        self.fetch(\n            \"/chunk\",\n            header_callback=header_callback,\n            streaming_callback=streaming_callback,\n        )\n        self.assertEqual(len(first_line), 1, first_line)\n        self.assertRegexpMatches(first_line[0], \"HTTP/[0-9]\\\\.[0-9] 200.*\\r\\n\")\n        self.assertEqual(chunks, [b\"asdf\", b\"qwer\"])", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Utility test method in HTTPClientCommonTestCase that verifies proper processing of HTTP response headers and streaming body chunks, ensuring header callbacks run before streaming and headers are correctly parsed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_configure_defaults", "line_number": 481, "body": "def test_configure_defaults(self):\n        defaults = dict(user_agent=\"TestDefaultUserAgent\", allow_ipv6=False)\n        # Construct a new instance of the configured client class\n        client = self.http_client.__class__(force_instance=True, defaults=defaults)\n        try:\n            response = yield client.fetch(self.get_url(\"/user_agent\"))\n            self.assertEqual(response.body, b\"TestDefaultUserAgent\")\n        finally:\n            client.close()", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client properly applies default configuration values such as user agent and IPv6 allowance during initialization and subsequent requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_header_types", "line_number": 491, "body": "def test_header_types(self):\n        # Header values may be passed as character or utf8 byte strings,\n        # in a plain dictionary or an HTTPHeaders object.\n        # Keys must always be the native str type.\n        # All combinations should have the same results on the wire.\n        for value in [u\"MyUserAgent\", b\"MyUserAgent\"]:\n            for container in [dict, HTTPHeaders]:\n                headers = container()\n                headers[\"User-Agent\"] = value\n                resp = self.fetch(\"/user_agent\", headers=headers)\n                self.assertEqual(\n                    resp.body,\n                    b\"MyUserAgent\",\n                    \"response=%r, value=%r, container=%r\"\n                    % (resp.body, value, container),\n                )", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP header values, whether unicode strings or UTF-8 bytes in different container types, are consistently processed and sent correctly in HTTP requests. This ensures uniform behavior of header handling across various input forms."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_multi_line_headers", "line_number": 508, "body": "def test_multi_line_headers(self):\n        # Multi-line http headers are rare but rfc-allowed\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.2\n        sock, port = bind_unused_port()\n        with closing(sock):\n\n            @gen.coroutine\n            def accept_callback(conn, address):\n                stream = IOStream(conn)\n                request_data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n                if b\"HTTP/1.\" not in request_data:\n                    self.skipTest(\"requires HTTP/1.x\")\n                yield stream.write(\n                    b\"\"\"\\\nHTTP/1.1 200 OK\nX-XSS-Protection: 1;\n\\tmode=block\n\n\"\"\".replace(\n                        b\"\\n\", b\"\\r\\n\"\n                    )\n                )\n                stream.close()\n\n            netutil.add_accept_handler(sock, accept_callback)  # type: ignore\n            try:\n                resp = self.fetch(\"http://127.0.0.1:%d/\" % port)\n                resp.rethrow()\n                self.assertEqual(resp.headers[\"X-XSS-Protection\"], \"1; mode=block\")\n            finally:\n                self.io_loop.remove_handler(sock.fileno())", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client properly handles multi-line HTTP headers per RFC2616, ensuring header values spanning multiple lines are correctly parsed and accessible."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_304_with_content_length", "line_number": 540, "body": "def test_304_with_content_length(self):\n        # According to the spec 304 responses SHOULD NOT include\n        # Content-Length or other entity headers, but some servers do it\n        # anyway.\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.5\n        response = self.fetch(\"/304_with_content_length\")\n        self.assertEqual(response.code, 304)\n        self.assertEqual(response.headers[\"Content-Length\"], \"42\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method verifying that a 304 HTTP response includes a Content-Length header despite the specification advising against it, ensuring correct handling of such edge cases during HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_future_interface", "line_number": 550, "body": "def test_future_interface(self):\n        response = yield self.http_client.fetch(self.get_url(\"/hello\"))\n        self.assertEqual(response.body, b\"Hello world!\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client correctly handles asynchronous fetch requests and receives the expected response content from a specified URL."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_future_http_error", "line_number": 555, "body": "def test_future_http_error(self):\n        with self.assertRaises(HTTPError) as context:\n            yield self.http_client.fetch(self.get_url(\"/notfound\"))\n        assert context.exception is not None\n        assert context.exception.response is not None\n        self.assertEqual(context.exception.code, 404)\n        self.assertEqual(context.exception.response.code, 404)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method in HTTPClientCommonTestCase that verifies the HTTP client correctly raises and handles a 404 HTTPError when fetching a non-existent URL endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_future_http_error_no_raise", "line_number": 564, "body": "def test_future_http_error_no_raise(self):\n        response = yield self.http_client.fetch(\n            self.get_url(\"/notfound\"), raise_error=False\n        )\n        self.assertEqual(response.code, 404)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method verifying that the HTTP client correctly returns a 404 response without raising an exception when errors are disabled. It ensures proper handling of HTTP errors without interrupting program flow."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_reuse_request_from_response", "line_number": 571, "body": "def test_reuse_request_from_response(self):\n        # The response.request attribute should be an HTTPRequest, not\n        # a _RequestProxy.\n        # This test uses self.http_client.fetch because self.fetch calls\n        # self.get_url on the input unconditionally.\n        url = self.get_url(\"/hello\")\n        response = yield self.http_client.fetch(url)\n        self.assertEqual(response.request.url, url)\n        self.assertTrue(isinstance(response.request, HTTPRequest))\n        response2 = yield self.http_client.fetch(response.request)\n        self.assertEqual(response2.body, b\"Hello world!\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that an HTTP response retains a proper HTTPRequest object allowing it to be reused for subsequent fetch calls, ensuring request objects are correctly preserved and reusable within HTTP client interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_bind_source_ip", "line_number": 584, "body": "def test_bind_source_ip(self):\n        url = self.get_url(\"/hello\")\n        request = HTTPRequest(url, network_interface=\"127.0.0.1\")\n        response = yield self.http_client.fetch(request)\n        self.assertEqual(response.code, 200)\n\n        with self.assertRaises((ValueError, HTTPError)) as context:  # type: ignore\n            request = HTTPRequest(url, network_interface=\"not-interface-or-ip\")\n            yield self.http_client.fetch(request)\n        self.assertIn(\"not-interface-or-ip\", str(context.exception))", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests whether HTTP requests can be correctly bound to a specified source IP address or network interface, and verifies proper error handling for invalid interface inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_all_methods", "line_number": 595, "body": "def test_all_methods(self):\n        for method in [\"GET\", \"DELETE\", \"OPTIONS\"]:\n            response = self.fetch(\"/all_methods\", method=method)\n            self.assertEqual(response.body, utf8(method))\n        for method in [\"POST\", \"PUT\", \"PATCH\"]:\n            response = self.fetch(\"/all_methods\", method=method, body=b\"\")\n            self.assertEqual(response.body, utf8(method))\n        response = self.fetch(\"/all_methods\", method=\"HEAD\")\n        self.assertEqual(response.body, b\"\")\n        response = self.fetch(\n            \"/all_methods\", method=\"OTHER\", allow_nonstandard_methods=True\n        )\n        self.assertEqual(response.body, b\"OTHER\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that the HTTP client correctly sends requests using various HTTP methods and validates the server's responses, ensuring support for standard, non-standard, and empty-body methods."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_body_sanity_checks", "line_number": 609, "body": "def test_body_sanity_checks(self):\n        # These methods require a body.\n        for method in (\"POST\", \"PUT\", \"PATCH\"):\n            with self.assertRaises(ValueError) as context:\n                self.fetch(\"/all_methods\", method=method, raise_error=True)\n            self.assertIn(\"must not be None\", str(context.exception))\n\n            resp = self.fetch(\n                \"/all_methods\", method=method, allow_nonstandard_methods=True\n            )\n            self.assertEqual(resp.code, 200)\n\n        # These methods don't allow a body.\n        for method in (\"GET\", \"DELETE\", \"OPTIONS\"):\n            with self.assertRaises(ValueError) as context:\n                self.fetch(\n                    \"/all_methods\", method=method, body=b\"asdf\", raise_error=True\n                )\n            self.assertIn(\"must be None\", str(context.exception))\n\n            # In most cases this can be overridden, but curl_httpclient\n            # does not allow body with a GET at all.\n            if method != \"GET\":\n                self.fetch(\n                    \"/all_methods\",\n                    method=method,\n                    body=b\"asdf\",\n                    allow_nonstandard_methods=True,\n                    raise_error=True,\n                )\n                self.assertEqual(resp.code, 200)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Unit test method of HTTPClientCommonTestCase that verifies HTTP methods enforce correct body presence rules, ensuring methods requiring a body reject missing content and methods disallowing a body reject its presence, supporting validation of HTTP request behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_put_307", "line_number": 657, "body": "def test_put_307(self):\n        response = self.fetch(\n            \"/redirect?status=307&url=/put\", method=\"PUT\", body=b\"hello\"\n        )\n        response.rethrow()\n        self.assertEqual(response.body, b\"Put body: hello\")", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Test method that verifies a HTTP PUT request correctly follows a 307 redirect and preserves the request body during redirection. It ensures the HTTP client handles temporary redirects for PUT methods as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_non_ascii_header", "line_number": 664, "body": "def test_non_ascii_header(self):\n        # Non-ascii headers are sent as latin1.\n        response = self.fetch(\"/set_header?k=foo&v=%E9\")\n        response.rethrow()\n        self.assertEqual(response.headers[\"Foo\"], native_str(u\"\\u00e9\"))", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP headers containing non-ASCII characters are correctly encoded and decoded using Latin-1 encoding, ensuring proper handling of such headers in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_response_times", "line_number": 670, "body": "def test_response_times(self):\n        # A few simple sanity checks of the response time fields to\n        # make sure they're using the right basis (between the\n        # wall-time and monotonic clocks).\n        start_time = time.time()\n        response = self.fetch(\"/hello\")\n        response.rethrow()\n        self.assertGreaterEqual(response.request_time, 0)\n        self.assertLess(response.request_time, 1.0)\n        # A very crude check to make sure that start_time is based on\n        # wall time and not the monotonic clock.\n        assert response.start_time is not None\n        self.assertLess(abs(response.start_time - start_time), 1.0)\n\n        for k, v in response.time_info.items():\n            self.assertTrue(0 <= v < 1.0, \"time_info[%s] out of bounds: %s\" % (k, v))", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP response time measurements are correctly recorded and within expected bounds, ensuring timing is based on appropriate clock sources for accurate performance tracking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_zero_timeout", "line_number": 687, "body": "def test_zero_timeout(self):\n        response = self.fetch(\"/hello\", connect_timeout=0)\n        self.assertEqual(response.code, 200)\n\n        response = self.fetch(\"/hello\", request_timeout=0)\n        self.assertEqual(response.code, 200)\n\n        response = self.fetch(\"/hello\", connect_timeout=0, request_timeout=0)\n        self.assertEqual(response.code, 200)", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that HTTP requests with zero connection or request timeouts successfully receive a 200 OK response, ensuring the client handles zero-timeout parameters correctly. It verifies timeout edge case behavior in HTTP request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_error_after_cancel", "line_number": 698, "body": "def test_error_after_cancel(self):\n        fut = self.http_client.fetch(self.get_url(\"/404\"))\n        self.assertTrue(fut.cancel())\n        with ExpectLog(app_log, \"Exception after Future was cancelled\") as el:\n            # We can't wait on the cancelled Future any more, so just\n            # let the IOLoop run until the exception gets logged (or\n            # not, in which case we exit the loop and ExpectLog will\n            # raise).\n            for i in range(100):\n                yield gen.sleep(0.01)\n                if el.logged_stack:\n                    break", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Tests that an error occurring after cancelling an HTTP request is properly logged, ensuring the client handles cancellation and subsequent exceptions as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_request_set", "line_number": 713, "body": "def test_request_set(self):\n        proxy = _RequestProxy(\n            HTTPRequest(\"http://example.com/\", user_agent=\"foo\"), dict()\n        )\n        self.assertEqual(proxy.user_agent, \"foo\")", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Unit test method in RequestProxyTest that verifies the _RequestProxy correctly extracts and stores the user agent from an HTTPRequest object."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_default_set", "line_number": 719, "body": "def test_default_set(self):\n        proxy = _RequestProxy(\n            HTTPRequest(\"http://example.com/\"), dict(network_interface=\"foo\")\n        )\n        self.assertEqual(proxy.network_interface, \"foo\")", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Unit test method in RequestProxyTest that verifies setting the default network interface attribute on a _RequestProxy instance works as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_both_set", "line_number": 725, "body": "def test_both_set(self):\n        proxy = _RequestProxy(\n            HTTPRequest(\"http://example.com/\", proxy_host=\"foo\"), dict(proxy_host=\"bar\")\n        )\n        self.assertEqual(proxy.proxy_host, \"foo\")", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Test method of RequestProxyTest that verifies the _RequestProxy prioritizes the proxy_host set in the HTTPRequest over the one provided in additional parameters."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_neither_set", "line_number": 731, "body": "def test_neither_set(self):\n        proxy = _RequestProxy(HTTPRequest(\"http://example.com/\"), dict())\n        self.assertIs(proxy.auth_username, None)", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Test method verifying that when no authentication is provided, the RequestProxy correctly reflects a None auth_username value. It ensures default authentication handling behavior in request proxy scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_bad_attribute", "line_number": 735, "body": "def test_bad_attribute(self):\n        proxy = _RequestProxy(HTTPRequest(\"http://example.com/\"), dict())\n        with self.assertRaises(AttributeError):\n            proxy.foo", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Unit test method in RequestProxyTest that verifies accessing a nonexistent attribute on a request proxy raises an AttributeError. It ensures the proxy correctly handles invalid attribute access."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_defaults_none", "line_number": 740, "body": "def test_defaults_none(self):\n        proxy = _RequestProxy(HTTPRequest(\"http://example.com/\"), None)\n        self.assertIs(proxy.auth_username, None)", "is_method": true, "class_name": "RequestProxyTest", "function_description": "Unit test method in RequestProxyTest that verifies the _RequestProxy correctly sets its auth_username attribute to None when no authentication information is provided."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_str", "line_number": 746, "body": "def test_str(self):\n        response = HTTPResponse(  # type: ignore\n            HTTPRequest(\"http://example.com\"), 200, buffer=BytesIO()\n        )\n        s = str(response)\n        self.assertTrue(s.startswith(\"HTTPResponse(\"))\n        self.assertIn(\"code=200\", s)", "is_method": true, "class_name": "HTTPResponseTestCase", "function_description": "Tests that the string representation of an HTTPResponse object properly includes the status code and starts with the class name, ensuring readable and informative output for debugging or logging."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "setUp", "line_number": 756, "body": "def setUp(self):\n        self.server_ioloop = IOLoop()\n        event = threading.Event()\n\n        @gen.coroutine\n        def init_server():\n            sock, self.port = bind_unused_port()\n            app = Application([(\"/\", HelloWorldHandler)])\n            self.server = HTTPServer(app)\n            self.server.add_socket(sock)\n            event.set()\n\n        def start():\n            self.server_ioloop.run_sync(init_server)\n            self.server_ioloop.start()\n\n        self.server_thread = threading.Thread(target=start)\n        self.server_thread.start()\n        event.wait()\n\n        self.http_client = HTTPClient()", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Sets up a synchronous HTTP test client and starts a Tornado HTTP server in a separate thread for testing; it prepares the environment for HTTP request handling in unit tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "tearDown", "line_number": 778, "body": "def tearDown(self):\n        def stop_server():\n            self.server.stop()\n            # Delay the shutdown of the IOLoop by several iterations because\n            # the server may still have some cleanup work left when\n            # the client finishes with the response (this is noticeable\n            # with http/2, which leaves a Future with an unexamined\n            # StreamClosedError on the loop).\n\n            @gen.coroutine\n            def slow_stop():\n                yield self.server.close_all_connections()\n                # The number of iterations is difficult to predict. Typically,\n                # one is sufficient, although sometimes it needs more.\n                for i in range(5):\n                    yield\n                self.server_ioloop.stop()\n\n            self.server_ioloop.add_callback(slow_stop)\n\n        self.server_ioloop.add_callback(stop_server)\n        self.server_thread.join()\n        self.http_client.close()\n        self.server_ioloop.close(all_fds=True)", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Cleans up and shuts down the test HTTP server and client, ensuring all connections and I/O resources are properly closed after each test run. This method supports reliable resource management in asynchronous server testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "get_url", "line_number": 803, "body": "def get_url(self, path):\n        return \"http://127.0.0.1:%d%s\" % (self.port, path)", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Constructs and returns a full HTTP URL using the local host address, the instance's port, and the given path. Useful for generating consistent URLs for HTTP requests within tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_sync_client", "line_number": 806, "body": "def test_sync_client(self):\n        response = self.http_client.fetch(self.get_url(\"/\"))\n        self.assertEqual(b\"Hello world!\", response.body)", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Simple test method in SyncHTTPClientTest that verifies the synchronous HTTP client correctly fetches a response with the expected content. It is used to ensure basic client-server communication works as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_sync_client_error", "line_number": 810, "body": "def test_sync_client_error(self):\n        # Synchronous HTTPClient raises errors directly; no need for\n        # response.rethrow()\n        with self.assertRaises(HTTPError) as assertion:\n            self.http_client.fetch(self.get_url(\"/notfound\"))\n        self.assertEqual(assertion.exception.code, 404)", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Unit test method in SyncHTTPClientTest that verifies the synchronous HTTP client raises HTTPError correctly for failed requests, ensuring proper error handling in synchronous HTTP operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_destructor_log", "line_number": 819, "body": "def test_destructor_log(self):\n        # Regression test for\n        # https://github.com/tornadoweb/tornado/issues/2539\n        #\n        # In the past, the following program would log an\n        # \"inconsistent AsyncHTTPClient cache\" error from a destructor\n        # when the process is shutting down. The shutdown process is\n        # subtle and I don't fully understand it; the failure does not\n        # manifest if that lambda isn't there or is a simpler object\n        # like an int (nor does it manifest in the tornado test suite\n        # as a whole, which is why we use this subprocess).\n        proc = subprocess.run(\n            [\n                sys.executable,\n                \"-c\",\n                \"from tornado.httpclient import HTTPClient; f = lambda: None; c = HTTPClient()\",\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            check=True,\n            timeout=5,\n        )\n        if proc.stdout:\n            print(\"STDOUT:\")\n            print(to_unicode(proc.stdout))\n        if proc.stdout:\n            self.fail(\"subprocess produced unexpected output\")", "is_method": true, "class_name": "SyncHTTPClientSubprocessTest", "function_description": "This test method verifies that no error logs occur from HTTPClient destructors during subprocess shutdown, preventing regressions related to asynchronous HTTP client cache inconsistencies. It ensures stable cleanup behavior in Tornado's synchronous HTTP client."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_headers", "line_number": 849, "body": "def test_headers(self):\n        request = HTTPRequest(\"http://example.com\", headers={\"foo\": \"bar\"})\n        self.assertEqual(request.headers, {\"foo\": \"bar\"})", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Tests that an HTTPRequest correctly stores and exposes custom HTTP headers. This ensures header management behaves as expected during request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_headers_setter", "line_number": 853, "body": "def test_headers_setter(self):\n        request = HTTPRequest(\"http://example.com\")\n        request.headers = {\"bar\": \"baz\"}  # type: ignore\n        self.assertEqual(request.headers, {\"bar\": \"baz\"})", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Test method in HTTPRequestTestCase that verifies the HTTPRequest class correctly assigns and retrieves HTTP headers through its headers setter and getter."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_null_headers_setter", "line_number": 858, "body": "def test_null_headers_setter(self):\n        request = HTTPRequest(\"http://example.com\")\n        request.headers = None  # type: ignore\n        self.assertEqual(request.headers, {})", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Unit test method verifying that setting HTTPRequest headers to None resets them to an empty dictionary, ensuring consistent header handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_body", "line_number": 863, "body": "def test_body(self):\n        request = HTTPRequest(\"http://example.com\", body=\"foo\")\n        self.assertEqual(request.body, utf8(\"foo\"))", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Unit test method of HTTPRequestTestCase that verifies the HTTPRequest correctly stores and returns the request body as UTF-8 encoded data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_body_setter", "line_number": 867, "body": "def test_body_setter(self):\n        request = HTTPRequest(\"http://example.com\")\n        request.body = \"foo\"  # type: ignore\n        self.assertEqual(request.body, utf8(\"foo\"))", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Unit test method in HTTPRequestTestCase that verifies the HTTPRequest class correctly encodes and stores the request body as UTF-8 when set."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_if_modified_since", "line_number": 872, "body": "def test_if_modified_since(self):\n        http_date = datetime.datetime.utcnow()\n        request = HTTPRequest(\"http://example.com\", if_modified_since=http_date)\n        self.assertEqual(\n            request.headers, {\"If-Modified-Since\": format_timestamp(http_date)}\n        )", "is_method": true, "class_name": "HTTPRequestTestCase", "function_description": "Unit test method in HTTPRequestTestCase that verifies whether the HTTP \"If-Modified-Since\" header is correctly set from a given datetime to handle conditional GET requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_copy", "line_number": 881, "body": "def test_copy(self):\n        e = HTTPError(403)\n        e2 = copy.copy(e)\n        self.assertIsNot(e, e2)\n        self.assertEqual(e.code, e2.code)", "is_method": true, "class_name": "HTTPErrorTestCase", "function_description": "Unit test method in HTTPErrorTestCase that verifies copying an HTTPError instance preserves its code while creating an independent copy."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_plain_error", "line_number": 887, "body": "def test_plain_error(self):\n        e = HTTPError(403)\n        self.assertEqual(str(e), \"HTTP 403: Forbidden\")\n        self.assertEqual(repr(e), \"HTTP 403: Forbidden\")", "is_method": true, "class_name": "HTTPErrorTestCase", "function_description": "Unit test in HTTPErrorTestCase that verifies an HTTPError with status 403 produces the correct string and representation messages. It ensures error message formatting matches expected output for forbidden access errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "test_error_with_response", "line_number": 892, "body": "def test_error_with_response(self):\n        resp = HTTPResponse(HTTPRequest(\"http://example.com/\"), 403)\n        with self.assertRaises(HTTPError) as cm:\n            resp.rethrow()\n        e = cm.exception\n        self.assertEqual(str(e), \"HTTP 403: Forbidden\")\n        self.assertEqual(repr(e), \"HTTP 403: Forbidden\")", "is_method": true, "class_name": "HTTPErrorTestCase", "function_description": "This test method verifies that an HTTP response with an error status correctly raises an HTTPError with the expected message when rethrowing the error. It ensures proper error handling and messaging for HTTP error responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "header_callback", "line_number": 454, "body": "def header_callback(header_line):\n            if header_line.startswith(\"HTTP/1.1 101\"):\n                # Upgrading to HTTP/2\n                pass\n            elif header_line.startswith(\"HTTP/\"):\n                first_line.append(header_line)\n            elif header_line != \"\\r\\n\":\n                k, v = header_line.split(\":\", 1)\n                headers[k.lower()] = v.strip()", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Parses HTTP response header lines, identifying status lines and extracting header key-value pairs to populate a headers dictionary."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "init_server", "line_number": 761, "body": "def init_server():\n            sock, self.port = bind_unused_port()\n            app = Application([(\"/\", HelloWorldHandler)])\n            self.server = HTTPServer(app)\n            self.server.add_socket(sock)\n            event.set()", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Initializes and starts an HTTP server on an available port with a predefined handler, enabling the server to accept requests during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "stop_server", "line_number": 779, "body": "def stop_server():\n            self.server.stop()\n            # Delay the shutdown of the IOLoop by several iterations because\n            # the server may still have some cleanup work left when\n            # the client finishes with the response (this is noticeable\n            # with http/2, which leaves a Future with an unexamined\n            # StreamClosedError on the loop).\n\n            @gen.coroutine\n            def slow_stop():\n                yield self.server.close_all_connections()\n                # The number of iterations is difficult to predict. Typically,\n                # one is sufficient, although sometimes it needs more.\n                for i in range(5):\n                    yield\n                self.server_ioloop.stop()\n\n            self.server_ioloop.add_callback(slow_stop)", "is_method": true, "class_name": "SyncHTTPClientTest", "function_description": "Stops the server gracefully by closing all connections and allowing asynchronous cleanup before stopping the event loop, ensuring proper shutdown especially in HTTP/2 scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpclient_test.py", "function": "accept_callback", "line_number": 229, "body": "def accept_callback(conn, address):\n                # fake an HTTP server using chunked encoding where the final chunks\n                # and connection close all happen at once\n                stream = IOStream(conn)\n                request_data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n                if b\"HTTP/1.\" not in request_data:\n                    self.skipTest(\"requires HTTP/1.x\")\n                yield stream.write(\n                    b\"\"\"\\\nHTTP/1.1 200 OK\nTransfer-Encoding: chunked\n\n1\n1\n1\n2\n0\n\n\"\"\".replace(\n                        b\"\\n\", b\"\\r\\n\"\n                    )\n                )\n                stream.close()", "is_method": true, "class_name": "HTTPClientCommonTestCase", "function_description": "Simulates an HTTP/1.x server connection that responds using chunked transfer encoding with multiple chunks sent simultaneously, useful for testing HTTP client handling of chunked responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "delay", "line_number": 32, "body": "def delay(self, iterations, arg):\n        \"\"\"Returns arg after a number of IOLoop iterations.\"\"\"\n        for i in range(iterations):\n            yield gen.moment\n        raise gen.Return(arg)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Delays returning a given argument by yielding control for a specified number of asynchronous IOLoop iterations. Useful for simulating or pausing execution in asynchronous test scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "async_future", "line_number": 39, "body": "def async_future(self, result):\n        yield gen.moment\n        return result", "is_method": true, "class_name": "GenBasicTest", "function_description": "Provides an asynchronous generator that yields control once before returning a given result, enabling non-blocking operation in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "async_exception", "line_number": 44, "body": "def async_exception(self, e):\n        yield gen.moment\n        raise e", "is_method": true, "class_name": "GenBasicTest", "function_description": "Raises the given exception asynchronously after yielding control briefly. Useful for simulating or handling exceptions within asynchronous flows in tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "add_one_async", "line_number": 49, "body": "def add_one_async(self, x):\n        yield gen.moment\n        raise gen.Return(x + 1)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Produces an asynchronous generator that yields control briefly before returning the input value incremented by one. This function enables asynchronous computations that require yielding execution momentarily."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_no_yield", "line_number": 53, "body": "def test_no_yield(self):\n        @gen.coroutine\n        def f():\n            pass\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Method in GenBasicTest that runs an empty coroutine to verify the test framework's ability to handle coroutines with no yield statements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_exception_phase1", "line_number": 60, "body": "def test_exception_phase1(self):\n        @gen.coroutine\n        def f():\n            1 / 0\n\n        self.assertRaises(ZeroDivisionError, self.io_loop.run_sync, f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "This test method verifies that the asynchronous function correctly raises a ZeroDivisionError when a division by zero occurs, ensuring proper exception handling in the async execution context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_exception_phase2", "line_number": 67, "body": "def test_exception_phase2(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            1 / 0\n\n        self.assertRaises(ZeroDivisionError, self.io_loop.run_sync, f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Core test method of the GenBasicTest class that verifies if a coroutine raising a ZeroDivisionError is correctly handled during asynchronous execution. It ensures proper exception propagation in asynchronous phases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_bogus_yield", "line_number": 75, "body": "def test_bogus_yield(self):\n        @gen.coroutine\n        def f():\n            yield 42\n\n        self.assertRaises(gen.BadYieldError, self.io_loop.run_sync, f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that a coroutine yielding an invalid value raises the appropriate BadYieldError, ensuring correct error handling in asynchronous code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_bogus_yield_tuple", "line_number": 82, "body": "def test_bogus_yield_tuple(self):\n        @gen.coroutine\n        def f():\n            yield (1, 2)\n\n        self.assertRaises(gen.BadYieldError, self.io_loop.run_sync, f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that a coroutine raising an error when yielding an invalid value (a tuple) behaves as expected, validating error handling in asynchronous code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_reuse", "line_number": 89, "body": "def test_reuse(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n\n        self.io_loop.run_sync(f)\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Provides a test method in GenBasicTest that verifies running the same asynchronous coroutine twice on an I/O loop completes successfully. It ensures coroutine reuse does not cause errors during event loop execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_none", "line_number": 97, "body": "def test_none(self):\n        @gen.coroutine\n        def f():\n            yield None\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies asynchronous coroutine handling of a None yield value within an event loop. It ensures the coroutine mechanism correctly processes a yield of None without errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi", "line_number": 104, "body": "def test_multi(self):\n        @gen.coroutine\n        def f():\n            results = yield [self.add_one_async(1), self.add_one_async(2)]\n            self.assertEqual(results, [2, 3])\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Unit test method of the GenBasicTest class that verifies asynchronous execution of multiple add_one_async calls, ensuring their combined results match expected incremented values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_dict", "line_number": 112, "body": "def test_multi_dict(self):\n        @gen.coroutine\n        def f():\n            results = yield dict(foo=self.add_one_async(1), bar=self.add_one_async(2))\n            self.assertEqual(results, dict(foo=2, bar=3))\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies asynchronous execution of multiple coroutines returning a dictionary, ensuring the combined results match expected incremented values."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_delayed", "line_number": 120, "body": "def test_multi_delayed(self):\n        @gen.coroutine\n        def f():\n            # callbacks run at different times\n            responses = yield gen.multi_future(\n                [self.delay(3, \"v1\"), self.delay(1, \"v2\")]\n            )\n            self.assertEqual(responses, [\"v1\", \"v2\"])\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "This test method verifies asynchronous execution order by ensuring multiple delayed operations complete correctly and return their expected results, validating concurrent handling in the GenBasicTest environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_dict_delayed", "line_number": 131, "body": "def test_multi_dict_delayed(self):\n        @gen.coroutine\n        def f():\n            # callbacks run at different times\n            responses = yield gen.multi_future(\n                dict(foo=self.delay(3, \"v1\"), bar=self.delay(1, \"v2\"))\n            )\n            self.assertEqual(responses, dict(foo=\"v1\", bar=\"v2\"))\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Core testing method in GenBasicTest that verifies gen.multi_future correctly waits for multiple asynchronous dictionary-based futures to complete, ensuring their results are properly aggregated by keys."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_performance", "line_number": 144, "body": "def test_multi_performance(self):\n        # Yielding a list used to have quadratic performance; make\n        # sure a large list stays reasonable.  On my laptop a list of\n        # 2000 used to take 1.8s, now it takes 0.12.\n        start = time.time()\n        yield [gen.moment for i in range(2000)]\n        end = time.time()\n        self.assertLess(end - start, 1.0)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies the performance efficiency of generating a large list to ensure it completes within a specified time limit."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_empty", "line_number": 154, "body": "def test_multi_empty(self):\n        # Empty lists or dicts should return the same type.\n        x = yield []\n        self.assertTrue(isinstance(x, list))\n        y = yield {}\n        self.assertTrue(isinstance(y, dict))", "is_method": true, "class_name": "GenBasicTest", "function_description": "Core test method of the GenBasicTest class that verifies a generator yields and receives empty collections preserving their original types, ensuring correct handling of empty lists and dictionaries in generator interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_future", "line_number": 162, "body": "def test_future(self):\n        result = yield self.async_future(1)\n        self.assertEqual(result, 1)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies the async_future method correctly completes with the expected result. It ensures asynchronous operations return the intended value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_future", "line_number": 167, "body": "def test_multi_future(self):\n        results = yield [self.async_future(1), self.async_future(2)]\n        self.assertEqual(results, [1, 2])", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that multiple asynchronous futures complete correctly and their results are gathered as a list, validating concurrent asynchronous execution behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_future_duplicate", "line_number": 172, "body": "def test_multi_future_duplicate(self):\n        # Note that this doesn't work with native corotines, only with\n        # decorated coroutines.\n        f = self.async_future(2)\n        results = yield [self.async_future(1), f, self.async_future(3), f]\n        self.assertEqual(results, [1, 2, 3, 2])", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies handling of a list containing duplicate asynchronous futures, ensuring their correct resolution and result consistency when yielded together."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_dict_future", "line_number": 180, "body": "def test_multi_dict_future(self):\n        results = yield dict(foo=self.async_future(1), bar=self.async_future(2))\n        self.assertEqual(results, dict(foo=1, bar=2))", "is_method": true, "class_name": "GenBasicTest", "function_description": "A test method in GenBasicTest that verifies asynchronous futures within a dictionary resolve correctly into expected results, ensuring concurrent async operations return the proper combined output."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_exceptions", "line_number": 185, "body": "def test_multi_exceptions(self):\n        with ExpectLog(app_log, \"Multiple exceptions in yield list\"):\n            with self.assertRaises(RuntimeError) as cm:\n                yield gen.Multi(\n                    [\n                        self.async_exception(RuntimeError(\"error 1\")),\n                        self.async_exception(RuntimeError(\"error 2\")),\n                    ]\n                )\n        self.assertEqual(str(cm.exception), \"error 1\")\n\n        # With only one exception, no error is logged.\n        with self.assertRaises(RuntimeError):\n            yield gen.Multi(\n                [self.async_exception(RuntimeError(\"error 1\")), self.async_future(2)]\n            )\n\n        # Exception logging may be explicitly quieted.\n        with self.assertRaises(RuntimeError):\n            yield gen.Multi(\n                [\n                    self.async_exception(RuntimeError(\"error 1\")),\n                    self.async_exception(RuntimeError(\"error 2\")),\n                ],\n                quiet_exceptions=RuntimeError,\n            )", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that the GenBasicTest class correctly handles multiple asynchronous exceptions, ensuring proper exception raising and logging behaviors in concurrent operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_future_exceptions", "line_number": 213, "body": "def test_multi_future_exceptions(self):\n        with ExpectLog(app_log, \"Multiple exceptions in yield list\"):\n            with self.assertRaises(RuntimeError) as cm:\n                yield [\n                    self.async_exception(RuntimeError(\"error 1\")),\n                    self.async_exception(RuntimeError(\"error 2\")),\n                ]\n        self.assertEqual(str(cm.exception), \"error 1\")\n\n        # With only one exception, no error is logged.\n        with self.assertRaises(RuntimeError):\n            yield [self.async_exception(RuntimeError(\"error 1\")), self.async_future(2)]\n\n        # Exception logging may be explicitly quieted.\n        with self.assertRaises(RuntimeError):\n            yield gen.multi_future(\n                [\n                    self.async_exception(RuntimeError(\"error 1\")),\n                    self.async_exception(RuntimeError(\"error 2\")),\n                ],\n                quiet_exceptions=RuntimeError,\n            )", "is_method": true, "class_name": "GenBasicTest", "function_description": "This test method verifies how multiple asynchronous exceptions are handled and logged when yielded concurrently. It ensures proper exception raising, logging behavior, and supports quieting specific exceptions during multi-future executions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_raise_return", "line_number": 236, "body": "def test_sync_raise_return(self):\n        @gen.coroutine\n        def f():\n            raise gen.Return()\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest verifying that a coroutine raising an empty gen.Return() correctly propagates when run synchronously via the I/O loop. It ensures compatibility of return flow in asynchronous code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_raise_return", "line_number": 243, "body": "def test_async_raise_return(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return()\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that an asynchronous coroutine correctly raises a gen.Return exception after yielding, validating the handling of asynchronous control flow in the GenBasicTest environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_raise_return_value", "line_number": 251, "body": "def test_sync_raise_return_value(self):\n        @gen.coroutine\n        def f():\n            raise gen.Return(42)\n\n        self.assertEqual(42, self.io_loop.run_sync(f))", "is_method": true, "class_name": "GenBasicTest", "function_description": "Tests that a coroutine raising a return value correctly returns that value when run synchronously, ensuring proper handling of asynchronous return semantics in the GenBasicTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_raise_return_value_tuple", "line_number": 258, "body": "def test_sync_raise_return_value_tuple(self):\n        @gen.coroutine\n        def f():\n            raise gen.Return((1, 2))\n\n        self.assertEqual((1, 2), self.io_loop.run_sync(f))", "is_method": true, "class_name": "GenBasicTest", "function_description": "This test verifies that a coroutine raising a gen.Return with a tuple correctly returns that tuple when run synchronously, ensuring expected behavior of synchronous coroutine execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_raise_return_value", "line_number": 265, "body": "def test_async_raise_return_value(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return(42)\n\n        self.assertEqual(42, self.io_loop.run_sync(f))", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method in GenBasicTest that verifies an asynchronous coroutine correctly raises a return value, ensuring proper handling and retrieval of yielded results in asynchronous code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_raise_return_value_tuple", "line_number": 273, "body": "def test_async_raise_return_value_tuple(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return((1, 2))\n\n        self.assertEqual((1, 2), self.io_loop.run_sync(f))", "is_method": true, "class_name": "GenBasicTest", "function_description": "Test method verifying that an asynchronous coroutine correctly raises a return value as a tuple, ensuring compatibility of async generators with expected return semantics."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "setUp", "line_number": 283, "body": "def setUp(self):\n        # Stray StopIteration exceptions can lead to tests exiting prematurely,\n        # so we need explicit checks here to make sure the tests run all\n        # the way through.\n        self.finished = False\n        super().setUp()", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Setup method in GenCoroutineTest that initializes test conditions to prevent premature test termination caused by stray StopIteration exceptions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "tearDown", "line_number": 290, "body": "def tearDown(self):\n        super().tearDown()\n        assert self.finished", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Method of GenCoroutineTest that finalizes test teardown by ensuring the coroutine completion flag is set, verifying that the test execution has properly finished."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_attributes", "line_number": 294, "body": "def test_attributes(self):\n        self.finished = True\n\n        def f():\n            yield gen.moment\n\n        coro = gen.coroutine(f)\n        self.assertEqual(coro.__name__, f.__name__)\n        self.assertEqual(coro.__module__, f.__module__)\n        self.assertIs(coro.__wrapped__, f)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Utility test method in GenCoroutineTest that verifies the preservation of function attributes when wrapping a generator function with gen.coroutine. It ensures metadata like name, module, and wrapped reference remain intact."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_is_coroutine_function", "line_number": 305, "body": "def test_is_coroutine_function(self):\n        self.finished = True\n\n        def f():\n            yield gen.moment\n\n        coro = gen.coroutine(f)\n        self.assertFalse(gen.is_coroutine_function(f))\n        self.assertTrue(gen.is_coroutine_function(coro))\n        self.assertFalse(gen.is_coroutine_function(coro()))", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests the identification of coroutine functions, confirming that wrapped functions are recognized as coroutines while original functions and coroutine instances are not. Useful for validating coroutine detection behavior in asynchronous programming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_gen_return", "line_number": 317, "body": "def test_sync_gen_return(self):\n        @gen.coroutine\n        def f():\n            raise gen.Return(42)\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies a synchronous generator coroutine correctly returns a specified value using gen.Return."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_gen_return", "line_number": 327, "body": "def test_async_gen_return(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return(42)\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that an asynchronous generator properly returns a specific value and completes execution, verifying expected coroutine behavior within the GenCoroutineTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_return", "line_number": 338, "body": "def test_sync_return(self):\n        @gen.coroutine\n        def f():\n            return 42\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "This test method verifies that a coroutine decorated function correctly returns a synchronous value when awaited. It ensures the coroutine yields the expected result within asynchronous code execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_return", "line_number": 348, "body": "def test_async_return(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            return 42\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies an asynchronous coroutine correctly returns the expected value upon completion. It ensures coroutine handling and result retrieval work as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_early_return", "line_number": 359, "body": "def test_async_early_return(self):\n        # A yield statement exists but is not executed, which means\n        # this function \"returns\" via an exception.  This exception\n        # doesn't happen before the exception handling is set up.\n        @gen.coroutine\n        def f():\n            if True:\n                return 42\n            yield gen.Task(self.io_loop.add_callback)\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that an asynchronous coroutine correctly returns a value early without executing any yield statements, validating proper handling of early return in async functions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_await", "line_number": 374, "body": "def test_async_await(self):\n        @gen.coroutine\n        def f1():\n            yield gen.moment\n            raise gen.Return(42)\n\n        # This test verifies that an async function can await a\n        # yield-based gen.coroutine, and that a gen.coroutine\n        # (the test method itself) can yield an async function.\n        async def f2():\n            result = await f1()\n            return result\n\n        result = yield f2()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests interoperability between Tornado-style gen.coroutine and native async/await functions, ensuring asynchronous functions can await coroutine yields and coroutines can yield async functions correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_asyncio_sleep_zero", "line_number": 392, "body": "def test_asyncio_sleep_zero(self):\n        # asyncio.sleep(0) turns into a special case (equivalent to\n        # `yield None`)\n        async def f():\n            import asyncio\n\n            await asyncio.sleep(0)\n            return 42\n\n        result = yield f()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies awaiting asyncio.sleep(0) correctly yields control and returns the expected result in an asynchronous coroutine."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_await_mixed_multi_native_future", "line_number": 406, "body": "def test_async_await_mixed_multi_native_future(self):\n        @gen.coroutine\n        def f1():\n            yield gen.moment\n\n        async def f2():\n            await f1()\n            return 42\n\n        @gen.coroutine\n        def f3():\n            yield gen.moment\n            raise gen.Return(43)\n\n        results = yield [f2(), f3()]\n        self.assertEqual(results, [42, 43])\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests integration of async/await and coroutine-style generators by running mixed asynchronous functions concurrently and verifying their returned results in the GenCoroutineTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_with_timeout", "line_number": 425, "body": "def test_async_with_timeout(self):\n        async def f1():\n            return 42\n\n        result = yield gen.with_timeout(datetime.timedelta(hours=1), f1())\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies an asynchronous coroutine completes within a specified timeout and returns the expected result."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_return_no_value", "line_number": 434, "body": "def test_sync_return_no_value(self):\n        @gen.coroutine\n        def f():\n            return\n\n        result = yield f()\n        self.assertEqual(result, None)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that a synchronous coroutine function with no return value yields None when awaited, verifying correct handling of such coroutines in asynchronous code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_return_no_value", "line_number": 444, "body": "def test_async_return_no_value(self):\n        # Without a return value we don't need python 3.3.\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            return\n\n        result = yield f()\n        self.assertEqual(result, None)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies an asynchronous coroutine correctly returns no value (None) after yielding, ensuring expected behavior of coroutines without explicit return results."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sync_raise", "line_number": 456, "body": "def test_sync_raise(self):\n        @gen.coroutine\n        def f():\n            1 / 0\n\n        # The exception is raised when the future is yielded\n        # (or equivalently when its result method is called),\n        # not when the function itself is called).\n        future = f()\n        with self.assertRaises(ZeroDivisionError):\n            yield future\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that a synchronous exception raised inside a coroutine is properly propagated when the coroutine's future is yielded, ensuring correct error handling in asynchronous code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_raise", "line_number": 470, "body": "def test_async_raise(self):\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            1 / 0\n\n        future = f()\n        with self.assertRaises(ZeroDivisionError):\n            yield future\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that verifies an asynchronous coroutine correctly raises a ZeroDivisionError during execution. It ensures exception handling works as expected in async code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_replace_yieldpoint_exception", "line_number": 482, "body": "def test_replace_yieldpoint_exception(self):\n        # Test exception handling: a coroutine can catch one exception\n        # raised by a yield point and raise a different one.\n        @gen.coroutine\n        def f1():\n            1 / 0\n\n        @gen.coroutine\n        def f2():\n            try:\n                yield f1()\n            except ZeroDivisionError:\n                raise KeyError()\n\n        future = f2()\n        with self.assertRaises(KeyError):\n            yield future\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that a coroutine can catch an exception raised during a yield and re-raise a different exception, verifying proper exception handling behavior in asynchronous coroutine execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_swallow_yieldpoint_exception", "line_number": 502, "body": "def test_swallow_yieldpoint_exception(self):\n        # Test exception handling: a coroutine can catch an exception\n        # raised by a yield point and not raise a different one.\n        @gen.coroutine\n        def f1():\n            1 / 0\n\n        @gen.coroutine\n        def f2():\n            try:\n                yield f1()\n            except ZeroDivisionError:\n                raise gen.Return(42)\n\n        result = yield f2()\n        self.assertEqual(result, 42)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that a coroutine correctly catches an exception raised at a yield point and returns a specified value without propagating a different error. Useful for verifying robust exception handling in asynchronous coroutine workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_moment", "line_number": 521, "body": "def test_moment(self):\n        calls = []\n\n        @gen.coroutine\n        def f(name, yieldable):\n            for i in range(5):\n                calls.append(name)\n                yield yieldable\n\n        # First, confirm the behavior without moment: each coroutine\n        # monopolizes the event loop until it finishes.\n        immediate = Future()  # type: Future[None]\n        immediate.set_result(None)\n        yield [f(\"a\", immediate), f(\"b\", immediate)]\n        self.assertEqual(\"\".join(calls), \"aaaaabbbbb\")\n\n        # With moment, they take turns.\n        calls = []\n        yield [f(\"a\", gen.moment), f(\"b\", gen.moment)]\n        self.assertEqual(\"\".join(calls), \"ababababab\")\n        self.finished = True\n\n        calls = []\n        yield [f(\"a\", gen.moment), f(\"b\", immediate)]\n        self.assertEqual(\"\".join(calls), \"abbbbbaaaa\")", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests coroutine scheduling behavior to verify how yielding different yieldables affects execution order, demonstrating the GenCoroutineTest\u2019s control over event loop concurrency and cooperative multitasking."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_sleep", "line_number": 548, "body": "def test_sleep(self):\n        yield gen.sleep(0.01)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Test method in GenCoroutineTest that yields a short asynchronous sleep, indicating completion afterward; useful for verifying coroutine-based sleep behavior in asynchronous code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_py3_leak_exception_context", "line_number": 553, "body": "def test_py3_leak_exception_context(self):\n        class LeakedException(Exception):\n            pass\n\n        @gen.coroutine\n        def inner(iteration):\n            raise LeakedException(iteration)\n\n        try:\n            yield inner(1)\n        except LeakedException as e:\n            self.assertEqual(str(e), \"1\")\n            self.assertIsNone(e.__context__)\n\n        try:\n            yield inner(2)\n        except LeakedException as e:\n            self.assertEqual(str(e), \"2\")\n            self.assertIsNone(e.__context__)\n\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that exceptions raised within asynchronous generator coroutines do not retain context from previous exceptions, ensuring proper exception isolation in asynchronous flows for the GenCoroutineTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_coroutine_refcounting", "line_number": 579, "body": "def test_coroutine_refcounting(self):\n        # On CPython, tasks and their arguments should be released immediately\n        # without waiting for garbage collection.\n        @gen.coroutine\n        def inner():\n            class Foo(object):\n                pass\n\n            local_var = Foo()\n            self.local_ref = weakref.ref(local_var)\n\n            def dummy():\n                pass\n\n            yield gen.coroutine(dummy)()\n            raise ValueError(\"Some error\")\n\n        @gen.coroutine\n        def inner2():\n            try:\n                yield inner()\n            except ValueError:\n                pass\n\n        self.io_loop.run_sync(inner2, timeout=3)\n\n        self.assertIs(self.local_ref(), None)\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Method in GenCoroutineTest that verifies coroutines release task and argument references promptly to avoid memory leaks, ensuring objects are garbage collected immediately after coroutine errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_asyncio_future_debug_info", "line_number": 608, "body": "def test_asyncio_future_debug_info(self):\n        self.finished = True\n        # Enable debug mode\n        asyncio_loop = asyncio.get_event_loop()\n        self.addCleanup(asyncio_loop.set_debug, asyncio_loop.get_debug())\n        asyncio_loop.set_debug(True)\n\n        def f():\n            yield gen.moment\n\n        coro = gen.coroutine(f)()\n        self.assertIsInstance(coro, asyncio.Future)\n        # We expect the coroutine repr() to show the place where\n        # it was instantiated\n        expected = \"created at %s:%d\" % (__file__, f.__code__.co_firstlineno + 3)\n        actual = repr(coro)\n        self.assertIn(expected, actual)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests that an asyncio coroutine created via gen.coroutine reports debug information showing its instantiation location when asyncio debug mode is enabled."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_asyncio_gather", "line_number": 627, "body": "def test_asyncio_gather(self):\n        # This demonstrates that tornado coroutines can be understood\n        # by asyncio (This failed prior to Tornado 5.0).\n        @gen.coroutine\n        def f():\n            yield gen.moment\n            raise gen.Return(1)\n\n        ret = yield asyncio.gather(f(), f())\n        self.assertEqual(ret, [1, 1])\n        self.finished = True", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Tests compatibility between Tornado coroutines and asyncio by confirming that asyncio.gather correctly awaits multiple Tornado coroutine results. Helps ensure seamless integration of Tornado async code within asyncio workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "get", "line_number": 642, "body": "def get(self):\n        yield gen.moment\n        self.write(\"1\")\n        yield gen.moment\n        self.write(\"2\")\n        yield gen.moment\n        self.finish(\"3\")", "is_method": true, "class_name": "GenCoroutineSequenceHandler", "function_description": "Provides a coroutine-based sequence that asynchronously writes incremental values and finishes with a final output, useful for managing stepwise asynchronous responses in GenCoroutineSequenceHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "get", "line_number": 653, "body": "def get(self):\n        yield gen.moment\n        self.write(\"1\")\n        yield gen.moment\n        self.write(\"2\")\n        yield gen.moment\n        # just write, don't finish\n        self.write(\"3\")", "is_method": true, "class_name": "GenCoroutineUnfinishedSequenceHandler", "function_description": "Handles a coroutine sequence by yielding control moments and incrementally writing output without completing the response, enabling asynchronous interaction with partial results."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "prepare", "line_number": 666, "body": "def prepare(self):\n        self.chunks = []  # type: List[str]\n        yield gen.moment\n        self.chunks.append(\"1\")", "is_method": true, "class_name": "UndecoratedCoroutinesHandler", "function_description": "Prepares internal state by resetting chunks and yields control once before appending an initial marker. It supports asynchronous coroutine management within UndecoratedCoroutinesHandler."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "get", "line_number": 672, "body": "def get(self):\n        self.chunks.append(\"2\")\n        yield gen.moment\n        self.chunks.append(\"3\")\n        yield gen.moment\n        self.write(\"\".join(self.chunks))", "is_method": true, "class_name": "UndecoratedCoroutinesHandler", "function_description": "Provides a coroutine-based method that appends markers asynchronously and writes their concatenation, demonstrating incremental execution flow typical in asynchronous handlers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "prepare", "line_number": 682, "body": "def prepare(self):\n        yield gen.moment\n        raise HTTPError(403)", "is_method": true, "class_name": "AsyncPrepareErrorHandler", "function_description": "Method in AsyncPrepareErrorHandler that immediately raises a 403 HTTP error after yielding control, typically used to enforce access restrictions during asynchronous request preparation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "get", "line_number": 686, "body": "def get(self):\n        self.finish(\"ok\")", "is_method": true, "class_name": "AsyncPrepareErrorHandler", "function_description": "Utility method of AsyncPrepareErrorHandler that completes an asynchronous request by sending a simple \"ok\" response, signaling successful handling without additional data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "get_app", "line_number": 697, "body": "def get_app(self):\n        return Application(\n            [\n                (\"/coroutine_sequence\", GenCoroutineSequenceHandler),\n                (\n                    \"/coroutine_unfinished_sequence\",\n                    GenCoroutineUnfinishedSequenceHandler,\n                ),\n                (\"/undecorated_coroutine\", UndecoratedCoroutinesHandler),\n                (\"/async_prepare_error\", AsyncPrepareErrorHandler),\n                (\"/native_coroutine\", NativeCoroutineHandler),\n            ]\n        )", "is_method": true, "class_name": "GenWebTest", "function_description": "Provides a configured web application instance with predefined URL routes linked to specific coroutine-based request handlers for testing asynchronous behaviors in the GenWebTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_coroutine_sequence_handler", "line_number": 711, "body": "def test_coroutine_sequence_handler(self):\n        response = self.fetch(\"/coroutine_sequence\")\n        self.assertEqual(response.body, b\"123\")", "is_method": true, "class_name": "GenWebTest", "function_description": "Core test method in GenWebTest that verifies the /coroutine_sequence endpoint returns the expected byte string response, ensuring correct handling of coroutine sequences in the web application."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_coroutine_unfinished_sequence_handler", "line_number": 715, "body": "def test_coroutine_unfinished_sequence_handler(self):\n        response = self.fetch(\"/coroutine_unfinished_sequence\")\n        self.assertEqual(response.body, b\"123\")", "is_method": true, "class_name": "GenWebTest", "function_description": "Test method in GenWebTest that verifies the response body from the \"/coroutine_unfinished_sequence\" endpoint matches the expected output \"123\". It ensures correct handling of unfinished coroutine sequences in web responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_undecorated_coroutines", "line_number": 719, "body": "def test_undecorated_coroutines(self):\n        response = self.fetch(\"/undecorated_coroutine\")\n        self.assertEqual(response.body, b\"123\")", "is_method": true, "class_name": "GenWebTest", "function_description": "Tests that a specific endpoint serving an undecorated coroutine returns the expected response, ensuring proper handling of coroutine-based web requests in the GenWebTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_async_prepare_error_handler", "line_number": 723, "body": "def test_async_prepare_error_handler(self):\n        response = self.fetch(\"/async_prepare_error\")\n        self.assertEqual(response.code, 403)", "is_method": true, "class_name": "GenWebTest", "function_description": "Tests that accessing the \"/async_prepare_error\" endpoint returns a 403 Forbidden response, verifying the error handling behavior of asynchronous preparation in the GenWebTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_native_coroutine_handler", "line_number": 727, "body": "def test_native_coroutine_handler(self):\n        response = self.fetch(\"/native_coroutine\")\n        self.assertEqual(response.code, 200)\n        self.assertEqual(response.body, b\"ok\")", "is_method": true, "class_name": "GenWebTest", "function_description": "Test method in GenWebTest that verifies the native coroutine handler endpoint responds successfully with status 200 and expected body content. It ensures correct asynchronous request handling in web application tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_timeout", "line_number": 735, "body": "def test_timeout(self):\n        with self.assertRaises(gen.TimeoutError):\n            yield gen.with_timeout(datetime.timedelta(seconds=0.1), Future())", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Method of WithTimeoutTest that verifies a timeout exception is raised when an operation exceeds a specified time limit, ensuring correct timeout handling in asynchronous code."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_completes_before_timeout", "line_number": 740, "body": "def test_completes_before_timeout(self):\n        future = Future()  # type: Future[str]\n        self.io_loop.add_timeout(\n            datetime.timedelta(seconds=0.1), lambda: future.set_result(\"asdf\")\n        )\n        result = yield gen.with_timeout(datetime.timedelta(seconds=3600), future)\n        self.assertEqual(result, \"asdf\")", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Test method in WithTimeoutTest that verifies an asynchronous operation completes within a specified timeout, ensuring the with_timeout function correctly waits and returns the expected result before timing out."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_fails_before_timeout", "line_number": 749, "body": "def test_fails_before_timeout(self):\n        future = Future()  # type: Future[str]\n        self.io_loop.add_timeout(\n            datetime.timedelta(seconds=0.1),\n            lambda: future.set_exception(ZeroDivisionError()),\n        )\n        with self.assertRaises(ZeroDivisionError):\n            yield gen.with_timeout(datetime.timedelta(seconds=3600), future)", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Tests that an operation raises an exception before a specified timeout elapses, verifying timeout handling behavior in asynchronous tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_already_resolved", "line_number": 759, "body": "def test_already_resolved(self):\n        future = Future()  # type: Future[str]\n        future.set_result(\"asdf\")\n        result = yield gen.with_timeout(datetime.timedelta(seconds=3600), future)\n        self.assertEqual(result, \"asdf\")", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Test method in WithTimeoutTest that verifies `gen.with_timeout` returns the result immediately if the given future is already resolved before the timeout. It ensures correct handling of pre-completed asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_timeout_concurrent_future", "line_number": 766, "body": "def test_timeout_concurrent_future(self):\n        # A concurrent future that does not resolve before the timeout.\n        with futures.ThreadPoolExecutor(1) as executor:\n            with self.assertRaises(gen.TimeoutError):\n                yield gen.with_timeout(\n                    self.io_loop.time(), executor.submit(time.sleep, 0.1)\n                )", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Tests that a concurrent future exceeding a specified timeout properly raises a timeout error, validating timeout handling in asynchronous execution contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_completed_concurrent_future", "line_number": 775, "body": "def test_completed_concurrent_future(self):\n        # A concurrent future that is resolved before we even submit it\n        # to with_timeout.\n        with futures.ThreadPoolExecutor(1) as executor:\n\n            def dummy():\n                pass\n\n            f = executor.submit(dummy)\n            f.result()  # wait for completion\n            yield gen.with_timeout(datetime.timedelta(seconds=3600), f)", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "Tests that a concurrent future already completed before applying a timeout behaves correctly when passed to a timeout utility. It verifies proper handling of pre-resolved futures in asynchronous timeout scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_normal_concurrent_future", "line_number": 788, "body": "def test_normal_concurrent_future(self):\n        # A conccurrent future that resolves while waiting for the timeout.\n        with futures.ThreadPoolExecutor(1) as executor:\n            yield gen.with_timeout(\n                datetime.timedelta(seconds=3600),\n                executor.submit(lambda: time.sleep(0.01)),\n            )", "is_method": true, "class_name": "WithTimeoutTest", "function_description": "This test method verifies that a concurrent future completes successfully before a specified timeout, ensuring proper behavior of timeout handling in asynchronous operations. It serves to validate time-limited task execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_empty_iterator", "line_number": 799, "body": "def test_empty_iterator(self):\n        g = gen.WaitIterator()\n        self.assertTrue(g.done(), \"empty generator iterated\")\n\n        with self.assertRaises(ValueError):\n            g = gen.WaitIterator(Future(), bar=Future())\n\n        self.assertEqual(g.current_index, None, \"bad nil current index\")\n        self.assertEqual(g.current_future, None, \"bad nil current future\")", "is_method": true, "class_name": "WaitIteratorTest", "function_description": "Test method in WaitIteratorTest that verifies the behavior of WaitIterator when initialized empty and with invalid parameters, ensuring proper error handling and initial state correctness."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_already_done", "line_number": 810, "body": "def test_already_done(self):\n        f1 = Future()  # type: Future[int]\n        f2 = Future()  # type: Future[int]\n        f3 = Future()  # type: Future[int]\n        f1.set_result(24)\n        f2.set_result(42)\n        f3.set_result(84)\n\n        g = gen.WaitIterator(f1, f2, f3)\n        i = 0\n        while not g.done():\n            r = yield g.next()\n            # Order is not guaranteed, but the current implementation\n            # preserves ordering of already-done Futures.\n            if i == 0:\n                self.assertEqual(g.current_index, 0)\n                self.assertIs(g.current_future, f1)\n                self.assertEqual(r, 24)\n            elif i == 1:\n                self.assertEqual(g.current_index, 1)\n                self.assertIs(g.current_future, f2)\n                self.assertEqual(r, 42)\n            elif i == 2:\n                self.assertEqual(g.current_index, 2)\n                self.assertIs(g.current_future, f3)\n                self.assertEqual(r, 84)\n            i += 1\n\n        self.assertEqual(g.current_index, None, \"bad nil current index\")\n        self.assertEqual(g.current_future, None, \"bad nil current future\")\n\n        dg = gen.WaitIterator(f1=f1, f2=f2)\n\n        while not dg.done():\n            dr = yield dg.next()\n            if dg.current_index == \"f1\":\n                self.assertTrue(\n                    dg.current_future == f1 and dr == 24,\n                    \"WaitIterator dict status incorrect\",\n                )\n            elif dg.current_index == \"f2\":\n                self.assertTrue(\n                    dg.current_future == f2 and dr == 42,\n                    \"WaitIterator dict status incorrect\",\n                )\n            else:\n                self.fail(\"got bad WaitIterator index {}\".format(dg.current_index))\n\n            i += 1\n\n        self.assertEqual(dg.current_index, None, \"bad nil current index\")\n        self.assertEqual(dg.current_future, None, \"bad nil current future\")", "is_method": true, "class_name": "WaitIteratorTest", "function_description": "This test method verifies that WaitIterator correctly yields results from already-completed Futures, maintaining accurate indexing and future references for both list and dictionary inputs. It ensures consistent iteration behavior over finished asynchronous tasks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "finish_coroutines", "line_number": 863, "body": "def finish_coroutines(self, iteration, futures):\n        if iteration == 3:\n            futures[2].set_result(24)\n        elif iteration == 5:\n            futures[0].set_exception(ZeroDivisionError())\n        elif iteration == 8:\n            futures[1].set_result(42)\n            futures[3].set_result(84)\n\n        if iteration < 8:\n            self.io_loop.add_callback(self.finish_coroutines, iteration + 1, futures)", "is_method": true, "class_name": "WaitIteratorTest", "function_description": "Method of WaitIteratorTest that simulates completion of asynchronous tasks by resolving or raising exceptions on specific iterations, useful for testing coroutine behavior and event loop scheduling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_no_ref", "line_number": 939, "body": "def test_no_ref(self):\n        # In this usage, there is no direct hard reference to the\n        # WaitIterator itself, only the Future it returns. Since\n        # WaitIterator uses weak references internally to improve GC\n        # performance, this used to cause problems.\n        yield gen.with_timeout(\n            datetime.timedelta(seconds=0.1), gen.WaitIterator(gen.sleep(0)).next()\n        )", "is_method": true, "class_name": "WaitIteratorTest", "function_description": "Test method in WaitIteratorTest class verifying that WaitIterator correctly handles cases without strong references, ensuring proper garbage collection when only its Future is referenced."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "is_pypy3", "line_number": 950, "body": "def is_pypy3(self):\n        return platform.python_implementation() == \"PyPy\" and sys.version_info > (3,)", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Checks if the current Python runtime is PyPy with version 3 or higher, enabling code to adapt behavior based on running environment specifics."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_gc", "line_number": 954, "body": "def test_gc(self):\n        # GitHub issue 1769: Runner objects can get GCed unexpectedly\n        # while their future is alive.\n        weakref_scope = [None]  # type: List[Optional[weakref.ReferenceType]]\n\n        def callback():\n            gc.collect(2)\n            weakref_scope[0]().set_result(123)  # type: ignore\n\n        @gen.coroutine\n        def tester():\n            fut = Future()  # type: Future[int]\n            weakref_scope[0] = weakref.ref(fut)\n            self.io_loop.add_callback(callback)\n            yield fut\n\n        yield gen.with_timeout(datetime.timedelta(seconds=0.2), tester())", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Core test method in RunnerGCTest that verifies Runner objects are not prematurely garbage collected while their futures are still pending, ensuring proper lifecycle management in asynchronous execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_gc_infinite_coro", "line_number": 972, "body": "def test_gc_infinite_coro(self):\n        # GitHub issue 2229: suspended coroutines should be GCed when\n        # their loop is closed, even if they're involved in a reference\n        # cycle.\n        loop = self.get_new_ioloop()\n        result = []  # type: List[Optional[bool]]\n        wfut = []\n\n        @gen.coroutine\n        def infinite_coro():\n            try:\n                while True:\n                    yield gen.sleep(1e-3)\n                    result.append(True)\n            finally:\n                # coroutine finalizer\n                result.append(None)\n\n        @gen.coroutine\n        def do_something():\n            fut = infinite_coro()\n            fut._refcycle = fut  # type: ignore\n            wfut.append(weakref.ref(fut))\n            yield gen.sleep(0.2)\n\n        loop.run_sync(do_something)\n        loop.close()\n        gc.collect()\n        # Future was collected\n        self.assertIs(wfut[0](), None)\n        # At least one wakeup\n        self.assertGreaterEqual(len(result), 2)\n        if not self.is_pypy3():\n            # coroutine finalizer was called (not on PyPy3 apparently)\n            self.assertIs(result[-1], None)", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Tests that suspended coroutines involved in reference cycles are properly garbage collected when their event loop closes, ensuring finalizers run and preventing resource leaks in asynchronous execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_gc_infinite_async_await", "line_number": 1008, "body": "def test_gc_infinite_async_await(self):\n        # Same as test_gc_infinite_coro, but with a `async def` function\n        import asyncio\n\n        async def infinite_coro(result):\n            try:\n                while True:\n                    await gen.sleep(1e-3)\n                    result.append(True)\n            finally:\n                # coroutine finalizer\n                result.append(None)\n\n        loop = self.get_new_ioloop()\n        result = []  # type: List[Optional[bool]]\n        wfut = []\n\n        @gen.coroutine\n        def do_something():\n            fut = asyncio.get_event_loop().create_task(infinite_coro(result))\n            fut._refcycle = fut  # type: ignore\n            wfut.append(weakref.ref(fut))\n            yield gen.sleep(0.2)\n\n        loop.run_sync(do_something)\n        with ExpectLog(\"asyncio\", \"Task was destroyed but it is pending\"):\n            loop.close()\n            gc.collect()\n        # Future was collected\n        self.assertIs(wfut[0](), None)\n        # At least one wakeup and one finally\n        self.assertGreaterEqual(len(result), 2)\n        if not self.is_pypy3():\n            # coroutine finalizer was called (not on PyPy3 apparently)\n            self.assertIs(result[-1], None)", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Test method in RunnerGCTest that verifies correct garbage collection and finalization behavior of infinite asynchronous coroutines using async/await syntax within an event loop."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_multi_moment", "line_number": 1044, "body": "def test_multi_moment(self):\n        # Test gen.multi with moment\n        # now that it's not a real Future\n        @gen.coroutine\n        def wait_a_moment():\n            result = yield gen.multi([gen.moment, gen.moment])\n            raise gen.Return(result)\n\n        loop = self.get_new_ioloop()\n        result = loop.run_sync(wait_a_moment)\n        self.assertEqual(result, [None, None])", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Unit test method in RunnerGCTest that verifies gen.multi correctly handles multiple gen.moment yields, ensuring asynchronous tasks complete and return expected results within an IOLoop execution context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "gen_root", "line_number": 1068, "body": "def gen_root(self, x):\n        ctx_var.set(x)\n        yield\n        yield self.inner(x)", "is_method": true, "class_name": "ContextVarsTest", "function_description": "Generates a root-level context in which a given value is set, then yields control and subsequently yields the result of an inner operation using the same value. Useful for managing and testing context variable propagation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "gen_inner", "line_number": 1090, "body": "def gen_inner(self, x):\n        self.assertEqual(ctx_var.get(), x)\n        yield\n        self.assertEqual(ctx_var.get(), x)", "is_method": true, "class_name": "ContextVarsTest", "function_description": "Tests that a context variable retains the expected value before and after a generator's yield point, ensuring context consistency during generator execution within the ContextVarsTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "thread_inner", "line_number": 1095, "body": "def thread_inner(self, x):\n        self.assertEqual(ctx_var.get(), x)", "is_method": true, "class_name": "ContextVarsTest", "function_description": "Tests that the context variable holds the expected value within a thread, verifying thread-local storage consistency in ContextVarsTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_propagate", "line_number": 1099, "body": "def test_propagate(self):\n        # Verify that context vars get propagated across various\n        # combinations of native and decorated coroutines.\n        yield [\n            self.native_root(1),\n            self.native_root(2),\n            self.gen_root(3),\n            self.gen_root(4),\n        ]", "is_method": true, "class_name": "ContextVarsTest", "function_description": "Tests propagation of context variables across multiple coroutine types, ensuring consistent context handling in both native and decorated asynchronous functions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "test_reset", "line_number": 1110, "body": "def test_reset(self):\n        token = ctx_var.set(1)\n        yield\n        # reset asserts that we are still at the same level of the context tree,\n        # so we must make sure that we maintain that property across yield.\n        ctx_var.reset(token)", "is_method": true, "class_name": "ContextVarsTest", "function_description": "This test method verifies that the context variable can be reset correctly across a yield boundary, ensuring consistent context state management during asynchronous or generator-based execution."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 77, "body": "def f():\n            yield 42", "is_method": true, "class_name": "GenBasicTest", "function_description": "Generates a single value, 42, using a generator. This function can be used where a simple iterable producing one fixed value is needed."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 84, "body": "def f():\n            yield (1, 2)", "is_method": true, "class_name": "GenBasicTest", "function_description": "Simple generator function that yields a single tuple (1, 2). Its specific purpose or context within GenBasicTest is not clear."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 133, "body": "def f():\n            # callbacks run at different times\n            responses = yield gen.multi_future(\n                dict(foo=self.delay(3, \"v1\"), bar=self.delay(1, \"v2\"))\n            )\n            self.assertEqual(responses, dict(foo=\"v1\", bar=\"v2\"))", "is_method": true, "class_name": "GenBasicTest", "function_description": "The function f in GenBasicTest asynchronously waits for multiple delayed results and asserts their expected values, serving as a test method for concurrent operations and result aggregation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 238, "body": "def f():\n            raise gen.Return()", "is_method": true, "class_name": "GenBasicTest", "function_description": "Returns nothing and immediately raises a generator-based return exception, effectively acting as a placeholder or signaling early exit in generator contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 260, "body": "def f():\n            raise gen.Return((1, 2))", "is_method": true, "class_name": "GenBasicTest", "function_description": "Returns a fixed tuple (1, 2) using a generator-based return mechanism. This function serves as a basic test stub for generator-related functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 319, "body": "def f():\n            raise gen.Return(42)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Returns the integer 42 wrapped as a coroutine result, demonstrating use of a generator-based coroutine return value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 329, "body": "def f():\n            yield gen.moment\n            raise gen.Return(42)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "This function serves as a simple generator yielding a moment from a generator utility before returning a fixed value, useful for testing coroutine behavior in asynchronous programming contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 340, "body": "def f():\n            return 42", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Returns the integer value 42. This simple function provides a fixed numerical output for any caller needing a constant value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f1", "line_number": 376, "body": "def f1():\n            yield gen.moment\n            raise gen.Return(42)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Returns a coroutine that yields a moment from a generator and then completes by returning the value 42. Useful for testing generator-based coroutine behavior in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 458, "body": "def f():\n            1 / 0", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Raises a ZeroDivisionError by attempting to divide one by zero, useful for testing error handling in coroutine contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f1", "line_number": 486, "body": "def f1():\n            1 / 0", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Raises a ZeroDivisionError by attempting to divide one by zero. This function serves as a test case for exception handling or error triggering scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f2", "line_number": 490, "body": "def f2():\n            try:\n                yield f1()\n            except ZeroDivisionError:\n                raise KeyError()", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "This function is a generator that yields the result of another function and converts any ZeroDivisionError into a KeyError. It is useful for error handling within coroutine-based flows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f1", "line_number": 506, "body": "def f1():\n            1 / 0", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Raises a division by zero error when called, primarily serving as a test function to trigger exceptions deliberately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 525, "body": "def f(name, yieldable):\n            for i in range(5):\n                calls.append(name)\n                yield yieldable", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Generates a coroutine that yields a specified value five times while recording each call with a given name. Useful for testing or simulating repeated asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "inner", "line_number": 558, "body": "def inner(iteration):\n            raise LeakedException(iteration)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Raises a LeakedException with the given iteration value, typically used to test coroutine behavior when exceptions occur."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "f", "line_number": 631, "body": "def f():\n            yield gen.moment\n            raise gen.Return(1)", "is_method": true, "class_name": "GenCoroutineTest", "function_description": "Generates a coroutine that yields a moment from a generator and then returns the integer 1. It provides a simple asynchronous sequence for testing generator behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "callback", "line_number": 959, "body": "def callback():\n            gc.collect(2)\n            weakref_scope[0]().set_result(123)", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Triggers a specific garbage collection generation and sets a result on a weakly-referenced future or promise, useful for synchronizing asynchronous test callbacks involving garbage collection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/gen_test.py", "function": "wait_a_moment", "line_number": 1048, "body": "def wait_a_moment():\n            result = yield gen.multi([gen.moment, gen.moment])\n            raise gen.Return(result)", "is_method": true, "class_name": "RunnerGCTest", "function_description": "Suspends execution briefly by yielding multiple asynchronous wait moments, then returns their combined results. It serves as a utility to introduce controlled pauses in asynchronous workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_linkify", "line_number": 213, "body": "def test_linkify(self):\n        for text, kwargs, html in linkify_tests:\n            linked = tornado.escape.linkify(text, **kwargs)\n            self.assertEqual(linked, html)", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Unit test method of EscapeTestCase that verifies the correctness of the linkify function by checking if input texts are properly converted into HTML links as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_xhtml_escape", "line_number": 218, "body": "def test_xhtml_escape(self):\n        tests = [\n            (\"<foo>\", \"&lt;foo&gt;\"),\n            (u\"<foo>\", u\"&lt;foo&gt;\"),\n            (b\"<foo>\", b\"&lt;foo&gt;\"),\n            (\"<>&\\\"'\", \"&lt;&gt;&amp;&quot;&#39;\"),\n            (\"&amp;\", \"&amp;amp;\"),\n            (u\"<\\u00e9>\", u\"&lt;\\u00e9&gt;\"),\n            (b\"<\\xc3\\xa9>\", b\"&lt;\\xc3\\xa9&gt;\"),\n        ]  # type: List[Tuple[Union[str, bytes], Union[str, bytes]]]\n        for unescaped, escaped in tests:\n            self.assertEqual(utf8(xhtml_escape(unescaped)), utf8(escaped))\n            self.assertEqual(utf8(unescaped), utf8(xhtml_unescape(escaped)))", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Tests the correctness of XHTML escape and unescape functions by verifying that special characters are properly encoded and decoded across string and byte inputs. It ensures reliable escaping behavior for safe XHTML content handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_xhtml_unescape_numeric", "line_number": 232, "body": "def test_xhtml_unescape_numeric(self):\n        tests = [\n            (\"foo&#32;bar\", \"foo bar\"),\n            (\"foo&#x20;bar\", \"foo bar\"),\n            (\"foo&#X20;bar\", \"foo bar\"),\n            (\"foo&#xabc;bar\", u\"foo\\u0abcbar\"),\n            (\"foo&#xyz;bar\", \"foo&#xyz;bar\"),  # invalid encoding\n            (\"foo&#;bar\", \"foo&#;bar\"),  # invalid encoding\n            (\"foo&#x;bar\", \"foo&#x;bar\"),  # invalid encoding\n        ]\n        for escaped, unescaped in tests:\n            self.assertEqual(unescaped, xhtml_unescape(escaped))", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Tests the xhtml_unescape function to ensure it correctly converts numeric character references to their corresponding characters, including handling invalid or malformed encodings gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_url_escape_unicode", "line_number": 245, "body": "def test_url_escape_unicode(self):\n        tests = [\n            # byte strings are passed through as-is\n            (u\"\\u00e9\".encode(\"utf8\"), \"%C3%A9\"),\n            (u\"\\u00e9\".encode(\"latin1\"), \"%E9\"),\n            # unicode strings become utf8\n            (u\"\\u00e9\", \"%C3%A9\"),\n        ]  # type: List[Tuple[Union[str, bytes], str]]\n        for unescaped, escaped in tests:\n            self.assertEqual(url_escape(unescaped), escaped)", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Unit test method in EscapeTestCase that verifies url_escape correctly converts various Unicode and byte string inputs into their proper URL-encoded representations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_url_unescape_unicode", "line_number": 256, "body": "def test_url_unescape_unicode(self):\n        tests = [\n            (\"%C3%A9\", u\"\\u00e9\", \"utf8\"),\n            (\"%C3%A9\", u\"\\u00c3\\u00a9\", \"latin1\"),\n            (\"%C3%A9\", utf8(u\"\\u00e9\"), None),\n        ]\n        for escaped, unescaped, encoding in tests:\n            # input strings to url_unescape should only contain ascii\n            # characters, but make sure the function accepts both byte\n            # and unicode strings.\n            self.assertEqual(url_unescape(to_unicode(escaped), encoding), unescaped)\n            self.assertEqual(url_unescape(utf8(escaped), encoding), unescaped)", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Tests that url_unescape correctly decodes percent-encoded strings into their original Unicode characters across different encodings and input types. It validates handling of both byte and Unicode strings for URL-unescaping."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_url_escape_quote_plus", "line_number": 269, "body": "def test_url_escape_quote_plus(self):\n        unescaped = \"+ #%\"\n        plus_escaped = \"%2B+%23%25\"\n        escaped = \"%2B%20%23%25\"\n        self.assertEqual(url_escape(unescaped), plus_escaped)\n        self.assertEqual(url_escape(unescaped, plus=False), escaped)\n        self.assertEqual(url_unescape(plus_escaped), unescaped)\n        self.assertEqual(url_unescape(escaped, plus=False), unescaped)\n        self.assertEqual(url_unescape(plus_escaped, encoding=None), utf8(unescaped))\n        self.assertEqual(\n            url_unescape(escaped, encoding=None, plus=False), utf8(unescaped)\n        )", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Tests correct URL escaping and unescaping behavior for special characters, verifying different plus-sign handling and encoding options in URL encoding utilities."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_escape_return_types", "line_number": 282, "body": "def test_escape_return_types(self):\n        # On python2 the escape methods should generally return the same\n        # type as their argument\n        self.assertEqual(type(xhtml_escape(\"foo\")), str)\n        self.assertEqual(type(xhtml_escape(u\"foo\")), unicode_type)", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Test method in EscapeTestCase that verifies the xhtml_escape function returns the same string type as its input, ensuring consistent escape behavior across Python versions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_json_decode", "line_number": 288, "body": "def test_json_decode(self):\n        # json_decode accepts both bytes and unicode, but strings it returns\n        # are always unicode.\n        self.assertEqual(json_decode(b'\"foo\"'), u\"foo\")\n        self.assertEqual(json_decode(u'\"foo\"'), u\"foo\")\n\n        # Non-ascii bytes are interpreted as utf8\n        self.assertEqual(json_decode(utf8(u'\"\\u00e9\"')), u\"\\u00e9\")", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Tests that the json_decode function correctly decodes byte and unicode JSON strings into unicode, handling UTF-8 encoded non-ASCII characters as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_json_encode", "line_number": 297, "body": "def test_json_encode(self):\n        # json deals with strings, not bytes.  On python 2 byte strings will\n        # convert automatically if they are utf8; on python 3 byte strings\n        # are not allowed.\n        self.assertEqual(json_decode(json_encode(u\"\\u00e9\")), u\"\\u00e9\")\n        if bytes is str:\n            self.assertEqual(json_decode(json_encode(utf8(u\"\\u00e9\"))), u\"\\u00e9\")\n            self.assertRaises(UnicodeDecodeError, json_encode, b\"\\xe9\")", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Core test method in EscapeTestCase that verifies correct JSON encoding and decoding of Unicode strings and byte strings across Python versions, ensuring compatibility and proper error handling for invalid byte input."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_squeeze", "line_number": 306, "body": "def test_squeeze(self):\n        self.assertEqual(\n            squeeze(u\"sequences     of    whitespace   chars\"),\n            u\"sequences of whitespace chars\",\n        )", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Unit test in EscapeTestCase that verifies the squeeze function correctly reduces multiple whitespace characters into single spaces within a string."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/escape_test.py", "function": "test_recursive_unicode", "line_number": 312, "body": "def test_recursive_unicode(self):\n        tests = {\n            \"dict\": {b\"foo\": b\"bar\"},\n            \"list\": [b\"foo\", b\"bar\"],\n            \"tuple\": (b\"foo\", b\"bar\"),\n            \"bytes\": b\"foo\",\n        }\n        self.assertEqual(recursive_unicode(tests[\"dict\"]), {u\"foo\": u\"bar\"})\n        self.assertEqual(recursive_unicode(tests[\"list\"]), [u\"foo\", u\"bar\"])\n        self.assertEqual(recursive_unicode(tests[\"tuple\"]), (u\"foo\", u\"bar\"))\n        self.assertEqual(recursive_unicode(tests[\"bytes\"]), u\"foo\")", "is_method": true, "class_name": "EscapeTestCase", "function_description": "Test method in EscapeTestCase that verifies recursive_unicode correctly converts byte strings to Unicode across nested data structures like dicts, lists, tuples, and bytes. It ensures that recursive decoding maintains original structure with Unicode elements."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_future_set_result_unless_cancelled", "line_number": 35, "body": "def test_future_set_result_unless_cancelled(self):\n        fut = Future()  # type: Future[int]\n        future_set_result_unless_cancelled(fut, 42)\n        self.assertEqual(fut.result(), 42)\n        self.assertFalse(fut.cancelled())\n\n        fut = Future()\n        fut.cancel()\n        is_cancelled = fut.cancelled()\n        future_set_result_unless_cancelled(fut, 42)\n        self.assertEqual(fut.cancelled(), is_cancelled)\n        if not is_cancelled:\n            self.assertEqual(fut.result(), 42)", "is_method": true, "class_name": "MiscFutureTest", "function_description": "Tests that a future's result is set only if it has not been cancelled, ensuring correct behavior when assigning results to asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "handle_stream", "line_number": 56, "body": "def handle_stream(self, stream, address):\n        data = yield stream.read_until(b\"\\n\")\n        data = to_unicode(data)\n        if data == data.upper():\n            stream.write(b\"error\\talready capitalized\\n\")\n        else:\n            # data already has \\n\n            stream.write(utf8(\"ok\\t%s\" % data.upper()))\n        stream.close()", "is_method": true, "class_name": "CapServer", "function_description": "Handles incoming text streams by checking capitalization and responding with an error or the uppercase version of the text, facilitating simple text transformation over a streaming interface."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "process_response", "line_number": 75, "body": "def process_response(self, data):\n        m = re.match(\"(.*)\\t(.*)\\n\", to_unicode(data))\n        if m is None:\n            raise Exception(\"did not match\")\n        status, message = m.groups()\n        if status == \"ok\":\n            return message\n        else:\n            raise CapError(message)", "is_method": true, "class_name": "BaseCapClient", "function_description": "Core method of BaseCapClient that parses and validates response data, returning the message if the status is \"ok\" or raising an error for failure statuses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "capitalize", "line_number": 88, "body": "def capitalize(self, request_data):\n        logging.debug(\"capitalize\")\n        stream = IOStream(socket.socket())\n        logging.debug(\"connecting\")\n        yield stream.connect((\"127.0.0.1\", self.port))\n        stream.write(utf8(request_data + \"\\n\"))\n        logging.debug(\"reading\")\n        data = yield stream.read_until(b\"\\n\")\n        logging.debug(\"returning\")\n        stream.close()\n        raise gen.Return(self.process_response(data))", "is_method": true, "class_name": "GeneratorCapClient", "function_description": "Core method of GeneratorCapClient that connects to a local service to send text data and asynchronously retrieve its capitalized form. It enables external text transformation through network communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "setUp", "line_number": 104, "body": "def setUp(self):\n        super().setUp()  # type: ignore\n        self.server = CapServer()\n        sock, port = bind_unused_port()\n        self.server.add_sockets([sock])\n        self.client = self.client_class(port=port)", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Setup method in ClientTestMixin that initializes a test server and a client connected to an available port, preparing the testing environment for client-server interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "tearDown", "line_number": 111, "body": "def tearDown(self):\n        self.server.stop()\n        super().tearDown()", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Provides cleanup by stopping the server after a test case, ensuring proper resource release in test environments using the ClientTestMixin class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_future", "line_number": 115, "body": "def test_future(self: typing.Any):\n        future = self.client.capitalize(\"hello\")\n        self.io_loop.add_future(future, self.stop)\n        self.wait()\n        self.assertEqual(future.result(), \"HELLO\")", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Test method verifying that the client's asynchronous capitalize function correctly converts input text to uppercase and integrates with the event loop for asynchronous execution and result retrieval."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_future_error", "line_number": 121, "body": "def test_future_error(self: typing.Any):\n        future = self.client.capitalize(\"HELLO\")\n        self.io_loop.add_future(future, self.stop)\n        self.wait()\n        self.assertRaisesRegexp(CapError, \"already capitalized\", future.result)", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Test method in ClientTestMixin that verifies the client\u2019s capitalize function properly raises an error when the input string is already capitalized. It ensures correct error handling in asynchronous calls."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_generator", "line_number": 127, "body": "def test_generator(self: typing.Any):\n        @gen.coroutine\n        def f():\n            result = yield self.client.capitalize(\"hello\")\n            self.assertEqual(result, \"HELLO\")\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Test utility method in ClientTestMixin that verifies the client\u2019s capitalize function correctly converts \"hello\" to uppercase within an asynchronous event loop context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_generator_error", "line_number": 135, "body": "def test_generator_error(self: typing.Any):\n        @gen.coroutine\n        def f():\n            with self.assertRaisesRegexp(CapError, \"already capitalized\"):\n                yield self.client.capitalize(\"HELLO\")\n\n        self.io_loop.run_sync(f)", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Utility test method in ClientTestMixin that verifies the client\u2019s capitalize function raises a specific error when input text is already capitalized. It ensures proper exception handling in asynchronous operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_no_calling", "line_number": 150, "body": "def test_no_calling(self):\n        class Object(object):\n            def __init__(self):\n                self.executor = futures.thread.ThreadPoolExecutor(1)\n\n            @run_on_executor\n            def f(self):\n                return 42\n\n        o = Object()\n        answer = yield o.f()\n        self.assertEqual(answer, 42)", "is_method": true, "class_name": "RunOnExecutorTest", "function_description": "Tests that a method decorated with run_on_executor correctly executes asynchronously on a thread pool and returns the expected result. It validates the integration of asynchronous execution within the RunOnExecutorTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_call_with_no_args", "line_number": 164, "body": "def test_call_with_no_args(self):\n        class Object(object):\n            def __init__(self):\n                self.executor = futures.thread.ThreadPoolExecutor(1)\n\n            @run_on_executor()\n            def f(self):\n                return 42\n\n        o = Object()\n        answer = yield o.f()\n        self.assertEqual(answer, 42)", "is_method": true, "class_name": "RunOnExecutorTest", "function_description": "Tests that a method decorated to run asynchronously on a thread executor executes without arguments and returns the expected result correctly."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_call_with_executor", "line_number": 178, "body": "def test_call_with_executor(self):\n        class Object(object):\n            def __init__(self):\n                self.__executor = futures.thread.ThreadPoolExecutor(1)\n\n            @run_on_executor(executor=\"_Object__executor\")\n            def f(self):\n                return 42\n\n        o = Object()\n        answer = yield o.f()\n        self.assertEqual(answer, 42)", "is_method": true, "class_name": "RunOnExecutorTest", "function_description": "Tests that a method decorated to run on a specified executor executes asynchronously and returns the expected result when awaited. This ensures correct integration of executor-based concurrency within the RunOnExecutorTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "test_async_await", "line_number": 192, "body": "def test_async_await(self):\n        class Object(object):\n            def __init__(self):\n                self.executor = futures.thread.ThreadPoolExecutor(1)\n\n            @run_on_executor()\n            def f(self):\n                return 42\n\n        o = Object()\n\n        async def f():\n            answer = await o.f()\n            return answer\n\n        result = yield f()\n        self.assertEqual(result, 42)", "is_method": true, "class_name": "RunOnExecutorTest", "function_description": "Tests asynchronous execution by running a method in a thread pool executor and verifying it correctly returns the expected result using async/await syntax. It serves to validate integration of concurrency utilities in the RunOnExecutorTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "f", "line_number": 137, "body": "def f():\n            with self.assertRaisesRegexp(CapError, \"already capitalized\"):\n                yield self.client.capitalize(\"HELLO\")", "is_method": true, "class_name": "ClientTestMixin", "function_description": "Test method in ClientTestMixin that verifies the client.capitalize function raises a CapError when given an already capitalized string. It ensures proper error handling for invalid capitalization inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "f", "line_number": 156, "body": "def f(self):\n                return 42", "is_method": true, "class_name": "Object", "function_description": "Returns the integer 42 as a fixed value. This function serves as a simple, constant-value provider within the Object class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "f", "line_number": 170, "body": "def f(self):\n                return 42", "is_method": true, "class_name": "Object", "function_description": "This function simply returns the constant integer 42, providing a fixed numeric value without any input dependence or computation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "f", "line_number": 184, "body": "def f(self):\n                return 42", "is_method": true, "class_name": "Object", "function_description": "This method returns the integer 42 regardless of object state or input. It provides a fixed value service that might be used as a placeholder or a constant response in the Object class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/concurrent_test.py", "function": "f", "line_number": 198, "body": "def f(self):\n                return 42", "is_method": true, "class_name": "Object", "function_description": "This method provides a fixed numeric value (42) when called. It can serve as a simple constant-returning utility within the Object class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 79, "body": "def get_app(self):\n        return Application([(\"/\", self.__class__.Handler)])", "is_method": true, "class_name": "HandlerBaseTestCase", "function_description": "Returns a web application instance configured with the test case's handler. This facilitates testing of request handling within the HandlerBaseTestCase framework."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "fetch_json", "line_number": 82, "body": "def fetch_json(self, *args, **kwargs):\n        response = self.fetch(*args, **kwargs)\n        response.rethrow()\n        return json_decode(response.body)", "is_method": true, "class_name": "HandlerBaseTestCase", "function_description": "This method in HandlerBaseTestCase fetches an HTTP response, raises an error for unsuccessful requests, and decodes the response body from JSON, facilitating streamlined JSON-based API testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "initialize", "line_number": 89, "body": "def initialize(self, protocol=\"http\"):\n        self.expected_protocol = protocol", "is_method": true, "class_name": "HelloWorldRequestHandler", "function_description": "Initializes the HelloWorldRequestHandler with a specified communication protocol, setting the expected protocol for handling incoming requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 92, "body": "def get(self):\n        if self.request.protocol != self.expected_protocol:\n            raise Exception(\"unexpected protocol\")\n        self.finish(\"Hello world\")", "is_method": true, "class_name": "HelloWorldRequestHandler", "function_description": "Handles HTTP GET requests by verifying the protocol and responding with a \"Hello world\" message if the protocol matches the expected value."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 97, "body": "def post(self):\n        self.finish(\"Got %d bytes in POST\" % len(self.request.body))", "is_method": true, "class_name": "HelloWorldRequestHandler", "function_description": "Handles POST requests by responding with the size of the received request body in bytes, enabling confirmation of data receipt in HTTP interactions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 113, "body": "def get_app(self):\n        return Application([(\"/\", HelloWorldRequestHandler, dict(protocol=\"https\"))])", "is_method": true, "class_name": "BaseSSLTest", "function_description": "Provides a web application instance configured with a single HTTPS endpoint handler, enabling test cases to interact with a secured HTTP server environment."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_ssl_options", "line_number": 118, "body": "def get_ssl_options(self):\n        return dict(\n            ssl_version=self.get_ssl_version(),\n            **AsyncHTTPSTestCase.default_ssl_options()\n        )", "is_method": true, "class_name": "SSLTestMixin", "function_description": "Utility method in SSLTestMixin that provides SSL configuration options by combining a custom SSL version with default asynchronous HTTPS test settings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_ssl", "line_number": 127, "body": "def test_ssl(self: typing.Any):\n        response = self.fetch(\"/\")\n        self.assertEqual(response.body, b\"Hello world\")", "is_method": true, "class_name": "SSLTestMixin", "function_description": "Simple test method in SSLTestMixin that verifies a basic HTTPS request returns the expected response body \"Hello world\". It ensures SSL connections function correctly in the tested context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_post", "line_number": 131, "body": "def test_large_post(self: typing.Any):\n        response = self.fetch(\"/\", method=\"POST\", body=\"A\" * 5000)\n        self.assertEqual(response.body, b\"Got 5000 bytes in POST\")", "is_method": true, "class_name": "SSLTestMixin", "function_description": "Test method in SSLTestMixin that verifies handling of large POST request bodies by sending 5000 bytes and checking the server response acknowledges the received data size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_non_ssl_request", "line_number": 135, "body": "def test_non_ssl_request(self: typing.Any):\n        # Make sure the server closes the connection when it gets a non-ssl\n        # connection, rather than waiting for a timeout or otherwise\n        # misbehaving.\n        with ExpectLog(gen_log, \"(SSL Error|uncaught exception)\"):\n            with ExpectLog(gen_log, \"Uncaught exception\", required=False):\n                with self.assertRaises((IOError, HTTPError)):  # type: ignore\n                    self.fetch(\n                        self.get_url(\"/\").replace(\"https:\", \"http:\"),\n                        request_timeout=3600,\n                        connect_timeout=3600,\n                        raise_error=True,\n                    )", "is_method": true, "class_name": "SSLTestMixin", "function_description": "Tests that the server properly rejects non-SSL (HTTP) requests by closing the connection instead of hanging or timing out, ensuring correct SSL enforcement behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_error_logging", "line_number": 149, "body": "def test_error_logging(self: typing.Any):\n        # No stack traces are logged for SSL errors.\n        with ExpectLog(gen_log, \"SSL Error\") as expect_log:\n            with self.assertRaises((IOError, HTTPError)):  # type: ignore\n                self.fetch(\n                    self.get_url(\"/\").replace(\"https:\", \"http:\"), raise_error=True\n                )\n        self.assertFalse(expect_log.logged_stack)", "is_method": true, "class_name": "SSLTestMixin", "function_description": "Utility method in SSLTestMixin that verifies SSL errors are logged without stack traces during HTTPS to HTTP fetch failures, ensuring clean error logging behavior in SSL-related network operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_ssl_version", "line_number": 166, "body": "def get_ssl_version(self):\n        return ssl.PROTOCOL_SSLv23", "is_method": true, "class_name": "SSLv23Test", "function_description": "Returns the specific SSL protocol version constant used by the SSLv23Test class, providing a consistent reference for SSL/TLS connection setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_ssl_version", "line_number": 172, "body": "def get_ssl_version(self):\n        return ssl.PROTOCOL_SSLv3", "is_method": true, "class_name": "SSLv3Test", "function_description": "Returns the SSLv3 protocol constant from the ssl module, allowing other components to specify or check this specific SSL version."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_ssl_version", "line_number": 178, "body": "def get_ssl_version(self):\n        return ssl.PROTOCOL_TLSv1", "is_method": true, "class_name": "TLSv1Test", "function_description": "Returns the SSL protocol version TLSv1 used by the TLSv1Test class, identifying the specific TLS version for secure communication tests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_ssl_options", "line_number": 183, "body": "def get_ssl_options(self):\n        context = ssl_options_to_context(AsyncHTTPSTestCase.get_ssl_options(self))\n        assert isinstance(context, ssl.SSLContext)\n        return context", "is_method": true, "class_name": "SSLContextTest", "function_description": "Utility method in SSLContextTest that obtains SSL options and converts them into an SSLContext object for use in secure HTTP testing scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_missing_arguments", "line_number": 190, "body": "def test_missing_arguments(self):\n        application = Application()\n        self.assertRaises(\n            KeyError,\n            HTTPServer,\n            application,\n            ssl_options={\"keyfile\": \"/__missing__.crt\"},\n        )", "is_method": true, "class_name": "BadSSLOptionsTest", "function_description": "Unit test in BadSSLOptionsTest that verifies HTTPServer raises an error when required SSL options are missing, ensuring robust handling of incomplete SSL configurations during server setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_missing_key", "line_number": 199, "body": "def test_missing_key(self):\n        \"\"\"A missing SSL key should cause an immediate exception.\"\"\"\n\n        application = Application()\n        module_dir = os.path.dirname(__file__)\n        existing_certificate = os.path.join(module_dir, \"test.crt\")\n        existing_key = os.path.join(module_dir, \"test.key\")\n\n        self.assertRaises(\n            (ValueError, IOError),\n            HTTPServer,\n            application,\n            ssl_options={\"certfile\": \"/__mising__.crt\"},\n        )\n        self.assertRaises(\n            (ValueError, IOError),\n            HTTPServer,\n            application,\n            ssl_options={\n                \"certfile\": existing_certificate,\n                \"keyfile\": \"/__missing__.key\",\n            },\n        )\n\n        # This actually works because both files exist\n        HTTPServer(\n            application,\n            ssl_options={\"certfile\": existing_certificate, \"keyfile\": existing_key},\n        )", "is_method": true, "class_name": "BadSSLOptionsTest", "function_description": "Tests that missing SSL key or certificate files raise exceptions, ensuring the HTTPServer correctly validates required SSL options during initialization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 231, "body": "def post(self):\n        self.finish(\n            {\n                \"header\": self.request.headers[\"X-Header-Encoding-Test\"],\n                \"argument\": self.get_argument(\"argument\"),\n                \"filename\": self.request.files[\"files\"][0].filename,\n                \"filebody\": _unicode(self.request.files[\"files\"][0][\"body\"]),\n            }\n        )", "is_method": true, "class_name": "MultipartTestHandler", "function_description": "Handles a POST request by extracting a specific header, a query argument, and the first uploaded file's name and content, then returns these details in the response. It supports processing multipart form submissions with file uploads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_handlers", "line_number": 244, "body": "def get_handlers(self):\n        return [\n            (\"/multipart\", MultipartTestHandler),\n            (\"/hello\", HelloWorldRequestHandler),\n        ]", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Provides the HTTPConnectionTest class with a list of URL patterns mapped to their respective request handlers, defining how specific endpoints are handled during HTTP connection testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 250, "body": "def get_app(self):\n        return Application(self.get_handlers())", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Returns a configured Application instance using the class's request handlers, enabling HTTP connection tests with the predefined routing setup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "raw_fetch", "line_number": 253, "body": "def raw_fetch(self, headers, body, newline=b\"\\r\\n\"):\n        with closing(IOStream(socket.socket())) as stream:\n            self.io_loop.run_sync(\n                lambda: stream.connect((\"127.0.0.1\", self.get_http_port()))\n            )\n            stream.write(\n                newline.join(headers + [utf8(\"Content-Length: %d\" % len(body))])\n                + newline\n                + newline\n                + body\n            )\n            start_line, headers, body = self.io_loop.run_sync(\n                lambda: read_stream_body(stream)\n            )\n            return body", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Core method of HTTPConnectionTest that sends raw HTTP headers and body to a local server and returns the server's response body for direct protocol-level testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_multipart_form", "line_number": 269, "body": "def test_multipart_form(self):\n        # Encodings here are tricky:  Headers are latin1, bodies can be\n        # anything (we use utf8 by default).\n        response = self.raw_fetch(\n            [\n                b\"POST /multipart HTTP/1.0\",\n                b\"Content-Type: multipart/form-data; boundary=1234567890\",\n                b\"X-Header-encoding-test: \\xe9\",\n            ],\n            b\"\\r\\n\".join(\n                [\n                    b\"Content-Disposition: form-data; name=argument\",\n                    b\"\",\n                    u\"\\u00e1\".encode(\"utf-8\"),\n                    b\"--1234567890\",\n                    u'Content-Disposition: form-data; name=\"files\"; filename=\"\\u00f3\"'.encode(\n                        \"utf8\"\n                    ),\n                    b\"\",\n                    u\"\\u00fa\".encode(\"utf-8\"),\n                    b\"--1234567890--\",\n                    b\"\",\n                ]\n            ),\n        )\n        data = json_decode(response)\n        self.assertEqual(u\"\\u00e9\", data[\"header\"])\n        self.assertEqual(u\"\\u00e1\", data[\"argument\"])\n        self.assertEqual(u\"\\u00f3\", data[\"filename\"])\n        self.assertEqual(u\"\\u00fa\", data[\"filebody\"])", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Tests handling of multipart/form-data HTTP POST requests with mixed character encodings, ensuring correct parsing of headers and body content including Unicode characters. Useful for verifying multipart form data processing in HTTP connections."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_newlines", "line_number": 300, "body": "def test_newlines(self):\n        # We support both CRLF and bare LF as line separators.\n        for newline in (b\"\\r\\n\", b\"\\n\"):\n            response = self.raw_fetch([b\"GET /hello HTTP/1.0\"], b\"\", newline=newline)\n            self.assertEqual(response, b\"Hello world\")", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Tests if the HTTP connection properly handles both CRLF and LF newline formats in requests, ensuring compatibility with various HTTP line-ending conventions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_100_continue", "line_number": 307, "body": "def test_100_continue(self):\n        # Run through a 100-continue interaction by hand:\n        # When given Expect: 100-continue, we get a 100 response after the\n        # headers, and then the real response after the body.\n        stream = IOStream(socket.socket())\n        yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        yield stream.write(\n            b\"\\r\\n\".join(\n                [\n                    b\"POST /hello HTTP/1.1\",\n                    b\"Content-Length: 1024\",\n                    b\"Expect: 100-continue\",\n                    b\"Connection: close\",\n                    b\"\\r\\n\",\n                ]\n            )\n        )\n        data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n        self.assertTrue(data.startswith(b\"HTTP/1.1 100 \"), data)\n        stream.write(b\"a\" * 1024)\n        first_line = yield stream.read_until(b\"\\r\\n\")\n        self.assertTrue(first_line.startswith(b\"HTTP/1.1 200\"), first_line)\n        header_data = yield stream.read_until(b\"\\r\\n\\r\\n\")\n        headers = HTTPHeaders.parse(native_str(header_data.decode(\"latin1\")))\n        body = yield stream.read_bytes(int(headers[\"Content-Length\"]))\n        self.assertEqual(body, b\"Got 1024 bytes in POST\")\n        stream.close()", "is_method": true, "class_name": "HTTPConnectionTest", "function_description": "Simulates and verifies the HTTP 100-continue handshake by manually sending a request and checking that the server correctly responds with a 100 status before processing the request body and returning the final response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 337, "body": "def get(self):\n        self.write(recursive_unicode(self.request.arguments))", "is_method": true, "class_name": "EchoHandler", "function_description": "Method of the EchoHandler class that returns the HTTP GET request's arguments in a Unicode-safe format. It provides a simple echo service reflecting client-sent parameters back in the response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 340, "body": "def post(self):\n        self.write(recursive_unicode(self.request.arguments))", "is_method": true, "class_name": "EchoHandler", "function_description": "Handles POST requests by returning the request's arguments in a Unicode-safe format, enabling echoing of client-sent data for debugging or verification purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "prepare", "line_number": 345, "body": "def prepare(self):\n        self.errors = {}  # type: Dict[str, str]\n        fields = [\n            (\"method\", str),\n            (\"uri\", str),\n            (\"version\", str),\n            (\"remote_ip\", str),\n            (\"protocol\", str),\n            (\"host\", str),\n            (\"path\", str),\n            (\"query\", str),\n        ]\n        for field, expected_type in fields:\n            self.check_type(field, getattr(self.request, field), expected_type)\n\n        self.check_type(\"header_key\", list(self.request.headers.keys())[0], str)\n        self.check_type(\"header_value\", list(self.request.headers.values())[0], str)\n\n        self.check_type(\"cookie_key\", list(self.request.cookies.keys())[0], str)\n        self.check_type(\n            \"cookie_value\", list(self.request.cookies.values())[0].value, str\n        )\n        # secure cookies\n\n        self.check_type(\"arg_key\", list(self.request.arguments.keys())[0], str)\n        self.check_type(\"arg_value\", list(self.request.arguments.values())[0][0], bytes)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Method of TypeCheckHandler that validates the types of key attributes in a request object to ensure data integrity before processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 372, "body": "def post(self):\n        self.check_type(\"body\", self.request.body, bytes)\n        self.write(self.errors)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Utility method in TypeCheckHandler that validates the request body type as bytes and returns any collected type-checking errors to the client."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 376, "body": "def get(self):\n        self.write(self.errors)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Simple method in TypeCheckHandler that outputs the current error messages stored in the handler, likely for reporting or debugging purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "check_type", "line_number": 379, "body": "def check_type(self, name, obj, expected_type):\n        actual_type = type(obj)\n        if expected_type != actual_type:\n            self.errors[name] = \"expected %s, got %s\" % (expected_type, actual_type)", "is_method": true, "class_name": "TypeCheckHandler", "function_description": "Utility method of TypeCheckHandler that verifies whether an object's type matches the expected type and records a descriptive error if there is a mismatch."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 386, "body": "def post(self, *path_args):\n        self.write(dict(echo=self.get_argument(\"data\")))", "is_method": true, "class_name": "PostEchoHandler", "function_description": "Handles POST requests by echoing back the value of the \"data\" argument, supporting simple data reflection in HTTP responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "decode_argument", "line_number": 391, "body": "def decode_argument(self, value, name=None):\n        try:\n            return value.decode(\"gbk\")\n        except Exception:\n            raise HTTPError(400, \"invalid gbk bytes: %r\" % value)", "is_method": true, "class_name": "PostEchoGBKHandler", "function_description": "Utility method in PostEchoGBKHandler that decodes byte inputs using GBK encoding, raising an HTTP error for invalid byte sequences to ensure proper request argument processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 399, "body": "def get_app(self):\n        return Application(\n            [\n                (\"/echo\", EchoHandler),\n                (\"/typecheck\", TypeCheckHandler),\n                (\"//doubleslash\", EchoHandler),\n                (\"/post_utf8\", PostEchoHandler),\n                (\"/post_gbk\", PostEchoGBKHandler),\n            ]\n        )", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Returns a configured web application with predefined route handlers for testing HTTP request handling, including echo, type checking, and POST requests with different encodings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_query_string_encoding", "line_number": 410, "body": "def test_query_string_encoding(self):\n        response = self.fetch(\"/echo?foo=%C3%A9\")\n        data = json_decode(response.body)\n        self.assertEqual(data, {u\"foo\": [u\"\\u00e9\"]})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Tests that query string parameters are correctly decoded and handled by the HTTP server, ensuring proper UTF-8 encoding interpretation. This method verifies accurate processing of URL-encoded input in server requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_empty_query_string", "line_number": 415, "body": "def test_empty_query_string(self):\n        response = self.fetch(\"/echo?foo=&foo=\")\n        data = json_decode(response.body)\n        self.assertEqual(data, {u\"foo\": [u\"\", u\"\"]})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Unit test method in HTTPServerTest that verifies handling of repeated query parameters with empty values, ensuring the server correctly parses them into a list."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_empty_post_parameters", "line_number": 420, "body": "def test_empty_post_parameters(self):\n        response = self.fetch(\"/echo\", method=\"POST\", body=\"foo=&bar=\")\n        data = json_decode(response.body)\n        self.assertEqual(data, {u\"foo\": [u\"\"], u\"bar\": [u\"\"]})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Tests that the HTTP server correctly parses empty POST parameters into a dictionary with empty string values, ensuring accurate handling of form data in POST requests during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_types", "line_number": 425, "body": "def test_types(self):\n        headers = {\"Cookie\": \"foo=bar\"}\n        response = self.fetch(\"/typecheck?foo=bar\", headers=headers)\n        data = json_decode(response.body)\n        self.assertEqual(data, {})\n\n        response = self.fetch(\n            \"/typecheck\", method=\"POST\", body=\"foo=bar\", headers=headers\n        )\n        data = json_decode(response.body)\n        self.assertEqual(data, {})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Core test method of the HTTPServerTest class that verifies the server's /typecheck endpoint correctly handles GET and POST requests, ensuring it returns an empty dictionary response for given inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_double_slash", "line_number": 437, "body": "def test_double_slash(self):\n        # urlparse.urlsplit (which tornado.httpserver used to use\n        # incorrectly) would parse paths beginning with \"//\" as\n        # protocol-relative urls.\n        response = self.fetch(\"//doubleslash\")\n        self.assertEqual(200, response.code)\n        self.assertEqual(json_decode(response.body), {})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Unit test method in HTTPServerTest that verifies the server correctly handles URLs starting with double slashes, ensuring they are not misinterpreted as protocol-relative URLs and respond with status 200 and an empty JSON body."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_post_encodings", "line_number": 445, "body": "def test_post_encodings(self):\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        uni_text = \"chinese: \\u5f20\\u4e09\"\n        for enc in (\"utf8\", \"gbk\"):\n            for quote in (True, False):\n                with self.subTest(enc=enc, quote=quote):\n                    bin_text = uni_text.encode(enc)\n                    if quote:\n                        bin_text = urllib.parse.quote(bin_text).encode(\"ascii\")\n                    response = self.fetch(\n                        \"/post_\" + enc,\n                        method=\"POST\",\n                        headers=headers,\n                        body=(b\"data=\" + bin_text),\n                    )\n                    self.assertEqual(json_decode(response.body), {\"echo\": uni_text})", "is_method": true, "class_name": "HTTPServerTest", "function_description": "Tests the HTTP server's ability to correctly handle POST requests with form-encoded data in different encodings, verifying proper decoding and echoing of Unicode text for UTF-8 and GBK formats."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 464, "body": "def get_app(self):\n        return Application([(\"/echo\", EchoHandler)])", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Provides an HTTP application instance configured with an echo endpoint, facilitating testing of raw HTTP server interactions in the HTTPServerRawTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "setUp", "line_number": 467, "body": "def setUp(self):\n        super().setUp()\n        self.stream = IOStream(socket.socket())\n        self.io_loop.run_sync(\n            lambda: self.stream.connect((\"127.0.0.1\", self.get_http_port()))\n        )", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Sets up a test environment by initializing a network stream connected to the HTTP server's local port, enabling raw socket communication for testing in the HTTPServerRawTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "tearDown", "line_number": 474, "body": "def tearDown(self):\n        self.stream.close()\n        super().tearDown()", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Cleans up resources after a test by closing the stream and invoking the parent class's teardown process, ensuring proper test environment reset."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_empty_request", "line_number": 478, "body": "def test_empty_request(self):\n        self.stream.close()\n        self.io_loop.add_timeout(datetime.timedelta(seconds=0.001), self.stop)\n        self.wait()", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "This test method checks server behavior when the input stream is closed immediately, simulating an empty request scenario to verify proper handling or clean shutdown without processing data."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_malformed_first_line_response", "line_number": 483, "body": "def test_malformed_first_line_response(self):\n        with ExpectLog(gen_log, \".*Malformed HTTP request line\", level=logging.INFO):\n            self.stream.write(b\"asdf\\r\\n\\r\\n\")\n            start_line, headers, response = self.io_loop.run_sync(\n                lambda: read_stream_body(self.stream)\n            )\n            self.assertEqual(\"HTTP/1.1\", start_line.version)\n            self.assertEqual(400, start_line.code)\n            self.assertEqual(\"Bad Request\", start_line.reason)", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Tests how the HTTPServerRawTest class handles and responds to malformed HTTP request lines, ensuring it returns a proper 400 Bad Request response for invalid input."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_malformed_first_line_log", "line_number": 493, "body": "def test_malformed_first_line_log(self):\n        with ExpectLog(gen_log, \".*Malformed HTTP request line\", level=logging.INFO):\n            self.stream.write(b\"asdf\\r\\n\\r\\n\")\n            # TODO: need an async version of ExpectLog so we don't need\n            # hard-coded timeouts here.\n            self.io_loop.add_timeout(datetime.timedelta(seconds=0.05), self.stop)\n            self.wait()", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Tests that the HTTP server logs an info-level message when receiving a malformed HTTP request line, ensuring proper detection and logging of invalid requests during testing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_malformed_headers", "line_number": 501, "body": "def test_malformed_headers(self):\n        with ExpectLog(\n            gen_log,\n            \".*Malformed HTTP message.*no colon in header line\",\n            level=logging.INFO,\n        ):\n            self.stream.write(b\"GET / HTTP/1.0\\r\\nasdf\\r\\n\\r\\n\")\n            self.io_loop.add_timeout(datetime.timedelta(seconds=0.05), self.stop)\n            self.wait()", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Tests the HTTP server's handling and logging of malformed HTTP headers without a colon, ensuring it correctly detects and records this protocol violation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_chunked_request_body", "line_number": 511, "body": "def test_chunked_request_body(self):\n        # Chunked requests are not widely supported and we don't have a way\n        # to generate them in AsyncHTTPClient, but HTTPServer will read them.\n        self.stream.write(\n            b\"\"\"\\\nPOST /echo HTTP/1.1\nTransfer-Encoding: chunked\nContent-Type: application/x-www-form-urlencoded\n\n4\nfoo=\n3\nbar\n0\n\n\"\"\".replace(\n                b\"\\n\", b\"\\r\\n\"\n            )\n        )\n        start_line, headers, response = self.io_loop.run_sync(\n            lambda: read_stream_body(self.stream)\n        )\n        self.assertEqual(json_decode(response), {u\"foo\": [u\"bar\"]})", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Tests that the HTTP server correctly handles and parses chunked transfer encoding in POST request bodies, ensuring proper processing of data sent in chunks despite limited client support."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_chunked_request_uppercase", "line_number": 535, "body": "def test_chunked_request_uppercase(self):\n        # As per RFC 2616 section 3.6, \"Transfer-Encoding\" header's value is\n        # case-insensitive.\n        self.stream.write(\n            b\"\"\"\\\nPOST /echo HTTP/1.1\nTransfer-Encoding: Chunked\nContent-Type: application/x-www-form-urlencoded\n\n4\nfoo=\n3\nbar\n0\n\n\"\"\".replace(\n                b\"\\n\", b\"\\r\\n\"\n            )\n        )\n        start_line, headers, response = self.io_loop.run_sync(\n            lambda: read_stream_body(self.stream)\n        )\n        self.assertEqual(json_decode(response), {u\"foo\": [u\"bar\"]})", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Tests that the HTTP server correctly handles chunked transfer encoding with case-insensitive \"Transfer-Encoding\" header values, ensuring proper request processing and response decoding."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_invalid_content_length", "line_number": 560, "body": "def test_invalid_content_length(self):\n        with ExpectLog(\n            gen_log, \".*Only integer Content-Length is allowed\", level=logging.INFO\n        ):\n            self.stream.write(\n                b\"\"\"\\\nPOST /echo HTTP/1.1\nContent-Length: foo\n\nbar\n\n\"\"\".replace(\n                    b\"\\n\", b\"\\r\\n\"\n                )\n            )\n            yield self.stream.read_until_close()", "is_method": true, "class_name": "HTTPServerRawTest", "function_description": "Core test method of HTTPServerRawTest that verifies the server correctly logs an error when the Content-Length header contains a non-integer value, ensuring robust handling of invalid HTTP headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 589, "body": "def get_httpserver_options(self):\n        return dict(xheaders=True, trusted_downstream=[\"5.5.5.5\"])", "is_method": true, "class_name": "XHeaderTest", "function_description": "Provides configured HTTP server options including enabling xheaders and specifying trusted downstream IPs for use in server setup or testing scenarios within XHeaderTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_ip_headers", "line_number": 592, "body": "def test_ip_headers(self):\n        self.assertEqual(self.fetch_json(\"/\")[\"remote_ip\"], \"127.0.0.1\")\n\n        valid_ipv4 = {\"X-Real-IP\": \"4.4.4.4\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=valid_ipv4)[\"remote_ip\"], \"4.4.4.4\"\n        )\n\n        valid_ipv4_list = {\"X-Forwarded-For\": \"127.0.0.1, 4.4.4.4\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=valid_ipv4_list)[\"remote_ip\"], \"4.4.4.4\"\n        )\n\n        valid_ipv6 = {\"X-Real-IP\": \"2620:0:1cfe:face:b00c::3\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=valid_ipv6)[\"remote_ip\"],\n            \"2620:0:1cfe:face:b00c::3\",\n        )\n\n        valid_ipv6_list = {\"X-Forwarded-For\": \"::1, 2620:0:1cfe:face:b00c::3\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=valid_ipv6_list)[\"remote_ip\"],\n            \"2620:0:1cfe:face:b00c::3\",\n        )\n\n        invalid_chars = {\"X-Real-IP\": \"4.4.4.4<script>\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=invalid_chars)[\"remote_ip\"], \"127.0.0.1\"\n        )\n\n        invalid_chars_list = {\"X-Forwarded-For\": \"4.4.4.4, 5.5.5.5<script>\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=invalid_chars_list)[\"remote_ip\"], \"127.0.0.1\"\n        )\n\n        invalid_host = {\"X-Real-IP\": \"www.google.com\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=invalid_host)[\"remote_ip\"], \"127.0.0.1\"\n        )", "is_method": true, "class_name": "XHeaderTest", "function_description": "Unit test method in XHeaderTest that verifies correct extraction and validation of client IP addresses from various HTTP header scenarios, ensuring proper handling of valid, multiple, and malicious IP inputs."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_trusted_downstream", "line_number": 632, "body": "def test_trusted_downstream(self):\n        valid_ipv4_list = {\"X-Forwarded-For\": \"127.0.0.1, 4.4.4.4, 5.5.5.5\"}\n        resp = self.fetch(\"/\", headers=valid_ipv4_list)\n        if resp.headers[\"request-version\"].startswith(\"HTTP/2\"):\n            # This is a hack - there's nothing that fundamentally requires http/1\n            # here but tornado_http2 doesn't support it yet.\n            self.skipTest(\"requires HTTP/1.x\")\n        result = json_decode(resp.body)\n        self.assertEqual(result[\"remote_ip\"], \"4.4.4.4\")", "is_method": true, "class_name": "XHeaderTest", "function_description": "Tests that the system correctly identifies the trusted downstream client IP from the X-Forwarded-For header in HTTP requests, ensuring proper handling of proxy-forwarded addresses. It validates IP extraction behavior under HTTP/1.x protocol conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_scheme_headers", "line_number": 642, "body": "def test_scheme_headers(self):\n        self.assertEqual(self.fetch_json(\"/\")[\"remote_protocol\"], \"http\")\n\n        https_scheme = {\"X-Scheme\": \"https\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=https_scheme)[\"remote_protocol\"], \"https\"\n        )\n\n        https_forwarded = {\"X-Forwarded-Proto\": \"https\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=https_forwarded)[\"remote_protocol\"], \"https\"\n        )\n\n        https_multi_forwarded = {\"X-Forwarded-Proto\": \"https , http\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=https_multi_forwarded)[\"remote_protocol\"],\n            \"http\",\n        )\n\n        http_multi_forwarded = {\"X-Forwarded-Proto\": \"http,https\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=http_multi_forwarded)[\"remote_protocol\"],\n            \"https\",\n        )\n\n        bad_forwarded = {\"X-Forwarded-Proto\": \"unknown\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=bad_forwarded)[\"remote_protocol\"], \"http\"\n        )", "is_method": true, "class_name": "XHeaderTest", "function_description": "Tests how different HTTP header schemes are interpreted to determine the remote protocol, ensuring the correct protocol value is returned based on various header configurations. This aids in validating request scheme detection logic in web applications."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 674, "body": "def get_app(self):\n        return Application([(\"/\", XHeaderTest.Handler)])", "is_method": true, "class_name": "SSLXHeaderTest", "function_description": "Returns a configured web application instance with a specific request handler, enabling the setup of a test server environment for SSL X-Header processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 677, "body": "def get_httpserver_options(self):\n        output = super().get_httpserver_options()\n        output[\"xheaders\"] = True\n        return output", "is_method": true, "class_name": "SSLXHeaderTest", "function_description": "Returns HTTP server configuration options with extended header support enabled, facilitating trusted handling of proxy headers within the SSLXHeaderTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_request_without_xprotocol", "line_number": 682, "body": "def test_request_without_xprotocol(self):\n        self.assertEqual(self.fetch_json(\"/\")[\"remote_protocol\"], \"https\")\n\n        http_scheme = {\"X-Scheme\": \"http\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=http_scheme)[\"remote_protocol\"], \"http\"\n        )\n\n        bad_scheme = {\"X-Scheme\": \"unknown\"}\n        self.assertEqual(\n            self.fetch_json(\"/\", headers=bad_scheme)[\"remote_protocol\"], \"https\"\n        )", "is_method": true, "class_name": "SSLXHeaderTest", "function_description": "Tests how the SSLXHeaderTest class's request handler interprets different X-Scheme headers, verifying that it correctly identifies the remote protocol as HTTP, HTTPS, or defaults appropriately."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 701, "body": "def get_httpserver_options(self):\n        return dict(protocol=\"https\")", "is_method": true, "class_name": "ManualProtocolTest", "function_description": "Returns HTTP server configuration options specifying the use of the HTTPS protocol, facilitating secure communication setup in the ManualProtocolTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_manual_protocol", "line_number": 704, "body": "def test_manual_protocol(self):\n        self.assertEqual(self.fetch_json(\"/\")[\"protocol\"], \"https\")", "is_method": true, "class_name": "ManualProtocolTest", "function_description": "Unit test in ManualProtocolTest class that verifies the fetched JSON response from the root endpoint uses the HTTPS protocol. It ensures the system correctly enforces or returns a secure protocol indicator."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "setUp", "line_number": 723, "body": "def setUp(self):\n        super().setUp()\n        self.tmpdir = tempfile.mkdtemp()\n        self.sockfile = os.path.join(self.tmpdir, \"test.sock\")\n        sock = netutil.bind_unix_socket(self.sockfile)\n        app = Application([(\"/hello\", HelloWorldRequestHandler)])\n        self.server = HTTPServer(app)\n        self.server.add_socket(sock)\n        self.stream = IOStream(socket.socket(socket.AF_UNIX))\n        self.io_loop.run_sync(lambda: self.stream.connect(self.sockfile))", "is_method": true, "class_name": "UnixSocketTest", "function_description": "Initializes a temporary Unix socket HTTP server and connects a client IOStream to it, setting up the test environment for Unix socket communication in the UnixSocketTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "tearDown", "line_number": 734, "body": "def tearDown(self):\n        self.stream.close()\n        self.io_loop.run_sync(self.server.close_all_connections)\n        self.server.stop()\n        shutil.rmtree(self.tmpdir)\n        super().tearDown()", "is_method": true, "class_name": "UnixSocketTest", "function_description": "Cleans up resources after a test by closing streams, stopping the server, removing temporary files, and performing superclass teardown operations. It ensures a clean state following UnixSocketTest executions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_unix_socket", "line_number": 742, "body": "def test_unix_socket(self):\n        self.stream.write(b\"GET /hello HTTP/1.0\\r\\n\\r\\n\")\n        response = yield self.stream.read_until(b\"\\r\\n\")\n        self.assertEqual(response, b\"HTTP/1.1 200 OK\\r\\n\")\n        header_data = yield self.stream.read_until(b\"\\r\\n\\r\\n\")\n        headers = HTTPHeaders.parse(header_data.decode(\"latin1\"))\n        body = yield self.stream.read_bytes(int(headers[\"Content-Length\"]))\n        self.assertEqual(body, b\"Hello world\")", "is_method": true, "class_name": "UnixSocketTest", "function_description": "Tests a Unix socket connection by sending an HTTP request and verifying the response status, headers, and body content. It ensures correct communication and data exchange through the socket stream."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_unix_socket_bad_request", "line_number": 752, "body": "def test_unix_socket_bad_request(self):\n        # Unix sockets don't have remote addresses so they just return an\n        # empty string.\n        with ExpectLog(gen_log, \"Malformed HTTP message from\"):\n            self.stream.write(b\"garbage\\r\\n\\r\\n\")\n            response = yield self.stream.read_until_close()\n        self.assertEqual(response, b\"HTTP/1.1 400 Bad Request\\r\\n\\r\\n\")", "is_method": true, "class_name": "UnixSocketTest", "function_description": "Tests handling of malformed HTTP requests over Unix sockets, ensuring the system responds with a 400 Bad Request despite the absence of remote addresses. Useful for validating Unix socket HTTP server robustness against bad input."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 768, "body": "def get_app(self):\n        class HelloHandler(RequestHandler):\n            def get(self):\n                self.finish(\"Hello world\")\n\n            def post(self):\n                self.finish(\"Hello world\")\n\n        class LargeHandler(RequestHandler):\n            def get(self):\n                # 512KB should be bigger than the socket buffers so it will\n                # be written out in chunks.\n                self.write(\"\".join(chr(i % 256) * 1024 for i in range(512)))\n\n        class TransferEncodingChunkedHandler(RequestHandler):\n            @gen.coroutine\n            def head(self):\n                self.write(\"Hello world\")\n                yield self.flush()\n\n        class FinishOnCloseHandler(RequestHandler):\n            def initialize(self, cleanup_event):\n                self.cleanup_event = cleanup_event\n\n            @gen.coroutine\n            def get(self):\n                self.flush()\n                yield self.cleanup_event.wait()\n\n            def on_connection_close(self):\n                # This is not very realistic, but finishing the request\n                # from the close callback has the right timing to mimic\n                # some errors seen in the wild.\n                self.finish(\"closed\")\n\n        self.cleanup_event = Event()\n        return Application(\n            [\n                (\"/\", HelloHandler),\n                (\"/large\", LargeHandler),\n                (\"/chunked\", TransferEncodingChunkedHandler),\n                (\n                    \"/finish_on_close\",\n                    FinishOnCloseHandler,\n                    dict(cleanup_event=self.cleanup_event),\n                ),\n            ]\n        )", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Creates and returns a web application with multiple request handlers designed to test HTTP keep-alive and connection behaviors. It provides endpoints that respond with simple messages, large data, chunked transfer encoding, and connection-close handling for server testing purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "setUp", "line_number": 817, "body": "def setUp(self):\n        super().setUp()\n        self.http_version = b\"HTTP/1.1\"", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Initializes the test environment by calling the parent setup and setting the HTTP version to HTTP/1.1, preparing the KeepAliveTest for HTTP-related test cases."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "tearDown", "line_number": 821, "body": "def tearDown(self):\n        # We just closed the client side of the socket; let the IOLoop run\n        # once to make sure the server side got the message.\n        self.io_loop.add_timeout(datetime.timedelta(seconds=0.001), self.stop)\n        self.wait()\n\n        if hasattr(self, \"stream\"):\n            self.stream.close()\n        super().tearDown()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Cleans up resources and closes network streams after a test runs, ensuring proper shutdown and preventing resource leaks in the KeepAliveTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "connect", "line_number": 833, "body": "def connect(self):\n        self.stream = IOStream(socket.socket())\n        yield self.stream.connect((\"127.0.0.1\", self.get_http_port()))", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Method in KeepAliveTest that establishes a network connection to a local server on the configured HTTP port, initiating communication through a new IO stream."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "read_headers", "line_number": 838, "body": "def read_headers(self):\n        first_line = yield self.stream.read_until(b\"\\r\\n\")\n        self.assertTrue(first_line.startswith(b\"HTTP/1.1 200\"), first_line)\n        header_bytes = yield self.stream.read_until(b\"\\r\\n\\r\\n\")\n        headers = HTTPHeaders.parse(header_bytes.decode(\"latin1\"))\n        raise gen.Return(headers)", "is_method": true, "class_name": "KeepAliveTest", "function_description": "This method reads and validates HTTP response headers from a stream, returning them as a parsed header object. It is useful for asynchronously processing HTTP responses within the KeepAliveTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "read_response", "line_number": 846, "body": "def read_response(self):\n        self.headers = yield self.read_headers()\n        body = yield self.stream.read_bytes(int(self.headers[\"Content-Length\"]))\n        self.assertEqual(b\"Hello world\", body)", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Method of KeepAliveTest that reads HTTP headers and body from a response, verifying the body matches the expected \"Hello world\" content. It supports testing of response handling and content validation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "close", "line_number": 851, "body": "def close(self):\n        self.stream.close()\n        del self.stream", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Core method of the KeepAliveTest class that safely closes and deletes the associated stream resource, helping manage connection lifecycles and resource cleanup."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_two_requests", "line_number": 856, "body": "def test_two_requests(self):\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.stream.write(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Simulates making two consecutive HTTP GET requests over a single connection to test if the server correctly supports persistent (keep-alive) connections. Useful for verifying connection reuse behavior in HTTP servers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_request_close", "line_number": 865, "body": "def test_request_close(self):\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\")\n        yield self.read_response()\n        data = yield self.stream.read_until_close()\n        self.assertTrue(not data)\n        self.assertEqual(self.headers[\"Connection\"], \"close\")\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Method of KeepAliveTest that verifies if a connection correctly closes after a HTTP request with a 'Connection: close' header, ensuring no further data is received and the connection is properly terminated."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_http10", "line_number": 876, "body": "def test_http10(self):\n        self.http_version = b\"HTTP/1.0\"\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n        yield self.read_response()\n        data = yield self.stream.read_until_close()\n        self.assertTrue(not data)\n        self.assertTrue(\"Connection\" not in self.headers)\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Core utility method of the KeepAliveTest class that verifies server behavior for HTTP/1.0 requests, ensuring no persistent connection is maintained and the response has no connection headers."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_http10_keepalive", "line_number": 887, "body": "def test_http10_keepalive(self):\n        self.http_version = b\"HTTP/1.0\"\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.0\\r\\nConnection: keep-alive\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.stream.write(b\"GET / HTTP/1.0\\r\\nConnection: keep-alive\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Tests that an HTTP/1.0 connection correctly supports the 'keep-alive' header by sending multiple requests over the same connection and verifying persistent connection behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_http10_keepalive_extra_crlf", "line_number": 899, "body": "def test_http10_keepalive_extra_crlf(self):\n        self.http_version = b\"HTTP/1.0\"\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.0\\r\\nConnection: keep-alive\\r\\n\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.stream.write(b\"GET / HTTP/1.0\\r\\nConnection: keep-alive\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Tests the handling of HTTP/1.0 persistent connections with extra CRLF characters, ensuring the server correctly maintains keep-alive behavior across multiple requests."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_pipelined_requests", "line_number": 911, "body": "def test_pipelined_requests(self):\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.1\\r\\n\\r\\nGET / HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_response()\n        yield self.read_response()\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Tests handling of multiple HTTP pipelined requests by sending two GET requests in sequence and reading their responses, verifying the server\u2019s ability to process them correctly within a single connection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_pipelined_cancel", "line_number": 919, "body": "def test_pipelined_cancel(self):\n        yield self.connect()\n        self.stream.write(b\"GET / HTTP/1.1\\r\\n\\r\\nGET / HTTP/1.1\\r\\n\\r\\n\")\n        # only read once\n        yield self.read_response()\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Test method in KeepAliveTest that simulates sending pipelined HTTP requests, reads one response, and closes the connection to verify proper handling of request cancellation in a keep-alive scenario."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_cancel_during_download", "line_number": 927, "body": "def test_cancel_during_download(self):\n        yield self.connect()\n        self.stream.write(b\"GET /large HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_headers()\n        yield self.stream.read_bytes(1024)\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Simulates initiating and then canceling a large download request to test connection handling and resource cleanup in the KeepAliveTest class. Useful for validating proper cancellation behavior during data transfer."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_finish_while_closed", "line_number": 935, "body": "def test_finish_while_closed(self):\n        yield self.connect()\n        self.stream.write(b\"GET /finish_on_close HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_headers()\n        self.close()\n        # Let the hanging coroutine clean up after itself\n        self.cleanup_event.set()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "This test method checks the behavior of finishing a connection while it is closed, ensuring proper cleanup of resources in the KeepAliveTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_keepalive_chunked", "line_number": 944, "body": "def test_keepalive_chunked(self):\n        self.http_version = b\"HTTP/1.0\"\n        yield self.connect()\n        self.stream.write(\n            b\"POST / HTTP/1.0\\r\\n\"\n            b\"Connection: keep-alive\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.stream.write(b\"GET / HTTP/1.0\\r\\nConnection: keep-alive\\r\\n\\r\\n\")\n        yield self.read_response()\n        self.assertEqual(self.headers[\"Connection\"], \"Keep-Alive\")\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Tests that HTTP/1.0 connections with 'keep-alive' and chunked encoding correctly maintain persistent connections across multiple requests. It validates the handling of keep-alive behavior in an HTTP communication context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_keepalive_chunked_head_no_body", "line_number": 963, "body": "def test_keepalive_chunked_head_no_body(self):\n        yield self.connect()\n        self.stream.write(b\"HEAD /chunked HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_headers()\n\n        self.stream.write(b\"HEAD /chunked HTTP/1.1\\r\\n\\r\\n\")\n        yield self.read_headers()\n        self.close()", "is_method": true, "class_name": "KeepAliveTest", "function_description": "Tests repeated HTTP HEAD requests with chunked transfer encoding to verify connection persistence and correct header handling in the KeepAliveTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 974, "body": "def get_app(self):\n        return Application([(\"/\", EchoHandler)])", "is_method": true, "class_name": "GzipBaseTest", "function_description": "Provides a web application instance configured with a single route linked to the EchoHandler. This method supports creating testable app environments in the GzipBaseTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post_gzip", "line_number": 977, "body": "def post_gzip(self, body):\n        bytesio = BytesIO()\n        gzip_file = gzip.GzipFile(mode=\"w\", fileobj=bytesio)\n        gzip_file.write(utf8(body))\n        gzip_file.close()\n        compressed_body = bytesio.getvalue()\n        return self.fetch(\n            \"/\",\n            method=\"POST\",\n            body=compressed_body,\n            headers={\"Content-Encoding\": \"gzip\"},\n        )", "is_method": true, "class_name": "GzipBaseTest", "function_description": "This method sends an HTTP POST request with the input data compressed using gzip encoding. It enables efficient transmission of large payloads by automatically applying gzip compression before sending."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_uncompressed", "line_number": 990, "body": "def test_uncompressed(self):\n        response = self.fetch(\"/\", method=\"POST\", body=\"foo=bar\")\n        self.assertEqual(json_decode(response.body), {u\"foo\": [u\"bar\"]})", "is_method": true, "class_name": "GzipBaseTest", "function_description": "Tests that sending an uncompressed POST request returns the expected JSON-decoded response, verifying correct handling of standard form data without gzip compression."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 996, "body": "def get_httpserver_options(self):\n        return dict(decompress_request=True)", "is_method": true, "class_name": "GzipTest", "function_description": "Returns HTTP server options enabling automatic decompression of incoming requests, facilitating handling of compressed HTTP data within the GzipTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_gzip", "line_number": 999, "body": "def test_gzip(self):\n        response = self.post_gzip(\"foo=bar\")\n        self.assertEqual(json_decode(response.body), {u\"foo\": [u\"bar\"]})", "is_method": true, "class_name": "GzipTest", "function_description": "Test method in GzipTest that verifies if posting gzip-compressed data correctly returns the expected JSON-decoded response. It ensures gzip handling and data decoding work as intended."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_gzip_unsupported", "line_number": 1005, "body": "def test_gzip_unsupported(self):\n        # Gzip support is opt-in; without it the server fails to parse\n        # the body (but parsing form bodies is currently just a log message,\n        # not a fatal error).\n        with ExpectLog(gen_log, \"Unsupported Content-Encoding\"):\n            response = self.post_gzip(\"foo=bar\")\n        self.assertEqual(json_decode(response.body), {})", "is_method": true, "class_name": "GzipUnsupportedTest", "function_description": "Tests that a server correctly logs an unsupported gzip encoding warning and returns an empty response when gzip support is not enabled. Useful for validating server behavior with unsupported content encodings."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_http_client", "line_number": 1019, "body": "def get_http_client(self):\n        # body_producer doesn't work on curl_httpclient, so override the\n        # configured AsyncHTTPClient implementation.\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Returns a specialized HTTP client instance that bypasses known compatibility issues with certain asynchronous clients, ensuring reliable HTTP request handling in streaming contexts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 1024, "body": "def get_httpserver_options(self):\n        return dict(chunk_size=self.CHUNK_SIZE, decompress_request=True)", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Returns HTTP server configuration options including chunk size and request decompression settings, supporting customizable streaming behavior for the StreamingChunkSizeTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 1046, "body": "def get_app(self):\n        class App(HTTPServerConnectionDelegate):\n            def start_request(self, server_conn, request_conn):\n                return StreamingChunkSizeTest.MessageDelegate(request_conn)\n\n        return App()", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Provides an HTTP server connection handler that initiates requests with a specific message delegate for streaming chunk size testing purposes. It facilitates controlled handling of incoming HTTP requests within the StreamingChunkSizeTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "fetch_chunk_sizes", "line_number": 1053, "body": "def fetch_chunk_sizes(self, **kwargs):\n        response = self.fetch(\"/\", method=\"POST\", **kwargs)\n        response.rethrow()\n        chunks = json_decode(response.body)\n        self.assertEqual(len(self.BODY), sum(chunks))\n        for chunk_size in chunks:\n            self.assertLessEqual(\n                chunk_size, self.CHUNK_SIZE, \"oversized chunk: \" + str(chunks)\n            )\n            self.assertGreater(chunk_size, 0, \"empty chunk: \" + str(chunks))\n        return chunks", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "This method tests and verifies the sizes of data chunks fetched from a streaming endpoint, ensuring they conform to expected size constraints and collectively match the total body size. It supports validating chunked data transfers in streaming scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "compress", "line_number": 1065, "body": "def compress(self, body):\n        bytesio = BytesIO()\n        gzfile = gzip.GzipFile(mode=\"w\", fileobj=bytesio)\n        gzfile.write(body)\n        gzfile.close()\n        compressed = bytesio.getvalue()\n        if len(compressed) >= len(body):\n            raise Exception(\"body did not shrink when compressed\")\n        return compressed", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Method of StreamingChunkSizeTest that compresses input data using gzip and ensures the compressed output is smaller than the original, raising an error if compression is ineffective."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_regular_body", "line_number": 1075, "body": "def test_regular_body(self):\n        chunks = self.fetch_chunk_sizes(body=self.BODY)\n        # Without compression we know exactly what to expect.\n        self.assertEqual([16, 16, 16, 2], chunks)", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Test method in StreamingChunkSizeTest that verifies if chunk sizes are correctly computed for a given body without compression, ensuring expected chunk segmentation during streaming."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_compressed_body", "line_number": 1080, "body": "def test_compressed_body(self):\n        self.fetch_chunk_sizes(\n            body=self.compress(self.BODY), headers={\"Content-Encoding\": \"gzip\"}\n        )", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Core test method of StreamingChunkSizeTest that verifies fetching chunk sizes when the request body is gzip-compressed, ensuring correct handling of compressed HTTP content."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_chunked_body", "line_number": 1087, "body": "def test_chunked_body(self):\n        def body_producer(write):\n            write(self.BODY[:20])\n            write(self.BODY[20:])\n\n        chunks = self.fetch_chunk_sizes(body_producer=body_producer)\n        # HTTP chunk boundaries translate to application-visible breaks\n        self.assertEqual([16, 4, 16, 14], chunks)", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "This method tests that an HTTP body producer correctly divides data into expected chunk sizes, verifying the streaming chunking behavior of the StreamingChunkSizeTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_chunked_compressed", "line_number": 1096, "body": "def test_chunked_compressed(self):\n        compressed = self.compress(self.BODY)\n        self.assertGreater(len(compressed), 20)\n\n        def body_producer(write):\n            write(compressed[:20])\n            write(compressed[20:])\n\n        self.fetch_chunk_sizes(\n            body_producer=body_producer, headers={\"Content-Encoding\": \"gzip\"}\n        )", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Tests that compressed data can be correctly streamed in chunks, verifying compression and chunk size handling during simulated HTTP transfers with gzip encoding. It ensures data integrity across chunk boundaries for streaming operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 1110, "body": "def get_app(self):\n        return Application([(\"/\", HelloWorldRequestHandler)])", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Returns a web application instance configured with a route handler, enabling the setup of an HTTP server for handling specific request paths."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 1113, "body": "def get_httpserver_options(self):\n        return dict(max_header_size=1024)", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Provides HTTP server configuration options, specifically setting the maximum allowed header size to 1024 bytes for testing header size limits in MaxHeaderSizeTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_small_headers", "line_number": 1116, "body": "def test_small_headers(self):\n        response = self.fetch(\"/\", headers={\"X-Filler\": \"a\" * 100})\n        response.rethrow()\n        self.assertEqual(response.body, b\"Hello world\")", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Core test method of MaxHeaderSizeTest that verifies the server correctly handles small headers by ensuring the response body is \"Hello world\" when a 100-character header is sent."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_headers", "line_number": 1121, "body": "def test_large_headers(self):\n        with ExpectLog(gen_log, \"Unsatisfiable read\", required=False):\n            try:\n                self.fetch(\"/\", headers={\"X-Filler\": \"a\" * 1000}, raise_error=True)\n                self.fail(\"did not raise expected exception\")\n            except HTTPError as e:\n                # 431 is \"Request Header Fields Too Large\", defined in RFC\n                # 6585. However, many implementations just close the\n                # connection in this case, resulting in a missing response.\n                if e.response is not None:\n                    self.assertIn(e.response.code, (431, 599))", "is_method": true, "class_name": "MaxHeaderSizeTest", "function_description": "Tests the server's response to an HTTP request with exceptionally large headers, ensuring appropriate error handling for headers exceeding size limits. It verifies the system correctly flags or rejects oversized header fields."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 1136, "body": "def get_app(self):\n        return Application([(\"/\", HelloWorldRequestHandler)])", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Returns a web application instance configured with a default request handler. This method provides the foundational application setup for testing request handling in the IdleTimeoutTest context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 1139, "body": "def get_httpserver_options(self):\n        return dict(idle_connection_timeout=0.1)", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Provides HTTP server configuration options with a short idle connection timeout, useful for testing server behavior under rapid timeout conditions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "setUp", "line_number": 1142, "body": "def setUp(self):\n        super().setUp()\n        self.streams = []", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Initializes the test environment by calling the parent setup and preparing an empty list for stream objects. It supports test case preparation within the IdleTimeoutTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "tearDown", "line_number": 1146, "body": "def tearDown(self):\n        super().tearDown()\n        for stream in self.streams:\n            stream.close()", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Clean-up method in the IdleTimeoutTest class that ensures all associated streams are properly closed after each test, preventing resource leaks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "connect", "line_number": 1152, "body": "def connect(self):\n        stream = IOStream(socket.socket())\n        yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n        self.streams.append(stream)\n        raise gen.Return(stream)", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Establishes a non-blocking socket connection to a local server and stores the connection stream for further communication, facilitating network interaction in tests involving idle timeouts."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_unused_connection", "line_number": 1159, "body": "def test_unused_connection(self):\n        stream = yield self.connect()\n        event = Event()\n        stream.set_close_callback(event.set)\n        yield event.wait()", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Test method in IdleTimeoutTest that verifies proper handling of unused connections by waiting for a connection to close after being established."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_idle_after_use", "line_number": 1166, "body": "def test_idle_after_use(self):\n        stream = yield self.connect()\n        event = Event()\n        stream.set_close_callback(event.set)\n\n        # Use the connection twice to make sure keep-alives are working\n        for i in range(2):\n            stream.write(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n            yield stream.read_until(b\"\\r\\n\\r\\n\")\n            data = yield stream.read_bytes(11)\n            self.assertEqual(data, b\"Hello world\")\n\n        # Now let the timeout trigger and close the connection.\n        yield event.wait()", "is_method": true, "class_name": "IdleTimeoutTest", "function_description": "Tests that an idle timeout correctly closes a connection after multiple uses and inactivity, ensuring keep-alive behavior functions as expected in the IdleTimeoutTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 1183, "body": "def get_app(self):\n        class BufferedHandler(RequestHandler):\n            def put(self):\n                self.write(str(len(self.request.body)))\n\n        @stream_request_body\n        class StreamingHandler(RequestHandler):\n            def initialize(self):\n                self.bytes_read = 0\n\n            def prepare(self):\n                conn = typing.cast(HTTP1Connection, self.request.connection)\n                if \"expected_size\" in self.request.arguments:\n                    conn.set_max_body_size(int(self.get_argument(\"expected_size\")))\n                if \"body_timeout\" in self.request.arguments:\n                    conn.set_body_timeout(float(self.get_argument(\"body_timeout\")))\n\n            def data_received(self, data):\n                self.bytes_read += len(data)\n\n            def put(self):\n                self.write(str(self.bytes_read))\n\n        return Application(\n            [(\"/buffered\", BufferedHandler), (\"/streaming\", StreamingHandler)]\n        )", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Provides a Tornado web application with two endpoints to test request body handling: one buffers the entire body to report its length, while the other streams the body to track and report the amount of data received during upload."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_httpserver_options", "line_number": 1210, "body": "def get_httpserver_options(self):\n        return dict(body_timeout=3600, max_body_size=4096)", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Returns HTTP server configuration options specifying maximum request body size and timeout limits for handling incoming request bodies."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_http_client", "line_number": 1213, "body": "def get_http_client(self):\n        # body_producer doesn't work on curl_httpclient, so override the\n        # configured AsyncHTTPClient implementation.\n        return SimpleAsyncHTTPClient()", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Returns a specific HTTP client instance overriding the default to ensure compatibility with body producers in HTTP requests. This method provides a tailored HTTP client for network operations within BodyLimitsTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_small_body", "line_number": 1218, "body": "def test_small_body(self):\n        response = self.fetch(\"/buffered\", method=\"PUT\", body=b\"a\" * 4096)\n        self.assertEqual(response.body, b\"4096\")\n        response = self.fetch(\"/streaming\", method=\"PUT\", body=b\"a\" * 4096)\n        self.assertEqual(response.body, b\"4096\")", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Test method in BodyLimitsTest that verifies handling of 4KB request bodies on two endpoints, ensuring the server correctly processes and responds with the expected body size."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_buffered", "line_number": 1224, "body": "def test_large_body_buffered(self):\n        with ExpectLog(gen_log, \".*Content-Length too long\", level=logging.INFO):\n            response = self.fetch(\"/buffered\", method=\"PUT\", body=b\"a\" * 10240)\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Test method in BodyLimitsTest that verifies the server correctly rejects buffered PUT requests with bodies exceeding size limits by asserting a 400 response and appropriate log message."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_buffered_chunked", "line_number": 1230, "body": "def test_large_body_buffered_chunked(self):\n        # This test is flaky on windows for unknown reasons.\n        with ExpectLog(gen_log, \".*chunked body too large\", level=logging.INFO):\n            response = self.fetch(\n                \"/buffered\",\n                method=\"PUT\",\n                body_producer=lambda write: write(b\"a\" * 10240),\n            )\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Tests that a buffered, chunked request body exceeding size limits correctly triggers a \"body too large\" error response, ensuring server-side body size enforcement."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_streaming", "line_number": 1240, "body": "def test_large_body_streaming(self):\n        with ExpectLog(gen_log, \".*Content-Length too long\", level=logging.INFO):\n            response = self.fetch(\"/streaming\", method=\"PUT\", body=b\"a\" * 10240)\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "This test method verifies that the server correctly rejects HTTP requests with excessively large bodies by expecting a specific log message and a 400 error response. It ensures the BodyLimitsTest class enforces body size limits during streaming uploads."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_streaming_chunked", "line_number": 1246, "body": "def test_large_body_streaming_chunked(self):\n        with ExpectLog(gen_log, \".*chunked body too large\", level=logging.INFO):\n            response = self.fetch(\n                \"/streaming\",\n                method=\"PUT\",\n                body_producer=lambda write: write(b\"a\" * 10240),\n            )\n        self.assertEqual(response.code, 400)", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Core test method in BodyLimitsTest that verifies the server correctly handles and rejects overly large chunked streaming request bodies, ensuring proper enforcement of body size limits with an expected error response."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_streaming_override", "line_number": 1255, "body": "def test_large_body_streaming_override(self):\n        response = self.fetch(\n            \"/streaming?expected_size=10240\", method=\"PUT\", body=b\"a\" * 10240\n        )\n        self.assertEqual(response.body, b\"10240\")", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Test method in BodyLimitsTest verifying that a 10KB request body is correctly handled and the server responds with the expected size confirmation. It ensures the system supports streaming large request bodies without errors."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_large_body_streaming_chunked_override", "line_number": 1261, "body": "def test_large_body_streaming_chunked_override(self):\n        response = self.fetch(\n            \"/streaming?expected_size=10240\",\n            method=\"PUT\",\n            body_producer=lambda write: write(b\"a\" * 10240),\n        )\n        self.assertEqual(response.body, b\"10240\")", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "A test method in BodyLimitsTest that verifies handling of large streaming request bodies by sending a 10KB payload and asserting the server processes it correctly. It ensures chunked body streaming overrides work as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_timeout", "line_number": 1270, "body": "def test_timeout(self):\n        stream = IOStream(socket.socket())\n        try:\n            yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n            # Use a raw stream because AsyncHTTPClient won't let us read a\n            # response without finishing a body.\n            stream.write(\n                b\"PUT /streaming?body_timeout=0.1 HTTP/1.0\\r\\n\"\n                b\"Content-Length: 42\\r\\n\\r\\n\"\n            )\n            with ExpectLog(gen_log, \"Timeout reading body\", level=logging.INFO):\n                response = yield stream.read_until_close()\n            self.assertEqual(response, b\"\")\n        finally:\n            stream.close()", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "Provides a test to verify that a streaming HTTP connection correctly times out when reading the response body exceeds a specified short timeout. It ensures proper handling of body read timeouts in network streams."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_body_size_override_reset", "line_number": 1287, "body": "def test_body_size_override_reset(self):\n        # The max_body_size override is reset between requests.\n        stream = IOStream(socket.socket())\n        try:\n            yield stream.connect((\"127.0.0.1\", self.get_http_port()))\n            # Use a raw stream so we can make sure it's all on one connection.\n            stream.write(\n                b\"PUT /streaming?expected_size=10240 HTTP/1.1\\r\\n\"\n                b\"Content-Length: 10240\\r\\n\\r\\n\"\n            )\n            stream.write(b\"a\" * 10240)\n            start_line, headers, response = yield read_stream_body(stream)\n            self.assertEqual(response, b\"10240\")\n            # Without the ?expected_size parameter, we get the old default value\n            stream.write(\n                b\"PUT /streaming HTTP/1.1\\r\\n\" b\"Content-Length: 10240\\r\\n\\r\\n\"\n            )\n            with ExpectLog(gen_log, \".*Content-Length too long\", level=logging.INFO):\n                data = yield stream.read_until_close()\n            self.assertEqual(data, b\"HTTP/1.1 400 Bad Request\\r\\n\\r\\n\")\n        finally:\n            stream.close()", "is_method": true, "class_name": "BodyLimitsTest", "function_description": "This test method verifies that the maximum allowed HTTP request body size override is correctly reset between requests, ensuring proper enforcement of size limits across multiple connections. It is useful for validating server-side request size handling behavior."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get_app", "line_number": 1312, "body": "def get_app(self):\n        # The old request_callback interface does not implement the\n        # delegate interface, and writes its response via request.write\n        # instead of request.connection.write_headers.\n        def handle_request(request):\n            self.http1 = request.version.startswith(\"HTTP/1.\")\n            if not self.http1:\n                # This test will be skipped if we're using HTTP/2,\n                # so just close it out cleanly using the modern interface.\n                request.connection.write_headers(\n                    ResponseStartLine(\"\", 200, \"OK\"), HTTPHeaders()\n                )\n                request.connection.finish()\n                return\n            message = b\"Hello world\"\n            request.connection.write(\n                utf8(\"HTTP/1.1 200 OK\\r\\n\" \"Content-Length: %d\\r\\n\\r\\n\" % len(message))\n            )\n            request.connection.write(message)\n            request.connection.finish()\n\n        return handle_request", "is_method": true, "class_name": "LegacyInterfaceTest", "function_description": "Provides a request handler that simulates legacy HTTP/1.x response behavior by manually writing headers and body, supporting tests for backward compatibility with older request interfaces."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "test_legacy_interface", "line_number": 1335, "body": "def test_legacy_interface(self):\n        response = self.fetch(\"/\")\n        if not self.http1:\n            self.skipTest(\"requires HTTP/1.x\")\n        self.assertEqual(response.body, b\"Hello world\")", "is_method": true, "class_name": "LegacyInterfaceTest", "function_description": "Tests that the legacy interface responds with \"Hello world\" over HTTP/1.x, skipping the test if the HTTP version is unsupported. It ensures backward compatibility of the interface in LegacyInterfaceTest."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "headers_received", "line_number": 60, "body": "def headers_received(self, start_line, headers):\n            self.headers = headers\n            self.start_line = start_line", "is_method": true, "class_name": "Delegate", "function_description": "Method of Delegate that records the start line and headers received from a message or request, enabling other components to access header metadata."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "finish", "line_number": 67, "body": "def finish(self):\n            conn.detach()", "is_method": true, "class_name": "Delegate", "function_description": "Terminates or finalizes a delegate operation by detaching the associated connection, ensuring proper resource cleanup or disconnection."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 580, "body": "def get(self):\n            self.set_header(\"request-version\", self.request.version)\n            self.write(\n                dict(\n                    remote_ip=self.request.remote_ip,\n                    remote_protocol=self.request.protocol,\n                )\n            )", "is_method": true, "class_name": "Handler", "function_description": "Returns the client's IP address and protocol used in the current request, along with setting the response header to indicate the request version."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 698, "body": "def get(self):\n            self.write(dict(protocol=self.request.protocol))", "is_method": true, "class_name": "Handler", "function_description": "Returns a response containing the protocol used in the incoming request, facilitating protocol awareness in request handling."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "headers_received", "line_number": 1031, "body": "def headers_received(self, start_line, headers):\n            self.chunk_lengths = []", "is_method": true, "class_name": "MessageDelegate", "function_description": "Resets the internal chunk length tracking when HTTP headers are received, preparing the MessageDelegate to process incoming message chunks."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "data_received", "line_number": 1034, "body": "def data_received(self, chunk):\n            self.chunk_lengths.append(len(chunk))", "is_method": true, "class_name": "MessageDelegate", "function_description": "Records the length of each data chunk received, supporting tracking or analysis of incoming data sizes within the MessageDelegate class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "finish", "line_number": 1037, "body": "def finish(self):\n            response_body = utf8(json_encode(self.chunk_lengths))\n            self.connection.write_headers(\n                ResponseStartLine(\"HTTP/1.1\", 200, \"OK\"),\n                HTTPHeaders({\"Content-Length\": str(len(response_body))}),\n            )\n            self.connection.write(response_body)\n            self.connection.finish()", "is_method": true, "class_name": "MessageDelegate", "function_description": "Completes an HTTP response by sending accumulated chunk length data with appropriate headers, then finalizes the connection. It supports signaling the end of a message transfer in an HTTP communication."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "body_producer", "line_number": 1088, "body": "def body_producer(write):\n            write(self.BODY[:20])\n            write(self.BODY[20:])", "is_method": true, "class_name": "StreamingChunkSizeTest", "function_description": "Produces a data stream by writing the content of a predefined body in two sequential chunks, facilitating tests related to streaming chunk sizes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "handle_request", "line_number": 1316, "body": "def handle_request(request):\n            self.http1 = request.version.startswith(\"HTTP/1.\")\n            if not self.http1:\n                # This test will be skipped if we're using HTTP/2,\n                # so just close it out cleanly using the modern interface.\n                request.connection.write_headers(\n                    ResponseStartLine(\"\", 200, \"OK\"), HTTPHeaders()\n                )\n                request.connection.finish()\n                return\n            message = b\"Hello world\"\n            request.connection.write(\n                utf8(\"HTTP/1.1 200 OK\\r\\n\" \"Content-Length: %d\\r\\n\\r\\n\" % len(message))\n            )\n            request.connection.write(message)\n            request.connection.finish()", "is_method": true, "class_name": "LegacyInterfaceTest", "function_description": "Handles HTTP requests by sending a simple \"Hello world\" response for HTTP/1.x requests and cleanly closing HTTP/2 connections, supporting both protocols in the LegacyInterfaceTest class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 770, "body": "def get(self):\n                self.finish(\"Hello world\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Handles HTTP GET requests by responding with a simple \"Hello world\" message, typically used to verify server responsiveness or provide a basic greeting endpoint."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "post", "line_number": 773, "body": "def post(self):\n                self.finish(\"Hello world\")", "is_method": true, "class_name": "HelloHandler", "function_description": "Simple HTTP POST handler method that responds with \"Hello world\". It provides a basic endpoint response, useful for testing or confirming server availability."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 777, "body": "def get(self):\n                # 512KB should be bigger than the socket buffers so it will\n                # be written out in chunks.\n                self.write(\"\".join(chr(i % 256) * 1024 for i in range(512)))", "is_method": true, "class_name": "LargeHandler", "function_description": "Generates and writes a 512KB pattern of cyclic byte values in 1KB chunks to the output stream. This method is useful for testing data transmission or buffering behavior in large data handling scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "head", "line_number": 784, "body": "def head(self):\n                self.write(\"Hello world\")\n                yield self.flush()", "is_method": true, "class_name": "TransferEncodingChunkedHandler", "function_description": "Simple method of TransferEncodingChunkedHandler that sends a \"Hello world\" message and flushes the output, typically used to initiate or test chunked transfer encoding responses."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "initialize", "line_number": 789, "body": "def initialize(self, cleanup_event):\n                self.cleanup_event = cleanup_event", "is_method": true, "class_name": "FinishOnCloseHandler", "function_description": "Initializes the FinishOnCloseHandler with a cleanup event to be triggered when the handler finishes, allowing coordinated resource cleanup or shutdown actions."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "get", "line_number": 793, "body": "def get(self):\n                self.flush()\n                yield self.cleanup_event.wait()", "is_method": true, "class_name": "FinishOnCloseHandler", "function_description": "Utility method in FinishOnCloseHandler that flushes pending operations and yields control until a cleanup event completes, facilitating orderly shutdown or resource cleanup synchronization."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "on_connection_close", "line_number": 797, "body": "def on_connection_close(self):\n                # This is not very realistic, but finishing the request\n                # from the close callback has the right timing to mimic\n                # some errors seen in the wild.\n                self.finish(\"closed\")", "is_method": true, "class_name": "FinishOnCloseHandler", "function_description": "Handles connection close events by finalizing the request with a \"closed\" status, simulating error conditions for testing or error replication purposes."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "start_request", "line_number": 1048, "body": "def start_request(self, server_conn, request_conn):\n                return StreamingChunkSizeTest.MessageDelegate(request_conn)", "is_method": true, "class_name": "App", "function_description": "Returns a message delegate to handle streaming chunks for a given request connection, facilitating communication management between server and request in the App context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "put", "line_number": 1185, "body": "def put(self):\n                self.write(str(len(self.request.body)))", "is_method": true, "class_name": "BufferedHandler", "function_description": "Returns the length of the request body as a string in the response. This method provides a simple way to confirm the size of incoming data in a BufferedHandler context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "initialize", "line_number": 1190, "body": "def initialize(self):\n                self.bytes_read = 0", "is_method": true, "class_name": "StreamingHandler", "function_description": "Resets the byte counter to zero, preparing the streaming handler to start tracking data from the beginning. This function is useful for initializing or restarting streaming operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "prepare", "line_number": 1193, "body": "def prepare(self):\n                conn = typing.cast(HTTP1Connection, self.request.connection)\n                if \"expected_size\" in self.request.arguments:\n                    conn.set_max_body_size(int(self.get_argument(\"expected_size\")))\n                if \"body_timeout\" in self.request.arguments:\n                    conn.set_body_timeout(float(self.get_argument(\"body_timeout\")))", "is_method": true, "class_name": "StreamingHandler", "function_description": "Configures HTTP connection parameters like maximum body size and body timeout based on request arguments to manage streaming request limits dynamically."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "data_received", "line_number": 1200, "body": "def data_received(self, data):\n                self.bytes_read += len(data)", "is_method": true, "class_name": "StreamingHandler", "function_description": "Tracks the number of bytes received by incrementing a counter each time new data arrives, supporting data streaming and monitoring within the StreamingHandler class."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/httpserver_test.py", "function": "put", "line_number": 1203, "body": "def put(self):\n                self.write(str(self.bytes_read))", "is_method": true, "class_name": "StreamingHandler", "function_description": "Outputs the total number of bytes read so far, providing a way to track data consumption or streaming progress in real time."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_repr_and_str", "line_number": 24, "body": "def test_repr_and_str(self):\n        q = queues.Queue(maxsize=1)  # type: queues.Queue[None]\n        self.assertIn(hex(id(q)), repr(q))\n        self.assertNotIn(hex(id(q)), str(q))\n        q.get()\n\n        for q_str in repr(q), str(q):\n            self.assertTrue(q_str.startswith(\"<Queue\"))\n            self.assertIn(\"maxsize=1\", q_str)\n            self.assertIn(\"getters[1]\", q_str)\n            self.assertNotIn(\"putters\", q_str)\n            self.assertNotIn(\"tasks\", q_str)\n\n        q.put(None)\n        q.put(None)\n        # Now the queue is full, this putter blocks.\n        q.put(None)\n\n        for q_str in repr(q), str(q):\n            self.assertNotIn(\"getters\", q_str)\n            self.assertIn(\"putters[1]\", q_str)\n            self.assertIn(\"tasks=2\", q_str)", "is_method": true, "class_name": "QueueBasicTest", "function_description": "Tests the string and representation outputs of a Queue to verify they reflect the queue\u2019s status, including max size, waiting getters, putters, and tasks accurately during different states."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_order", "line_number": 47, "body": "def test_order(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        for i in [1, 3, 2]:\n            q.put_nowait(i)\n\n        items = [q.get_nowait() for _ in range(3)]\n        self.assertEqual([1, 3, 2], items)", "is_method": true, "class_name": "QueueBasicTest", "function_description": "Tests that the Queue class preserves insertion order when adding and retrieving items, ensuring correct queue behavior in processing sequences."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_maxsize", "line_number": 56, "body": "def test_maxsize(self):\n        self.assertRaises(TypeError, queues.Queue, maxsize=None)\n        self.assertRaises(ValueError, queues.Queue, maxsize=-1)\n\n        q = queues.Queue(maxsize=2)  # type: queues.Queue[int]\n        self.assertTrue(q.empty())\n        self.assertFalse(q.full())\n        self.assertEqual(2, q.maxsize)\n        self.assertTrue(q.put(0).done())\n        self.assertTrue(q.put(1).done())\n        self.assertFalse(q.empty())\n        self.assertTrue(q.full())\n        put2 = q.put(2)\n        self.assertFalse(put2.done())\n        self.assertEqual(0, (yield q.get()))  # Make room.\n        self.assertTrue(put2.done())\n        self.assertFalse(q.empty())\n        self.assertTrue(q.full())", "is_method": true, "class_name": "QueueBasicTest", "function_description": "Tests the behavior and constraints of a queue with a fixed maximum size, verifying correct exceptions, fullness, emptiness, and blocking behavior during put/get operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_blocking_get", "line_number": 78, "body": "def test_blocking_get(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        q.put_nowait(0)\n        self.assertEqual(0, (yield q.get()))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Test method in QueueGetTest that verifies the queue's get operation correctly retrieves an item in a blocking manner. It ensures that an item put into the queue is obtained as expected during the get call."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_nonblocking_get", "line_number": 83, "body": "def test_nonblocking_get(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        q.put_nowait(0)\n        self.assertEqual(0, q.get_nowait())", "is_method": true, "class_name": "QueueGetTest", "function_description": "A test method in QueueGetTest that verifies immediate retrieval from a queue without blocking, ensuring that an item put into the queue can be retrieved instantly with a non-blocking get operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_nonblocking_get_exception", "line_number": 88, "body": "def test_nonblocking_get_exception(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        self.assertRaises(queues.QueueEmpty, q.get_nowait)", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests that calling a non-blocking get operation on an empty Queue raises the appropriate QueueEmpty exception, ensuring correct exception handling behavior in queue operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_get_with_putters", "line_number": 93, "body": "def test_get_with_putters(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        q.put_nowait(0)\n        put = q.put(1)\n        self.assertEqual(0, (yield q.get()))\n        self.assertIsNone((yield put))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests that items placed in a queue can be retrieved in the correct order and that a put operation waiting for space completes after an item is consumed. It verifies proper synchronization between queue put and get operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_blocking_get_wait", "line_number": 101, "body": "def test_blocking_get_wait(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        q.put(0)\n        self.io_loop.call_later(0.01, q.put_nowait, 1)\n        self.io_loop.call_later(0.02, q.put_nowait, 2)\n        self.assertEqual(0, (yield q.get(timeout=timedelta(seconds=1))))\n        self.assertEqual(1, (yield q.get(timeout=timedelta(seconds=1))))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests whether a queue's blocking get method correctly waits for and retrieves items, supporting timeouts and asynchronous item insertion. It validates the queue's behavior in timed, asynchronous consumption scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_get_timeout", "line_number": 110, "body": "def test_get_timeout(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        get_timeout = q.get(timeout=timedelta(seconds=0.01))\n        get = q.get()\n        with self.assertRaises(TimeoutError):\n            yield get_timeout\n\n        q.put_nowait(0)\n        self.assertEqual(0, (yield get))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests that the queue's get method correctly handles timeout behavior, raising a TimeoutError if no item is available within the specified duration, and successfully retrieves items when present."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_get_timeout_preempted", "line_number": 121, "body": "def test_get_timeout_preempted(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        get = q.get(timeout=timedelta(seconds=0.01))\n        q.put(0)\n        yield gen.sleep(0.02)\n        self.assertEqual(0, (yield get))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Test method in QueueGetTest that verifies a queue's get operation properly preempts a timeout when an item is put shortly after the get call is initiated. It ensures correct retrieval behavior under timing constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_get_clears_timed_out_putters", "line_number": 129, "body": "def test_get_clears_timed_out_putters(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        # First putter succeeds, remainder block.\n        putters = [q.put(i, timedelta(seconds=0.01)) for i in range(10)]\n        put = q.put(10)\n        self.assertEqual(10, len(q._putters))\n        yield gen.sleep(0.02)\n        self.assertEqual(10, len(q._putters))\n        self.assertFalse(put.done())  # Final waiter is still active.\n        q.put(11)\n        self.assertEqual(0, (yield q.get()))  # get() clears the waiters.\n        self.assertEqual(1, len(q._putters))\n        for putter in putters[1:]:\n            self.assertRaises(TimeoutError, putter.result)", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests that calling get() on the Queue clears all timed-out put operations, raising TimeoutError for those expired while keeping active putters intact. This ensures proper handling of blocked putters with timeouts in queue operations."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_get_clears_timed_out_getters", "line_number": 145, "body": "def test_get_clears_timed_out_getters(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        getters = [\n            asyncio.ensure_future(q.get(timedelta(seconds=0.01))) for _ in range(10)\n        ]\n        get = asyncio.ensure_future(q.get())\n        self.assertEqual(11, len(q._getters))\n        yield gen.sleep(0.02)\n        self.assertEqual(11, len(q._getters))\n        self.assertFalse(get.done())  # Final waiter is still active.\n        q.get()  # get() clears the waiters.\n        self.assertEqual(2, len(q._getters))\n        for getter in getters:\n            self.assertRaises(TimeoutError, getter.result)", "is_method": true, "class_name": "QueueGetTest", "function_description": "Tests that the queue properly clears and times out multiple pending get requests after a short delay, ensuring timed-out getters raise TimeoutError while active getters remain unaffected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_async_for", "line_number": 161, "body": "def test_async_for(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        for i in range(5):\n            q.put(i)\n\n        async def f():\n            results = []\n            async for i in q:\n                results.append(i)\n                if i == 4:\n                    return results\n\n        results = yield f()\n        self.assertEqual(results, list(range(5)))", "is_method": true, "class_name": "QueueGetTest", "function_description": "Test method in QueueGetTest verifying that asynchronous iteration over a queue correctly yields all enqueued items in order. It ensures the queue supports async iteration for consumption."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_blocking_put", "line_number": 179, "body": "def test_blocking_put(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        q.put(0)\n        self.assertEqual(0, q.get_nowait())", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that an item can be put into the queue and retrieved immediately without blocking, verifying basic queue put and get functionality."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_nonblocking_put_exception", "line_number": 184, "body": "def test_nonblocking_put_exception(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        q.put(0)\n        self.assertRaises(queues.QueueFull, q.put_nowait, 1)", "is_method": true, "class_name": "QueuePutTest", "function_description": "Test method in QueuePutTest that verifies a non-blocking put call raises a QueueFull exception when a full queue rejects new items. It ensures correct exception handling for queue overflow scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_put_with_getters", "line_number": 190, "body": "def test_put_with_getters(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        get0 = q.get()\n        get1 = q.get()\n        yield q.put(0)\n        self.assertEqual(0, (yield get0))\n        yield q.put(1)\n        self.assertEqual(1, (yield get1))", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that values put into a queue can be retrieved correctly via multiple getter coroutines, validating the queue's asynchronous put-get behavior. It ensures that each get returns the expected value in order."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_nonblocking_put_with_getters", "line_number": 200, "body": "def test_nonblocking_put_with_getters(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        get0 = q.get()\n        get1 = q.get()\n        q.put_nowait(0)\n        # put_nowait does *not* immediately unblock getters.\n        yield gen.moment\n        self.assertEqual(0, (yield get0))\n        q.put_nowait(1)\n        yield gen.moment\n        self.assertEqual(1, (yield get1))", "is_method": true, "class_name": "QueuePutTest", "function_description": "This test method verifies that non-blocking put operations into a queue correctly unblock pending get operations in order. It ensures queue put_nowait calls deliver values to waiting getters as expected asynchronously."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_blocking_put_wait", "line_number": 213, "body": "def test_blocking_put_wait(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        q.put_nowait(0)\n\n        def get_and_discard():\n            q.get()\n\n        self.io_loop.call_later(0.01, get_and_discard)\n        self.io_loop.call_later(0.02, get_and_discard)\n        futures = [q.put(0), q.put(1)]\n        self.assertFalse(any(f.done() for f in futures))\n        yield futures", "is_method": true, "class_name": "QueuePutTest", "function_description": "Provides a test verifying that putting items into a full queue blocks until space is available, ensuring correct asynchronous queue behavior under capacity constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_put_timeout", "line_number": 227, "body": "def test_put_timeout(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        q.put_nowait(0)  # Now it's full.\n        put_timeout = q.put(1, timeout=timedelta(seconds=0.01))\n        put = q.put(2)\n        with self.assertRaises(TimeoutError):\n            yield put_timeout\n\n        self.assertEqual(0, q.get_nowait())\n        # 1 was never put in the queue.\n        self.assertEqual(2, (yield q.get()))\n\n        # Final get() unblocked this putter.\n        yield put", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that a queue's put operation respects timeout behavior by raising TimeoutError when full, ensuring items are correctly enqueued or rejected according to timing constraints. Useful for verifying queue blocking and timeout mechanics."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_put_timeout_preempted", "line_number": 243, "body": "def test_put_timeout_preempted(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        q.put_nowait(0)\n        put = q.put(1, timeout=timedelta(seconds=0.01))\n        q.get()\n        yield gen.sleep(0.02)\n        yield put", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that a put operation on a full Queue with a short timeout can be preempted by a get operation, verifying the timeout and concurrency behavior of queue insertion."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_put_clears_timed_out_putters", "line_number": 252, "body": "def test_put_clears_timed_out_putters(self):\n        q = queues.Queue(1)  # type: queues.Queue[int]\n        # First putter succeeds, remainder block.\n        putters = [q.put(i, timedelta(seconds=0.01)) for i in range(10)]\n        put = q.put(10)\n        self.assertEqual(10, len(q._putters))\n        yield gen.sleep(0.02)\n        self.assertEqual(10, len(q._putters))\n        self.assertFalse(put.done())  # Final waiter is still active.\n        q.put(11)  # put() clears the waiters.\n        self.assertEqual(2, len(q._putters))\n        for putter in putters[1:]:\n            self.assertRaises(TimeoutError, putter.result)", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that inserting items into a queue clears timed-out put operations and properly handles waiting putters. This ensures the queue manages blocked puts and timeouts correctly in concurrent scenarios."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_put_clears_timed_out_getters", "line_number": 267, "body": "def test_put_clears_timed_out_getters(self):\n        q = queues.Queue()  # type: queues.Queue[int]\n        getters = [\n            asyncio.ensure_future(q.get(timedelta(seconds=0.01))) for _ in range(10)\n        ]\n        get = asyncio.ensure_future(q.get())\n        q.get()\n        self.assertEqual(12, len(q._getters))\n        yield gen.sleep(0.02)\n        self.assertEqual(12, len(q._getters))\n        self.assertFalse(get.done())  # Final waiters still active.\n        q.put(0)  # put() clears the waiters.\n        self.assertEqual(1, len(q._getters))\n        self.assertEqual(0, (yield get))\n        for getter in getters:\n            self.assertRaises(TimeoutError, getter.result)", "is_method": true, "class_name": "QueuePutTest", "function_description": "Tests that inserting an item into a queue clears timed-out and pending getter waiters, ensuring that pending gets are properly resolved or timed out after a put operation."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_float_maxsize", "line_number": 285, "body": "def test_float_maxsize(self):\n        # If a float is passed for maxsize, a reasonable limit should\n        # be enforced, instead of being treated as unlimited.\n        # It happens to be rounded up.\n        # http://bugs.python.org/issue21723\n        q = queues.Queue(maxsize=1.3)  # type: ignore\n        self.assertTrue(q.empty())\n        self.assertFalse(q.full())\n        q.put_nowait(0)\n        q.put_nowait(1)\n        self.assertFalse(q.empty())\n        self.assertTrue(q.full())\n        self.assertRaises(queues.QueueFull, q.put_nowait, 2)\n        self.assertEqual(0, q.get_nowait())\n        self.assertFalse(q.empty())\n        self.assertFalse(q.full())\n\n        yield q.put(2)\n        put = q.put(3)\n        self.assertFalse(put.done())\n        self.assertEqual(1, (yield q.get()))\n        yield put\n        self.assertTrue(q.full())", "is_method": true, "class_name": "QueuePutTest", "function_description": "Test method in QueuePutTest that verifies how the queue handles float values for maxsize, ensuring proper capacity limits and correct behavior when adding or retrieving items under those constraints."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_task_done_underflow", "line_number": 313, "body": "def test_task_done_underflow(self):\n        q = self.queue_class()  # type: queues.Queue\n        self.assertRaises(ValueError, q.task_done)", "is_method": true, "class_name": "QueueJoinTest", "function_description": "Unit test method in QueueJoinTest that verifies a queue raises an error when task_done is called more times than tasks were added, ensuring correct task tracking in queue processing."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_task_done", "line_number": 318, "body": "def test_task_done(self):\n        q = self.queue_class()  # type: queues.Queue\n        for i in range(100):\n            q.put_nowait(i)\n\n        self.accumulator = 0\n\n        @gen.coroutine\n        def worker():\n            while True:\n                item = yield q.get()\n                self.accumulator += item\n                q.task_done()\n                yield gen.sleep(random() * 0.01)\n\n        # Two coroutines share work.\n        worker()\n        worker()\n        yield q.join()\n        self.assertEqual(sum(range(100)), self.accumulator)", "is_method": true, "class_name": "QueueJoinTest", "function_description": "Tests that multiple asynchronous workers correctly process all items in a queue and that the queue's join mechanism waits until all tasks are completed. It validates concurrent task handling and synchronization in an asynchronous queue context."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_task_done_delay", "line_number": 340, "body": "def test_task_done_delay(self):\n        # Verify it is task_done(), not get(), that unblocks join().\n        q = self.queue_class()  # type: queues.Queue\n        q.put_nowait(0)\n        join = asyncio.ensure_future(q.join())\n        self.assertFalse(join.done())\n        yield q.get()\n        self.assertFalse(join.done())\n        yield gen.moment\n        self.assertFalse(join.done())\n        q.task_done()\n        self.assertTrue(join.done())", "is_method": true, "class_name": "QueueJoinTest", "function_description": "Tests that the queue's join method only completes after task_done is called for each enqueued item, ensuring correct synchronization between task completion and join unblocking. It verifies the proper behavior of task tracking in asynchronous queues."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_join_empty_queue", "line_number": 354, "body": "def test_join_empty_queue(self):\n        q = self.queue_class()  # type: queues.Queue\n        yield q.join()\n        yield q.join()", "is_method": true, "class_name": "QueueJoinTest", "function_description": "Tests that calling join on an empty queue does not block or cause errors, verifying the queue's join method handles empty states gracefully."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_join_timeout", "line_number": 360, "body": "def test_join_timeout(self):\n        q = self.queue_class()  # type: queues.Queue\n        q.put(0)\n        with self.assertRaises(TimeoutError):\n            yield q.join(timeout=timedelta(seconds=0.01))", "is_method": true, "class_name": "QueueJoinTest", "function_description": "Tests that the queue's join method correctly raises a TimeoutError if tasks are not completed within the specified timeout period. It verifies the queue's timeout handling during task joining."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_order", "line_number": 371, "body": "def test_order(self):\n        q = self.queue_class(maxsize=2)\n        q.put_nowait((1, \"a\"))\n        q.put_nowait((0, \"b\"))\n        self.assertTrue(q.full())\n        q.put((3, \"c\"))\n        q.put((2, \"d\"))\n        self.assertEqual((0, \"b\"), q.get_nowait())\n        self.assertEqual((1, \"a\"), (yield q.get()))\n        self.assertEqual((2, \"d\"), q.get_nowait())\n        self.assertEqual((3, \"c\"), (yield q.get()))\n        self.assertTrue(q.empty())", "is_method": true, "class_name": "PriorityQueueJoinTest", "function_description": "Tests that the PriorityQueue maintains correct item ordering based on priority under various put and get operations. It verifies queue behavior including fullness, emptiness, and priority-based retrieval."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_order", "line_number": 389, "body": "def test_order(self):\n        q = self.queue_class(maxsize=2)\n        q.put_nowait(1)\n        q.put_nowait(0)\n        self.assertTrue(q.full())\n        q.put(3)\n        q.put(2)\n        self.assertEqual(3, q.get_nowait())\n        self.assertEqual(2, (yield q.get()))\n        self.assertEqual(0, q.get_nowait())\n        self.assertEqual(1, (yield q.get()))\n        self.assertTrue(q.empty())", "is_method": true, "class_name": "LifoQueueJoinTest", "function_description": "Tests that the LifoQueue implementation correctly handles insertion and retrieval order, verifying that elements are retrieved in last-in, first-out sequence and that queue size limits and empty/full states behave as expected."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "test_producer_consumer", "line_number": 405, "body": "def test_producer_consumer(self):\n        q = queues.Queue(maxsize=3)  # type: queues.Queue[int]\n        history = []\n\n        # We don't yield between get() and task_done(), so get() must wait for\n        # the next tick. Otherwise we'd immediately call task_done and unblock\n        # join() before q.put() resumes, and we'd only process the first four\n        # items.\n        @gen.coroutine\n        def consumer():\n            while True:\n                history.append((yield q.get()))\n                q.task_done()\n\n        @gen.coroutine\n        def producer():\n            for item in range(10):\n                yield q.put(item)\n\n        consumer()\n        yield producer()\n        yield q.join()\n        self.assertEqual(list(range(10)), history)", "is_method": true, "class_name": "ProducerConsumerTest", "function_description": "Core test method in ProducerConsumerTest that verifies correct coordination between asynchronous producer and consumer coroutines using a bounded queue, ensuring all produced items are consumed in order without loss or deadlock."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "get_and_discard", "line_number": 217, "body": "def get_and_discard():\n            q.get()", "is_method": true, "class_name": "QueuePutTest", "function_description": "Discards and removes a single item from the queue without returning it, useful for acknowledging or clearing items without processing them."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "consumer", "line_number": 414, "body": "def consumer():\n            while True:\n                history.append((yield q.get()))\n                q.task_done()", "is_method": true, "class_name": "ProducerConsumerTest", "function_description": "Generates an infinite consumer coroutine that retrieves items from a queue, records them in history, and signals task completion, facilitating asynchronous producer-consumer workflows."}, {"file": "./dataset/RepoExec/test-apps/tornado/tornado/test/queues_test.py", "function": "producer", "line_number": 420, "body": "def producer():\n            for item in range(10):\n                yield q.put(item)", "is_method": true, "class_name": "ProducerConsumerTest", "function_description": "Generates a sequence of items and enqueues each into a shared queue for consumption. This function facilitates producer-consumer coordination by producing data to be processed asynchronously."}]